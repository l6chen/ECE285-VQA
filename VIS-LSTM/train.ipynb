{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading QA DATA\n",
      "Reading fc7 features\n",
      "FC7 features (20000, 4096)\n",
      "image_id_list (20000,)\n",
      "5321\n",
      "WARNING:tensorflow:From /datasets/home/home-03/85/485/l6chen/lstmcnn/vis_lstm_model.py:81: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Loss 1383.0436 1 0\n",
      "Training Accuracy 0.0\n",
      "Loss 1353.3154 2 0\n",
      "Training Accuracy 0.02\n",
      "Loss 1328.1427 3 0\n",
      "Training Accuracy 0.215\n",
      "Loss 1290.4402 4 0\n",
      "Training Accuracy 0.24\n",
      "Loss 1252.0168 5 0\n",
      "Training Accuracy 0.27\n",
      "Loss 1248.9083 6 0\n",
      "Training Accuracy 0.215\n",
      "Loss 1207.8595 7 0\n",
      "Training Accuracy 0.24\n",
      "Loss 1196.8322 8 0\n",
      "Training Accuracy 0.25\n",
      "Loss 1180.639 9 0\n",
      "Training Accuracy 0.185\n",
      "Loss 1110.0977 10 0\n",
      "Training Accuracy 0.275\n",
      "Loss 1117.8469 11 0\n",
      "Training Accuracy 0.205\n",
      "Loss 1046.1879 12 0\n",
      "Training Accuracy 0.235\n",
      "Loss 983.5632 13 0\n",
      "Training Accuracy 0.305\n",
      "Loss 1042.5707 14 0\n",
      "Training Accuracy 0.18\n",
      "Loss 922.2398 15 0\n",
      "Training Accuracy 0.275\n",
      "Loss 976.3878 16 0\n",
      "Training Accuracy 0.19\n",
      "Loss 884.27594 17 0\n",
      "Training Accuracy 0.33\n",
      "Loss 901.3111 18 0\n",
      "Training Accuracy 0.265\n",
      "Loss 913.8108 19 0\n",
      "Training Accuracy 0.22\n",
      "Loss 873.7819 20 0\n",
      "Training Accuracy 0.265\n",
      "Loss 903.0915 21 0\n",
      "Training Accuracy 0.255\n",
      "Loss 886.4662 22 0\n",
      "Training Accuracy 0.215\n",
      "Loss 906.975 23 0\n",
      "Training Accuracy 0.215\n",
      "Loss 857.26874 24 0\n",
      "Training Accuracy 0.2\n",
      "Loss 808.23254 25 0\n",
      "Training Accuracy 0.19\n",
      "Loss 853.094 26 0\n",
      "Training Accuracy 0.17\n",
      "Loss 808.0058 27 0\n",
      "Training Accuracy 0.205\n",
      "Loss 843.61743 28 0\n",
      "Training Accuracy 0.155\n",
      "Loss 811.06726 29 0\n",
      "Training Accuracy 0.185\n",
      "Loss 871.87 30 0\n",
      "Training Accuracy 0.245\n",
      "Loss 852.82056 31 0\n",
      "Training Accuracy 0.235\n",
      "Loss 826.23035 32 0\n",
      "Training Accuracy 0.235\n",
      "Loss 828.7008 33 0\n",
      "Training Accuracy 0.27\n",
      "Loss 826.95325 34 0\n",
      "Training Accuracy 0.265\n",
      "Loss 757.62805 35 0\n",
      "Training Accuracy 0.245\n",
      "Loss 798.79724 36 0\n",
      "Training Accuracy 0.27\n",
      "Loss 807.98816 37 0\n",
      "Training Accuracy 0.265\n",
      "Loss 842.4114 38 0\n",
      "Training Accuracy 0.21\n",
      "Loss 740.39655 39 0\n",
      "Training Accuracy 0.31\n",
      "Loss 773.6889 40 0\n",
      "Training Accuracy 0.22\n",
      "Loss 757.0026 41 0\n",
      "Training Accuracy 0.255\n",
      "Loss 856.5727 42 0\n",
      "Training Accuracy 0.2\n",
      "Loss 812.85095 43 0\n",
      "Training Accuracy 0.25\n",
      "Loss 755.08685 44 0\n",
      "Training Accuracy 0.23\n",
      "Loss 833.803 45 0\n",
      "Training Accuracy 0.185\n",
      "Loss 822.09344 46 0\n",
      "Training Accuracy 0.22\n",
      "Loss 771.62854 47 0\n",
      "Training Accuracy 0.24\n",
      "Loss 760.91583 48 0\n",
      "Training Accuracy 0.245\n",
      "Loss 829.6173 49 0\n",
      "Training Accuracy 0.18\n",
      "Loss 778.63007 50 0\n",
      "Training Accuracy 0.19\n",
      "Loss 768.8999 51 0\n",
      "Training Accuracy 0.24\n",
      "Loss 797.6038 52 0\n",
      "Training Accuracy 0.185\n",
      "Loss 780.3792 53 0\n",
      "Training Accuracy 0.27\n",
      "Loss 778.64545 54 0\n",
      "Training Accuracy 0.22\n",
      "Loss 777.52185 55 0\n",
      "Training Accuracy 0.24\n",
      "Loss 725.81555 56 0\n",
      "Training Accuracy 0.27\n",
      "Loss 730.03784 57 0\n",
      "Training Accuracy 0.295\n",
      "Loss 710.026 58 0\n",
      "Training Accuracy 0.285\n",
      "Loss 773.9738 59 0\n",
      "Training Accuracy 0.28\n",
      "Loss 753.4679 60 0\n",
      "Training Accuracy 0.305\n",
      "Loss 762.6383 61 0\n",
      "Training Accuracy 0.23\n",
      "Loss 744.598 62 0\n",
      "Training Accuracy 0.275\n",
      "Loss 757.5141 63 0\n",
      "Training Accuracy 0.23\n",
      "Loss 798.4466 64 0\n",
      "Training Accuracy 0.235\n",
      "Loss 742.60974 65 0\n",
      "Training Accuracy 0.23\n",
      "Loss 732.8064 66 0\n",
      "Training Accuracy 0.22\n",
      "Loss 786.2405 67 0\n",
      "Training Accuracy 0.205\n",
      "Loss 750.0917 68 0\n",
      "Training Accuracy 0.21\n",
      "Loss 719.3282 69 0\n",
      "Training Accuracy 0.275\n",
      "Loss 692.09894 70 0\n",
      "Training Accuracy 0.325\n",
      "Loss 685.145 71 0\n",
      "Training Accuracy 0.28\n",
      "Loss 707.1664 72 0\n",
      "Training Accuracy 0.24\n",
      "Loss 780.7858 73 0\n",
      "Training Accuracy 0.23\n",
      "Loss 794.6027 74 0\n",
      "Training Accuracy 0.27\n",
      "Loss 728.4094 75 0\n",
      "Training Accuracy 0.265\n",
      "Loss 692.16266 76 0\n",
      "Training Accuracy 0.315\n",
      "Loss 627.78107 77 0\n",
      "Training Accuracy 0.33\n",
      "Loss 636.2309 78 0\n",
      "Training Accuracy 0.325\n",
      "Loss 598.4239 79 0\n",
      "Training Accuracy 0.33\n",
      "Loss 660.8342 80 0\n",
      "Training Accuracy 0.27\n",
      "Loss 726.8798 81 0\n",
      "Training Accuracy 0.23\n",
      "Loss 644.2766 82 0\n",
      "Training Accuracy 0.305\n",
      "Loss 667.56494 83 0\n",
      "Training Accuracy 0.395\n",
      "Loss 721.07996 84 0\n",
      "Training Accuracy 0.3\n",
      "Loss 651.23987 85 0\n",
      "Training Accuracy 0.365\n",
      "Loss 643.1868 86 0\n",
      "Training Accuracy 0.375\n",
      "Loss 699.20264 87 0\n",
      "Training Accuracy 0.28\n",
      "Loss 645.676 88 0\n",
      "Training Accuracy 0.335\n",
      "Loss 717.5792 89 0\n",
      "Training Accuracy 0.33\n",
      "Loss 673.50995 90 0\n",
      "Training Accuracy 0.33\n",
      "Loss 687.50116 91 0\n",
      "Training Accuracy 0.285\n",
      "Loss 722.715 92 0\n",
      "Training Accuracy 0.31\n",
      "Loss 641.50775 93 0\n",
      "Training Accuracy 0.355\n",
      "Loss 625.01794 94 0\n",
      "Training Accuracy 0.315\n",
      "Loss 625.7229 95 0\n",
      "Training Accuracy 0.355\n",
      "Loss 646.1712 96 0\n",
      "Training Accuracy 0.315\n",
      "Loss 665.7546 97 0\n",
      "Training Accuracy 0.34\n",
      "Loss 675.3737 98 0\n",
      "Training Accuracy 0.315\n",
      "Loss 628.7623 99 0\n",
      "Training Accuracy 0.305\n",
      "Loss 667.6272 100 0\n",
      "Training Accuracy 0.345\n",
      "Loss 685.2328 101 0\n",
      "Training Accuracy 0.25\n",
      "Loss 593.4347 102 0\n",
      "Training Accuracy 0.395\n",
      "Loss 631.9135 103 0\n",
      "Training Accuracy 0.36\n",
      "Loss 594.63043 104 0\n",
      "Training Accuracy 0.3\n",
      "Loss 686.82434 105 0\n",
      "Training Accuracy 0.3\n",
      "Loss 654.4373 106 0\n",
      "Training Accuracy 0.345\n",
      "Loss 631.1884 107 0\n",
      "Training Accuracy 0.295\n",
      "Loss 604.76605 108 0\n",
      "Training Accuracy 0.315\n",
      "Loss 624.33923 109 0\n",
      "Training Accuracy 0.35\n",
      "Loss 622.76733 110 0\n",
      "Training Accuracy 0.29\n",
      "Loss 593.8124 111 0\n",
      "Training Accuracy 0.37\n",
      "Loss 654.2682 112 0\n",
      "Training Accuracy 0.33\n",
      "Loss 646.1818 113 0\n",
      "Training Accuracy 0.33\n",
      "Loss 588.3216 114 0\n",
      "Training Accuracy 0.34\n",
      "Loss 639.3163 115 0\n",
      "Training Accuracy 0.31\n",
      "Loss 676.5491 116 0\n",
      "Training Accuracy 0.35\n",
      "Loss 580.4978 117 0\n",
      "Training Accuracy 0.37\n",
      "Loss 646.4577 118 0\n",
      "Training Accuracy 0.32\n",
      "Loss 688.31525 119 0\n",
      "Training Accuracy 0.3\n",
      "Loss 661.0012 120 0\n",
      "Training Accuracy 0.335\n",
      "Loss 671.63477 121 0\n",
      "Training Accuracy 0.29\n",
      "Loss 625.1824 122 0\n",
      "Training Accuracy 0.3\n",
      "Loss 648.2163 123 0\n",
      "Training Accuracy 0.29\n",
      "Loss 604.227 124 0\n",
      "Training Accuracy 0.33\n",
      "Loss 577.6341 125 0\n",
      "Training Accuracy 0.34\n",
      "Loss 628.90967 126 0\n",
      "Training Accuracy 0.34\n",
      "Loss 573.22473 127 0\n",
      "Training Accuracy 0.38\n",
      "Loss 606.0393 128 0\n",
      "Training Accuracy 0.305\n",
      "Loss 616.55566 129 0\n",
      "Training Accuracy 0.315\n",
      "Loss 593.4188 130 0\n",
      "Training Accuracy 0.355\n",
      "Loss 571.82947 131 0\n",
      "Training Accuracy 0.33\n",
      "Loss 588.2457 132 0\n",
      "Training Accuracy 0.315\n",
      "Loss 641.5561 133 0\n",
      "Training Accuracy 0.305\n",
      "Loss 635.6783 134 0\n",
      "Training Accuracy 0.295\n",
      "Loss 552.9535 135 0\n",
      "Training Accuracy 0.345\n",
      "Loss 652.7973 136 0\n",
      "Training Accuracy 0.275\n",
      "Loss 596.0984 137 0\n",
      "Training Accuracy 0.345\n",
      "Loss 638.43677 138 0\n",
      "Training Accuracy 0.29\n",
      "Loss 707.0968 139 0\n",
      "Training Accuracy 0.31\n",
      "Loss 644.17847 140 0\n",
      "Training Accuracy 0.325\n",
      "Loss 625.046 141 0\n",
      "Training Accuracy 0.28\n",
      "Loss 583.2276 142 0\n",
      "Training Accuracy 0.355\n",
      "Loss 566.99756 143 0\n",
      "Training Accuracy 0.34\n",
      "Loss 591.76166 144 0\n",
      "Training Accuracy 0.3\n",
      "Loss 607.89923 145 0\n",
      "Training Accuracy 0.335\n",
      "Loss 573.9921 146 0\n",
      "Training Accuracy 0.345\n",
      "Loss 606.39374 147 0\n",
      "Training Accuracy 0.36\n",
      "Loss 600.16406 148 0\n",
      "Training Accuracy 0.305\n",
      "Loss 552.90436 149 0\n",
      "Training Accuracy 0.37\n",
      "Loss 622.7597 150 0\n",
      "Training Accuracy 0.3\n",
      "Loss 619.5019 151 0\n",
      "Training Accuracy 0.35\n",
      "Loss 630.92346 152 0\n",
      "Training Accuracy 0.345\n",
      "Loss 609.2541 153 0\n",
      "Training Accuracy 0.27\n",
      "Loss 641.6102 154 0\n",
      "Training Accuracy 0.305\n",
      "Loss 571.26636 155 0\n",
      "Training Accuracy 0.33\n",
      "Loss 631.8655 156 0\n",
      "Training Accuracy 0.285\n",
      "Loss 572.1516 157 0\n",
      "Training Accuracy 0.39\n",
      "Loss 616.8996 158 0\n",
      "Training Accuracy 0.32\n",
      "Loss 668.0913 159 0\n",
      "Training Accuracy 0.305\n",
      "Loss 570.8535 160 0\n",
      "Training Accuracy 0.33\n",
      "Loss 637.13837 161 0\n",
      "Training Accuracy 0.26\n",
      "Loss 570.9118 162 0\n",
      "Training Accuracy 0.37\n",
      "Loss 602.1154 163 0\n",
      "Training Accuracy 0.32\n",
      "Loss 541.69244 164 0\n",
      "Training Accuracy 0.385\n",
      "Loss 602.1222 165 0\n",
      "Training Accuracy 0.35\n",
      "Loss 702.5666 166 0\n",
      "Training Accuracy 0.29\n",
      "Loss 539.209 167 0\n",
      "Training Accuracy 0.385\n",
      "Loss 671.9432 168 0\n",
      "Training Accuracy 0.31\n",
      "Loss 584.5059 169 0\n",
      "Training Accuracy 0.335\n",
      "Loss 600.84894 170 0\n",
      "Training Accuracy 0.32\n",
      "Loss 601.74817 171 0\n",
      "Training Accuracy 0.37\n",
      "Loss 639.3985 172 0\n",
      "Training Accuracy 0.255\n",
      "Loss 649.4706 173 0\n",
      "Training Accuracy 0.265\n",
      "Loss 541.82513 174 0\n",
      "Training Accuracy 0.365\n",
      "Loss 599.66125 175 0\n",
      "Training Accuracy 0.36\n",
      "Loss 544.839 176 0\n",
      "Training Accuracy 0.38\n",
      "Loss 654.0767 177 0\n",
      "Training Accuracy 0.315\n",
      "Loss 532.4081 178 0\n",
      "Training Accuracy 0.44\n",
      "Loss 647.4951 179 0\n",
      "Training Accuracy 0.315\n",
      "Loss 572.69165 180 0\n",
      "Training Accuracy 0.32\n",
      "Loss 514.43396 181 0\n",
      "Training Accuracy 0.36\n",
      "Loss 631.4388 182 0\n",
      "Training Accuracy 0.275\n",
      "Loss 605.2777 183 0\n",
      "Training Accuracy 0.325\n",
      "Loss 537.889 184 0\n",
      "Training Accuracy 0.42\n",
      "Loss 576.60614 185 0\n",
      "Training Accuracy 0.355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 607.69763 186 0\n",
      "Training Accuracy 0.355\n",
      "Loss 642.7817 187 0\n",
      "Training Accuracy 0.295\n",
      "Loss 603.5609 188 0\n",
      "Training Accuracy 0.34\n",
      "Loss 602.09564 189 0\n",
      "Training Accuracy 0.325\n",
      "Loss 567.1484 190 0\n",
      "Training Accuracy 0.37\n",
      "Loss 549.26404 191 0\n",
      "Training Accuracy 0.375\n",
      "Loss 593.67163 192 0\n",
      "Training Accuracy 0.35\n",
      "Loss 547.1641 193 0\n",
      "Training Accuracy 0.44\n",
      "Loss 598.0718 194 0\n",
      "Training Accuracy 0.305\n",
      "Loss 547.51715 195 0\n",
      "Training Accuracy 0.345\n",
      "Loss 584.43823 196 0\n",
      "Training Accuracy 0.38\n",
      "Loss 590.82544 197 0\n",
      "Training Accuracy 0.325\n",
      "Loss 597.68317 198 0\n",
      "Training Accuracy 0.33\n",
      "Loss 506.0273 199 0\n",
      "Training Accuracy 0.42\n",
      "Loss 587.9557 200 0\n",
      "Training Accuracy 0.335\n",
      "Loss 570.6882 201 0\n",
      "Training Accuracy 0.325\n",
      "Loss 621.5019 202 0\n",
      "Training Accuracy 0.285\n",
      "Loss 597.2257 203 0\n",
      "Training Accuracy 0.32\n",
      "Loss 569.66156 204 0\n",
      "Training Accuracy 0.375\n",
      "Loss 570.4658 205 0\n",
      "Training Accuracy 0.355\n",
      "Loss 560.03296 206 0\n",
      "Training Accuracy 0.31\n",
      "Loss 548.0404 207 0\n",
      "Training Accuracy 0.29\n",
      "Loss 599.8299 208 0\n",
      "Training Accuracy 0.33\n",
      "Loss 596.81384 209 0\n",
      "Training Accuracy 0.28\n",
      "Loss 531.64484 210 0\n",
      "Training Accuracy 0.305\n",
      "Loss 562.8544 211 0\n",
      "Training Accuracy 0.36\n",
      "Loss 541.9212 212 0\n",
      "Training Accuracy 0.355\n",
      "Loss 646.5165 213 0\n",
      "Training Accuracy 0.32\n",
      "Loss 579.6207 214 0\n",
      "Training Accuracy 0.365\n",
      "Loss 573.4221 215 0\n",
      "Training Accuracy 0.305\n",
      "Loss 639.78174 216 0\n",
      "Training Accuracy 0.32\n",
      "Loss 521.128 217 0\n",
      "Training Accuracy 0.335\n",
      "Loss 604.0316 218 0\n",
      "Training Accuracy 0.315\n",
      "Loss 578.81775 219 0\n",
      "Training Accuracy 0.38\n",
      "Loss 565.9883 220 0\n",
      "Training Accuracy 0.37\n",
      "Loss 598.5262 221 0\n",
      "Training Accuracy 0.305\n",
      "Loss 526.6235 222 0\n",
      "Training Accuracy 0.39\n",
      "Loss 575.41656 223 0\n",
      "Training Accuracy 0.325\n",
      "Loss 597.34247 224 0\n",
      "Training Accuracy 0.355\n",
      "Loss 576.0988 225 0\n",
      "Training Accuracy 0.335\n",
      "Loss 534.43475 226 0\n",
      "Training Accuracy 0.32\n",
      "Loss 652.08356 227 0\n",
      "Training Accuracy 0.285\n",
      "Loss 622.74884 228 0\n",
      "Training Accuracy 0.28\n",
      "Loss 527.2733 229 0\n",
      "Training Accuracy 0.37\n",
      "Loss 565.3392 230 0\n",
      "Training Accuracy 0.335\n",
      "Loss 516.4758 231 0\n",
      "Training Accuracy 0.37\n",
      "Loss 620.035 232 0\n",
      "Training Accuracy 0.275\n",
      "Loss 578.48376 233 0\n",
      "Training Accuracy 0.34\n",
      "Loss 565.1573 234 0\n",
      "Training Accuracy 0.325\n",
      "Loss 550.5761 235 0\n",
      "Training Accuracy 0.325\n",
      "Loss 523.2484 236 0\n",
      "Training Accuracy 0.355\n",
      "Loss 620.2128 237 0\n",
      "Training Accuracy 0.315\n",
      "Loss 538.70575 238 0\n",
      "Training Accuracy 0.33\n",
      "Loss 639.973 239 0\n",
      "Training Accuracy 0.29\n",
      "Loss 565.79926 240 0\n",
      "Training Accuracy 0.33\n",
      "Loss 602.60724 241 0\n",
      "Training Accuracy 0.32\n",
      "Loss 530.8531 242 0\n",
      "Training Accuracy 0.335\n",
      "Loss 527.2306 243 0\n",
      "Training Accuracy 0.38\n",
      "Loss 500.3214 244 0\n",
      "Training Accuracy 0.365\n",
      "Loss 534.35754 245 0\n",
      "Training Accuracy 0.315\n",
      "Loss 571.70825 246 0\n",
      "Training Accuracy 0.29\n",
      "Loss 474.45264 247 0\n",
      "Training Accuracy 0.39\n",
      "Loss 519.7139 248 0\n",
      "Training Accuracy 0.335\n",
      "Loss 534.09033 249 0\n",
      "Training Accuracy 0.335\n",
      "Loss 565.04395 250 0\n",
      "Training Accuracy 0.335\n",
      "Loss 556.655 251 0\n",
      "Training Accuracy 0.305\n",
      "Loss 543.37366 252 0\n",
      "Training Accuracy 0.305\n",
      "Loss 523.0544 253 0\n",
      "Training Accuracy 0.4\n",
      "Loss 542.5384 254 0\n",
      "Training Accuracy 0.375\n",
      "Loss 528.9328 255 0\n",
      "Training Accuracy 0.34\n",
      "Loss 590.4592 256 0\n",
      "Training Accuracy 0.29\n",
      "Loss 521.1185 257 0\n",
      "Training Accuracy 0.345\n",
      "Loss 552.9981 258 0\n",
      "Training Accuracy 0.29\n",
      "Loss 553.0887 259 0\n",
      "Training Accuracy 0.34\n",
      "Loss 533.4853 260 0\n",
      "Training Accuracy 0.39\n",
      "Loss 608.4505 261 0\n",
      "Training Accuracy 0.33\n",
      "Loss 511.9899 262 0\n",
      "Training Accuracy 0.33\n",
      "Loss 653.4385 263 0\n",
      "Training Accuracy 0.3\n",
      "Loss 560.097 264 0\n",
      "Training Accuracy 0.35\n",
      "Loss 596.7819 265 0\n",
      "Training Accuracy 0.305\n",
      "Loss 551.0544 266 0\n",
      "Training Accuracy 0.335\n",
      "Loss 535.3687 267 0\n",
      "Training Accuracy 0.355\n",
      "Loss 562.82697 268 0\n",
      "Training Accuracy 0.37\n",
      "Loss 512.0135 269 0\n",
      "Training Accuracy 0.32\n",
      "Loss 525.422 270 0\n",
      "Training Accuracy 0.385\n",
      "Loss 622.0721 271 0\n",
      "Training Accuracy 0.275\n",
      "Loss 553.3231 272 0\n",
      "Training Accuracy 0.31\n",
      "Loss 512.6792 273 0\n",
      "Training Accuracy 0.355\n",
      "Loss 544.7779 274 0\n",
      "Training Accuracy 0.345\n",
      "Loss 599.01086 275 0\n",
      "Training Accuracy 0.28\n",
      "Loss 517.22437 276 0\n",
      "Training Accuracy 0.325\n",
      "Loss 656.8483 277 0\n",
      "Training Accuracy 0.25\n",
      "Loss 523.52795 278 0\n",
      "Training Accuracy 0.315\n",
      "Loss 518.7194 279 0\n",
      "Training Accuracy 0.345\n",
      "Loss 494.0847 280 0\n",
      "Training Accuracy 0.375\n",
      "Loss 527.95605 281 0\n",
      "Training Accuracy 0.38\n",
      "Loss 544.2986 282 0\n",
      "Training Accuracy 0.34\n",
      "Loss 478.06677 283 0\n",
      "Training Accuracy 0.37\n",
      "Loss 546.3769 284 0\n",
      "Training Accuracy 0.37\n",
      "Loss 603.3614 285 0\n",
      "Training Accuracy 0.335\n",
      "Loss 536.29517 286 0\n",
      "Training Accuracy 0.375\n",
      "Loss 526.9806 287 0\n",
      "Training Accuracy 0.39\n",
      "Loss 563.6867 288 0\n",
      "Training Accuracy 0.385\n",
      "Loss 484.81326 289 0\n",
      "Training Accuracy 0.36\n",
      "Loss 570.6342 290 0\n",
      "Training Accuracy 0.35\n",
      "Loss 570.4134 291 0\n",
      "Training Accuracy 0.32\n",
      "Loss 355.95474 292 0\n",
      "Training Accuracy 0.37121212\n",
      "Loss 516.06995 1 1\n",
      "Training Accuracy 0.38\n",
      "Loss 523.3564 2 1\n",
      "Training Accuracy 0.285\n",
      "Loss 578.9284 3 1\n",
      "Training Accuracy 0.345\n",
      "Loss 552.5524 4 1\n",
      "Training Accuracy 0.4\n",
      "Loss 484.83673 5 1\n",
      "Training Accuracy 0.38\n",
      "Loss 549.60004 6 1\n",
      "Training Accuracy 0.36\n",
      "Loss 531.26624 7 1\n",
      "Training Accuracy 0.36\n",
      "Loss 634.32654 8 1\n",
      "Training Accuracy 0.315\n",
      "Loss 574.8179 9 1\n",
      "Training Accuracy 0.25\n",
      "Loss 525.2315 10 1\n",
      "Training Accuracy 0.38\n",
      "Loss 606.15326 11 1\n",
      "Training Accuracy 0.315\n",
      "Loss 520.2996 12 1\n",
      "Training Accuracy 0.32\n",
      "Loss 499.28247 13 1\n",
      "Training Accuracy 0.37\n",
      "Loss 556.84515 14 1\n",
      "Training Accuracy 0.305\n",
      "Loss 506.55057 15 1\n",
      "Training Accuracy 0.41\n",
      "Loss 526.2915 16 1\n",
      "Training Accuracy 0.295\n",
      "Loss 529.42615 17 1\n",
      "Training Accuracy 0.345\n",
      "Loss 531.5971 18 1\n",
      "Training Accuracy 0.36\n",
      "Loss 536.62604 19 1\n",
      "Training Accuracy 0.325\n",
      "Loss 516.7936 20 1\n",
      "Training Accuracy 0.365\n",
      "Loss 553.73035 21 1\n",
      "Training Accuracy 0.4\n",
      "Loss 577.45905 22 1\n",
      "Training Accuracy 0.315\n",
      "Loss 587.2604 23 1\n",
      "Training Accuracy 0.33\n",
      "Loss 529.556 24 1\n",
      "Training Accuracy 0.34\n",
      "Loss 507.72528 25 1\n",
      "Training Accuracy 0.355\n",
      "Loss 552.55566 26 1\n",
      "Training Accuracy 0.31\n",
      "Loss 522.37164 27 1\n",
      "Training Accuracy 0.33\n",
      "Loss 541.9293 28 1\n",
      "Training Accuracy 0.315\n",
      "Loss 519.29956 29 1\n",
      "Training Accuracy 0.405\n",
      "Loss 549.3954 30 1\n",
      "Training Accuracy 0.34\n",
      "Loss 567.33386 31 1\n",
      "Training Accuracy 0.33\n",
      "Loss 536.1405 32 1\n",
      "Training Accuracy 0.335\n",
      "Loss 542.18787 33 1\n",
      "Training Accuracy 0.375\n",
      "Loss 530.1864 34 1\n",
      "Training Accuracy 0.345\n",
      "Loss 474.10718 35 1\n",
      "Training Accuracy 0.335\n",
      "Loss 519.9 36 1\n",
      "Training Accuracy 0.35\n",
      "Loss 547.02545 37 1\n",
      "Training Accuracy 0.335\n",
      "Loss 555.7154 38 1\n",
      "Training Accuracy 0.32\n",
      "Loss 485.2002 39 1\n",
      "Training Accuracy 0.375\n",
      "Loss 493.94434 40 1\n",
      "Training Accuracy 0.36\n",
      "Loss 494.92303 41 1\n",
      "Training Accuracy 0.355\n",
      "Loss 593.10394 42 1\n",
      "Training Accuracy 0.23\n",
      "Loss 545.83386 43 1\n",
      "Training Accuracy 0.34\n",
      "Loss 500.55444 44 1\n",
      "Training Accuracy 0.345\n",
      "Loss 554.78314 45 1\n",
      "Training Accuracy 0.295\n",
      "Loss 547.31366 46 1\n",
      "Training Accuracy 0.335\n",
      "Loss 501.92252 47 1\n",
      "Training Accuracy 0.335\n",
      "Loss 518.9551 48 1\n",
      "Training Accuracy 0.33\n",
      "Loss 554.59595 49 1\n",
      "Training Accuracy 0.35\n",
      "Loss 530.8093 50 1\n",
      "Training Accuracy 0.365\n",
      "Loss 520.4279 51 1\n",
      "Training Accuracy 0.35\n",
      "Loss 542.04913 52 1\n",
      "Training Accuracy 0.325\n",
      "Loss 537.6672 53 1\n",
      "Training Accuracy 0.345\n",
      "Loss 530.35706 54 1\n",
      "Training Accuracy 0.3\n",
      "Loss 529.79395 55 1\n",
      "Training Accuracy 0.345\n",
      "Loss 488.47522 56 1\n",
      "Training Accuracy 0.35\n",
      "Loss 481.1895 57 1\n",
      "Training Accuracy 0.465\n",
      "Loss 467.41385 58 1\n",
      "Training Accuracy 0.41\n",
      "Loss 542.365 59 1\n",
      "Training Accuracy 0.34\n",
      "Loss 521.7892 60 1\n",
      "Training Accuracy 0.39\n",
      "Loss 515.50134 61 1\n",
      "Training Accuracy 0.305\n",
      "Loss 513.4419 62 1\n",
      "Training Accuracy 0.38\n",
      "Loss 535.84656 63 1\n",
      "Training Accuracy 0.335\n",
      "Loss 545.2539 64 1\n",
      "Training Accuracy 0.35\n",
      "Loss 521.9631 65 1\n",
      "Training Accuracy 0.35\n",
      "Loss 511.70483 66 1\n",
      "Training Accuracy 0.325\n",
      "Loss 566.8979 67 1\n",
      "Training Accuracy 0.345\n",
      "Loss 540.4384 68 1\n",
      "Training Accuracy 0.32\n",
      "Loss 526.26074 69 1\n",
      "Training Accuracy 0.355\n",
      "Loss 520.7262 70 1\n",
      "Training Accuracy 0.365\n",
      "Loss 497.00934 71 1\n",
      "Training Accuracy 0.41\n",
      "Loss 519.9073 72 1\n",
      "Training Accuracy 0.335\n",
      "Loss 592.01465 73 1\n",
      "Training Accuracy 0.28\n",
      "Loss 593.06085 74 1\n",
      "Training Accuracy 0.35\n",
      "Loss 537.16815 75 1\n",
      "Training Accuracy 0.36\n",
      "Loss 526.98126 76 1\n",
      "Training Accuracy 0.385\n",
      "Loss 487.16858 77 1\n",
      "Training Accuracy 0.38\n",
      "Loss 483.70026 78 1\n",
      "Training Accuracy 0.39\n",
      "Loss 454.87457 79 1\n",
      "Training Accuracy 0.385\n",
      "Loss 497.07355 80 1\n",
      "Training Accuracy 0.36\n",
      "Loss 559.37134 81 1\n",
      "Training Accuracy 0.35\n",
      "Loss 506.7964 82 1\n",
      "Training Accuracy 0.395\n",
      "Loss 524.96826 83 1\n",
      "Training Accuracy 0.335\n",
      "Loss 566.99603 84 1\n",
      "Training Accuracy 0.305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 507.73245 85 1\n",
      "Training Accuracy 0.325\n",
      "Loss 507.75653 86 1\n",
      "Training Accuracy 0.385\n",
      "Loss 554.59247 87 1\n",
      "Training Accuracy 0.315\n",
      "Loss 505.4262 88 1\n",
      "Training Accuracy 0.365\n",
      "Loss 572.04065 89 1\n",
      "Training Accuracy 0.36\n",
      "Loss 539.0184 90 1\n",
      "Training Accuracy 0.355\n",
      "Loss 553.7462 91 1\n",
      "Training Accuracy 0.315\n",
      "Loss 564.01025 92 1\n",
      "Training Accuracy 0.33\n",
      "Loss 517.87805 93 1\n",
      "Training Accuracy 0.385\n",
      "Loss 502.42047 94 1\n",
      "Training Accuracy 0.375\n",
      "Loss 476.44955 95 1\n",
      "Training Accuracy 0.395\n",
      "Loss 520.1997 96 1\n",
      "Training Accuracy 0.335\n",
      "Loss 538.7425 97 1\n",
      "Training Accuracy 0.315\n",
      "Loss 550.81885 98 1\n",
      "Training Accuracy 0.29\n",
      "Loss 504.48788 99 1\n",
      "Training Accuracy 0.355\n",
      "Loss 546.13513 100 1\n",
      "Training Accuracy 0.345\n",
      "Loss 554.96295 101 1\n",
      "Training Accuracy 0.275\n",
      "Loss 473.53943 102 1\n",
      "Training Accuracy 0.41\n",
      "Loss 518.73346 103 1\n",
      "Training Accuracy 0.36\n",
      "Loss 484.29056 104 1\n",
      "Training Accuracy 0.335\n",
      "Loss 546.9829 105 1\n",
      "Training Accuracy 0.365\n",
      "Loss 521.1772 106 1\n",
      "Training Accuracy 0.355\n",
      "Loss 523.0151 107 1\n",
      "Training Accuracy 0.305\n",
      "Loss 505.09305 108 1\n",
      "Training Accuracy 0.34\n",
      "Loss 518.47815 109 1\n",
      "Training Accuracy 0.39\n",
      "Loss 524.33203 110 1\n",
      "Training Accuracy 0.31\n",
      "Loss 494.5098 111 1\n",
      "Training Accuracy 0.385\n",
      "Loss 549.6594 112 1\n",
      "Training Accuracy 0.365\n",
      "Loss 542.6136 113 1\n",
      "Training Accuracy 0.325\n",
      "Loss 487.36676 114 1\n",
      "Training Accuracy 0.39\n",
      "Loss 537.6002 115 1\n",
      "Training Accuracy 0.325\n",
      "Loss 563.49945 116 1\n",
      "Training Accuracy 0.38\n",
      "Loss 483.1516 117 1\n",
      "Training Accuracy 0.405\n",
      "Loss 572.0496 118 1\n",
      "Training Accuracy 0.335\n",
      "Loss 592.4349 119 1\n",
      "Training Accuracy 0.29\n",
      "Loss 560.2998 120 1\n",
      "Training Accuracy 0.35\n",
      "Loss 557.00055 121 1\n",
      "Training Accuracy 0.34\n",
      "Loss 522.9879 122 1\n",
      "Training Accuracy 0.325\n",
      "Loss 526.67804 123 1\n",
      "Training Accuracy 0.315\n",
      "Loss 499.18744 124 1\n",
      "Training Accuracy 0.325\n",
      "Loss 473.90457 125 1\n",
      "Training Accuracy 0.375\n",
      "Loss 530.7837 126 1\n",
      "Training Accuracy 0.39\n",
      "Loss 460.84686 127 1\n",
      "Training Accuracy 0.4\n",
      "Loss 501.4984 128 1\n",
      "Training Accuracy 0.38\n",
      "Loss 498.59467 129 1\n",
      "Training Accuracy 0.37\n",
      "Loss 491.73874 130 1\n",
      "Training Accuracy 0.415\n",
      "Loss 470.28857 131 1\n",
      "Training Accuracy 0.37\n",
      "Loss 492.08328 132 1\n",
      "Training Accuracy 0.355\n",
      "Loss 522.18097 133 1\n",
      "Training Accuracy 0.355\n",
      "Loss 520.62823 134 1\n",
      "Training Accuracy 0.34\n",
      "Loss 461.94168 135 1\n",
      "Training Accuracy 0.41\n",
      "Loss 558.7082 136 1\n",
      "Training Accuracy 0.33\n",
      "Loss 503.515 137 1\n",
      "Training Accuracy 0.355\n",
      "Loss 539.1894 138 1\n",
      "Training Accuracy 0.33\n",
      "Loss 586.24634 139 1\n",
      "Training Accuracy 0.34\n",
      "Loss 521.3998 140 1\n",
      "Training Accuracy 0.345\n",
      "Loss 524.10376 141 1\n",
      "Training Accuracy 0.325\n",
      "Loss 490.58786 142 1\n",
      "Training Accuracy 0.375\n",
      "Loss 476.25946 143 1\n",
      "Training Accuracy 0.36\n",
      "Loss 501.1583 144 1\n",
      "Training Accuracy 0.345\n",
      "Loss 510.10464 145 1\n",
      "Training Accuracy 0.395\n",
      "Loss 468.49066 146 1\n",
      "Training Accuracy 0.39\n",
      "Loss 505.8458 147 1\n",
      "Training Accuracy 0.43\n",
      "Loss 514.3549 148 1\n",
      "Training Accuracy 0.315\n",
      "Loss 471.19867 149 1\n",
      "Training Accuracy 0.39\n",
      "Loss 515.1169 150 1\n",
      "Training Accuracy 0.355\n",
      "Loss 519.00635 151 1\n",
      "Training Accuracy 0.41\n",
      "Loss 544.21857 152 1\n",
      "Training Accuracy 0.36\n",
      "Loss 513.6389 153 1\n",
      "Training Accuracy 0.375\n",
      "Loss 529.63684 154 1\n",
      "Training Accuracy 0.335\n",
      "Loss 478.0237 155 1\n",
      "Training Accuracy 0.39\n",
      "Loss 524.78064 156 1\n",
      "Training Accuracy 0.33\n",
      "Loss 476.26233 157 1\n",
      "Training Accuracy 0.39\n",
      "Loss 523.6194 158 1\n",
      "Training Accuracy 0.385\n",
      "Loss 558.86554 159 1\n",
      "Training Accuracy 0.355\n",
      "Loss 471.29596 160 1\n",
      "Training Accuracy 0.395\n",
      "Loss 549.4812 161 1\n",
      "Training Accuracy 0.29\n",
      "Loss 476.68155 162 1\n",
      "Training Accuracy 0.405\n",
      "Loss 517.6714 163 1\n",
      "Training Accuracy 0.335\n",
      "Loss 443.07657 164 1\n",
      "Training Accuracy 0.41\n",
      "Loss 493.02475 165 1\n",
      "Training Accuracy 0.4\n",
      "Loss 569.91614 166 1\n",
      "Training Accuracy 0.3\n",
      "Loss 443.53137 167 1\n",
      "Training Accuracy 0.425\n",
      "Loss 558.78156 168 1\n",
      "Training Accuracy 0.34\n",
      "Loss 478.76004 169 1\n",
      "Training Accuracy 0.365\n",
      "Loss 498.9278 170 1\n",
      "Training Accuracy 0.375\n",
      "Loss 510.20486 171 1\n",
      "Training Accuracy 0.39\n",
      "Loss 512.7256 172 1\n",
      "Training Accuracy 0.36\n",
      "Loss 547.38403 173 1\n",
      "Training Accuracy 0.3\n",
      "Loss 453.48315 174 1\n",
      "Training Accuracy 0.43\n",
      "Loss 504.935 175 1\n",
      "Training Accuracy 0.385\n",
      "Loss 459.2721 176 1\n",
      "Training Accuracy 0.435\n",
      "Loss 552.55725 177 1\n",
      "Training Accuracy 0.36\n",
      "Loss 451.6292 178 1\n",
      "Training Accuracy 0.43\n",
      "Loss 548.79224 179 1\n",
      "Training Accuracy 0.34\n",
      "Loss 488.16904 180 1\n",
      "Training Accuracy 0.365\n",
      "Loss 439.22537 181 1\n",
      "Training Accuracy 0.395\n",
      "Loss 535.0972 182 1\n",
      "Training Accuracy 0.305\n",
      "Loss 506.87262 183 1\n",
      "Training Accuracy 0.37\n",
      "Loss 448.69315 184 1\n",
      "Training Accuracy 0.46\n",
      "Loss 483.50067 185 1\n",
      "Training Accuracy 0.4\n",
      "Loss 494.6858 186 1\n",
      "Training Accuracy 0.425\n",
      "Loss 538.6089 187 1\n",
      "Training Accuracy 0.35\n",
      "Loss 496.72595 188 1\n",
      "Training Accuracy 0.39\n",
      "Loss 511.5617 189 1\n",
      "Training Accuracy 0.355\n",
      "Loss 485.47223 190 1\n",
      "Training Accuracy 0.435\n",
      "Loss 474.26883 191 1\n",
      "Training Accuracy 0.365\n",
      "Loss 493.71313 192 1\n",
      "Training Accuracy 0.36\n",
      "Loss 444.92023 193 1\n",
      "Training Accuracy 0.46\n",
      "Loss 490.21713 194 1\n",
      "Training Accuracy 0.38\n",
      "Loss 463.25995 195 1\n",
      "Training Accuracy 0.39\n",
      "Loss 505.97888 196 1\n",
      "Training Accuracy 0.4\n",
      "Loss 509.6926 197 1\n",
      "Training Accuracy 0.345\n",
      "Loss 477.5063 198 1\n",
      "Training Accuracy 0.365\n",
      "Loss 419.98117 199 1\n",
      "Training Accuracy 0.475\n",
      "Loss 499.98825 200 1\n",
      "Training Accuracy 0.365\n",
      "Loss 493.24545 201 1\n",
      "Training Accuracy 0.345\n",
      "Loss 528.94855 202 1\n",
      "Training Accuracy 0.335\n",
      "Loss 519.19745 203 1\n",
      "Training Accuracy 0.36\n",
      "Loss 491.57126 204 1\n",
      "Training Accuracy 0.43\n",
      "Loss 495.75055 205 1\n",
      "Training Accuracy 0.395\n",
      "Loss 482.64502 206 1\n",
      "Training Accuracy 0.42\n",
      "Loss 456.54617 207 1\n",
      "Training Accuracy 0.36\n",
      "Loss 521.604 208 1\n",
      "Training Accuracy 0.365\n",
      "Loss 506.54312 209 1\n",
      "Training Accuracy 0.345\n",
      "Loss 457.9937 210 1\n",
      "Training Accuracy 0.335\n",
      "Loss 479.11194 211 1\n",
      "Training Accuracy 0.42\n",
      "Loss 453.8672 212 1\n",
      "Training Accuracy 0.395\n",
      "Loss 553.8119 213 1\n",
      "Training Accuracy 0.345\n",
      "Loss 491.6439 214 1\n",
      "Training Accuracy 0.38\n",
      "Loss 489.5913 215 1\n",
      "Training Accuracy 0.36\n",
      "Loss 551.8653 216 1\n",
      "Training Accuracy 0.33\n",
      "Loss 454.6079 217 1\n",
      "Training Accuracy 0.385\n",
      "Loss 520.09174 218 1\n",
      "Training Accuracy 0.385\n",
      "Loss 502.9645 219 1\n",
      "Training Accuracy 0.38\n",
      "Loss 483.1765 220 1\n",
      "Training Accuracy 0.425\n",
      "Loss 527.6588 221 1\n",
      "Training Accuracy 0.315\n",
      "Loss 458.9487 222 1\n",
      "Training Accuracy 0.445\n",
      "Loss 505.28766 223 1\n",
      "Training Accuracy 0.34\n",
      "Loss 516.6362 224 1\n",
      "Training Accuracy 0.365\n",
      "Loss 502.62143 225 1\n",
      "Training Accuracy 0.355\n",
      "Loss 470.34183 226 1\n",
      "Training Accuracy 0.31\n",
      "Loss 552.0813 227 1\n",
      "Training Accuracy 0.335\n",
      "Loss 534.95123 228 1\n",
      "Training Accuracy 0.29\n",
      "Loss 472.87286 229 1\n",
      "Training Accuracy 0.36\n",
      "Loss 489.8962 230 1\n",
      "Training Accuracy 0.365\n",
      "Loss 434.20197 231 1\n",
      "Training Accuracy 0.415\n",
      "Loss 530.82715 232 1\n",
      "Training Accuracy 0.345\n",
      "Loss 503.5788 233 1\n",
      "Training Accuracy 0.35\n",
      "Loss 483.43878 234 1\n",
      "Training Accuracy 0.395\n",
      "Loss 482.77094 235 1\n",
      "Training Accuracy 0.375\n",
      "Loss 450.65378 236 1\n",
      "Training Accuracy 0.4\n",
      "Loss 531.88885 237 1\n",
      "Training Accuracy 0.33\n",
      "Loss 470.3171 238 1\n",
      "Training Accuracy 0.35\n",
      "Loss 559.0322 239 1\n",
      "Training Accuracy 0.36\n",
      "Loss 504.5069 240 1\n",
      "Training Accuracy 0.37\n",
      "Loss 521.6722 241 1\n",
      "Training Accuracy 0.325\n",
      "Loss 441.3362 242 1\n",
      "Training Accuracy 0.445\n",
      "Loss 450.7166 243 1\n",
      "Training Accuracy 0.405\n",
      "Loss 454.37393 244 1\n",
      "Training Accuracy 0.415\n",
      "Loss 465.44598 245 1\n",
      "Training Accuracy 0.37\n",
      "Loss 501.75793 246 1\n",
      "Training Accuracy 0.365\n",
      "Loss 414.37173 247 1\n",
      "Training Accuracy 0.44\n",
      "Loss 447.6817 248 1\n",
      "Training Accuracy 0.395\n",
      "Loss 464.96872 249 1\n",
      "Training Accuracy 0.39\n",
      "Loss 487.46402 250 1\n",
      "Training Accuracy 0.35\n",
      "Loss 481.5139 251 1\n",
      "Training Accuracy 0.335\n",
      "Loss 470.645 252 1\n",
      "Training Accuracy 0.375\n",
      "Loss 463.95825 253 1\n",
      "Training Accuracy 0.395\n",
      "Loss 479.7201 254 1\n",
      "Training Accuracy 0.36\n",
      "Loss 454.7212 255 1\n",
      "Training Accuracy 0.41\n",
      "Loss 521.01874 256 1\n",
      "Training Accuracy 0.34\n",
      "Loss 459.13748 257 1\n",
      "Training Accuracy 0.415\n",
      "Loss 465.9008 258 1\n",
      "Training Accuracy 0.355\n",
      "Loss 481.75537 259 1\n",
      "Training Accuracy 0.36\n",
      "Loss 456.87665 260 1\n",
      "Training Accuracy 0.43\n",
      "Loss 531.1791 261 1\n",
      "Training Accuracy 0.355\n",
      "Loss 459.0551 262 1\n",
      "Training Accuracy 0.39\n",
      "Loss 584.3917 263 1\n",
      "Training Accuracy 0.29\n",
      "Loss 492.497 264 1\n",
      "Training Accuracy 0.385\n",
      "Loss 525.09235 265 1\n",
      "Training Accuracy 0.345\n",
      "Loss 486.0462 266 1\n",
      "Training Accuracy 0.365\n",
      "Loss 477.2427 267 1\n",
      "Training Accuracy 0.4\n",
      "Loss 502.78506 268 1\n",
      "Training Accuracy 0.415\n",
      "Loss 450.83847 269 1\n",
      "Training Accuracy 0.375\n",
      "Loss 454.6983 270 1\n",
      "Training Accuracy 0.365\n",
      "Loss 544.00415 271 1\n",
      "Training Accuracy 0.305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 490.7644 272 1\n",
      "Training Accuracy 0.39\n",
      "Loss 440.33325 273 1\n",
      "Training Accuracy 0.41\n",
      "Loss 478.39362 274 1\n",
      "Training Accuracy 0.355\n",
      "Loss 530.77496 275 1\n",
      "Training Accuracy 0.325\n",
      "Loss 465.43442 276 1\n",
      "Training Accuracy 0.375\n",
      "Loss 601.4023 277 1\n",
      "Training Accuracy 0.275\n",
      "Loss 453.208 278 1\n",
      "Training Accuracy 0.44\n",
      "Loss 451.06357 279 1\n",
      "Training Accuracy 0.405\n",
      "Loss 431.0927 280 1\n",
      "Training Accuracy 0.44\n",
      "Loss 470.2848 281 1\n",
      "Training Accuracy 0.4\n",
      "Loss 474.4493 282 1\n",
      "Training Accuracy 0.395\n",
      "Loss 427.98352 283 1\n",
      "Training Accuracy 0.395\n",
      "Loss 473.9601 284 1\n",
      "Training Accuracy 0.385\n",
      "Loss 528.4732 285 1\n",
      "Training Accuracy 0.345\n",
      "Loss 481.12408 286 1\n",
      "Training Accuracy 0.395\n",
      "Loss 455.0153 287 1\n",
      "Training Accuracy 0.435\n",
      "Loss 496.1343 288 1\n",
      "Training Accuracy 0.41\n",
      "Loss 429.06595 289 1\n",
      "Training Accuracy 0.39\n",
      "Loss 496.70016 290 1\n",
      "Training Accuracy 0.365\n",
      "Loss 493.55 291 1\n",
      "Training Accuracy 0.39\n",
      "Loss 303.11517 292 1\n",
      "Training Accuracy 0.42424244\n",
      "Loss 447.07733 1 2\n",
      "Training Accuracy 0.425\n",
      "Loss 465.14807 2 2\n",
      "Training Accuracy 0.335\n",
      "Loss 513.7538 3 2\n",
      "Training Accuracy 0.4\n",
      "Loss 487.77438 4 2\n",
      "Training Accuracy 0.41\n",
      "Loss 429.5101 5 2\n",
      "Training Accuracy 0.425\n",
      "Loss 480.0219 6 2\n",
      "Training Accuracy 0.405\n",
      "Loss 465.9889 7 2\n",
      "Training Accuracy 0.415\n",
      "Loss 575.0112 8 2\n",
      "Training Accuracy 0.33\n",
      "Loss 506.2342 9 2\n",
      "Training Accuracy 0.285\n",
      "Loss 473.82202 10 2\n",
      "Training Accuracy 0.395\n",
      "Loss 529.96545 11 2\n",
      "Training Accuracy 0.375\n",
      "Loss 461.471 12 2\n",
      "Training Accuracy 0.385\n",
      "Loss 439.31122 13 2\n",
      "Training Accuracy 0.425\n",
      "Loss 493.1178 14 2\n",
      "Training Accuracy 0.37\n",
      "Loss 458.64322 15 2\n",
      "Training Accuracy 0.405\n",
      "Loss 480.3503 16 2\n",
      "Training Accuracy 0.305\n",
      "Loss 461.34903 17 2\n",
      "Training Accuracy 0.43\n",
      "Loss 466.33746 18 2\n",
      "Training Accuracy 0.39\n",
      "Loss 485.88016 19 2\n",
      "Training Accuracy 0.38\n",
      "Loss 456.57956 20 2\n",
      "Training Accuracy 0.42\n",
      "Loss 487.21805 21 2\n",
      "Training Accuracy 0.39\n",
      "Loss 511.62872 22 2\n",
      "Training Accuracy 0.35\n",
      "Loss 519.56226 23 2\n",
      "Training Accuracy 0.395\n",
      "Loss 464.35538 24 2\n",
      "Training Accuracy 0.35\n",
      "Loss 455.26996 25 2\n",
      "Training Accuracy 0.39\n",
      "Loss 501.3486 26 2\n",
      "Training Accuracy 0.305\n",
      "Loss 463.5919 27 2\n",
      "Training Accuracy 0.39\n",
      "Loss 477.87546 28 2\n",
      "Training Accuracy 0.35\n",
      "Loss 455.06763 29 2\n",
      "Training Accuracy 0.38\n",
      "Loss 484.34402 30 2\n",
      "Training Accuracy 0.375\n",
      "Loss 509.27234 31 2\n",
      "Training Accuracy 0.355\n",
      "Loss 475.39767 32 2\n",
      "Training Accuracy 0.39\n",
      "Loss 475.06815 33 2\n",
      "Training Accuracy 0.405\n",
      "Loss 469.79877 34 2\n",
      "Training Accuracy 0.37\n",
      "Loss 411.24884 35 2\n",
      "Training Accuracy 0.375\n",
      "Loss 461.74945 36 2\n",
      "Training Accuracy 0.385\n",
      "Loss 485.4942 37 2\n",
      "Training Accuracy 0.4\n",
      "Loss 487.02094 38 2\n",
      "Training Accuracy 0.335\n",
      "Loss 420.12662 39 2\n",
      "Training Accuracy 0.395\n",
      "Loss 440.81943 40 2\n",
      "Training Accuracy 0.415\n",
      "Loss 438.70428 41 2\n",
      "Training Accuracy 0.4\n",
      "Loss 519.74146 42 2\n",
      "Training Accuracy 0.295\n",
      "Loss 484.66785 43 2\n",
      "Training Accuracy 0.385\n",
      "Loss 456.09964 44 2\n",
      "Training Accuracy 0.425\n",
      "Loss 488.234 45 2\n",
      "Training Accuracy 0.36\n",
      "Loss 490.33383 46 2\n",
      "Training Accuracy 0.395\n",
      "Loss 460.03897 47 2\n",
      "Training Accuracy 0.43\n",
      "Loss 464.8304 48 2\n",
      "Training Accuracy 0.36\n",
      "Loss 486.15817 49 2\n",
      "Training Accuracy 0.445\n",
      "Loss 481.6954 50 2\n",
      "Training Accuracy 0.395\n",
      "Loss 464.30164 51 2\n",
      "Training Accuracy 0.385\n",
      "Loss 486.25858 52 2\n",
      "Training Accuracy 0.39\n",
      "Loss 484.14862 53 2\n",
      "Training Accuracy 0.395\n",
      "Loss 466.31967 54 2\n",
      "Training Accuracy 0.375\n",
      "Loss 469.37817 55 2\n",
      "Training Accuracy 0.395\n",
      "Loss 446.84674 56 2\n",
      "Training Accuracy 0.405\n",
      "Loss 425.00803 57 2\n",
      "Training Accuracy 0.505\n",
      "Loss 403.93353 58 2\n",
      "Training Accuracy 0.45\n",
      "Loss 487.62292 59 2\n",
      "Training Accuracy 0.365\n",
      "Loss 465.4837 60 2\n",
      "Training Accuracy 0.405\n",
      "Loss 461.02615 61 2\n",
      "Training Accuracy 0.35\n",
      "Loss 447.51788 62 2\n",
      "Training Accuracy 0.43\n",
      "Loss 472.82367 63 2\n",
      "Training Accuracy 0.365\n",
      "Loss 480.9877 64 2\n",
      "Training Accuracy 0.4\n",
      "Loss 468.62042 65 2\n",
      "Training Accuracy 0.385\n",
      "Loss 447.19135 66 2\n",
      "Training Accuracy 0.38\n",
      "Loss 503.20413 67 2\n",
      "Training Accuracy 0.375\n",
      "Loss 475.00684 68 2\n",
      "Training Accuracy 0.39\n",
      "Loss 477.44922 69 2\n",
      "Training Accuracy 0.4\n",
      "Loss 472.1011 70 2\n",
      "Training Accuracy 0.42\n",
      "Loss 442.1811 71 2\n",
      "Training Accuracy 0.505\n",
      "Loss 468.5704 72 2\n",
      "Training Accuracy 0.365\n",
      "Loss 525.4979 73 2\n",
      "Training Accuracy 0.335\n",
      "Loss 535.8673 74 2\n",
      "Training Accuracy 0.37\n",
      "Loss 479.00592 75 2\n",
      "Training Accuracy 0.395\n",
      "Loss 460.66046 76 2\n",
      "Training Accuracy 0.415\n",
      "Loss 430.555 77 2\n",
      "Training Accuracy 0.415\n",
      "Loss 436.0908 78 2\n",
      "Training Accuracy 0.41\n",
      "Loss 411.08313 79 2\n",
      "Training Accuracy 0.395\n",
      "Loss 439.62582 80 2\n",
      "Training Accuracy 0.405\n",
      "Loss 497.89746 81 2\n",
      "Training Accuracy 0.395\n",
      "Loss 455.8631 82 2\n",
      "Training Accuracy 0.365\n",
      "Loss 449.08267 83 2\n",
      "Training Accuracy 0.405\n",
      "Loss 505.68643 84 2\n",
      "Training Accuracy 0.3\n",
      "Loss 450.26837 85 2\n",
      "Training Accuracy 0.42\n",
      "Loss 448.32535 86 2\n",
      "Training Accuracy 0.43\n",
      "Loss 498.73993 87 2\n",
      "Training Accuracy 0.38\n",
      "Loss 457.13995 88 2\n",
      "Training Accuracy 0.385\n",
      "Loss 514.7764 89 2\n",
      "Training Accuracy 0.38\n",
      "Loss 467.2095 90 2\n",
      "Training Accuracy 0.41\n",
      "Loss 492.1121 91 2\n",
      "Training Accuracy 0.36\n",
      "Loss 495.90985 92 2\n",
      "Training Accuracy 0.395\n",
      "Loss 460.46124 93 2\n",
      "Training Accuracy 0.375\n",
      "Loss 456.29288 94 2\n",
      "Training Accuracy 0.39\n",
      "Loss 422.5922 95 2\n",
      "Training Accuracy 0.435\n",
      "Loss 453.978 96 2\n",
      "Training Accuracy 0.385\n",
      "Loss 472.0958 97 2\n",
      "Training Accuracy 0.345\n",
      "Loss 488.87344 98 2\n",
      "Training Accuracy 0.335\n",
      "Loss 452.27036 99 2\n",
      "Training Accuracy 0.39\n",
      "Loss 489.5795 100 2\n",
      "Training Accuracy 0.42\n",
      "Loss 491.41876 101 2\n",
      "Training Accuracy 0.345\n",
      "Loss 414.1396 102 2\n",
      "Training Accuracy 0.44\n",
      "Loss 455.11877 103 2\n",
      "Training Accuracy 0.435\n",
      "Loss 443.92996 104 2\n",
      "Training Accuracy 0.37\n",
      "Loss 488.27603 105 2\n",
      "Training Accuracy 0.405\n",
      "Loss 468.50806 106 2\n",
      "Training Accuracy 0.395\n",
      "Loss 464.794 107 2\n",
      "Training Accuracy 0.345\n",
      "Loss 455.2589 108 2\n",
      "Training Accuracy 0.415\n",
      "Loss 468.30438 109 2\n",
      "Training Accuracy 0.425\n",
      "Loss 472.16437 110 2\n",
      "Training Accuracy 0.395\n",
      "Loss 444.53476 111 2\n",
      "Training Accuracy 0.42\n",
      "Loss 491.40747 112 2\n",
      "Training Accuracy 0.35\n",
      "Loss 498.02722 113 2\n",
      "Training Accuracy 0.395\n",
      "Loss 439.64697 114 2\n",
      "Training Accuracy 0.4\n",
      "Loss 490.13208 115 2\n",
      "Training Accuracy 0.365\n",
      "Loss 507.21817 116 2\n",
      "Training Accuracy 0.425\n",
      "Loss 426.99933 117 2\n",
      "Training Accuracy 0.475\n",
      "Loss 506.48746 118 2\n",
      "Training Accuracy 0.37\n",
      "Loss 546.177 119 2\n",
      "Training Accuracy 0.34\n",
      "Loss 495.21323 120 2\n",
      "Training Accuracy 0.35\n",
      "Loss 501.62555 121 2\n",
      "Training Accuracy 0.37\n",
      "Loss 444.6091 122 2\n",
      "Training Accuracy 0.4\n",
      "Loss 467.65125 123 2\n",
      "Training Accuracy 0.345\n",
      "Loss 452.73868 124 2\n",
      "Training Accuracy 0.385\n",
      "Loss 424.31454 125 2\n",
      "Training Accuracy 0.43\n",
      "Loss 465.82114 126 2\n",
      "Training Accuracy 0.36\n",
      "Loss 405.2972 127 2\n",
      "Training Accuracy 0.45\n",
      "Loss 442.50537 128 2\n",
      "Training Accuracy 0.415\n",
      "Loss 437.5697 129 2\n",
      "Training Accuracy 0.39\n",
      "Loss 429.90295 130 2\n",
      "Training Accuracy 0.435\n",
      "Loss 421.06488 131 2\n",
      "Training Accuracy 0.405\n",
      "Loss 433.98743 132 2\n",
      "Training Accuracy 0.405\n",
      "Loss 464.71777 133 2\n",
      "Training Accuracy 0.39\n",
      "Loss 448.32477 134 2\n",
      "Training Accuracy 0.415\n",
      "Loss 409.49127 135 2\n",
      "Training Accuracy 0.46\n",
      "Loss 495.39636 136 2\n",
      "Training Accuracy 0.36\n",
      "Loss 446.96155 137 2\n",
      "Training Accuracy 0.385\n",
      "Loss 468.71707 138 2\n",
      "Training Accuracy 0.42\n",
      "Loss 516.0373 139 2\n",
      "Training Accuracy 0.37\n",
      "Loss 449.10275 140 2\n",
      "Training Accuracy 0.385\n",
      "Loss 476.51468 141 2\n",
      "Training Accuracy 0.41\n",
      "Loss 441.40863 142 2\n",
      "Training Accuracy 0.425\n",
      "Loss 419.49734 143 2\n",
      "Training Accuracy 0.405\n",
      "Loss 444.40027 144 2\n",
      "Training Accuracy 0.44\n",
      "Loss 465.1784 145 2\n",
      "Training Accuracy 0.425\n",
      "Loss 419.12424 146 2\n",
      "Training Accuracy 0.425\n",
      "Loss 454.85 147 2\n",
      "Training Accuracy 0.46\n",
      "Loss 461.49844 148 2\n",
      "Training Accuracy 0.38\n",
      "Loss 420.35034 149 2\n",
      "Training Accuracy 0.455\n",
      "Loss 464.3557 150 2\n",
      "Training Accuracy 0.395\n",
      "Loss 461.1513 151 2\n",
      "Training Accuracy 0.44\n",
      "Loss 477.95074 152 2\n",
      "Training Accuracy 0.425\n",
      "Loss 454.4179 153 2\n",
      "Training Accuracy 0.385\n",
      "Loss 483.13184 154 2\n",
      "Training Accuracy 0.4\n",
      "Loss 423.68387 155 2\n",
      "Training Accuracy 0.41\n",
      "Loss 471.64545 156 2\n",
      "Training Accuracy 0.355\n",
      "Loss 424.4978 157 2\n",
      "Training Accuracy 0.41\n",
      "Loss 472.016 158 2\n",
      "Training Accuracy 0.405\n",
      "Loss 499.4594 159 2\n",
      "Training Accuracy 0.365\n",
      "Loss 416.845 160 2\n",
      "Training Accuracy 0.405\n",
      "Loss 490.22858 161 2\n",
      "Training Accuracy 0.33\n",
      "Loss 426.25177 162 2\n",
      "Training Accuracy 0.43\n",
      "Loss 466.86667 163 2\n",
      "Training Accuracy 0.37\n",
      "Loss 396.46027 164 2\n",
      "Training Accuracy 0.455\n",
      "Loss 433.11884 165 2\n",
      "Training Accuracy 0.45\n",
      "Loss 502.5375 166 2\n",
      "Training Accuracy 0.365\n",
      "Loss 384.50592 167 2\n",
      "Training Accuracy 0.46\n",
      "Loss 481.58423 168 2\n",
      "Training Accuracy 0.415\n",
      "Loss 424.3643 169 2\n",
      "Training Accuracy 0.435\n",
      "Loss 433.59174 170 2\n",
      "Training Accuracy 0.445\n",
      "Loss 463.1384 171 2\n",
      "Training Accuracy 0.44\n",
      "Loss 448.703 172 2\n",
      "Training Accuracy 0.43\n",
      "Loss 507.74915 173 2\n",
      "Training Accuracy 0.355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 393.552 174 2\n",
      "Training Accuracy 0.465\n",
      "Loss 457.04504 175 2\n",
      "Training Accuracy 0.42\n",
      "Loss 411.79056 176 2\n",
      "Training Accuracy 0.5\n",
      "Loss 494.8487 177 2\n",
      "Training Accuracy 0.375\n",
      "Loss 407.06403 178 2\n",
      "Training Accuracy 0.44\n",
      "Loss 491.2289 179 2\n",
      "Training Accuracy 0.37\n",
      "Loss 441.6644 180 2\n",
      "Training Accuracy 0.385\n",
      "Loss 395.4015 181 2\n",
      "Training Accuracy 0.41\n",
      "Loss 488.9151 182 2\n",
      "Training Accuracy 0.34\n",
      "Loss 458.34717 183 2\n",
      "Training Accuracy 0.385\n",
      "Loss 402.25824 184 2\n",
      "Training Accuracy 0.485\n",
      "Loss 424.96146 185 2\n",
      "Training Accuracy 0.43\n",
      "Loss 433.8869 186 2\n",
      "Training Accuracy 0.45\n",
      "Loss 488.35516 187 2\n",
      "Training Accuracy 0.385\n",
      "Loss 446.9637 188 2\n",
      "Training Accuracy 0.445\n",
      "Loss 453.72974 189 2\n",
      "Training Accuracy 0.39\n",
      "Loss 449.95544 190 2\n",
      "Training Accuracy 0.415\n",
      "Loss 426.21487 191 2\n",
      "Training Accuracy 0.42\n",
      "Loss 447.13803 192 2\n",
      "Training Accuracy 0.405\n",
      "Loss 400.46774 193 2\n",
      "Training Accuracy 0.485\n",
      "Loss 440.84296 194 2\n",
      "Training Accuracy 0.415\n",
      "Loss 418.48065 195 2\n",
      "Training Accuracy 0.42\n",
      "Loss 457.09854 196 2\n",
      "Training Accuracy 0.405\n",
      "Loss 447.84235 197 2\n",
      "Training Accuracy 0.415\n",
      "Loss 416.05142 198 2\n",
      "Training Accuracy 0.41\n",
      "Loss 364.9926 199 2\n",
      "Training Accuracy 0.52\n",
      "Loss 456.68634 200 2\n",
      "Training Accuracy 0.38\n",
      "Loss 432.69885 201 2\n",
      "Training Accuracy 0.395\n",
      "Loss 471.84335 202 2\n",
      "Training Accuracy 0.36\n",
      "Loss 466.46393 203 2\n",
      "Training Accuracy 0.42\n",
      "Loss 450.29337 204 2\n",
      "Training Accuracy 0.435\n",
      "Loss 452.18848 205 2\n",
      "Training Accuracy 0.41\n",
      "Loss 441.1265 206 2\n",
      "Training Accuracy 0.41\n",
      "Loss 396.2236 207 2\n",
      "Training Accuracy 0.435\n",
      "Loss 463.54248 208 2\n",
      "Training Accuracy 0.4\n",
      "Loss 461.55234 209 2\n",
      "Training Accuracy 0.395\n",
      "Loss 417.61264 210 2\n",
      "Training Accuracy 0.415\n",
      "Loss 442.5068 211 2\n",
      "Training Accuracy 0.41\n",
      "Loss 397.3131 212 2\n",
      "Training Accuracy 0.46\n",
      "Loss 509.8586 213 2\n",
      "Training Accuracy 0.355\n",
      "Loss 452.11575 214 2\n",
      "Training Accuracy 0.37\n",
      "Loss 440.89648 215 2\n",
      "Training Accuracy 0.395\n",
      "Loss 500.1446 216 2\n",
      "Training Accuracy 0.37\n",
      "Loss 412.785 217 2\n",
      "Training Accuracy 0.38\n",
      "Loss 465.45148 218 2\n",
      "Training Accuracy 0.375\n",
      "Loss 441.91473 219 2\n",
      "Training Accuracy 0.415\n",
      "Loss 439.92285 220 2\n",
      "Training Accuracy 0.455\n",
      "Loss 479.61844 221 2\n",
      "Training Accuracy 0.39\n",
      "Loss 423.4397 222 2\n",
      "Training Accuracy 0.465\n",
      "Loss 463.34537 223 2\n",
      "Training Accuracy 0.37\n",
      "Loss 463.40274 224 2\n",
      "Training Accuracy 0.395\n",
      "Loss 464.42374 225 2\n",
      "Training Accuracy 0.405\n",
      "Loss 417.60052 226 2\n",
      "Training Accuracy 0.425\n",
      "Loss 494.59778 227 2\n",
      "Training Accuracy 0.375\n",
      "Loss 477.12405 228 2\n",
      "Training Accuracy 0.34\n",
      "Loss 432.623 229 2\n",
      "Training Accuracy 0.425\n",
      "Loss 432.59122 230 2\n",
      "Training Accuracy 0.405\n",
      "Loss 378.4524 231 2\n",
      "Training Accuracy 0.5\n",
      "Loss 475.64325 232 2\n",
      "Training Accuracy 0.4\n",
      "Loss 451.94385 233 2\n",
      "Training Accuracy 0.4\n",
      "Loss 441.36703 234 2\n",
      "Training Accuracy 0.415\n",
      "Loss 434.94974 235 2\n",
      "Training Accuracy 0.405\n",
      "Loss 403.84344 236 2\n",
      "Training Accuracy 0.475\n",
      "Loss 477.89197 237 2\n",
      "Training Accuracy 0.38\n",
      "Loss 429.5248 238 2\n",
      "Training Accuracy 0.405\n",
      "Loss 502.1009 239 2\n",
      "Training Accuracy 0.415\n",
      "Loss 446.49692 240 2\n",
      "Training Accuracy 0.395\n",
      "Loss 473.37482 241 2\n",
      "Training Accuracy 0.385\n",
      "Loss 397.39682 242 2\n",
      "Training Accuracy 0.46\n",
      "Loss 408.39035 243 2\n",
      "Training Accuracy 0.41\n",
      "Loss 422.85672 244 2\n",
      "Training Accuracy 0.42\n",
      "Loss 412.228 245 2\n",
      "Training Accuracy 0.41\n",
      "Loss 455.65384 246 2\n",
      "Training Accuracy 0.395\n",
      "Loss 377.082 247 2\n",
      "Training Accuracy 0.425\n",
      "Loss 411.85727 248 2\n",
      "Training Accuracy 0.425\n",
      "Loss 417.73145 249 2\n",
      "Training Accuracy 0.46\n",
      "Loss 442.8568 250 2\n",
      "Training Accuracy 0.41\n",
      "Loss 441.43607 251 2\n",
      "Training Accuracy 0.345\n",
      "Loss 424.54092 252 2\n",
      "Training Accuracy 0.39\n",
      "Loss 423.58597 253 2\n",
      "Training Accuracy 0.47\n",
      "Loss 440.9668 254 2\n",
      "Training Accuracy 0.39\n",
      "Loss 407.5546 255 2\n",
      "Training Accuracy 0.415\n",
      "Loss 456.68088 256 2\n",
      "Training Accuracy 0.375\n",
      "Loss 410.36447 257 2\n",
      "Training Accuracy 0.425\n",
      "Loss 420.52936 258 2\n",
      "Training Accuracy 0.405\n",
      "Loss 438.7557 259 2\n",
      "Training Accuracy 0.4\n",
      "Loss 401.07794 260 2\n",
      "Training Accuracy 0.49\n",
      "Loss 477.18625 261 2\n",
      "Training Accuracy 0.385\n",
      "Loss 422.99423 262 2\n",
      "Training Accuracy 0.395\n",
      "Loss 526.79156 263 2\n",
      "Training Accuracy 0.35\n",
      "Loss 454.13138 264 2\n",
      "Training Accuracy 0.38\n",
      "Loss 479.38757 265 2\n",
      "Training Accuracy 0.395\n",
      "Loss 437.01175 266 2\n",
      "Training Accuracy 0.37\n",
      "Loss 431.42667 267 2\n",
      "Training Accuracy 0.435\n",
      "Loss 461.04306 268 2\n",
      "Training Accuracy 0.415\n",
      "Loss 392.1392 269 2\n",
      "Training Accuracy 0.45\n",
      "Loss 406.44598 270 2\n",
      "Training Accuracy 0.445\n",
      "Loss 494.29013 271 2\n",
      "Training Accuracy 0.34\n",
      "Loss 444.30783 272 2\n",
      "Training Accuracy 0.41\n",
      "Loss 411.34668 273 2\n",
      "Training Accuracy 0.415\n",
      "Loss 426.54636 274 2\n",
      "Training Accuracy 0.375\n",
      "Loss 480.86472 275 2\n",
      "Training Accuracy 0.385\n",
      "Loss 408.5616 276 2\n",
      "Training Accuracy 0.435\n",
      "Loss 545.12555 277 2\n",
      "Training Accuracy 0.365\n",
      "Loss 411.8365 278 2\n",
      "Training Accuracy 0.435\n",
      "Loss 407.4947 279 2\n",
      "Training Accuracy 0.43\n",
      "Loss 398.77972 280 2\n",
      "Training Accuracy 0.43\n",
      "Loss 426.65863 281 2\n",
      "Training Accuracy 0.43\n",
      "Loss 431.55472 282 2\n",
      "Training Accuracy 0.45\n",
      "Loss 394.21973 283 2\n",
      "Training Accuracy 0.425\n",
      "Loss 435.71326 284 2\n",
      "Training Accuracy 0.43\n",
      "Loss 481.29745 285 2\n",
      "Training Accuracy 0.385\n",
      "Loss 437.98898 286 2\n",
      "Training Accuracy 0.435\n",
      "Loss 418.08975 287 2\n",
      "Training Accuracy 0.445\n",
      "Loss 443.63528 288 2\n",
      "Training Accuracy 0.45\n",
      "Loss 383.2766 289 2\n",
      "Training Accuracy 0.495\n",
      "Loss 449.28085 290 2\n",
      "Training Accuracy 0.43\n",
      "Loss 449.3697 291 2\n",
      "Training Accuracy 0.41\n",
      "Loss 277.45462 292 2\n",
      "Training Accuracy 0.41666666\n",
      "Loss 402.72318 1 3\n",
      "Training Accuracy 0.47\n",
      "Loss 417.82513 2 3\n",
      "Training Accuracy 0.39\n",
      "Loss 466.1862 3 3\n",
      "Training Accuracy 0.425\n",
      "Loss 432.69662 4 3\n",
      "Training Accuracy 0.475\n",
      "Loss 388.37137 5 3\n",
      "Training Accuracy 0.495\n",
      "Loss 437.84427 6 3\n",
      "Training Accuracy 0.445\n",
      "Loss 416.652 7 3\n",
      "Training Accuracy 0.455\n",
      "Loss 516.7716 8 3\n",
      "Training Accuracy 0.405\n",
      "Loss 445.7459 9 3\n",
      "Training Accuracy 0.335\n",
      "Loss 427.73523 10 3\n",
      "Training Accuracy 0.445\n",
      "Loss 482.29834 11 3\n",
      "Training Accuracy 0.435\n",
      "Loss 424.19324 12 3\n",
      "Training Accuracy 0.405\n",
      "Loss 401.66708 13 3\n",
      "Training Accuracy 0.44\n",
      "Loss 450.26923 14 3\n",
      "Training Accuracy 0.415\n",
      "Loss 413.43735 15 3\n",
      "Training Accuracy 0.435\n",
      "Loss 438.95435 16 3\n",
      "Training Accuracy 0.365\n",
      "Loss 420.57303 17 3\n",
      "Training Accuracy 0.44\n",
      "Loss 425.11337 18 3\n",
      "Training Accuracy 0.43\n",
      "Loss 441.15604 19 3\n",
      "Training Accuracy 0.415\n",
      "Loss 425.97723 20 3\n",
      "Training Accuracy 0.36\n",
      "Loss 433.6848 21 3\n",
      "Training Accuracy 0.465\n",
      "Loss 469.52856 22 3\n",
      "Training Accuracy 0.39\n",
      "Loss 469.03604 23 3\n",
      "Training Accuracy 0.415\n",
      "Loss 426.68704 24 3\n",
      "Training Accuracy 0.38\n",
      "Loss 422.39215 25 3\n",
      "Training Accuracy 0.405\n",
      "Loss 458.39777 26 3\n",
      "Training Accuracy 0.365\n",
      "Loss 420.8236 27 3\n",
      "Training Accuracy 0.435\n",
      "Loss 430.13657 28 3\n",
      "Training Accuracy 0.375\n",
      "Loss 404.91245 29 3\n",
      "Training Accuracy 0.445\n",
      "Loss 445.46106 30 3\n",
      "Training Accuracy 0.39\n",
      "Loss 462.04657 31 3\n",
      "Training Accuracy 0.41\n",
      "Loss 430.24088 32 3\n",
      "Training Accuracy 0.41\n",
      "Loss 430.41055 33 3\n",
      "Training Accuracy 0.435\n",
      "Loss 419.7042 34 3\n",
      "Training Accuracy 0.435\n",
      "Loss 376.99805 35 3\n",
      "Training Accuracy 0.465\n",
      "Loss 423.9909 36 3\n",
      "Training Accuracy 0.375\n",
      "Loss 436.83795 37 3\n",
      "Training Accuracy 0.46\n",
      "Loss 430.16 38 3\n",
      "Training Accuracy 0.405\n",
      "Loss 384.6222 39 3\n",
      "Training Accuracy 0.435\n",
      "Loss 387.92847 40 3\n",
      "Training Accuracy 0.495\n",
      "Loss 399.255 41 3\n",
      "Training Accuracy 0.435\n",
      "Loss 465.03064 42 3\n",
      "Training Accuracy 0.35\n",
      "Loss 437.45645 43 3\n",
      "Training Accuracy 0.42\n",
      "Loss 409.49582 44 3\n",
      "Training Accuracy 0.42\n",
      "Loss 438.06158 45 3\n",
      "Training Accuracy 0.39\n",
      "Loss 444.86795 46 3\n",
      "Training Accuracy 0.41\n",
      "Loss 422.8168 47 3\n",
      "Training Accuracy 0.445\n",
      "Loss 416.0523 48 3\n",
      "Training Accuracy 0.47\n",
      "Loss 431.79837 49 3\n",
      "Training Accuracy 0.43\n",
      "Loss 447.08856 50 3\n",
      "Training Accuracy 0.41\n",
      "Loss 415.25955 51 3\n",
      "Training Accuracy 0.48\n",
      "Loss 433.239 52 3\n",
      "Training Accuracy 0.42\n",
      "Loss 448.66165 53 3\n",
      "Training Accuracy 0.41\n",
      "Loss 425.78363 54 3\n",
      "Training Accuracy 0.395\n",
      "Loss 433.39032 55 3\n",
      "Training Accuracy 0.38\n",
      "Loss 399.11267 56 3\n",
      "Training Accuracy 0.435\n",
      "Loss 380.76804 57 3\n",
      "Training Accuracy 0.535\n",
      "Loss 367.85217 58 3\n",
      "Training Accuracy 0.465\n",
      "Loss 452.5822 59 3\n",
      "Training Accuracy 0.425\n",
      "Loss 430.2841 60 3\n",
      "Training Accuracy 0.445\n",
      "Loss 406.6544 61 3\n",
      "Training Accuracy 0.4\n",
      "Loss 406.6482 62 3\n",
      "Training Accuracy 0.465\n",
      "Loss 424.06766 63 3\n",
      "Training Accuracy 0.405\n",
      "Loss 435.30203 64 3\n",
      "Training Accuracy 0.41\n",
      "Loss 437.3831 65 3\n",
      "Training Accuracy 0.385\n",
      "Loss 414.95392 66 3\n",
      "Training Accuracy 0.4\n",
      "Loss 461.85968 67 3\n",
      "Training Accuracy 0.445\n",
      "Loss 422.33484 68 3\n",
      "Training Accuracy 0.395\n",
      "Loss 430.22247 69 3\n",
      "Training Accuracy 0.43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 426.23056 70 3\n",
      "Training Accuracy 0.475\n",
      "Loss 412.8446 71 3\n",
      "Training Accuracy 0.475\n",
      "Loss 425.6004 72 3\n",
      "Training Accuracy 0.4\n",
      "Loss 465.0999 73 3\n",
      "Training Accuracy 0.395\n",
      "Loss 490.86093 74 3\n",
      "Training Accuracy 0.4\n",
      "Loss 431.859 75 3\n",
      "Training Accuracy 0.42\n",
      "Loss 415.45602 76 3\n",
      "Training Accuracy 0.455\n",
      "Loss 391.595 77 3\n",
      "Training Accuracy 0.445\n",
      "Loss 406.41965 78 3\n",
      "Training Accuracy 0.465\n",
      "Loss 385.33273 79 3\n",
      "Training Accuracy 0.4\n",
      "Loss 398.8997 80 3\n",
      "Training Accuracy 0.425\n",
      "Loss 451.54453 81 3\n",
      "Training Accuracy 0.395\n",
      "Loss 414.09378 82 3\n",
      "Training Accuracy 0.425\n",
      "Loss 406.27145 83 3\n",
      "Training Accuracy 0.435\n",
      "Loss 462.80597 84 3\n",
      "Training Accuracy 0.395\n",
      "Loss 406.68686 85 3\n",
      "Training Accuracy 0.46\n",
      "Loss 420.83786 86 3\n",
      "Training Accuracy 0.43\n",
      "Loss 452.00433 87 3\n",
      "Training Accuracy 0.42\n",
      "Loss 432.15103 88 3\n",
      "Training Accuracy 0.4\n",
      "Loss 462.90573 89 3\n",
      "Training Accuracy 0.4\n",
      "Loss 412.22046 90 3\n",
      "Training Accuracy 0.44\n",
      "Loss 449.80386 91 3\n",
      "Training Accuracy 0.4\n",
      "Loss 453.3672 92 3\n",
      "Training Accuracy 0.44\n",
      "Loss 408.24033 93 3\n",
      "Training Accuracy 0.47\n",
      "Loss 422.88 94 3\n",
      "Training Accuracy 0.405\n",
      "Loss 394.82712 95 3\n",
      "Training Accuracy 0.42\n",
      "Loss 396.78937 96 3\n",
      "Training Accuracy 0.465\n",
      "Loss 439.31787 97 3\n",
      "Training Accuracy 0.375\n",
      "Loss 443.16064 98 3\n",
      "Training Accuracy 0.45\n",
      "Loss 402.45404 99 3\n",
      "Training Accuracy 0.405\n",
      "Loss 436.70325 100 3\n",
      "Training Accuracy 0.48\n",
      "Loss 440.37823 101 3\n",
      "Training Accuracy 0.355\n",
      "Loss 377.15564 102 3\n",
      "Training Accuracy 0.48\n",
      "Loss 421.43698 103 3\n",
      "Training Accuracy 0.41\n",
      "Loss 400.69214 104 3\n",
      "Training Accuracy 0.4\n",
      "Loss 442.92493 105 3\n",
      "Training Accuracy 0.415\n",
      "Loss 435.0069 106 3\n",
      "Training Accuracy 0.435\n",
      "Loss 428.95236 107 3\n",
      "Training Accuracy 0.36\n",
      "Loss 423.48584 108 3\n",
      "Training Accuracy 0.42\n",
      "Loss 426.3001 109 3\n",
      "Training Accuracy 0.41\n",
      "Loss 423.5703 110 3\n",
      "Training Accuracy 0.41\n",
      "Loss 411.62003 111 3\n",
      "Training Accuracy 0.41\n",
      "Loss 441.43558 112 3\n",
      "Training Accuracy 0.41\n",
      "Loss 466.91977 113 3\n",
      "Training Accuracy 0.4\n",
      "Loss 410.9149 114 3\n",
      "Training Accuracy 0.395\n",
      "Loss 451.22812 115 3\n",
      "Training Accuracy 0.4\n",
      "Loss 465.08093 116 3\n",
      "Training Accuracy 0.445\n",
      "Loss 384.39468 117 3\n",
      "Training Accuracy 0.49\n",
      "Loss 466.74295 118 3\n",
      "Training Accuracy 0.41\n",
      "Loss 502.03735 119 3\n",
      "Training Accuracy 0.355\n",
      "Loss 453.67694 120 3\n",
      "Training Accuracy 0.365\n",
      "Loss 461.8237 121 3\n",
      "Training Accuracy 0.385\n",
      "Loss 393.5842 122 3\n",
      "Training Accuracy 0.43\n",
      "Loss 417.50037 123 3\n",
      "Training Accuracy 0.395\n",
      "Loss 405.84064 124 3\n",
      "Training Accuracy 0.475\n",
      "Loss 374.98273 125 3\n",
      "Training Accuracy 0.47\n",
      "Loss 424.78055 126 3\n",
      "Training Accuracy 0.4\n",
      "Loss 380.12915 127 3\n",
      "Training Accuracy 0.45\n",
      "Loss 392.5714 128 3\n",
      "Training Accuracy 0.455\n",
      "Loss 388.66986 129 3\n",
      "Training Accuracy 0.46\n",
      "Loss 393.67984 130 3\n",
      "Training Accuracy 0.455\n",
      "Loss 381.7673 131 3\n",
      "Training Accuracy 0.49\n",
      "Loss 392.8123 132 3\n",
      "Training Accuracy 0.43\n",
      "Loss 420.5863 133 3\n",
      "Training Accuracy 0.415\n",
      "Loss 407.21985 134 3\n",
      "Training Accuracy 0.445\n",
      "Loss 369.08844 135 3\n",
      "Training Accuracy 0.49\n",
      "Loss 454.91803 136 3\n",
      "Training Accuracy 0.415\n",
      "Loss 409.7597 137 3\n",
      "Training Accuracy 0.435\n",
      "Loss 408.40036 138 3\n",
      "Training Accuracy 0.465\n",
      "Loss 475.18427 139 3\n",
      "Training Accuracy 0.415\n",
      "Loss 400.5393 140 3\n",
      "Training Accuracy 0.49\n",
      "Loss 443.78247 141 3\n",
      "Training Accuracy 0.44\n",
      "Loss 413.5908 142 3\n",
      "Training Accuracy 0.41\n",
      "Loss 366.3882 143 3\n",
      "Training Accuracy 0.455\n",
      "Loss 405.3299 144 3\n",
      "Training Accuracy 0.465\n",
      "Loss 424.19873 145 3\n",
      "Training Accuracy 0.48\n",
      "Loss 376.39923 146 3\n",
      "Training Accuracy 0.45\n",
      "Loss 410.44067 147 3\n",
      "Training Accuracy 0.44\n",
      "Loss 417.3343 148 3\n",
      "Training Accuracy 0.42\n",
      "Loss 382.56845 149 3\n",
      "Training Accuracy 0.5\n",
      "Loss 422.55338 150 3\n",
      "Training Accuracy 0.41\n",
      "Loss 417.85297 151 3\n",
      "Training Accuracy 0.435\n",
      "Loss 445.54437 152 3\n",
      "Training Accuracy 0.415\n",
      "Loss 411.45135 153 3\n",
      "Training Accuracy 0.415\n",
      "Loss 442.0337 154 3\n",
      "Training Accuracy 0.44\n",
      "Loss 387.06122 155 3\n",
      "Training Accuracy 0.435\n",
      "Loss 438.05588 156 3\n",
      "Training Accuracy 0.42\n",
      "Loss 380.98157 157 3\n",
      "Training Accuracy 0.445\n",
      "Loss 425.0094 158 3\n",
      "Training Accuracy 0.435\n",
      "Loss 454.81012 159 3\n",
      "Training Accuracy 0.475\n",
      "Loss 383.45258 160 3\n",
      "Training Accuracy 0.45\n",
      "Loss 450.61725 161 3\n",
      "Training Accuracy 0.375\n",
      "Loss 390.2424 162 3\n",
      "Training Accuracy 0.47\n",
      "Loss 424.45972 163 3\n",
      "Training Accuracy 0.395\n",
      "Loss 358.39218 164 3\n",
      "Training Accuracy 0.48\n",
      "Loss 394.55884 165 3\n",
      "Training Accuracy 0.46\n",
      "Loss 455.34158 166 3\n",
      "Training Accuracy 0.385\n",
      "Loss 349.1237 167 3\n",
      "Training Accuracy 0.495\n",
      "Loss 440.01923 168 3\n",
      "Training Accuracy 0.485\n",
      "Loss 392.84637 169 3\n",
      "Training Accuracy 0.425\n",
      "Loss 393.1466 170 3\n",
      "Training Accuracy 0.465\n",
      "Loss 427.23703 171 3\n",
      "Training Accuracy 0.465\n",
      "Loss 409.23148 172 3\n",
      "Training Accuracy 0.455\n",
      "Loss 471.25845 173 3\n",
      "Training Accuracy 0.395\n",
      "Loss 362.21365 174 3\n",
      "Training Accuracy 0.505\n",
      "Loss 405.86566 175 3\n",
      "Training Accuracy 0.455\n",
      "Loss 370.94244 176 3\n",
      "Training Accuracy 0.5\n",
      "Loss 461.65063 177 3\n",
      "Training Accuracy 0.37\n",
      "Loss 379.89722 178 3\n",
      "Training Accuracy 0.455\n",
      "Loss 448.39404 179 3\n",
      "Training Accuracy 0.415\n",
      "Loss 407.18137 180 3\n",
      "Training Accuracy 0.415\n",
      "Loss 359.76843 181 3\n",
      "Training Accuracy 0.45\n",
      "Loss 434.90817 182 3\n",
      "Training Accuracy 0.375\n",
      "Loss 422.5612 183 3\n",
      "Training Accuracy 0.41\n",
      "Loss 366.18405 184 3\n",
      "Training Accuracy 0.485\n",
      "Loss 379.5448 185 3\n",
      "Training Accuracy 0.495\n",
      "Loss 402.0812 186 3\n",
      "Training Accuracy 0.47\n",
      "Loss 445.9464 187 3\n",
      "Training Accuracy 0.395\n",
      "Loss 417.89096 188 3\n",
      "Training Accuracy 0.445\n",
      "Loss 419.80347 189 3\n",
      "Training Accuracy 0.445\n",
      "Loss 408.25436 190 3\n",
      "Training Accuracy 0.48\n",
      "Loss 387.19415 191 3\n",
      "Training Accuracy 0.485\n",
      "Loss 403.9301 192 3\n",
      "Training Accuracy 0.465\n",
      "Loss 370.09982 193 3\n",
      "Training Accuracy 0.485\n",
      "Loss 390.12695 194 3\n",
      "Training Accuracy 0.455\n",
      "Loss 383.67438 195 3\n",
      "Training Accuracy 0.435\n",
      "Loss 410.6473 196 3\n",
      "Training Accuracy 0.455\n",
      "Loss 403.4972 197 3\n",
      "Training Accuracy 0.445\n",
      "Loss 378.30045 198 3\n",
      "Training Accuracy 0.46\n",
      "Loss 334.33502 199 3\n",
      "Training Accuracy 0.55\n",
      "Loss 419.25974 200 3\n",
      "Training Accuracy 0.415\n",
      "Loss 399.39923 201 3\n",
      "Training Accuracy 0.415\n",
      "Loss 414.52258 202 3\n",
      "Training Accuracy 0.4\n",
      "Loss 419.24432 203 3\n",
      "Training Accuracy 0.46\n",
      "Loss 413.73645 204 3\n",
      "Training Accuracy 0.445\n",
      "Loss 424.68372 205 3\n",
      "Training Accuracy 0.45\n",
      "Loss 404.73557 206 3\n",
      "Training Accuracy 0.465\n",
      "Loss 366.92508 207 3\n",
      "Training Accuracy 0.45\n",
      "Loss 421.8866 208 3\n",
      "Training Accuracy 0.465\n",
      "Loss 422.26334 209 3\n",
      "Training Accuracy 0.405\n",
      "Loss 377.9143 210 3\n",
      "Training Accuracy 0.45\n",
      "Loss 412.44315 211 3\n",
      "Training Accuracy 0.425\n",
      "Loss 356.83963 212 3\n",
      "Training Accuracy 0.5\n",
      "Loss 461.30997 213 3\n",
      "Training Accuracy 0.41\n",
      "Loss 413.88507 214 3\n",
      "Training Accuracy 0.445\n",
      "Loss 408.75793 215 3\n",
      "Training Accuracy 0.435\n",
      "Loss 459.5454 216 3\n",
      "Training Accuracy 0.405\n",
      "Loss 381.23193 217 3\n",
      "Training Accuracy 0.43\n",
      "Loss 421.73297 218 3\n",
      "Training Accuracy 0.385\n",
      "Loss 393.76837 219 3\n",
      "Training Accuracy 0.445\n",
      "Loss 391.32303 220 3\n",
      "Training Accuracy 0.49\n",
      "Loss 438.9571 221 3\n",
      "Training Accuracy 0.38\n",
      "Loss 380.87888 222 3\n",
      "Training Accuracy 0.485\n",
      "Loss 424.54868 223 3\n",
      "Training Accuracy 0.405\n",
      "Loss 431.3827 224 3\n",
      "Training Accuracy 0.37\n",
      "Loss 426.3168 225 3\n",
      "Training Accuracy 0.455\n",
      "Loss 379.54102 226 3\n",
      "Training Accuracy 0.42\n",
      "Loss 458.05447 227 3\n",
      "Training Accuracy 0.41\n",
      "Loss 441.5805 228 3\n",
      "Training Accuracy 0.37\n",
      "Loss 389.9688 229 3\n",
      "Training Accuracy 0.495\n",
      "Loss 397.36105 230 3\n",
      "Training Accuracy 0.46\n",
      "Loss 335.3911 231 3\n",
      "Training Accuracy 0.51\n",
      "Loss 419.97333 232 3\n",
      "Training Accuracy 0.445\n",
      "Loss 411.57748 233 3\n",
      "Training Accuracy 0.42\n",
      "Loss 408.80823 234 3\n",
      "Training Accuracy 0.435\n",
      "Loss 400.8644 235 3\n",
      "Training Accuracy 0.44\n",
      "Loss 368.34515 236 3\n",
      "Training Accuracy 0.49\n",
      "Loss 423.98892 237 3\n",
      "Training Accuracy 0.445\n",
      "Loss 391.53226 238 3\n",
      "Training Accuracy 0.45\n",
      "Loss 454.807 239 3\n",
      "Training Accuracy 0.48\n",
      "Loss 407.70288 240 3\n",
      "Training Accuracy 0.415\n",
      "Loss 433.7879 241 3\n",
      "Training Accuracy 0.415\n",
      "Loss 358.37442 242 3\n",
      "Training Accuracy 0.485\n",
      "Loss 360.6759 243 3\n",
      "Training Accuracy 0.455\n",
      "Loss 391.2 244 3\n",
      "Training Accuracy 0.42\n",
      "Loss 387.6525 245 3\n",
      "Training Accuracy 0.455\n",
      "Loss 407.40884 246 3\n",
      "Training Accuracy 0.43\n",
      "Loss 336.529 247 3\n",
      "Training Accuracy 0.48\n",
      "Loss 376.9397 248 3\n",
      "Training Accuracy 0.43\n",
      "Loss 381.09555 249 3\n",
      "Training Accuracy 0.44\n",
      "Loss 406.55408 250 3\n",
      "Training Accuracy 0.435\n",
      "Loss 403.40402 251 3\n",
      "Training Accuracy 0.41\n",
      "Loss 381.94745 252 3\n",
      "Training Accuracy 0.43\n",
      "Loss 391.91275 253 3\n",
      "Training Accuracy 0.46\n",
      "Loss 394.46878 254 3\n",
      "Training Accuracy 0.47\n",
      "Loss 356.0943 255 3\n",
      "Training Accuracy 0.52\n",
      "Loss 410.22662 256 3\n",
      "Training Accuracy 0.44\n",
      "Loss 377.32333 257 3\n",
      "Training Accuracy 0.445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 389.24997 258 3\n",
      "Training Accuracy 0.465\n",
      "Loss 395.69238 259 3\n",
      "Training Accuracy 0.46\n",
      "Loss 357.51022 260 3\n",
      "Training Accuracy 0.51\n",
      "Loss 427.88184 261 3\n",
      "Training Accuracy 0.425\n",
      "Loss 392.10388 262 3\n",
      "Training Accuracy 0.405\n",
      "Loss 484.63254 263 3\n",
      "Training Accuracy 0.39\n",
      "Loss 428.91498 264 3\n",
      "Training Accuracy 0.44\n",
      "Loss 430.19666 265 3\n",
      "Training Accuracy 0.475\n",
      "Loss 392.87756 266 3\n",
      "Training Accuracy 0.44\n",
      "Loss 406.45404 267 3\n",
      "Training Accuracy 0.44\n",
      "Loss 420.97177 268 3\n",
      "Training Accuracy 0.44\n",
      "Loss 355.45755 269 3\n",
      "Training Accuracy 0.435\n",
      "Loss 373.94568 270 3\n",
      "Training Accuracy 0.49\n",
      "Loss 460.37106 271 3\n",
      "Training Accuracy 0.345\n",
      "Loss 412.8084 272 3\n",
      "Training Accuracy 0.415\n",
      "Loss 381.09848 273 3\n",
      "Training Accuracy 0.455\n",
      "Loss 381.05994 274 3\n",
      "Training Accuracy 0.5\n",
      "Loss 428.82407 275 3\n",
      "Training Accuracy 0.37\n",
      "Loss 369.157 276 3\n",
      "Training Accuracy 0.455\n",
      "Loss 496.2953 277 3\n",
      "Training Accuracy 0.4\n",
      "Loss 361.4199 278 3\n",
      "Training Accuracy 0.51\n",
      "Loss 367.273 279 3\n",
      "Training Accuracy 0.495\n",
      "Loss 365.92105 280 3\n",
      "Training Accuracy 0.485\n",
      "Loss 394.12283 281 3\n",
      "Training Accuracy 0.455\n",
      "Loss 398.48395 282 3\n",
      "Training Accuracy 0.435\n",
      "Loss 364.5151 283 3\n",
      "Training Accuracy 0.445\n",
      "Loss 383.67966 284 3\n",
      "Training Accuracy 0.49\n",
      "Loss 436.85083 285 3\n",
      "Training Accuracy 0.435\n",
      "Loss 401.0741 286 3\n",
      "Training Accuracy 0.48\n",
      "Loss 384.2075 287 3\n",
      "Training Accuracy 0.49\n",
      "Loss 409.70743 288 3\n",
      "Training Accuracy 0.48\n",
      "Loss 353.46805 289 3\n",
      "Training Accuracy 0.445\n",
      "Loss 400.8464 290 3\n",
      "Training Accuracy 0.445\n",
      "Loss 399.63397 291 3\n",
      "Training Accuracy 0.425\n",
      "Loss 258.0903 292 3\n",
      "Training Accuracy 0.42424244\n",
      "Loss 366.4691 1 4\n",
      "Training Accuracy 0.45\n",
      "Loss 382.1522 2 4\n",
      "Training Accuracy 0.485\n",
      "Loss 425.26883 3 4\n",
      "Training Accuracy 0.475\n",
      "Loss 396.37198 4 4\n",
      "Training Accuracy 0.445\n",
      "Loss 351.71423 5 4\n",
      "Training Accuracy 0.48\n",
      "Loss 393.51086 6 4\n",
      "Training Accuracy 0.46\n",
      "Loss 374.4595 7 4\n",
      "Training Accuracy 0.49\n",
      "Loss 461.9913 8 4\n",
      "Training Accuracy 0.43\n",
      "Loss 398.61398 9 4\n",
      "Training Accuracy 0.43\n",
      "Loss 386.56436 10 4\n",
      "Training Accuracy 0.45\n",
      "Loss 438.27972 11 4\n",
      "Training Accuracy 0.47\n",
      "Loss 386.88486 12 4\n",
      "Training Accuracy 0.43\n",
      "Loss 366.8321 13 4\n",
      "Training Accuracy 0.455\n",
      "Loss 409.13568 14 4\n",
      "Training Accuracy 0.43\n",
      "Loss 384.40662 15 4\n",
      "Training Accuracy 0.46\n",
      "Loss 402.89542 16 4\n",
      "Training Accuracy 0.405\n",
      "Loss 370.75174 17 4\n",
      "Training Accuracy 0.495\n",
      "Loss 400.38895 18 4\n",
      "Training Accuracy 0.425\n",
      "Loss 398.55164 19 4\n",
      "Training Accuracy 0.425\n",
      "Loss 391.00055 20 4\n",
      "Training Accuracy 0.46\n",
      "Loss 399.3982 21 4\n",
      "Training Accuracy 0.445\n",
      "Loss 438.04276 22 4\n",
      "Training Accuracy 0.415\n",
      "Loss 432.0324 23 4\n",
      "Training Accuracy 0.435\n",
      "Loss 392.47687 24 4\n",
      "Training Accuracy 0.415\n",
      "Loss 391.72284 25 4\n",
      "Training Accuracy 0.44\n",
      "Loss 412.43555 26 4\n",
      "Training Accuracy 0.395\n",
      "Loss 375.59204 27 4\n",
      "Training Accuracy 0.52\n",
      "Loss 394.1319 28 4\n",
      "Training Accuracy 0.425\n",
      "Loss 374.00977 29 4\n",
      "Training Accuracy 0.485\n",
      "Loss 410.79227 30 4\n",
      "Training Accuracy 0.4\n",
      "Loss 427.04843 31 4\n",
      "Training Accuracy 0.45\n",
      "Loss 392.1287 32 4\n",
      "Training Accuracy 0.425\n",
      "Loss 391.78198 33 4\n",
      "Training Accuracy 0.465\n",
      "Loss 373.7214 34 4\n",
      "Training Accuracy 0.465\n",
      "Loss 351.50787 35 4\n",
      "Training Accuracy 0.445\n",
      "Loss 387.28662 36 4\n",
      "Training Accuracy 0.41\n",
      "Loss 392.03207 37 4\n",
      "Training Accuracy 0.51\n",
      "Loss 390.25784 38 4\n",
      "Training Accuracy 0.425\n",
      "Loss 343.3906 39 4\n",
      "Training Accuracy 0.53\n",
      "Loss 354.25104 40 4\n",
      "Training Accuracy 0.51\n",
      "Loss 363.0258 41 4\n",
      "Training Accuracy 0.45\n",
      "Loss 430.21576 42 4\n",
      "Training Accuracy 0.385\n",
      "Loss 394.01526 43 4\n",
      "Training Accuracy 0.435\n",
      "Loss 370.7174 44 4\n",
      "Training Accuracy 0.475\n",
      "Loss 392.7123 45 4\n",
      "Training Accuracy 0.38\n",
      "Loss 407.87228 46 4\n",
      "Training Accuracy 0.465\n",
      "Loss 380.6907 47 4\n",
      "Training Accuracy 0.49\n",
      "Loss 372.17804 48 4\n",
      "Training Accuracy 0.505\n",
      "Loss 396.46945 49 4\n",
      "Training Accuracy 0.48\n",
      "Loss 402.65915 50 4\n",
      "Training Accuracy 0.46\n",
      "Loss 374.15805 51 4\n",
      "Training Accuracy 0.515\n",
      "Loss 375.111 52 4\n",
      "Training Accuracy 0.46\n",
      "Loss 396.60452 53 4\n",
      "Training Accuracy 0.45\n",
      "Loss 391.5343 54 4\n",
      "Training Accuracy 0.41\n",
      "Loss 401.1192 55 4\n",
      "Training Accuracy 0.41\n",
      "Loss 377.22275 56 4\n",
      "Training Accuracy 0.48\n",
      "Loss 345.31784 57 4\n",
      "Training Accuracy 0.53\n",
      "Loss 335.71307 58 4\n",
      "Training Accuracy 0.475\n",
      "Loss 411.5179 59 4\n",
      "Training Accuracy 0.42\n",
      "Loss 389.3568 60 4\n",
      "Training Accuracy 0.515\n",
      "Loss 381.40607 61 4\n",
      "Training Accuracy 0.39\n",
      "Loss 369.80817 62 4\n",
      "Training Accuracy 0.46\n",
      "Loss 389.85477 63 4\n",
      "Training Accuracy 0.44\n",
      "Loss 390.90988 64 4\n",
      "Training Accuracy 0.455\n",
      "Loss 394.94336 65 4\n",
      "Training Accuracy 0.435\n",
      "Loss 374.31677 66 4\n",
      "Training Accuracy 0.435\n",
      "Loss 421.54422 67 4\n",
      "Training Accuracy 0.46\n",
      "Loss 383.49356 68 4\n",
      "Training Accuracy 0.415\n",
      "Loss 394.2628 69 4\n",
      "Training Accuracy 0.445\n",
      "Loss 390.91888 70 4\n",
      "Training Accuracy 0.46\n",
      "Loss 370.37888 71 4\n",
      "Training Accuracy 0.55\n",
      "Loss 388.35 72 4\n",
      "Training Accuracy 0.44\n",
      "Loss 417.35254 73 4\n",
      "Training Accuracy 0.425\n",
      "Loss 445.10358 74 4\n",
      "Training Accuracy 0.45\n",
      "Loss 407.0195 75 4\n",
      "Training Accuracy 0.44\n",
      "Loss 372.4441 76 4\n",
      "Training Accuracy 0.5\n",
      "Loss 365.98566 77 4\n",
      "Training Accuracy 0.455\n",
      "Loss 365.99768 78 4\n",
      "Training Accuracy 0.475\n",
      "Loss 348.12985 79 4\n",
      "Training Accuracy 0.455\n",
      "Loss 366.67407 80 4\n",
      "Training Accuracy 0.44\n",
      "Loss 403.58597 81 4\n",
      "Training Accuracy 0.435\n",
      "Loss 376.87848 82 4\n",
      "Training Accuracy 0.445\n",
      "Loss 366.96176 83 4\n",
      "Training Accuracy 0.46\n",
      "Loss 416.79745 84 4\n",
      "Training Accuracy 0.44\n",
      "Loss 385.17538 85 4\n",
      "Training Accuracy 0.44\n",
      "Loss 387.71198 86 4\n",
      "Training Accuracy 0.48\n",
      "Loss 417.18054 87 4\n",
      "Training Accuracy 0.445\n",
      "Loss 397.19376 88 4\n",
      "Training Accuracy 0.43\n",
      "Loss 404.65115 89 4\n",
      "Training Accuracy 0.49\n",
      "Loss 379.29526 90 4\n",
      "Training Accuracy 0.46\n",
      "Loss 407.48544 91 4\n",
      "Training Accuracy 0.43\n",
      "Loss 421.9392 92 4\n",
      "Training Accuracy 0.46\n",
      "Loss 366.30432 93 4\n",
      "Training Accuracy 0.47\n",
      "Loss 382.31168 94 4\n",
      "Training Accuracy 0.43\n",
      "Loss 359.4987 95 4\n",
      "Training Accuracy 0.465\n",
      "Loss 361.9284 96 4\n",
      "Training Accuracy 0.49\n",
      "Loss 396.59378 97 4\n",
      "Training Accuracy 0.43\n",
      "Loss 401.47888 98 4\n",
      "Training Accuracy 0.435\n",
      "Loss 369.18542 99 4\n",
      "Training Accuracy 0.48\n",
      "Loss 407.8802 100 4\n",
      "Training Accuracy 0.48\n",
      "Loss 398.23807 101 4\n",
      "Training Accuracy 0.435\n",
      "Loss 348.6548 102 4\n",
      "Training Accuracy 0.475\n",
      "Loss 388.7688 103 4\n",
      "Training Accuracy 0.465\n",
      "Loss 365.70996 104 4\n",
      "Training Accuracy 0.435\n",
      "Loss 411.68314 105 4\n",
      "Training Accuracy 0.43\n",
      "Loss 401.5164 106 4\n",
      "Training Accuracy 0.455\n",
      "Loss 385.60553 107 4\n",
      "Training Accuracy 0.44\n",
      "Loss 396.47586 108 4\n",
      "Training Accuracy 0.425\n",
      "Loss 391.1731 109 4\n",
      "Training Accuracy 0.42\n",
      "Loss 398.41483 110 4\n",
      "Training Accuracy 0.465\n",
      "Loss 387.22018 111 4\n",
      "Training Accuracy 0.485\n",
      "Loss 409.69034 112 4\n",
      "Training Accuracy 0.45\n",
      "Loss 432.42358 113 4\n",
      "Training Accuracy 0.44\n",
      "Loss 377.95346 114 4\n",
      "Training Accuracy 0.43\n",
      "Loss 417.85745 115 4\n",
      "Training Accuracy 0.46\n",
      "Loss 427.50415 116 4\n",
      "Training Accuracy 0.44\n",
      "Loss 348.7032 117 4\n",
      "Training Accuracy 0.555\n",
      "Loss 425.90967 118 4\n",
      "Training Accuracy 0.45\n",
      "Loss 461.90195 119 4\n",
      "Training Accuracy 0.38\n",
      "Loss 424.81152 120 4\n",
      "Training Accuracy 0.425\n",
      "Loss 421.66574 121 4\n",
      "Training Accuracy 0.405\n",
      "Loss 350.15036 122 4\n",
      "Training Accuracy 0.455\n",
      "Loss 391.8606 123 4\n",
      "Training Accuracy 0.44\n",
      "Loss 377.72452 124 4\n",
      "Training Accuracy 0.46\n",
      "Loss 345.92007 125 4\n",
      "Training Accuracy 0.49\n",
      "Loss 382.75235 126 4\n",
      "Training Accuracy 0.495\n",
      "Loss 350.06543 127 4\n",
      "Training Accuracy 0.505\n",
      "Loss 368.07642 128 4\n",
      "Training Accuracy 0.455\n",
      "Loss 351.5849 129 4\n",
      "Training Accuracy 0.53\n",
      "Loss 361.02975 130 4\n",
      "Training Accuracy 0.5\n",
      "Loss 351.47052 131 4\n",
      "Training Accuracy 0.485\n",
      "Loss 358.85562 132 4\n",
      "Training Accuracy 0.47\n",
      "Loss 379.94556 133 4\n",
      "Training Accuracy 0.495\n",
      "Loss 370.104 134 4\n",
      "Training Accuracy 0.5\n",
      "Loss 330.77667 135 4\n",
      "Training Accuracy 0.55\n",
      "Loss 412.20306 136 4\n",
      "Training Accuracy 0.45\n",
      "Loss 381.69308 137 4\n",
      "Training Accuracy 0.435\n",
      "Loss 358.24286 138 4\n",
      "Training Accuracy 0.55\n",
      "Loss 429.9933 139 4\n",
      "Training Accuracy 0.43\n",
      "Loss 354.73352 140 4\n",
      "Training Accuracy 0.51\n",
      "Loss 409.1103 141 4\n",
      "Training Accuracy 0.445\n",
      "Loss 384.31647 142 4\n",
      "Training Accuracy 0.455\n",
      "Loss 339.50818 143 4\n",
      "Training Accuracy 0.48\n",
      "Loss 373.20233 144 4\n",
      "Training Accuracy 0.47\n",
      "Loss 391.25964 145 4\n",
      "Training Accuracy 0.465\n",
      "Loss 352.09802 146 4\n",
      "Training Accuracy 0.47\n",
      "Loss 383.79605 147 4\n",
      "Training Accuracy 0.435\n",
      "Loss 377.06183 148 4\n",
      "Training Accuracy 0.43\n",
      "Loss 345.34076 149 4\n",
      "Training Accuracy 0.535\n",
      "Loss 385.36642 150 4\n",
      "Training Accuracy 0.44\n",
      "Loss 393.03464 151 4\n",
      "Training Accuracy 0.455\n",
      "Loss 410.72885 152 4\n",
      "Training Accuracy 0.445\n",
      "Loss 374.8272 153 4\n",
      "Training Accuracy 0.45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 394.3233 154 4\n",
      "Training Accuracy 0.445\n",
      "Loss 352.74088 155 4\n",
      "Training Accuracy 0.51\n",
      "Loss 392.52414 156 4\n",
      "Training Accuracy 0.445\n",
      "Loss 348.0809 157 4\n",
      "Training Accuracy 0.455\n",
      "Loss 388.02664 158 4\n",
      "Training Accuracy 0.48\n",
      "Loss 418.0032 159 4\n",
      "Training Accuracy 0.475\n",
      "Loss 358.69922 160 4\n",
      "Training Accuracy 0.47\n",
      "Loss 411.0768 161 4\n",
      "Training Accuracy 0.355\n",
      "Loss 361.7549 162 4\n",
      "Training Accuracy 0.53\n",
      "Loss 397.25238 163 4\n",
      "Training Accuracy 0.39\n",
      "Loss 339.5828 164 4\n",
      "Training Accuracy 0.49\n",
      "Loss 360.8313 165 4\n",
      "Training Accuracy 0.505\n",
      "Loss 416.3148 166 4\n",
      "Training Accuracy 0.45\n",
      "Loss 324.01935 167 4\n",
      "Training Accuracy 0.515\n",
      "Loss 403.58365 168 4\n",
      "Training Accuracy 0.495\n",
      "Loss 354.69818 169 4\n",
      "Training Accuracy 0.46\n",
      "Loss 360.89282 170 4\n",
      "Training Accuracy 0.445\n",
      "Loss 387.4922 171 4\n",
      "Training Accuracy 0.515\n",
      "Loss 370.6114 172 4\n",
      "Training Accuracy 0.455\n",
      "Loss 434.38828 173 4\n",
      "Training Accuracy 0.42\n",
      "Loss 328.1163 174 4\n",
      "Training Accuracy 0.515\n",
      "Loss 365.34116 175 4\n",
      "Training Accuracy 0.51\n",
      "Loss 335.013 176 4\n",
      "Training Accuracy 0.57\n",
      "Loss 423.8702 177 4\n",
      "Training Accuracy 0.43\n",
      "Loss 348.4439 178 4\n",
      "Training Accuracy 0.525\n",
      "Loss 410.51163 179 4\n",
      "Training Accuracy 0.435\n",
      "Loss 377.09805 180 4\n",
      "Training Accuracy 0.4\n",
      "Loss 323.99475 181 4\n",
      "Training Accuracy 0.485\n",
      "Loss 407.60605 182 4\n",
      "Training Accuracy 0.4\n",
      "Loss 395.90582 183 4\n",
      "Training Accuracy 0.445\n",
      "Loss 326.4766 184 4\n",
      "Training Accuracy 0.52\n",
      "Loss 345.04544 185 4\n",
      "Training Accuracy 0.53\n",
      "Loss 361.83893 186 4\n",
      "Training Accuracy 0.495\n",
      "Loss 403.459 187 4\n",
      "Training Accuracy 0.445\n",
      "Loss 390.30847 188 4\n",
      "Training Accuracy 0.45\n",
      "Loss 375.6481 189 4\n",
      "Training Accuracy 0.475\n",
      "Loss 375.9069 190 4\n",
      "Training Accuracy 0.475\n",
      "Loss 356.95975 191 4\n",
      "Training Accuracy 0.475\n",
      "Loss 373.704 192 4\n",
      "Training Accuracy 0.485\n",
      "Loss 342.79996 193 4\n",
      "Training Accuracy 0.535\n",
      "Loss 355.6859 194 4\n",
      "Training Accuracy 0.51\n",
      "Loss 357.18106 195 4\n",
      "Training Accuracy 0.485\n",
      "Loss 366.6042 196 4\n",
      "Training Accuracy 0.505\n",
      "Loss 384.04648 197 4\n",
      "Training Accuracy 0.445\n",
      "Loss 336.01663 198 4\n",
      "Training Accuracy 0.51\n",
      "Loss 306.52008 199 4\n",
      "Training Accuracy 0.575\n",
      "Loss 391.001 200 4\n",
      "Training Accuracy 0.435\n",
      "Loss 368.20593 201 4\n",
      "Training Accuracy 0.415\n",
      "Loss 377.12524 202 4\n",
      "Training Accuracy 0.465\n",
      "Loss 383.25858 203 4\n",
      "Training Accuracy 0.47\n",
      "Loss 379.58673 204 4\n",
      "Training Accuracy 0.47\n",
      "Loss 384.6477 205 4\n",
      "Training Accuracy 0.475\n",
      "Loss 378.58755 206 4\n",
      "Training Accuracy 0.465\n",
      "Loss 345.8146 207 4\n",
      "Training Accuracy 0.47\n",
      "Loss 394.3572 208 4\n",
      "Training Accuracy 0.475\n",
      "Loss 386.15286 209 4\n",
      "Training Accuracy 0.425\n",
      "Loss 352.3895 210 4\n",
      "Training Accuracy 0.435\n",
      "Loss 383.50714 211 4\n",
      "Training Accuracy 0.475\n",
      "Loss 329.87067 212 4\n",
      "Training Accuracy 0.52\n",
      "Loss 418.88712 213 4\n",
      "Training Accuracy 0.435\n",
      "Loss 383.96664 214 4\n",
      "Training Accuracy 0.455\n",
      "Loss 390.00043 215 4\n",
      "Training Accuracy 0.45\n",
      "Loss 416.16467 216 4\n",
      "Training Accuracy 0.49\n",
      "Loss 349.25198 217 4\n",
      "Training Accuracy 0.455\n",
      "Loss 388.4772 218 4\n",
      "Training Accuracy 0.45\n",
      "Loss 368.3247 219 4\n",
      "Training Accuracy 0.49\n",
      "Loss 362.43588 220 4\n",
      "Training Accuracy 0.525\n",
      "Loss 396.62317 221 4\n",
      "Training Accuracy 0.435\n",
      "Loss 353.66306 222 4\n",
      "Training Accuracy 0.515\n",
      "Loss 391.9126 223 4\n",
      "Training Accuracy 0.41\n",
      "Loss 399.99002 224 4\n",
      "Training Accuracy 0.39\n",
      "Loss 401.5438 225 4\n",
      "Training Accuracy 0.39\n",
      "Loss 349.16827 226 4\n",
      "Training Accuracy 0.485\n",
      "Loss 429.98517 227 4\n",
      "Training Accuracy 0.405\n",
      "Loss 412.64355 228 4\n",
      "Training Accuracy 0.39\n",
      "Loss 367.79227 229 4\n",
      "Training Accuracy 0.525\n",
      "Loss 373.9443 230 4\n",
      "Training Accuracy 0.47\n",
      "Loss 309.4387 231 4\n",
      "Training Accuracy 0.56\n",
      "Loss 389.00717 232 4\n",
      "Training Accuracy 0.415\n",
      "Loss 388.86606 233 4\n",
      "Training Accuracy 0.405\n",
      "Loss 373.15598 234 4\n",
      "Training Accuracy 0.445\n",
      "Loss 368.9244 235 4\n",
      "Training Accuracy 0.48\n",
      "Loss 341.1526 236 4\n",
      "Training Accuracy 0.5\n",
      "Loss 381.89066 237 4\n",
      "Training Accuracy 0.485\n",
      "Loss 358.35016 238 4\n",
      "Training Accuracy 0.51\n",
      "Loss 415.3377 239 4\n",
      "Training Accuracy 0.455\n",
      "Loss 370.14368 240 4\n",
      "Training Accuracy 0.48\n",
      "Loss 395.16962 241 4\n",
      "Training Accuracy 0.44\n",
      "Loss 334.17572 242 4\n",
      "Training Accuracy 0.535\n",
      "Loss 331.2329 243 4\n",
      "Training Accuracy 0.515\n",
      "Loss 364.1953 244 4\n",
      "Training Accuracy 0.465\n",
      "Loss 347.64893 245 4\n",
      "Training Accuracy 0.505\n",
      "Loss 384.15747 246 4\n",
      "Training Accuracy 0.45\n",
      "Loss 310.21896 247 4\n",
      "Training Accuracy 0.49\n",
      "Loss 346.53036 248 4\n",
      "Training Accuracy 0.475\n",
      "Loss 358.07196 249 4\n",
      "Training Accuracy 0.455\n",
      "Loss 386.31628 250 4\n",
      "Training Accuracy 0.455\n",
      "Loss 383.43637 251 4\n",
      "Training Accuracy 0.435\n",
      "Loss 353.1121 252 4\n",
      "Training Accuracy 0.445\n",
      "Loss 356.10046 253 4\n",
      "Training Accuracy 0.485\n",
      "Loss 353.1452 254 4\n",
      "Training Accuracy 0.505\n",
      "Loss 325.05463 255 4\n",
      "Training Accuracy 0.515\n",
      "Loss 378.70404 256 4\n",
      "Training Accuracy 0.45\n",
      "Loss 355.35693 257 4\n",
      "Training Accuracy 0.47\n",
      "Loss 359.45535 258 4\n",
      "Training Accuracy 0.48\n",
      "Loss 368.46692 259 4\n",
      "Training Accuracy 0.47\n",
      "Loss 327.33157 260 4\n",
      "Training Accuracy 0.57\n",
      "Loss 387.55386 261 4\n",
      "Training Accuracy 0.46\n",
      "Loss 362.92288 262 4\n",
      "Training Accuracy 0.475\n",
      "Loss 448.3189 263 4\n",
      "Training Accuracy 0.41\n",
      "Loss 396.38943 264 4\n",
      "Training Accuracy 0.45\n",
      "Loss 392.9305 265 4\n",
      "Training Accuracy 0.515\n",
      "Loss 367.35843 266 4\n",
      "Training Accuracy 0.44\n",
      "Loss 361.02597 267 4\n",
      "Training Accuracy 0.535\n",
      "Loss 384.5957 268 4\n",
      "Training Accuracy 0.51\n",
      "Loss 323.4234 269 4\n",
      "Training Accuracy 0.485\n",
      "Loss 341.62708 270 4\n",
      "Training Accuracy 0.465\n",
      "Loss 419.37784 271 4\n",
      "Training Accuracy 0.425\n",
      "Loss 375.72925 272 4\n",
      "Training Accuracy 0.44\n",
      "Loss 356.00894 273 4\n",
      "Training Accuracy 0.53\n",
      "Loss 345.4622 274 4\n",
      "Training Accuracy 0.49\n",
      "Loss 396.3557 275 4\n",
      "Training Accuracy 0.405\n",
      "Loss 331.3583 276 4\n",
      "Training Accuracy 0.52\n",
      "Loss 448.17297 277 4\n",
      "Training Accuracy 0.46\n",
      "Loss 338.27008 278 4\n",
      "Training Accuracy 0.52\n",
      "Loss 342.05847 279 4\n",
      "Training Accuracy 0.51\n",
      "Loss 337.92526 280 4\n",
      "Training Accuracy 0.515\n",
      "Loss 361.09558 281 4\n",
      "Training Accuracy 0.475\n",
      "Loss 363.5553 282 4\n",
      "Training Accuracy 0.495\n",
      "Loss 336.3768 283 4\n",
      "Training Accuracy 0.49\n",
      "Loss 347.78693 284 4\n",
      "Training Accuracy 0.49\n",
      "Loss 415.83395 285 4\n",
      "Training Accuracy 0.405\n",
      "Loss 377.29962 286 4\n",
      "Training Accuracy 0.475\n",
      "Loss 352.04016 287 4\n",
      "Training Accuracy 0.505\n",
      "Loss 383.1251 288 4\n",
      "Training Accuracy 0.49\n",
      "Loss 325.47437 289 4\n",
      "Training Accuracy 0.525\n",
      "Loss 372.9922 290 4\n",
      "Training Accuracy 0.465\n",
      "Loss 367.34656 291 4\n",
      "Training Accuracy 0.45\n",
      "Loss 240.30048 292 4\n",
      "Training Accuracy 0.46212122\n",
      "Loss 335.5146 1 5\n",
      "Training Accuracy 0.505\n",
      "Loss 373.0402 2 5\n",
      "Training Accuracy 0.47\n",
      "Loss 390.9043 3 5\n",
      "Training Accuracy 0.51\n",
      "Loss 370.31067 4 5\n",
      "Training Accuracy 0.495\n",
      "Loss 331.63724 5 5\n",
      "Training Accuracy 0.51\n",
      "Loss 376.6833 6 5\n",
      "Training Accuracy 0.495\n",
      "Loss 358.69263 7 5\n",
      "Training Accuracy 0.48\n",
      "Loss 421.2395 8 5\n",
      "Training Accuracy 0.45\n",
      "Loss 363.72687 9 5\n",
      "Training Accuracy 0.455\n",
      "Loss 368.49252 10 5\n",
      "Training Accuracy 0.47\n",
      "Loss 405.50375 11 5\n",
      "Training Accuracy 0.49\n",
      "Loss 351.59894 12 5\n",
      "Training Accuracy 0.43\n",
      "Loss 345.4994 13 5\n",
      "Training Accuracy 0.535\n",
      "Loss 378.96323 14 5\n",
      "Training Accuracy 0.435\n",
      "Loss 355.1375 15 5\n",
      "Training Accuracy 0.51\n",
      "Loss 371.99173 16 5\n",
      "Training Accuracy 0.425\n",
      "Loss 345.98468 17 5\n",
      "Training Accuracy 0.505\n",
      "Loss 364.46573 18 5\n",
      "Training Accuracy 0.5\n",
      "Loss 362.33926 19 5\n",
      "Training Accuracy 0.445\n",
      "Loss 366.05316 20 5\n",
      "Training Accuracy 0.485\n",
      "Loss 372.54785 21 5\n",
      "Training Accuracy 0.52\n",
      "Loss 406.27237 22 5\n",
      "Training Accuracy 0.405\n",
      "Loss 389.8974 23 5\n",
      "Training Accuracy 0.495\n",
      "Loss 369.02905 24 5\n",
      "Training Accuracy 0.445\n",
      "Loss 360.07788 25 5\n",
      "Training Accuracy 0.505\n",
      "Loss 386.359 26 5\n",
      "Training Accuracy 0.375\n",
      "Loss 351.43887 27 5\n",
      "Training Accuracy 0.48\n",
      "Loss 366.8003 28 5\n",
      "Training Accuracy 0.39\n",
      "Loss 344.72305 29 5\n",
      "Training Accuracy 0.465\n",
      "Loss 380.6178 30 5\n",
      "Training Accuracy 0.455\n",
      "Loss 397.106 31 5\n",
      "Training Accuracy 0.455\n",
      "Loss 369.5824 32 5\n",
      "Training Accuracy 0.415\n",
      "Loss 369.34827 33 5\n",
      "Training Accuracy 0.51\n",
      "Loss 345.63983 34 5\n",
      "Training Accuracy 0.49\n",
      "Loss 318.4344 35 5\n",
      "Training Accuracy 0.51\n",
      "Loss 361.4263 36 5\n",
      "Training Accuracy 0.465\n",
      "Loss 377.11478 37 5\n",
      "Training Accuracy 0.52\n",
      "Loss 370.71545 38 5\n",
      "Training Accuracy 0.455\n",
      "Loss 327.4507 39 5\n",
      "Training Accuracy 0.48\n",
      "Loss 315.21405 40 5\n",
      "Training Accuracy 0.545\n",
      "Loss 340.68857 41 5\n",
      "Training Accuracy 0.5\n",
      "Loss 399.17923 42 5\n",
      "Training Accuracy 0.39\n",
      "Loss 357.9155 43 5\n",
      "Training Accuracy 0.505\n",
      "Loss 355.13458 44 5\n",
      "Training Accuracy 0.465\n",
      "Loss 368.84955 45 5\n",
      "Training Accuracy 0.45\n",
      "Loss 382.80695 46 5\n",
      "Training Accuracy 0.43\n",
      "Loss 351.245 47 5\n",
      "Training Accuracy 0.5\n",
      "Loss 341.3332 48 5\n",
      "Training Accuracy 0.475\n",
      "Loss 366.75732 49 5\n",
      "Training Accuracy 0.47\n",
      "Loss 371.80978 50 5\n",
      "Training Accuracy 0.445\n",
      "Loss 350.72668 51 5\n",
      "Training Accuracy 0.53\n",
      "Loss 354.69263 52 5\n",
      "Training Accuracy 0.485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 369.83075 53 5\n",
      "Training Accuracy 0.445\n",
      "Loss 365.76025 54 5\n",
      "Training Accuracy 0.455\n",
      "Loss 373.85086 55 5\n",
      "Training Accuracy 0.425\n",
      "Loss 359.47787 56 5\n",
      "Training Accuracy 0.415\n",
      "Loss 321.29364 57 5\n",
      "Training Accuracy 0.57\n",
      "Loss 315.03442 58 5\n",
      "Training Accuracy 0.51\n",
      "Loss 384.0719 59 5\n",
      "Training Accuracy 0.41\n",
      "Loss 369.99887 60 5\n",
      "Training Accuracy 0.475\n",
      "Loss 364.41086 61 5\n",
      "Training Accuracy 0.42\n",
      "Loss 342.6116 62 5\n",
      "Training Accuracy 0.51\n",
      "Loss 368.01318 63 5\n",
      "Training Accuracy 0.47\n",
      "Loss 351.3531 64 5\n",
      "Training Accuracy 0.51\n",
      "Loss 371.4032 65 5\n",
      "Training Accuracy 0.445\n",
      "Loss 349.7534 66 5\n",
      "Training Accuracy 0.46\n",
      "Loss 403.33438 67 5\n",
      "Training Accuracy 0.405\n",
      "Loss 357.68103 68 5\n",
      "Training Accuracy 0.455\n",
      "Loss 366.552 69 5\n",
      "Training Accuracy 0.485\n",
      "Loss 373.37418 70 5\n",
      "Training Accuracy 0.455\n",
      "Loss 351.64166 71 5\n",
      "Training Accuracy 0.535\n",
      "Loss 361.9566 72 5\n",
      "Training Accuracy 0.48\n",
      "Loss 381.91104 73 5\n",
      "Training Accuracy 0.435\n",
      "Loss 416.70334 74 5\n",
      "Training Accuracy 0.465\n",
      "Loss 368.03613 75 5\n",
      "Training Accuracy 0.52\n",
      "Loss 339.87607 76 5\n",
      "Training Accuracy 0.525\n",
      "Loss 336.3087 77 5\n",
      "Training Accuracy 0.515\n",
      "Loss 352.36752 78 5\n",
      "Training Accuracy 0.49\n",
      "Loss 326.21213 79 5\n",
      "Training Accuracy 0.435\n",
      "Loss 340.37396 80 5\n",
      "Training Accuracy 0.51\n",
      "Loss 370.71088 81 5\n",
      "Training Accuracy 0.485\n",
      "Loss 358.36145 82 5\n",
      "Training Accuracy 0.46\n",
      "Loss 343.84317 83 5\n",
      "Training Accuracy 0.505\n",
      "Loss 411.03162 84 5\n",
      "Training Accuracy 0.36\n",
      "Loss 372.93033 85 5\n",
      "Training Accuracy 0.45\n",
      "Loss 359.89508 86 5\n",
      "Training Accuracy 0.49\n",
      "Loss 399.8863 87 5\n",
      "Training Accuracy 0.425\n",
      "Loss 376.69598 88 5\n",
      "Training Accuracy 0.43\n",
      "Loss 369.1942 89 5\n",
      "Training Accuracy 0.505\n",
      "Loss 358.74463 90 5\n",
      "Training Accuracy 0.47\n",
      "Loss 378.10336 91 5\n",
      "Training Accuracy 0.455\n",
      "Loss 382.8426 92 5\n",
      "Training Accuracy 0.485\n",
      "Loss 352.52325 93 5\n",
      "Training Accuracy 0.475\n",
      "Loss 364.22302 94 5\n",
      "Training Accuracy 0.435\n",
      "Loss 332.50992 95 5\n",
      "Training Accuracy 0.5\n",
      "Loss 337.06888 96 5\n",
      "Training Accuracy 0.5\n",
      "Loss 368.70532 97 5\n",
      "Training Accuracy 0.44\n",
      "Loss 370.38077 98 5\n",
      "Training Accuracy 0.44\n",
      "Loss 346.6797 99 5\n",
      "Training Accuracy 0.485\n",
      "Loss 380.22604 100 5\n",
      "Training Accuracy 0.505\n",
      "Loss 358.9569 101 5\n",
      "Training Accuracy 0.47\n",
      "Loss 316.91287 102 5\n",
      "Training Accuracy 0.525\n",
      "Loss 363.32266 103 5\n",
      "Training Accuracy 0.44\n",
      "Loss 343.6364 104 5\n",
      "Training Accuracy 0.465\n",
      "Loss 382.2703 105 5\n",
      "Training Accuracy 0.49\n",
      "Loss 370.45844 106 5\n",
      "Training Accuracy 0.49\n",
      "Loss 366.0378 107 5\n",
      "Training Accuracy 0.435\n",
      "Loss 368.18393 108 5\n",
      "Training Accuracy 0.445\n",
      "Loss 362.925 109 5\n",
      "Training Accuracy 0.48\n",
      "Loss 370.57605 110 5\n",
      "Training Accuracy 0.48\n",
      "Loss 363.25406 111 5\n",
      "Training Accuracy 0.465\n",
      "Loss 389.96054 112 5\n",
      "Training Accuracy 0.445\n",
      "Loss 404.78165 113 5\n",
      "Training Accuracy 0.495\n",
      "Loss 350.34464 114 5\n",
      "Training Accuracy 0.395\n",
      "Loss 383.51443 115 5\n",
      "Training Accuracy 0.475\n",
      "Loss 404.49585 116 5\n",
      "Training Accuracy 0.465\n",
      "Loss 327.94363 117 5\n",
      "Training Accuracy 0.585\n",
      "Loss 383.08847 118 5\n",
      "Training Accuracy 0.475\n",
      "Loss 433.56198 119 5\n",
      "Training Accuracy 0.425\n",
      "Loss 389.528 120 5\n",
      "Training Accuracy 0.46\n",
      "Loss 399.21713 121 5\n",
      "Training Accuracy 0.405\n",
      "Loss 323.35623 122 5\n",
      "Training Accuracy 0.495\n",
      "Loss 361.96613 123 5\n",
      "Training Accuracy 0.445\n",
      "Loss 352.27945 124 5\n",
      "Training Accuracy 0.455\n",
      "Loss 321.5819 125 5\n",
      "Training Accuracy 0.53\n",
      "Loss 375.85233 126 5\n",
      "Training Accuracy 0.45\n",
      "Loss 338.93793 127 5\n",
      "Training Accuracy 0.485\n",
      "Loss 347.67758 128 5\n",
      "Training Accuracy 0.485\n",
      "Loss 332.16443 129 5\n",
      "Training Accuracy 0.49\n",
      "Loss 348.19357 130 5\n",
      "Training Accuracy 0.485\n",
      "Loss 337.69214 131 5\n",
      "Training Accuracy 0.49\n",
      "Loss 335.8539 132 5\n",
      "Training Accuracy 0.48\n",
      "Loss 360.8904 133 5\n",
      "Training Accuracy 0.48\n",
      "Loss 334.62653 134 5\n",
      "Training Accuracy 0.505\n",
      "Loss 311.01114 135 5\n",
      "Training Accuracy 0.55\n",
      "Loss 383.84592 136 5\n",
      "Training Accuracy 0.49\n",
      "Loss 353.14688 137 5\n",
      "Training Accuracy 0.465\n",
      "Loss 339.57715 138 5\n",
      "Training Accuracy 0.56\n",
      "Loss 394.69608 139 5\n",
      "Training Accuracy 0.495\n",
      "Loss 331.17328 140 5\n",
      "Training Accuracy 0.555\n",
      "Loss 376.82187 141 5\n",
      "Training Accuracy 0.47\n",
      "Loss 364.0186 142 5\n",
      "Training Accuracy 0.465\n",
      "Loss 317.08423 143 5\n",
      "Training Accuracy 0.515\n",
      "Loss 358.4563 144 5\n",
      "Training Accuracy 0.485\n",
      "Loss 362.47144 145 5\n",
      "Training Accuracy 0.52\n",
      "Loss 340.70596 146 5\n",
      "Training Accuracy 0.45\n",
      "Loss 354.72467 147 5\n",
      "Training Accuracy 0.48\n",
      "Loss 357.14865 148 5\n",
      "Training Accuracy 0.455\n",
      "Loss 328.01605 149 5\n",
      "Training Accuracy 0.525\n",
      "Loss 362.52344 150 5\n",
      "Training Accuracy 0.48\n",
      "Loss 369.15054 151 5\n",
      "Training Accuracy 0.46\n",
      "Loss 381.75378 152 5\n",
      "Training Accuracy 0.47\n",
      "Loss 348.39474 153 5\n",
      "Training Accuracy 0.475\n",
      "Loss 363.12952 154 5\n",
      "Training Accuracy 0.5\n",
      "Loss 330.31573 155 5\n",
      "Training Accuracy 0.545\n",
      "Loss 365.7905 156 5\n",
      "Training Accuracy 0.465\n",
      "Loss 318.2497 157 5\n",
      "Training Accuracy 0.5\n",
      "Loss 363.22107 158 5\n",
      "Training Accuracy 0.5\n",
      "Loss 399.16388 159 5\n",
      "Training Accuracy 0.465\n",
      "Loss 347.37555 160 5\n",
      "Training Accuracy 0.455\n",
      "Loss 385.49673 161 5\n",
      "Training Accuracy 0.465\n",
      "Loss 344.1938 162 5\n",
      "Training Accuracy 0.51\n",
      "Loss 367.82422 163 5\n",
      "Training Accuracy 0.44\n",
      "Loss 306.4539 164 5\n",
      "Training Accuracy 0.52\n",
      "Loss 334.51038 165 5\n",
      "Training Accuracy 0.51\n",
      "Loss 382.93216 166 5\n",
      "Training Accuracy 0.45\n",
      "Loss 298.10297 167 5\n",
      "Training Accuracy 0.515\n",
      "Loss 372.52615 168 5\n",
      "Training Accuracy 0.525\n",
      "Loss 337.33646 169 5\n",
      "Training Accuracy 0.475\n",
      "Loss 332.29578 170 5\n",
      "Training Accuracy 0.515\n",
      "Loss 376.8039 171 5\n",
      "Training Accuracy 0.535\n",
      "Loss 343.00885 172 5\n",
      "Training Accuracy 0.5\n",
      "Loss 421.68143 173 5\n",
      "Training Accuracy 0.415\n",
      "Loss 301.92374 174 5\n",
      "Training Accuracy 0.535\n",
      "Loss 332.259 175 5\n",
      "Training Accuracy 0.525\n",
      "Loss 315.54956 176 5\n",
      "Training Accuracy 0.555\n",
      "Loss 397.14883 177 5\n",
      "Training Accuracy 0.415\n",
      "Loss 329.45007 178 5\n",
      "Training Accuracy 0.53\n",
      "Loss 386.4282 179 5\n",
      "Training Accuracy 0.46\n",
      "Loss 349.49374 180 5\n",
      "Training Accuracy 0.46\n",
      "Loss 308.14087 181 5\n",
      "Training Accuracy 0.485\n",
      "Loss 365.7665 182 5\n",
      "Training Accuracy 0.44\n",
      "Loss 368.89816 183 5\n",
      "Training Accuracy 0.48\n",
      "Loss 314.42633 184 5\n",
      "Training Accuracy 0.525\n",
      "Loss 327.7143 185 5\n",
      "Training Accuracy 0.53\n",
      "Loss 335.44052 186 5\n",
      "Training Accuracy 0.515\n",
      "Loss 387.43735 187 5\n",
      "Training Accuracy 0.44\n",
      "Loss 366.5775 188 5\n",
      "Training Accuracy 0.465\n",
      "Loss 355.66714 189 5\n",
      "Training Accuracy 0.505\n",
      "Loss 355.30643 190 5\n",
      "Training Accuracy 0.495\n",
      "Loss 341.55475 191 5\n",
      "Training Accuracy 0.5\n",
      "Loss 352.66507 192 5\n",
      "Training Accuracy 0.505\n",
      "Loss 318.98062 193 5\n",
      "Training Accuracy 0.53\n",
      "Loss 333.84064 194 5\n",
      "Training Accuracy 0.505\n",
      "Loss 341.2954 195 5\n",
      "Training Accuracy 0.48\n",
      "Loss 354.58554 196 5\n",
      "Training Accuracy 0.485\n",
      "Loss 355.22607 197 5\n",
      "Training Accuracy 0.505\n",
      "Loss 322.28177 198 5\n",
      "Training Accuracy 0.505\n",
      "Loss 301.63263 199 5\n",
      "Training Accuracy 0.54\n",
      "Loss 364.0872 200 5\n",
      "Training Accuracy 0.455\n",
      "Loss 338.3358 201 5\n",
      "Training Accuracy 0.485\n",
      "Loss 353.54855 202 5\n",
      "Training Accuracy 0.455\n",
      "Loss 367.7547 203 5\n",
      "Training Accuracy 0.48\n",
      "Loss 352.73767 204 5\n",
      "Training Accuracy 0.455\n",
      "Loss 374.34323 205 5\n",
      "Training Accuracy 0.46\n",
      "Loss 366.35257 206 5\n",
      "Training Accuracy 0.445\n",
      "Loss 326.83374 207 5\n",
      "Training Accuracy 0.495\n",
      "Loss 366.83807 208 5\n",
      "Training Accuracy 0.485\n",
      "Loss 371.94363 209 5\n",
      "Training Accuracy 0.49\n",
      "Loss 328.4682 210 5\n",
      "Training Accuracy 0.485\n",
      "Loss 363.22815 211 5\n",
      "Training Accuracy 0.485\n",
      "Loss 319.6209 212 5\n",
      "Training Accuracy 0.5\n",
      "Loss 402.5881 213 5\n",
      "Training Accuracy 0.415\n",
      "Loss 356.14716 214 5\n",
      "Training Accuracy 0.51\n",
      "Loss 366.92706 215 5\n",
      "Training Accuracy 0.5\n",
      "Loss 398.33194 216 5\n",
      "Training Accuracy 0.435\n",
      "Loss 343.423 217 5\n",
      "Training Accuracy 0.415\n",
      "Loss 370.0098 218 5\n",
      "Training Accuracy 0.425\n",
      "Loss 351.38504 219 5\n",
      "Training Accuracy 0.51\n",
      "Loss 340.3904 220 5\n",
      "Training Accuracy 0.525\n",
      "Loss 377.60187 221 5\n",
      "Training Accuracy 0.425\n",
      "Loss 339.79712 222 5\n",
      "Training Accuracy 0.5\n",
      "Loss 369.92517 223 5\n",
      "Training Accuracy 0.43\n",
      "Loss 368.93454 224 5\n",
      "Training Accuracy 0.46\n",
      "Loss 372.12433 225 5\n",
      "Training Accuracy 0.465\n",
      "Loss 331.36792 226 5\n",
      "Training Accuracy 0.48\n",
      "Loss 405.5084 227 5\n",
      "Training Accuracy 0.44\n",
      "Loss 394.53098 228 5\n",
      "Training Accuracy 0.415\n",
      "Loss 347.44547 229 5\n",
      "Training Accuracy 0.5\n",
      "Loss 361.2316 230 5\n",
      "Training Accuracy 0.48\n",
      "Loss 289.87207 231 5\n",
      "Training Accuracy 0.595\n",
      "Loss 366.29007 232 5\n",
      "Training Accuracy 0.45\n",
      "Loss 368.60587 233 5\n",
      "Training Accuracy 0.435\n",
      "Loss 360.64914 234 5\n",
      "Training Accuracy 0.44\n",
      "Loss 354.74716 235 5\n",
      "Training Accuracy 0.485\n",
      "Loss 306.3705 236 5\n",
      "Training Accuracy 0.595\n",
      "Loss 358.27264 237 5\n",
      "Training Accuracy 0.515\n",
      "Loss 339.88522 238 5\n",
      "Training Accuracy 0.515\n",
      "Loss 383.1115 239 5\n",
      "Training Accuracy 0.505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 342.55603 240 5\n",
      "Training Accuracy 0.5\n",
      "Loss 376.14075 241 5\n",
      "Training Accuracy 0.46\n",
      "Loss 305.0886 242 5\n",
      "Training Accuracy 0.575\n",
      "Loss 314.1434 243 5\n",
      "Training Accuracy 0.53\n",
      "Loss 347.79193 244 5\n",
      "Training Accuracy 0.48\n",
      "Loss 335.9959 245 5\n",
      "Training Accuracy 0.49\n",
      "Loss 354.00183 246 5\n",
      "Training Accuracy 0.46\n",
      "Loss 294.49286 247 5\n",
      "Training Accuracy 0.475\n",
      "Loss 339.34174 248 5\n",
      "Training Accuracy 0.42\n",
      "Loss 346.36252 249 5\n",
      "Training Accuracy 0.44\n",
      "Loss 359.4004 250 5\n",
      "Training Accuracy 0.47\n",
      "Loss 355.90393 251 5\n",
      "Training Accuracy 0.475\n",
      "Loss 330.03183 252 5\n",
      "Training Accuracy 0.47\n",
      "Loss 336.5859 253 5\n",
      "Training Accuracy 0.53\n",
      "Loss 333.36182 254 5\n",
      "Training Accuracy 0.53\n",
      "Loss 309.24802 255 5\n",
      "Training Accuracy 0.52\n",
      "Loss 366.2074 256 5\n",
      "Training Accuracy 0.48\n",
      "Loss 339.26675 257 5\n",
      "Training Accuracy 0.485\n",
      "Loss 338.76865 258 5\n",
      "Training Accuracy 0.49\n",
      "Loss 343.48102 259 5\n",
      "Training Accuracy 0.495\n",
      "Loss 300.27417 260 5\n",
      "Training Accuracy 0.57\n",
      "Loss 357.9955 261 5\n",
      "Training Accuracy 0.455\n",
      "Loss 344.42825 262 5\n",
      "Training Accuracy 0.44\n",
      "Loss 424.2566 263 5\n",
      "Training Accuracy 0.39\n",
      "Loss 374.43372 264 5\n",
      "Training Accuracy 0.525\n",
      "Loss 370.37305 265 5\n",
      "Training Accuracy 0.505\n",
      "Loss 333.5222 266 5\n",
      "Training Accuracy 0.47\n",
      "Loss 350.40787 267 5\n",
      "Training Accuracy 0.47\n",
      "Loss 366.17734 268 5\n",
      "Training Accuracy 0.475\n",
      "Loss 315.15994 269 5\n",
      "Training Accuracy 0.485\n",
      "Loss 325.02036 270 5\n",
      "Training Accuracy 0.53\n",
      "Loss 401.18777 271 5\n",
      "Training Accuracy 0.425\n",
      "Loss 353.9561 272 5\n",
      "Training Accuracy 0.49\n",
      "Loss 342.8383 273 5\n",
      "Training Accuracy 0.52\n",
      "Loss 330.42032 274 5\n",
      "Training Accuracy 0.505\n",
      "Loss 377.37015 275 5\n",
      "Training Accuracy 0.39\n",
      "Loss 317.433 276 5\n",
      "Training Accuracy 0.535\n",
      "Loss 419.5109 277 5\n",
      "Training Accuracy 0.475\n",
      "Loss 317.88608 278 5\n",
      "Training Accuracy 0.49\n",
      "Loss 338.67395 279 5\n",
      "Training Accuracy 0.51\n",
      "Loss 332.57587 280 5\n",
      "Training Accuracy 0.5\n",
      "Loss 355.90646 281 5\n",
      "Training Accuracy 0.445\n",
      "Loss 346.8246 282 5\n",
      "Training Accuracy 0.48\n",
      "Loss 317.43835 283 5\n",
      "Training Accuracy 0.495\n",
      "Loss 313.86734 284 5\n",
      "Training Accuracy 0.57\n",
      "Loss 392.25174 285 5\n",
      "Training Accuracy 0.45\n",
      "Loss 354.76688 286 5\n",
      "Training Accuracy 0.49\n",
      "Loss 331.72128 287 5\n",
      "Training Accuracy 0.55\n",
      "Loss 357.65912 288 5\n",
      "Training Accuracy 0.48\n",
      "Loss 308.53723 289 5\n",
      "Training Accuracy 0.49\n",
      "Loss 351.5397 290 5\n",
      "Training Accuracy 0.505\n",
      "Loss 350.4407 291 5\n",
      "Training Accuracy 0.485\n",
      "Loss 227.25278 292 5\n",
      "Training Accuracy 0.5\n",
      "Loss 319.37744 1 6\n",
      "Training Accuracy 0.49\n",
      "Loss 330.67664 2 6\n",
      "Training Accuracy 0.525\n",
      "Loss 367.3726 3 6\n",
      "Training Accuracy 0.515\n",
      "Loss 344.98438 4 6\n",
      "Training Accuracy 0.495\n",
      "Loss 312.40915 5 6\n",
      "Training Accuracy 0.535\n",
      "Loss 355.01532 6 6\n",
      "Training Accuracy 0.51\n",
      "Loss 331.50558 7 6\n",
      "Training Accuracy 0.515\n",
      "Loss 405.15457 8 6\n",
      "Training Accuracy 0.5\n",
      "Loss 336.4797 9 6\n",
      "Training Accuracy 0.49\n",
      "Loss 351.60507 10 6\n",
      "Training Accuracy 0.48\n",
      "Loss 373.24185 11 6\n",
      "Training Accuracy 0.535\n",
      "Loss 333.9103 12 6\n",
      "Training Accuracy 0.475\n",
      "Loss 323.02985 13 6\n",
      "Training Accuracy 0.505\n",
      "Loss 356.25772 14 6\n",
      "Training Accuracy 0.51\n",
      "Loss 328.3633 15 6\n",
      "Training Accuracy 0.54\n",
      "Loss 358.70035 16 6\n",
      "Training Accuracy 0.47\n",
      "Loss 318.9833 17 6\n",
      "Training Accuracy 0.565\n",
      "Loss 343.98627 18 6\n",
      "Training Accuracy 0.5\n",
      "Loss 343.97104 19 6\n",
      "Training Accuracy 0.45\n",
      "Loss 353.94083 20 6\n",
      "Training Accuracy 0.48\n",
      "Loss 351.6949 21 6\n",
      "Training Accuracy 0.505\n",
      "Loss 378.37524 22 6\n",
      "Training Accuracy 0.455\n",
      "Loss 372.49127 23 6\n",
      "Training Accuracy 0.49\n",
      "Loss 349.64346 24 6\n",
      "Training Accuracy 0.455\n",
      "Loss 344.37164 25 6\n",
      "Training Accuracy 0.51\n",
      "Loss 367.60345 26 6\n",
      "Training Accuracy 0.385\n",
      "Loss 327.19482 27 6\n",
      "Training Accuracy 0.515\n",
      "Loss 351.7456 28 6\n",
      "Training Accuracy 0.44\n",
      "Loss 334.44336 29 6\n",
      "Training Accuracy 0.47\n",
      "Loss 353.66586 30 6\n",
      "Training Accuracy 0.48\n",
      "Loss 381.56717 31 6\n",
      "Training Accuracy 0.495\n",
      "Loss 340.8096 32 6\n",
      "Training Accuracy 0.46\n",
      "Loss 354.57837 33 6\n",
      "Training Accuracy 0.475\n",
      "Loss 321.78387 34 6\n",
      "Training Accuracy 0.47\n",
      "Loss 297.96408 35 6\n",
      "Training Accuracy 0.54\n",
      "Loss 335.14862 36 6\n",
      "Training Accuracy 0.475\n",
      "Loss 355.55713 37 6\n",
      "Training Accuracy 0.49\n",
      "Loss 343.51404 38 6\n",
      "Training Accuracy 0.495\n",
      "Loss 308.37387 39 6\n",
      "Training Accuracy 0.52\n",
      "Loss 303.23547 40 6\n",
      "Training Accuracy 0.565\n",
      "Loss 324.83463 41 6\n",
      "Training Accuracy 0.51\n",
      "Loss 377.27466 42 6\n",
      "Training Accuracy 0.465\n",
      "Loss 332.84586 43 6\n",
      "Training Accuracy 0.51\n",
      "Loss 321.3638 44 6\n",
      "Training Accuracy 0.5\n",
      "Loss 346.9271 45 6\n",
      "Training Accuracy 0.435\n",
      "Loss 358.79022 46 6\n",
      "Training Accuracy 0.495\n",
      "Loss 326.77023 47 6\n",
      "Training Accuracy 0.535\n",
      "Loss 326.59323 48 6\n",
      "Training Accuracy 0.53\n",
      "Loss 354.20468 49 6\n",
      "Training Accuracy 0.475\n",
      "Loss 364.37912 50 6\n",
      "Training Accuracy 0.45\n",
      "Loss 334.70572 51 6\n",
      "Training Accuracy 0.53\n",
      "Loss 331.89142 52 6\n",
      "Training Accuracy 0.505\n",
      "Loss 329.77393 53 6\n",
      "Training Accuracy 0.5\n",
      "Loss 344.29462 54 6\n",
      "Training Accuracy 0.48\n",
      "Loss 359.25278 55 6\n",
      "Training Accuracy 0.445\n",
      "Loss 334.5263 56 6\n",
      "Training Accuracy 0.45\n",
      "Loss 300.26147 57 6\n",
      "Training Accuracy 0.58\n",
      "Loss 292.3319 58 6\n",
      "Training Accuracy 0.545\n",
      "Loss 356.81143 59 6\n",
      "Training Accuracy 0.47\n",
      "Loss 340.8616 60 6\n",
      "Training Accuracy 0.495\n",
      "Loss 343.9579 61 6\n",
      "Training Accuracy 0.46\n",
      "Loss 341.1712 62 6\n",
      "Training Accuracy 0.49\n",
      "Loss 350.07672 63 6\n",
      "Training Accuracy 0.495\n",
      "Loss 343.01355 64 6\n",
      "Training Accuracy 0.5\n",
      "Loss 354.49023 65 6\n",
      "Training Accuracy 0.465\n",
      "Loss 335.12045 66 6\n",
      "Training Accuracy 0.465\n",
      "Loss 387.13672 67 6\n",
      "Training Accuracy 0.475\n",
      "Loss 340.3897 68 6\n",
      "Training Accuracy 0.475\n",
      "Loss 344.46423 69 6\n",
      "Training Accuracy 0.505\n",
      "Loss 352.7342 70 6\n",
      "Training Accuracy 0.515\n",
      "Loss 334.63748 71 6\n",
      "Training Accuracy 0.555\n",
      "Loss 342.71832 72 6\n",
      "Training Accuracy 0.445\n",
      "Loss 367.4073 73 6\n",
      "Training Accuracy 0.46\n",
      "Loss 392.95584 74 6\n",
      "Training Accuracy 0.475\n",
      "Loss 361.1225 75 6\n",
      "Training Accuracy 0.52\n",
      "Loss 331.79868 76 6\n",
      "Training Accuracy 0.49\n",
      "Loss 321.93777 77 6\n",
      "Training Accuracy 0.54\n",
      "Loss 334.76044 78 6\n",
      "Training Accuracy 0.51\n",
      "Loss 316.27255 79 6\n",
      "Training Accuracy 0.45\n",
      "Loss 326.81137 80 6\n",
      "Training Accuracy 0.5\n",
      "Loss 349.35733 81 6\n",
      "Training Accuracy 0.465\n",
      "Loss 329.94308 82 6\n",
      "Training Accuracy 0.525\n",
      "Loss 327.18817 83 6\n",
      "Training Accuracy 0.53\n",
      "Loss 380.08173 84 6\n",
      "Training Accuracy 0.425\n",
      "Loss 357.1709 85 6\n",
      "Training Accuracy 0.475\n",
      "Loss 348.31955 86 6\n",
      "Training Accuracy 0.485\n",
      "Loss 375.2467 87 6\n",
      "Training Accuracy 0.45\n",
      "Loss 355.56613 88 6\n",
      "Training Accuracy 0.455\n",
      "Loss 342.02545 89 6\n",
      "Training Accuracy 0.51\n",
      "Loss 337.35184 90 6\n",
      "Training Accuracy 0.5\n",
      "Loss 354.9928 91 6\n",
      "Training Accuracy 0.49\n",
      "Loss 356.20206 92 6\n",
      "Training Accuracy 0.525\n",
      "Loss 341.39337 93 6\n",
      "Training Accuracy 0.51\n",
      "Loss 353.3564 94 6\n",
      "Training Accuracy 0.45\n",
      "Loss 319.98785 95 6\n",
      "Training Accuracy 0.5\n",
      "Loss 321.73563 96 6\n",
      "Training Accuracy 0.51\n",
      "Loss 349.4148 97 6\n",
      "Training Accuracy 0.425\n",
      "Loss 355.81757 98 6\n",
      "Training Accuracy 0.47\n",
      "Loss 321.7142 99 6\n",
      "Training Accuracy 0.475\n",
      "Loss 363.07468 100 6\n",
      "Training Accuracy 0.49\n",
      "Loss 350.45172 101 6\n",
      "Training Accuracy 0.455\n",
      "Loss 298.73117 102 6\n",
      "Training Accuracy 0.54\n",
      "Loss 336.64926 103 6\n",
      "Training Accuracy 0.495\n",
      "Loss 332.2284 104 6\n",
      "Training Accuracy 0.475\n",
      "Loss 357.85538 105 6\n",
      "Training Accuracy 0.475\n",
      "Loss 355.83884 106 6\n",
      "Training Accuracy 0.5\n",
      "Loss 346.65588 107 6\n",
      "Training Accuracy 0.445\n",
      "Loss 352.4307 108 6\n",
      "Training Accuracy 0.48\n",
      "Loss 340.50555 109 6\n",
      "Training Accuracy 0.475\n",
      "Loss 349.71155 110 6\n",
      "Training Accuracy 0.45\n",
      "Loss 347.08234 111 6\n",
      "Training Accuracy 0.515\n",
      "Loss 364.34454 112 6\n",
      "Training Accuracy 0.49\n",
      "Loss 388.03256 113 6\n",
      "Training Accuracy 0.47\n",
      "Loss 334.1258 114 6\n",
      "Training Accuracy 0.505\n",
      "Loss 372.86682 115 6\n",
      "Training Accuracy 0.49\n",
      "Loss 385.74243 116 6\n",
      "Training Accuracy 0.45\n",
      "Loss 320.32355 117 6\n",
      "Training Accuracy 0.565\n",
      "Loss 365.46725 118 6\n",
      "Training Accuracy 0.53\n",
      "Loss 415.58008 119 6\n",
      "Training Accuracy 0.435\n",
      "Loss 376.46133 120 6\n",
      "Training Accuracy 0.45\n",
      "Loss 379.12164 121 6\n",
      "Training Accuracy 0.45\n",
      "Loss 305.12128 122 6\n",
      "Training Accuracy 0.51\n",
      "Loss 351.80307 123 6\n",
      "Training Accuracy 0.45\n",
      "Loss 332.67874 124 6\n",
      "Training Accuracy 0.52\n",
      "Loss 303.24066 125 6\n",
      "Training Accuracy 0.56\n",
      "Loss 342.21124 126 6\n",
      "Training Accuracy 0.465\n",
      "Loss 326.50568 127 6\n",
      "Training Accuracy 0.525\n",
      "Loss 329.8436 128 6\n",
      "Training Accuracy 0.465\n",
      "Loss 324.80286 129 6\n",
      "Training Accuracy 0.53\n",
      "Loss 328.93796 130 6\n",
      "Training Accuracy 0.475\n",
      "Loss 306.78607 131 6\n",
      "Training Accuracy 0.555\n",
      "Loss 317.83136 132 6\n",
      "Training Accuracy 0.5\n",
      "Loss 343.90543 133 6\n",
      "Training Accuracy 0.5\n",
      "Loss 325.7646 134 6\n",
      "Training Accuracy 0.51\n",
      "Loss 303.4294 135 6\n",
      "Training Accuracy 0.545\n",
      "Loss 361.91925 136 6\n",
      "Training Accuracy 0.505\n",
      "Loss 343.54407 137 6\n",
      "Training Accuracy 0.46\n",
      "Loss 314.23267 138 6\n",
      "Training Accuracy 0.56\n",
      "Loss 373.21393 139 6\n",
      "Training Accuracy 0.5\n",
      "Loss 301.4261 140 6\n",
      "Training Accuracy 0.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 355.73233 141 6\n",
      "Training Accuracy 0.505\n",
      "Loss 351.2959 142 6\n",
      "Training Accuracy 0.47\n",
      "Loss 301.69397 143 6\n",
      "Training Accuracy 0.485\n",
      "Loss 336.0184 144 6\n",
      "Training Accuracy 0.51\n",
      "Loss 348.41513 145 6\n",
      "Training Accuracy 0.505\n",
      "Loss 326.43646 146 6\n",
      "Training Accuracy 0.47\n",
      "Loss 331.23984 147 6\n",
      "Training Accuracy 0.52\n",
      "Loss 341.3003 148 6\n",
      "Training Accuracy 0.475\n",
      "Loss 321.95587 149 6\n",
      "Training Accuracy 0.515\n",
      "Loss 343.4083 150 6\n",
      "Training Accuracy 0.47\n",
      "Loss 346.42905 151 6\n",
      "Training Accuracy 0.505\n",
      "Loss 359.9618 152 6\n",
      "Training Accuracy 0.48\n",
      "Loss 336.3993 153 6\n",
      "Training Accuracy 0.495\n",
      "Loss 338.24152 154 6\n",
      "Training Accuracy 0.52\n",
      "Loss 312.91205 155 6\n",
      "Training Accuracy 0.545\n",
      "Loss 347.29507 156 6\n",
      "Training Accuracy 0.49\n",
      "Loss 302.5499 157 6\n",
      "Training Accuracy 0.505\n",
      "Loss 347.44064 158 6\n",
      "Training Accuracy 0.505\n",
      "Loss 378.50967 159 6\n",
      "Training Accuracy 0.47\n",
      "Loss 326.01526 160 6\n",
      "Training Accuracy 0.515\n",
      "Loss 361.46448 161 6\n",
      "Training Accuracy 0.475\n",
      "Loss 335.5895 162 6\n",
      "Training Accuracy 0.475\n",
      "Loss 361.70123 163 6\n",
      "Training Accuracy 0.455\n",
      "Loss 296.6857 164 6\n",
      "Training Accuracy 0.51\n",
      "Loss 322.79736 165 6\n",
      "Training Accuracy 0.52\n",
      "Loss 359.94058 166 6\n",
      "Training Accuracy 0.495\n",
      "Loss 284.66605 167 6\n",
      "Training Accuracy 0.53\n",
      "Loss 361.01904 168 6\n",
      "Training Accuracy 0.495\n",
      "Loss 321.75354 169 6\n",
      "Training Accuracy 0.49\n",
      "Loss 318.1699 170 6\n",
      "Training Accuracy 0.51\n",
      "Loss 354.5666 171 6\n",
      "Training Accuracy 0.55\n",
      "Loss 315.42743 172 6\n",
      "Training Accuracy 0.535\n",
      "Loss 388.72226 173 6\n",
      "Training Accuracy 0.48\n",
      "Loss 298.01987 174 6\n",
      "Training Accuracy 0.505\n",
      "Loss 320.01382 175 6\n",
      "Training Accuracy 0.52\n",
      "Loss 291.79 176 6\n",
      "Training Accuracy 0.59\n",
      "Loss 384.21762 177 6\n",
      "Training Accuracy 0.43\n",
      "Loss 305.47733 178 6\n",
      "Training Accuracy 0.545\n",
      "Loss 368.4061 179 6\n",
      "Training Accuracy 0.475\n",
      "Loss 337.86465 180 6\n",
      "Training Accuracy 0.46\n",
      "Loss 290.06644 181 6\n",
      "Training Accuracy 0.5\n",
      "Loss 358.6429 182 6\n",
      "Training Accuracy 0.42\n",
      "Loss 357.35156 183 6\n",
      "Training Accuracy 0.48\n",
      "Loss 302.39127 184 6\n",
      "Training Accuracy 0.525\n",
      "Loss 316.34772 185 6\n",
      "Training Accuracy 0.55\n",
      "Loss 319.42673 186 6\n",
      "Training Accuracy 0.52\n",
      "Loss 370.373 187 6\n",
      "Training Accuracy 0.45\n",
      "Loss 351.7944 188 6\n",
      "Training Accuracy 0.48\n",
      "Loss 347.96384 189 6\n",
      "Training Accuracy 0.46\n",
      "Loss 331.02274 190 6\n",
      "Training Accuracy 0.53\n",
      "Loss 325.57663 191 6\n",
      "Training Accuracy 0.495\n",
      "Loss 339.33218 192 6\n",
      "Training Accuracy 0.475\n",
      "Loss 306.66406 193 6\n",
      "Training Accuracy 0.575\n",
      "Loss 312.74863 194 6\n",
      "Training Accuracy 0.52\n",
      "Loss 313.72253 195 6\n",
      "Training Accuracy 0.53\n",
      "Loss 328.8943 196 6\n",
      "Training Accuracy 0.525\n",
      "Loss 335.04614 197 6\n",
      "Training Accuracy 0.525\n",
      "Loss 298.84467 198 6\n",
      "Training Accuracy 0.515\n",
      "Loss 281.95465 199 6\n",
      "Training Accuracy 0.55\n",
      "Loss 343.69592 200 6\n",
      "Training Accuracy 0.49\n",
      "Loss 320.60913 201 6\n",
      "Training Accuracy 0.51\n",
      "Loss 327.4888 202 6\n",
      "Training Accuracy 0.495\n",
      "Loss 350.83807 203 6\n",
      "Training Accuracy 0.47\n",
      "Loss 331.45367 204 6\n",
      "Training Accuracy 0.485\n",
      "Loss 354.32343 205 6\n",
      "Training Accuracy 0.485\n",
      "Loss 345.89288 206 6\n",
      "Training Accuracy 0.495\n",
      "Loss 307.27957 207 6\n",
      "Training Accuracy 0.495\n",
      "Loss 354.929 208 6\n",
      "Training Accuracy 0.475\n",
      "Loss 365.83548 209 6\n",
      "Training Accuracy 0.475\n",
      "Loss 308.905 210 6\n",
      "Training Accuracy 0.5\n",
      "Loss 352.97623 211 6\n",
      "Training Accuracy 0.495\n",
      "Loss 289.1341 212 6\n",
      "Training Accuracy 0.595\n",
      "Loss 388.3391 213 6\n",
      "Training Accuracy 0.455\n",
      "Loss 345.41876 214 6\n",
      "Training Accuracy 0.48\n",
      "Loss 338.02808 215 6\n",
      "Training Accuracy 0.52\n",
      "Loss 372.62946 216 6\n",
      "Training Accuracy 0.48\n",
      "Loss 321.3804 217 6\n",
      "Training Accuracy 0.485\n",
      "Loss 347.7773 218 6\n",
      "Training Accuracy 0.435\n",
      "Loss 328.95358 219 6\n",
      "Training Accuracy 0.51\n",
      "Loss 323.30695 220 6\n",
      "Training Accuracy 0.525\n",
      "Loss 344.91553 221 6\n",
      "Training Accuracy 0.455\n",
      "Loss 331.8202 222 6\n",
      "Training Accuracy 0.45\n",
      "Loss 366.93085 223 6\n",
      "Training Accuracy 0.465\n",
      "Loss 355.9807 224 6\n",
      "Training Accuracy 0.435\n",
      "Loss 354.69437 225 6\n",
      "Training Accuracy 0.46\n",
      "Loss 318.17902 226 6\n",
      "Training Accuracy 0.495\n",
      "Loss 389.335 227 6\n",
      "Training Accuracy 0.44\n",
      "Loss 381.88263 228 6\n",
      "Training Accuracy 0.455\n",
      "Loss 329.76025 229 6\n",
      "Training Accuracy 0.515\n",
      "Loss 344.28314 230 6\n",
      "Training Accuracy 0.5\n",
      "Loss 280.58835 231 6\n",
      "Training Accuracy 0.575\n",
      "Loss 341.2344 232 6\n",
      "Training Accuracy 0.485\n",
      "Loss 345.66846 233 6\n",
      "Training Accuracy 0.455\n",
      "Loss 343.12582 234 6\n",
      "Training Accuracy 0.475\n",
      "Loss 335.51743 235 6\n",
      "Training Accuracy 0.47\n",
      "Loss 294.82117 236 6\n",
      "Training Accuracy 0.585\n",
      "Loss 346.29578 237 6\n",
      "Training Accuracy 0.485\n",
      "Loss 323.54443 238 6\n",
      "Training Accuracy 0.485\n",
      "Loss 376.60297 239 6\n",
      "Training Accuracy 0.505\n",
      "Loss 330.1792 240 6\n",
      "Training Accuracy 0.49\n",
      "Loss 359.91183 241 6\n",
      "Training Accuracy 0.465\n",
      "Loss 307.33585 242 6\n",
      "Training Accuracy 0.565\n",
      "Loss 287.03342 243 6\n",
      "Training Accuracy 0.535\n",
      "Loss 335.93924 244 6\n",
      "Training Accuracy 0.495\n",
      "Loss 315.69507 245 6\n",
      "Training Accuracy 0.53\n",
      "Loss 351.76996 246 6\n",
      "Training Accuracy 0.47\n",
      "Loss 271.7776 247 6\n",
      "Training Accuracy 0.565\n",
      "Loss 314.79166 248 6\n",
      "Training Accuracy 0.48\n",
      "Loss 319.37753 249 6\n",
      "Training Accuracy 0.46\n",
      "Loss 359.98697 250 6\n",
      "Training Accuracy 0.49\n",
      "Loss 345.3015 251 6\n",
      "Training Accuracy 0.465\n",
      "Loss 313.7265 252 6\n",
      "Training Accuracy 0.44\n",
      "Loss 316.99164 253 6\n",
      "Training Accuracy 0.525\n",
      "Loss 314.95963 254 6\n",
      "Training Accuracy 0.545\n",
      "Loss 297.9938 255 6\n",
      "Training Accuracy 0.54\n",
      "Loss 346.8372 256 6\n",
      "Training Accuracy 0.495\n",
      "Loss 319.03796 257 6\n",
      "Training Accuracy 0.5\n",
      "Loss 329.80292 258 6\n",
      "Training Accuracy 0.505\n",
      "Loss 332.76398 259 6\n",
      "Training Accuracy 0.515\n",
      "Loss 295.071 260 6\n",
      "Training Accuracy 0.55\n",
      "Loss 340.3317 261 6\n",
      "Training Accuracy 0.495\n",
      "Loss 319.22128 262 6\n",
      "Training Accuracy 0.48\n",
      "Loss 406.71204 263 6\n",
      "Training Accuracy 0.42\n",
      "Loss 366.29803 264 6\n",
      "Training Accuracy 0.53\n",
      "Loss 350.87213 265 6\n",
      "Training Accuracy 0.505\n",
      "Loss 317.08984 266 6\n",
      "Training Accuracy 0.5\n",
      "Loss 342.6347 267 6\n",
      "Training Accuracy 0.52\n",
      "Loss 356.54587 268 6\n",
      "Training Accuracy 0.51\n",
      "Loss 291.88095 269 6\n",
      "Training Accuracy 0.505\n",
      "Loss 306.77026 270 6\n",
      "Training Accuracy 0.525\n",
      "Loss 377.2296 271 6\n",
      "Training Accuracy 0.45\n",
      "Loss 334.8591 272 6\n",
      "Training Accuracy 0.54\n",
      "Loss 334.72775 273 6\n",
      "Training Accuracy 0.46\n",
      "Loss 304.94952 274 6\n",
      "Training Accuracy 0.505\n",
      "Loss 358.64822 275 6\n",
      "Training Accuracy 0.4\n",
      "Loss 299.76553 276 6\n",
      "Training Accuracy 0.54\n",
      "Loss 405.40582 277 6\n",
      "Training Accuracy 0.475\n",
      "Loss 305.3019 278 6\n",
      "Training Accuracy 0.545\n",
      "Loss 312.0718 279 6\n",
      "Training Accuracy 0.54\n",
      "Loss 309.5749 280 6\n",
      "Training Accuracy 0.565\n",
      "Loss 332.84766 281 6\n",
      "Training Accuracy 0.485\n",
      "Loss 337.30475 282 6\n",
      "Training Accuracy 0.485\n",
      "Loss 308.90442 283 6\n",
      "Training Accuracy 0.505\n",
      "Loss 307.02927 284 6\n",
      "Training Accuracy 0.58\n",
      "Loss 375.88797 285 6\n",
      "Training Accuracy 0.465\n",
      "Loss 334.0836 286 6\n",
      "Training Accuracy 0.48\n",
      "Loss 327.06793 287 6\n",
      "Training Accuracy 0.525\n",
      "Loss 335.21484 288 6\n",
      "Training Accuracy 0.57\n",
      "Loss 292.9884 289 6\n",
      "Training Accuracy 0.55\n",
      "Loss 340.994 290 6\n",
      "Training Accuracy 0.515\n",
      "Loss 334.64713 291 6\n",
      "Training Accuracy 0.47\n",
      "Loss 218.28258 292 6\n",
      "Training Accuracy 0.46212122\n",
      "Loss 308.69052 1 7\n",
      "Training Accuracy 0.535\n",
      "Loss 325.1538 2 7\n",
      "Training Accuracy 0.515\n",
      "Loss 348.49136 3 7\n",
      "Training Accuracy 0.485\n",
      "Loss 328.91318 4 7\n",
      "Training Accuracy 0.54\n",
      "Loss 306.08966 5 7\n",
      "Training Accuracy 0.54\n",
      "Loss 333.22617 6 7\n",
      "Training Accuracy 0.49\n",
      "Loss 319.10526 7 7\n",
      "Training Accuracy 0.535\n",
      "Loss 394.50937 8 7\n",
      "Training Accuracy 0.46\n",
      "Loss 324.81534 9 7\n",
      "Training Accuracy 0.48\n",
      "Loss 337.42032 10 7\n",
      "Training Accuracy 0.485\n",
      "Loss 362.81003 11 7\n",
      "Training Accuracy 0.51\n",
      "Loss 318.57556 12 7\n",
      "Training Accuracy 0.465\n",
      "Loss 312.07135 13 7\n",
      "Training Accuracy 0.48\n",
      "Loss 343.53424 14 7\n",
      "Training Accuracy 0.505\n",
      "Loss 315.67734 15 7\n",
      "Training Accuracy 0.555\n",
      "Loss 348.31647 16 7\n",
      "Training Accuracy 0.475\n",
      "Loss 309.5193 17 7\n",
      "Training Accuracy 0.535\n",
      "Loss 323.1425 18 7\n",
      "Training Accuracy 0.515\n",
      "Loss 322.4323 19 7\n",
      "Training Accuracy 0.5\n",
      "Loss 329.6797 20 7\n",
      "Training Accuracy 0.485\n",
      "Loss 341.59973 21 7\n",
      "Training Accuracy 0.5\n",
      "Loss 360.4826 22 7\n",
      "Training Accuracy 0.485\n",
      "Loss 356.59076 23 7\n",
      "Training Accuracy 0.495\n",
      "Loss 341.34854 24 7\n",
      "Training Accuracy 0.485\n",
      "Loss 330.19397 25 7\n",
      "Training Accuracy 0.51\n",
      "Loss 351.84335 26 7\n",
      "Training Accuracy 0.44\n",
      "Loss 320.17575 27 7\n",
      "Training Accuracy 0.525\n",
      "Loss 333.83356 28 7\n",
      "Training Accuracy 0.465\n",
      "Loss 315.07513 29 7\n",
      "Training Accuracy 0.495\n",
      "Loss 339.3148 30 7\n",
      "Training Accuracy 0.48\n",
      "Loss 371.27167 31 7\n",
      "Training Accuracy 0.465\n",
      "Loss 336.96277 32 7\n",
      "Training Accuracy 0.445\n",
      "Loss 337.40143 33 7\n",
      "Training Accuracy 0.53\n",
      "Loss 299.44974 34 7\n",
      "Training Accuracy 0.54\n",
      "Loss 285.6788 35 7\n",
      "Training Accuracy 0.525\n",
      "Loss 323.04047 36 7\n",
      "Training Accuracy 0.515\n",
      "Loss 336.1956 37 7\n",
      "Training Accuracy 0.505\n",
      "Loss 337.07962 38 7\n",
      "Training Accuracy 0.475\n",
      "Loss 290.91818 39 7\n",
      "Training Accuracy 0.55\n",
      "Loss 300.33 40 7\n",
      "Training Accuracy 0.59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 316.9423 41 7\n",
      "Training Accuracy 0.51\n",
      "Loss 358.20636 42 7\n",
      "Training Accuracy 0.465\n",
      "Loss 323.89282 43 7\n",
      "Training Accuracy 0.49\n",
      "Loss 310.49548 44 7\n",
      "Training Accuracy 0.48\n",
      "Loss 334.2259 45 7\n",
      "Training Accuracy 0.46\n",
      "Loss 354.78723 46 7\n",
      "Training Accuracy 0.495\n",
      "Loss 310.7128 47 7\n",
      "Training Accuracy 0.56\n",
      "Loss 300.8872 48 7\n",
      "Training Accuracy 0.57\n",
      "Loss 331.95807 49 7\n",
      "Training Accuracy 0.475\n",
      "Loss 352.43198 50 7\n",
      "Training Accuracy 0.485\n",
      "Loss 317.37503 51 7\n",
      "Training Accuracy 0.55\n",
      "Loss 320.08414 52 7\n",
      "Training Accuracy 0.495\n",
      "Loss 319.87643 53 7\n",
      "Training Accuracy 0.53\n",
      "Loss 331.99207 54 7\n",
      "Training Accuracy 0.47\n",
      "Loss 348.348 55 7\n",
      "Training Accuracy 0.41\n",
      "Loss 326.34167 56 7\n",
      "Training Accuracy 0.475\n",
      "Loss 289.09302 57 7\n",
      "Training Accuracy 0.59\n",
      "Loss 293.21106 58 7\n",
      "Training Accuracy 0.51\n",
      "Loss 354.23077 59 7\n",
      "Training Accuracy 0.445\n",
      "Loss 327.7246 60 7\n",
      "Training Accuracy 0.515\n",
      "Loss 328.24448 61 7\n",
      "Training Accuracy 0.43\n",
      "Loss 314.2735 62 7\n",
      "Training Accuracy 0.52\n",
      "Loss 339.06653 63 7\n",
      "Training Accuracy 0.48\n",
      "Loss 330.89838 64 7\n",
      "Training Accuracy 0.535\n",
      "Loss 343.01035 65 7\n",
      "Training Accuracy 0.49\n",
      "Loss 312.60336 66 7\n",
      "Training Accuracy 0.535\n",
      "Loss 362.22836 67 7\n",
      "Training Accuracy 0.475\n",
      "Loss 313.56186 68 7\n",
      "Training Accuracy 0.49\n",
      "Loss 329.9823 69 7\n",
      "Training Accuracy 0.495\n",
      "Loss 334.78714 70 7\n",
      "Training Accuracy 0.49\n",
      "Loss 317.94272 71 7\n",
      "Training Accuracy 0.55\n",
      "Loss 325.05396 72 7\n",
      "Training Accuracy 0.53\n",
      "Loss 334.44556 73 7\n",
      "Training Accuracy 0.53\n",
      "Loss 378.0049 74 7\n",
      "Training Accuracy 0.49\n",
      "Loss 344.69928 75 7\n",
      "Training Accuracy 0.52\n",
      "Loss 305.05536 76 7\n",
      "Training Accuracy 0.53\n",
      "Loss 301.23413 77 7\n",
      "Training Accuracy 0.56\n",
      "Loss 316.5178 78 7\n",
      "Training Accuracy 0.525\n",
      "Loss 301.3955 79 7\n",
      "Training Accuracy 0.495\n",
      "Loss 320.82007 80 7\n",
      "Training Accuracy 0.475\n",
      "Loss 330.0884 81 7\n",
      "Training Accuracy 0.45\n",
      "Loss 319.23907 82 7\n",
      "Training Accuracy 0.46\n",
      "Loss 319.0938 83 7\n",
      "Training Accuracy 0.555\n",
      "Loss 367.6989 84 7\n",
      "Training Accuracy 0.435\n",
      "Loss 336.4873 85 7\n",
      "Training Accuracy 0.44\n",
      "Loss 337.7826 86 7\n",
      "Training Accuracy 0.47\n",
      "Loss 369.66214 87 7\n",
      "Training Accuracy 0.435\n",
      "Loss 349.451 88 7\n",
      "Training Accuracy 0.485\n",
      "Loss 341.35556 89 7\n",
      "Training Accuracy 0.49\n",
      "Loss 322.39093 90 7\n",
      "Training Accuracy 0.515\n",
      "Loss 334.4695 91 7\n",
      "Training Accuracy 0.48\n",
      "Loss 344.08276 92 7\n",
      "Training Accuracy 0.46\n",
      "Loss 323.4691 93 7\n",
      "Training Accuracy 0.495\n",
      "Loss 340.44196 94 7\n",
      "Training Accuracy 0.465\n",
      "Loss 305.86304 95 7\n",
      "Training Accuracy 0.485\n",
      "Loss 312.29666 96 7\n",
      "Training Accuracy 0.55\n",
      "Loss 330.8816 97 7\n",
      "Training Accuracy 0.49\n",
      "Loss 336.53253 98 7\n",
      "Training Accuracy 0.49\n",
      "Loss 317.89734 99 7\n",
      "Training Accuracy 0.485\n",
      "Loss 356.21683 100 7\n",
      "Training Accuracy 0.49\n",
      "Loss 335.4692 101 7\n",
      "Training Accuracy 0.5\n",
      "Loss 286.7635 102 7\n",
      "Training Accuracy 0.535\n",
      "Loss 326.6427 103 7\n",
      "Training Accuracy 0.485\n",
      "Loss 310.80865 104 7\n",
      "Training Accuracy 0.51\n",
      "Loss 347.94495 105 7\n",
      "Training Accuracy 0.46\n",
      "Loss 344.13474 106 7\n",
      "Training Accuracy 0.495\n",
      "Loss 334.26987 107 7\n",
      "Training Accuracy 0.45\n",
      "Loss 327.95575 108 7\n",
      "Training Accuracy 0.5\n",
      "Loss 324.56314 109 7\n",
      "Training Accuracy 0.47\n",
      "Loss 336.35837 110 7\n",
      "Training Accuracy 0.485\n",
      "Loss 329.3193 111 7\n",
      "Training Accuracy 0.5\n",
      "Loss 350.1803 112 7\n",
      "Training Accuracy 0.51\n",
      "Loss 370.70117 113 7\n",
      "Training Accuracy 0.485\n",
      "Loss 312.58725 114 7\n",
      "Training Accuracy 0.45\n",
      "Loss 357.79233 115 7\n",
      "Training Accuracy 0.455\n",
      "Loss 365.05545 116 7\n",
      "Training Accuracy 0.495\n",
      "Loss 300.63928 117 7\n",
      "Training Accuracy 0.59\n",
      "Loss 352.01898 118 7\n",
      "Training Accuracy 0.54\n",
      "Loss 397.8231 119 7\n",
      "Training Accuracy 0.405\n",
      "Loss 365.06866 120 7\n",
      "Training Accuracy 0.445\n",
      "Loss 360.7911 121 7\n",
      "Training Accuracy 0.495\n",
      "Loss 285.87256 122 7\n",
      "Training Accuracy 0.56\n",
      "Loss 330.31836 123 7\n",
      "Training Accuracy 0.485\n",
      "Loss 331.60492 124 7\n",
      "Training Accuracy 0.485\n",
      "Loss 300.9896 125 7\n",
      "Training Accuracy 0.525\n",
      "Loss 340.38608 126 7\n",
      "Training Accuracy 0.475\n",
      "Loss 321.53592 127 7\n",
      "Training Accuracy 0.51\n",
      "Loss 315.60367 128 7\n",
      "Training Accuracy 0.49\n",
      "Loss 318.84705 129 7\n",
      "Training Accuracy 0.53\n",
      "Loss 310.54166 130 7\n",
      "Training Accuracy 0.49\n",
      "Loss 297.6258 131 7\n",
      "Training Accuracy 0.58\n",
      "Loss 304.50272 132 7\n",
      "Training Accuracy 0.555\n",
      "Loss 325.8429 133 7\n",
      "Training Accuracy 0.51\n",
      "Loss 305.1514 134 7\n",
      "Training Accuracy 0.525\n",
      "Loss 288.35312 135 7\n",
      "Training Accuracy 0.55\n",
      "Loss 347.14447 136 7\n",
      "Training Accuracy 0.505\n",
      "Loss 331.96835 137 7\n",
      "Training Accuracy 0.505\n",
      "Loss 308.49747 138 7\n",
      "Training Accuracy 0.545\n",
      "Loss 357.48837 139 7\n",
      "Training Accuracy 0.54\n",
      "Loss 292.94257 140 7\n",
      "Training Accuracy 0.57\n",
      "Loss 343.7239 141 7\n",
      "Training Accuracy 0.495\n",
      "Loss 330.15622 142 7\n",
      "Training Accuracy 0.49\n",
      "Loss 287.8558 143 7\n",
      "Training Accuracy 0.505\n",
      "Loss 327.44257 144 7\n",
      "Training Accuracy 0.5\n",
      "Loss 327.4306 145 7\n",
      "Training Accuracy 0.475\n",
      "Loss 314.03833 146 7\n",
      "Training Accuracy 0.49\n",
      "Loss 318.51443 147 7\n",
      "Training Accuracy 0.51\n",
      "Loss 321.90274 148 7\n",
      "Training Accuracy 0.475\n",
      "Loss 311.55035 149 7\n",
      "Training Accuracy 0.535\n",
      "Loss 314.12082 150 7\n",
      "Training Accuracy 0.5\n",
      "Loss 334.87207 151 7\n",
      "Training Accuracy 0.52\n",
      "Loss 345.30533 152 7\n",
      "Training Accuracy 0.475\n",
      "Loss 326.28818 153 7\n",
      "Training Accuracy 0.485\n",
      "Loss 325.1477 154 7\n",
      "Training Accuracy 0.51\n",
      "Loss 305.43637 155 7\n",
      "Training Accuracy 0.51\n",
      "Loss 340.35483 156 7\n",
      "Training Accuracy 0.445\n",
      "Loss 276.44028 157 7\n",
      "Training Accuracy 0.555\n",
      "Loss 328.89032 158 7\n",
      "Training Accuracy 0.51\n",
      "Loss 365.27136 159 7\n",
      "Training Accuracy 0.48\n",
      "Loss 327.9646 160 7\n",
      "Training Accuracy 0.53\n",
      "Loss 360.37653 161 7\n",
      "Training Accuracy 0.455\n",
      "Loss 309.0893 162 7\n",
      "Training Accuracy 0.565\n",
      "Loss 340.13147 163 7\n",
      "Training Accuracy 0.495\n",
      "Loss 286.039 164 7\n",
      "Training Accuracy 0.53\n",
      "Loss 313.8683 165 7\n",
      "Training Accuracy 0.53\n",
      "Loss 338.48056 166 7\n",
      "Training Accuracy 0.52\n",
      "Loss 268.67026 167 7\n",
      "Training Accuracy 0.55\n",
      "Loss 348.4678 168 7\n",
      "Training Accuracy 0.5\n",
      "Loss 303.10767 169 7\n",
      "Training Accuracy 0.485\n",
      "Loss 306.96756 170 7\n",
      "Training Accuracy 0.52\n",
      "Loss 339.42923 171 7\n",
      "Training Accuracy 0.585\n",
      "Loss 312.2428 172 7\n",
      "Training Accuracy 0.52\n",
      "Loss 384.2082 173 7\n",
      "Training Accuracy 0.43\n",
      "Loss 279.06436 174 7\n",
      "Training Accuracy 0.555\n",
      "Loss 303.80505 175 7\n",
      "Training Accuracy 0.58\n",
      "Loss 290.9142 176 7\n",
      "Training Accuracy 0.6\n",
      "Loss 362.87158 177 7\n",
      "Training Accuracy 0.47\n",
      "Loss 304.7712 178 7\n",
      "Training Accuracy 0.52\n",
      "Loss 354.895 179 7\n",
      "Training Accuracy 0.465\n",
      "Loss 323.23892 180 7\n",
      "Training Accuracy 0.435\n",
      "Loss 283.18933 181 7\n",
      "Training Accuracy 0.515\n",
      "Loss 348.06213 182 7\n",
      "Training Accuracy 0.425\n",
      "Loss 338.19525 183 7\n",
      "Training Accuracy 0.475\n",
      "Loss 290.19025 184 7\n",
      "Training Accuracy 0.545\n",
      "Loss 300.82544 185 7\n",
      "Training Accuracy 0.525\n",
      "Loss 300.05502 186 7\n",
      "Training Accuracy 0.56\n",
      "Loss 361.8874 187 7\n",
      "Training Accuracy 0.45\n",
      "Loss 335.6713 188 7\n",
      "Training Accuracy 0.53\n",
      "Loss 331.74292 189 7\n",
      "Training Accuracy 0.53\n",
      "Loss 319.78934 190 7\n",
      "Training Accuracy 0.53\n",
      "Loss 321.41425 191 7\n",
      "Training Accuracy 0.505\n",
      "Loss 328.36508 192 7\n",
      "Training Accuracy 0.465\n",
      "Loss 282.25876 193 7\n",
      "Training Accuracy 0.59\n",
      "Loss 305.65253 194 7\n",
      "Training Accuracy 0.52\n",
      "Loss 308.91965 195 7\n",
      "Training Accuracy 0.505\n",
      "Loss 313.4442 196 7\n",
      "Training Accuracy 0.55\n",
      "Loss 330.58408 197 7\n",
      "Training Accuracy 0.505\n",
      "Loss 293.64795 198 7\n",
      "Training Accuracy 0.51\n",
      "Loss 266.11862 199 7\n",
      "Training Accuracy 0.58\n",
      "Loss 330.2149 200 7\n",
      "Training Accuracy 0.46\n",
      "Loss 309.05685 201 7\n",
      "Training Accuracy 0.485\n",
      "Loss 304.02014 202 7\n",
      "Training Accuracy 0.495\n",
      "Loss 333.1505 203 7\n",
      "Training Accuracy 0.475\n",
      "Loss 324.2038 204 7\n",
      "Training Accuracy 0.485\n",
      "Loss 346.9218 205 7\n",
      "Training Accuracy 0.5\n",
      "Loss 335.99042 206 7\n",
      "Training Accuracy 0.495\n",
      "Loss 302.8097 207 7\n",
      "Training Accuracy 0.51\n",
      "Loss 349.58218 208 7\n",
      "Training Accuracy 0.5\n",
      "Loss 343.1394 209 7\n",
      "Training Accuracy 0.5\n",
      "Loss 303.16348 210 7\n",
      "Training Accuracy 0.495\n",
      "Loss 338.73672 211 7\n",
      "Training Accuracy 0.47\n",
      "Loss 291.526 212 7\n",
      "Training Accuracy 0.57\n",
      "Loss 377.4014 213 7\n",
      "Training Accuracy 0.415\n",
      "Loss 326.40976 214 7\n",
      "Training Accuracy 0.515\n",
      "Loss 338.0979 215 7\n",
      "Training Accuracy 0.495\n",
      "Loss 361.52698 216 7\n",
      "Training Accuracy 0.495\n",
      "Loss 317.74606 217 7\n",
      "Training Accuracy 0.465\n",
      "Loss 344.08688 218 7\n",
      "Training Accuracy 0.455\n",
      "Loss 321.90924 219 7\n",
      "Training Accuracy 0.5\n",
      "Loss 313.92273 220 7\n",
      "Training Accuracy 0.555\n",
      "Loss 335.41077 221 7\n",
      "Training Accuracy 0.51\n",
      "Loss 309.96664 222 7\n",
      "Training Accuracy 0.545\n",
      "Loss 345.02646 223 7\n",
      "Training Accuracy 0.445\n",
      "Loss 342.81772 224 7\n",
      "Training Accuracy 0.455\n",
      "Loss 347.43427 225 7\n",
      "Training Accuracy 0.5\n",
      "Loss 299.9705 226 7\n",
      "Training Accuracy 0.51\n",
      "Loss 360.80478 227 7\n",
      "Training Accuracy 0.475\n",
      "Loss 362.09378 228 7\n",
      "Training Accuracy 0.45\n",
      "Loss 315.60098 229 7\n",
      "Training Accuracy 0.535\n",
      "Loss 311.97684 230 7\n",
      "Training Accuracy 0.51\n",
      "Loss 268.077 231 7\n",
      "Training Accuracy 0.605\n",
      "Loss 322.9354 232 7\n",
      "Training Accuracy 0.505\n",
      "Loss 335.5961 233 7\n",
      "Training Accuracy 0.485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 329.95172 234 7\n",
      "Training Accuracy 0.5\n",
      "Loss 320.9674 235 7\n",
      "Training Accuracy 0.53\n",
      "Loss 283.84756 236 7\n",
      "Training Accuracy 0.6\n",
      "Loss 324.3789 237 7\n",
      "Training Accuracy 0.515\n",
      "Loss 308.1241 238 7\n",
      "Training Accuracy 0.495\n",
      "Loss 361.27252 239 7\n",
      "Training Accuracy 0.49\n",
      "Loss 317.30933 240 7\n",
      "Training Accuracy 0.51\n",
      "Loss 346.68954 241 7\n",
      "Training Accuracy 0.46\n",
      "Loss 280.92603 242 7\n",
      "Training Accuracy 0.565\n",
      "Loss 289.0551 243 7\n",
      "Training Accuracy 0.5\n",
      "Loss 329.79794 244 7\n",
      "Training Accuracy 0.465\n",
      "Loss 315.34338 245 7\n",
      "Training Accuracy 0.515\n",
      "Loss 332.1268 246 7\n",
      "Training Accuracy 0.495\n",
      "Loss 266.2621 247 7\n",
      "Training Accuracy 0.565\n",
      "Loss 294.47336 248 7\n",
      "Training Accuracy 0.495\n",
      "Loss 315.872 249 7\n",
      "Training Accuracy 0.505\n",
      "Loss 341.9818 250 7\n",
      "Training Accuracy 0.445\n",
      "Loss 328.41028 251 7\n",
      "Training Accuracy 0.46\n",
      "Loss 299.6872 252 7\n",
      "Training Accuracy 0.515\n",
      "Loss 303.8613 253 7\n",
      "Training Accuracy 0.54\n",
      "Loss 305.12225 254 7\n",
      "Training Accuracy 0.545\n",
      "Loss 285.90863 255 7\n",
      "Training Accuracy 0.56\n",
      "Loss 322.91675 256 7\n",
      "Training Accuracy 0.535\n",
      "Loss 301.73962 257 7\n",
      "Training Accuracy 0.535\n",
      "Loss 302.51706 258 7\n",
      "Training Accuracy 0.53\n",
      "Loss 322.13016 259 7\n",
      "Training Accuracy 0.465\n",
      "Loss 280.82462 260 7\n",
      "Training Accuracy 0.575\n",
      "Loss 327.9235 261 7\n",
      "Training Accuracy 0.535\n",
      "Loss 313.9134 262 7\n",
      "Training Accuracy 0.47\n",
      "Loss 390.79834 263 7\n",
      "Training Accuracy 0.43\n",
      "Loss 345.25192 264 7\n",
      "Training Accuracy 0.515\n",
      "Loss 328.5401 265 7\n",
      "Training Accuracy 0.51\n",
      "Loss 307.30945 266 7\n",
      "Training Accuracy 0.515\n",
      "Loss 330.45215 267 7\n",
      "Training Accuracy 0.52\n",
      "Loss 333.58325 268 7\n",
      "Training Accuracy 0.505\n",
      "Loss 284.73874 269 7\n",
      "Training Accuracy 0.49\n",
      "Loss 289.0576 270 7\n",
      "Training Accuracy 0.55\n",
      "Loss 361.14972 271 7\n",
      "Training Accuracy 0.47\n",
      "Loss 318.9659 272 7\n",
      "Training Accuracy 0.545\n",
      "Loss 326.05444 273 7\n",
      "Training Accuracy 0.51\n",
      "Loss 294.35245 274 7\n",
      "Training Accuracy 0.565\n",
      "Loss 347.57495 275 7\n",
      "Training Accuracy 0.44\n",
      "Loss 292.1862 276 7\n",
      "Training Accuracy 0.58\n",
      "Loss 392.27362 277 7\n",
      "Training Accuracy 0.445\n",
      "Loss 298.42606 278 7\n",
      "Training Accuracy 0.52\n",
      "Loss 307.58722 279 7\n",
      "Training Accuracy 0.545\n",
      "Loss 297.69916 280 7\n",
      "Training Accuracy 0.515\n",
      "Loss 319.37216 281 7\n",
      "Training Accuracy 0.515\n",
      "Loss 325.20877 282 7\n",
      "Training Accuracy 0.48\n",
      "Loss 299.4622 283 7\n",
      "Training Accuracy 0.52\n",
      "Loss 296.72894 284 7\n",
      "Training Accuracy 0.575\n",
      "Loss 354.57245 285 7\n",
      "Training Accuracy 0.5\n",
      "Loss 319.04318 286 7\n",
      "Training Accuracy 0.535\n",
      "Loss 310.01074 287 7\n",
      "Training Accuracy 0.555\n",
      "Loss 323.58908 288 7\n",
      "Training Accuracy 0.545\n",
      "Loss 285.69748 289 7\n",
      "Training Accuracy 0.535\n",
      "Loss 322.90726 290 7\n",
      "Training Accuracy 0.455\n",
      "Loss 311.1836 291 7\n",
      "Training Accuracy 0.51\n",
      "Loss 207.2604 292 7\n",
      "Training Accuracy 0.49242425\n",
      "Loss 289.89255 1 8\n",
      "Training Accuracy 0.555\n",
      "Loss 320.28564 2 8\n",
      "Training Accuracy 0.55\n",
      "Loss 332.1611 3 8\n",
      "Training Accuracy 0.52\n",
      "Loss 314.2559 4 8\n",
      "Training Accuracy 0.525\n",
      "Loss 283.23917 5 8\n",
      "Training Accuracy 0.56\n",
      "Loss 321.83063 6 8\n",
      "Training Accuracy 0.495\n",
      "Loss 303.52783 7 8\n",
      "Training Accuracy 0.55\n",
      "Loss 367.6 8 8\n",
      "Training Accuracy 0.495\n",
      "Loss 309.89124 9 8\n",
      "Training Accuracy 0.515\n",
      "Loss 326.17224 10 8\n",
      "Training Accuracy 0.51\n",
      "Loss 359.2033 11 8\n",
      "Training Accuracy 0.52\n",
      "Loss 305.49124 12 8\n",
      "Training Accuracy 0.495\n",
      "Loss 305.75998 13 8\n",
      "Training Accuracy 0.515\n",
      "Loss 330.48395 14 8\n",
      "Training Accuracy 0.495\n",
      "Loss 303.2105 15 8\n",
      "Training Accuracy 0.555\n",
      "Loss 351.58023 16 8\n",
      "Training Accuracy 0.46\n",
      "Loss 302.2224 17 8\n",
      "Training Accuracy 0.57\n",
      "Loss 317.08267 18 8\n",
      "Training Accuracy 0.485\n",
      "Loss 303.07306 19 8\n",
      "Training Accuracy 0.52\n",
      "Loss 321.479 20 8\n",
      "Training Accuracy 0.48\n",
      "Loss 315.4939 21 8\n",
      "Training Accuracy 0.52\n",
      "Loss 340.48184 22 8\n",
      "Training Accuracy 0.51\n",
      "Loss 336.87247 23 8\n",
      "Training Accuracy 0.505\n",
      "Loss 324.0908 24 8\n",
      "Training Accuracy 0.505\n",
      "Loss 317.72244 25 8\n",
      "Training Accuracy 0.51\n",
      "Loss 342.88943 26 8\n",
      "Training Accuracy 0.445\n",
      "Loss 307.63815 27 8\n",
      "Training Accuracy 0.51\n",
      "Loss 319.43625 28 8\n",
      "Training Accuracy 0.455\n",
      "Loss 307.08264 29 8\n",
      "Training Accuracy 0.51\n",
      "Loss 345.45175 30 8\n",
      "Training Accuracy 0.445\n",
      "Loss 349.22098 31 8\n",
      "Training Accuracy 0.5\n",
      "Loss 314.27402 32 8\n",
      "Training Accuracy 0.485\n",
      "Loss 330.80252 33 8\n",
      "Training Accuracy 0.48\n",
      "Loss 293.3873 34 8\n",
      "Training Accuracy 0.545\n",
      "Loss 283.25198 35 8\n",
      "Training Accuracy 0.54\n",
      "Loss 302.18372 36 8\n",
      "Training Accuracy 0.515\n",
      "Loss 320.55988 37 8\n",
      "Training Accuracy 0.53\n",
      "Loss 318.89758 38 8\n",
      "Training Accuracy 0.51\n",
      "Loss 280.45816 39 8\n",
      "Training Accuracy 0.565\n",
      "Loss 287.19135 40 8\n",
      "Training Accuracy 0.575\n",
      "Loss 302.32767 41 8\n",
      "Training Accuracy 0.505\n",
      "Loss 357.2083 42 8\n",
      "Training Accuracy 0.42\n",
      "Loss 300.1336 43 8\n",
      "Training Accuracy 0.55\n",
      "Loss 304.72736 44 8\n",
      "Training Accuracy 0.52\n",
      "Loss 320.0767 45 8\n",
      "Training Accuracy 0.51\n",
      "Loss 338.3926 46 8\n",
      "Training Accuracy 0.48\n",
      "Loss 298.27164 47 8\n",
      "Training Accuracy 0.53\n",
      "Loss 297.09085 48 8\n",
      "Training Accuracy 0.56\n",
      "Loss 322.95047 49 8\n",
      "Training Accuracy 0.48\n",
      "Loss 331.7065 50 8\n",
      "Training Accuracy 0.515\n",
      "Loss 309.47403 51 8\n",
      "Training Accuracy 0.545\n",
      "Loss 305.20667 52 8\n",
      "Training Accuracy 0.53\n",
      "Loss 309.2963 53 8\n",
      "Training Accuracy 0.53\n",
      "Loss 324.12604 54 8\n",
      "Training Accuracy 0.47\n",
      "Loss 320.29434 55 8\n",
      "Training Accuracy 0.445\n",
      "Loss 320.53387 56 8\n",
      "Training Accuracy 0.45\n",
      "Loss 279.93695 57 8\n",
      "Training Accuracy 0.59\n",
      "Loss 277.71365 58 8\n",
      "Training Accuracy 0.56\n",
      "Loss 334.79623 59 8\n",
      "Training Accuracy 0.48\n",
      "Loss 318.04764 60 8\n",
      "Training Accuracy 0.53\n",
      "Loss 307.4556 61 8\n",
      "Training Accuracy 0.53\n",
      "Loss 295.91132 62 8\n",
      "Training Accuracy 0.52\n",
      "Loss 322.8436 63 8\n",
      "Training Accuracy 0.505\n",
      "Loss 317.1552 64 8\n",
      "Training Accuracy 0.52\n",
      "Loss 330.74353 65 8\n",
      "Training Accuracy 0.465\n",
      "Loss 304.96158 66 8\n",
      "Training Accuracy 0.505\n",
      "Loss 352.54294 67 8\n",
      "Training Accuracy 0.48\n",
      "Loss 319.66882 68 8\n",
      "Training Accuracy 0.52\n",
      "Loss 321.16577 69 8\n",
      "Training Accuracy 0.52\n",
      "Loss 324.71448 70 8\n",
      "Training Accuracy 0.52\n",
      "Loss 311.51294 71 8\n",
      "Training Accuracy 0.535\n",
      "Loss 317.73605 72 8\n",
      "Training Accuracy 0.495\n",
      "Loss 323.38333 73 8\n",
      "Training Accuracy 0.515\n",
      "Loss 356.14508 74 8\n",
      "Training Accuracy 0.495\n",
      "Loss 326.67462 75 8\n",
      "Training Accuracy 0.535\n",
      "Loss 299.1315 76 8\n",
      "Training Accuracy 0.545\n",
      "Loss 307.6379 77 8\n",
      "Training Accuracy 0.5\n",
      "Loss 310.8496 78 8\n",
      "Training Accuracy 0.565\n",
      "Loss 289.3011 79 8\n",
      "Training Accuracy 0.46\n",
      "Loss 315.2888 80 8\n",
      "Training Accuracy 0.505\n",
      "Loss 318.1407 81 8\n",
      "Training Accuracy 0.49\n",
      "Loss 303.14157 82 8\n",
      "Training Accuracy 0.58\n",
      "Loss 302.8318 83 8\n",
      "Training Accuracy 0.535\n",
      "Loss 362.65375 84 8\n",
      "Training Accuracy 0.455\n",
      "Loss 317.88016 85 8\n",
      "Training Accuracy 0.47\n",
      "Loss 312.85687 86 8\n",
      "Training Accuracy 0.515\n",
      "Loss 354.94644 87 8\n",
      "Training Accuracy 0.475\n",
      "Loss 336.3902 88 8\n",
      "Training Accuracy 0.47\n",
      "Loss 311.6015 89 8\n",
      "Training Accuracy 0.52\n",
      "Loss 308.35974 90 8\n",
      "Training Accuracy 0.54\n",
      "Loss 326.49844 91 8\n",
      "Training Accuracy 0.51\n",
      "Loss 328.66296 92 8\n",
      "Training Accuracy 0.51\n",
      "Loss 311.77298 93 8\n",
      "Training Accuracy 0.5\n",
      "Loss 324.9008 94 8\n",
      "Training Accuracy 0.51\n",
      "Loss 299.42444 95 8\n",
      "Training Accuracy 0.485\n",
      "Loss 308.7015 96 8\n",
      "Training Accuracy 0.53\n",
      "Loss 323.21686 97 8\n",
      "Training Accuracy 0.45\n",
      "Loss 314.19293 98 8\n",
      "Training Accuracy 0.465\n",
      "Loss 302.60736 99 8\n",
      "Training Accuracy 0.545\n",
      "Loss 346.11926 100 8\n",
      "Training Accuracy 0.505\n",
      "Loss 318.1464 101 8\n",
      "Training Accuracy 0.485\n",
      "Loss 279.58716 102 8\n",
      "Training Accuracy 0.555\n",
      "Loss 310.31357 103 8\n",
      "Training Accuracy 0.475\n",
      "Loss 303.53857 104 8\n",
      "Training Accuracy 0.505\n",
      "Loss 333.1571 105 8\n",
      "Training Accuracy 0.52\n",
      "Loss 331.9078 106 8\n",
      "Training Accuracy 0.48\n",
      "Loss 326.92148 107 8\n",
      "Training Accuracy 0.505\n",
      "Loss 325.8008 108 8\n",
      "Training Accuracy 0.485\n",
      "Loss 314.37817 109 8\n",
      "Training Accuracy 0.52\n",
      "Loss 327.06967 110 8\n",
      "Training Accuracy 0.52\n",
      "Loss 319.62762 111 8\n",
      "Training Accuracy 0.495\n",
      "Loss 342.01923 112 8\n",
      "Training Accuracy 0.515\n",
      "Loss 355.0718 113 8\n",
      "Training Accuracy 0.515\n",
      "Loss 309.47305 114 8\n",
      "Training Accuracy 0.46\n",
      "Loss 352.8921 115 8\n",
      "Training Accuracy 0.47\n",
      "Loss 355.09763 116 8\n",
      "Training Accuracy 0.49\n",
      "Loss 297.08752 117 8\n",
      "Training Accuracy 0.605\n",
      "Loss 343.16412 118 8\n",
      "Training Accuracy 0.485\n",
      "Loss 377.4739 119 8\n",
      "Training Accuracy 0.42\n",
      "Loss 340.1473 120 8\n",
      "Training Accuracy 0.48\n",
      "Loss 340.35715 121 8\n",
      "Training Accuracy 0.49\n",
      "Loss 275.00717 122 8\n",
      "Training Accuracy 0.57\n",
      "Loss 323.33777 123 8\n",
      "Training Accuracy 0.46\n",
      "Loss 306.5599 124 8\n",
      "Training Accuracy 0.51\n",
      "Loss 288.1545 125 8\n",
      "Training Accuracy 0.575\n",
      "Loss 327.23972 126 8\n",
      "Training Accuracy 0.485\n",
      "Loss 302.3837 127 8\n",
      "Training Accuracy 0.5\n",
      "Loss 293.61963 128 8\n",
      "Training Accuracy 0.49\n",
      "Loss 310.29135 129 8\n",
      "Training Accuracy 0.53\n",
      "Loss 310.8498 130 8\n",
      "Training Accuracy 0.525\n",
      "Loss 285.85114 131 8\n",
      "Training Accuracy 0.58\n",
      "Loss 292.0859 132 8\n",
      "Training Accuracy 0.535\n",
      "Loss 312.90875 133 8\n",
      "Training Accuracy 0.525\n",
      "Loss 297.59787 134 8\n",
      "Training Accuracy 0.52\n",
      "Loss 281.5226 135 8\n",
      "Training Accuracy 0.53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 327.14978 136 8\n",
      "Training Accuracy 0.515\n",
      "Loss 322.46548 137 8\n",
      "Training Accuracy 0.5\n",
      "Loss 292.6043 138 8\n",
      "Training Accuracy 0.585\n",
      "Loss 338.76947 139 8\n",
      "Training Accuracy 0.545\n",
      "Loss 279.18564 140 8\n",
      "Training Accuracy 0.545\n",
      "Loss 331.4099 141 8\n",
      "Training Accuracy 0.515\n",
      "Loss 327.38074 142 8\n",
      "Training Accuracy 0.495\n",
      "Loss 278.34036 143 8\n",
      "Training Accuracy 0.525\n",
      "Loss 318.91174 144 8\n",
      "Training Accuracy 0.505\n",
      "Loss 315.19983 145 8\n",
      "Training Accuracy 0.525\n",
      "Loss 320.282 146 8\n",
      "Training Accuracy 0.495\n",
      "Loss 307.2801 147 8\n",
      "Training Accuracy 0.54\n",
      "Loss 316.7948 148 8\n",
      "Training Accuracy 0.485\n",
      "Loss 292.57806 149 8\n",
      "Training Accuracy 0.54\n",
      "Loss 302.42532 150 8\n",
      "Training Accuracy 0.54\n",
      "Loss 315.7021 151 8\n",
      "Training Accuracy 0.55\n",
      "Loss 334.77737 152 8\n",
      "Training Accuracy 0.48\n",
      "Loss 315.28778 153 8\n",
      "Training Accuracy 0.46\n",
      "Loss 315.6509 154 8\n",
      "Training Accuracy 0.51\n",
      "Loss 288.23203 155 8\n",
      "Training Accuracy 0.56\n",
      "Loss 321.72717 156 8\n",
      "Training Accuracy 0.495\n",
      "Loss 268.9214 157 8\n",
      "Training Accuracy 0.56\n",
      "Loss 318.4114 158 8\n",
      "Training Accuracy 0.53\n",
      "Loss 359.0788 159 8\n",
      "Training Accuracy 0.475\n",
      "Loss 318.66708 160 8\n",
      "Training Accuracy 0.505\n",
      "Loss 336.9141 161 8\n",
      "Training Accuracy 0.515\n",
      "Loss 300.4981 162 8\n",
      "Training Accuracy 0.55\n",
      "Loss 334.07892 163 8\n",
      "Training Accuracy 0.505\n",
      "Loss 268.58118 164 8\n",
      "Training Accuracy 0.54\n",
      "Loss 300.21326 165 8\n",
      "Training Accuracy 0.53\n",
      "Loss 324.7887 166 8\n",
      "Training Accuracy 0.52\n",
      "Loss 256.37576 167 8\n",
      "Training Accuracy 0.59\n",
      "Loss 339.08597 168 8\n",
      "Training Accuracy 0.485\n",
      "Loss 298.12482 169 8\n",
      "Training Accuracy 0.48\n",
      "Loss 301.92667 170 8\n",
      "Training Accuracy 0.555\n",
      "Loss 334.3852 171 8\n",
      "Training Accuracy 0.555\n",
      "Loss 311.09192 172 8\n",
      "Training Accuracy 0.535\n",
      "Loss 364.45938 173 8\n",
      "Training Accuracy 0.46\n",
      "Loss 266.09824 174 8\n",
      "Training Accuracy 0.575\n",
      "Loss 289.24564 175 8\n",
      "Training Accuracy 0.61\n",
      "Loss 271.72034 176 8\n",
      "Training Accuracy 0.615\n",
      "Loss 357.17136 177 8\n",
      "Training Accuracy 0.465\n",
      "Loss 290.89856 178 8\n",
      "Training Accuracy 0.51\n",
      "Loss 330.2552 179 8\n",
      "Training Accuracy 0.53\n",
      "Loss 308.35107 180 8\n",
      "Training Accuracy 0.475\n",
      "Loss 269.8682 181 8\n",
      "Training Accuracy 0.555\n",
      "Loss 329.8204 182 8\n",
      "Training Accuracy 0.435\n",
      "Loss 331.9079 183 8\n",
      "Training Accuracy 0.495\n",
      "Loss 281.91013 184 8\n",
      "Training Accuracy 0.565\n",
      "Loss 296.5212 185 8\n",
      "Training Accuracy 0.53\n",
      "Loss 284.82333 186 8\n",
      "Training Accuracy 0.585\n",
      "Loss 350.77277 187 8\n",
      "Training Accuracy 0.47\n",
      "Loss 338.0847 188 8\n",
      "Training Accuracy 0.5\n",
      "Loss 318.0411 189 8\n",
      "Training Accuracy 0.51\n",
      "Loss 304.96756 190 8\n",
      "Training Accuracy 0.54\n",
      "Loss 295.26608 191 8\n",
      "Training Accuracy 0.545\n",
      "Loss 317.53674 192 8\n",
      "Training Accuracy 0.495\n",
      "Loss 289.21548 193 8\n",
      "Training Accuracy 0.545\n",
      "Loss 291.32697 194 8\n",
      "Training Accuracy 0.545\n",
      "Loss 296.88126 195 8\n",
      "Training Accuracy 0.545\n",
      "Loss 306.02493 196 8\n",
      "Training Accuracy 0.545\n",
      "Loss 310.82767 197 8\n",
      "Training Accuracy 0.545\n",
      "Loss 278.46967 198 8\n",
      "Training Accuracy 0.495\n",
      "Loss 255.36266 199 8\n",
      "Training Accuracy 0.6\n",
      "Loss 337.6973 200 8\n",
      "Training Accuracy 0.455\n",
      "Loss 300.70996 201 8\n",
      "Training Accuracy 0.51\n",
      "Loss 300.43192 202 8\n",
      "Training Accuracy 0.465\n",
      "Loss 311.68735 203 8\n",
      "Training Accuracy 0.545\n",
      "Loss 306.98236 204 8\n",
      "Training Accuracy 0.525\n",
      "Loss 334.95306 205 8\n",
      "Training Accuracy 0.49\n",
      "Loss 322.57565 206 8\n",
      "Training Accuracy 0.515\n",
      "Loss 293.32376 207 8\n",
      "Training Accuracy 0.535\n",
      "Loss 337.33722 208 8\n",
      "Training Accuracy 0.505\n",
      "Loss 339.47116 209 8\n",
      "Training Accuracy 0.515\n",
      "Loss 292.57578 210 8\n",
      "Training Accuracy 0.51\n",
      "Loss 318.41986 211 8\n",
      "Training Accuracy 0.52\n",
      "Loss 278.1285 212 8\n",
      "Training Accuracy 0.555\n",
      "Loss 363.2373 213 8\n",
      "Training Accuracy 0.455\n",
      "Loss 316.36334 214 8\n",
      "Training Accuracy 0.525\n",
      "Loss 322.5734 215 8\n",
      "Training Accuracy 0.49\n",
      "Loss 358.68396 216 8\n",
      "Training Accuracy 0.465\n",
      "Loss 296.5435 217 8\n",
      "Training Accuracy 0.49\n",
      "Loss 327.3651 218 8\n",
      "Training Accuracy 0.45\n",
      "Loss 304.04303 219 8\n",
      "Training Accuracy 0.54\n",
      "Loss 305.0851 220 8\n",
      "Training Accuracy 0.56\n",
      "Loss 315.4898 221 8\n",
      "Training Accuracy 0.475\n",
      "Loss 303.02847 222 8\n",
      "Training Accuracy 0.565\n",
      "Loss 325.01895 223 8\n",
      "Training Accuracy 0.52\n",
      "Loss 325.3026 224 8\n",
      "Training Accuracy 0.49\n",
      "Loss 332.27747 225 8\n",
      "Training Accuracy 0.49\n",
      "Loss 291.17453 226 8\n",
      "Training Accuracy 0.535\n",
      "Loss 352.40143 227 8\n",
      "Training Accuracy 0.475\n",
      "Loss 360.5625 228 8\n",
      "Training Accuracy 0.455\n",
      "Loss 313.5343 229 8\n",
      "Training Accuracy 0.52\n",
      "Loss 317.9104 230 8\n",
      "Training Accuracy 0.52\n",
      "Loss 268.49988 231 8\n",
      "Training Accuracy 0.565\n",
      "Loss 312.73914 232 8\n",
      "Training Accuracy 0.495\n",
      "Loss 334.89224 233 8\n",
      "Training Accuracy 0.44\n",
      "Loss 317.8785 234 8\n",
      "Training Accuracy 0.53\n",
      "Loss 312.33078 235 8\n",
      "Training Accuracy 0.51\n",
      "Loss 280.328 236 8\n",
      "Training Accuracy 0.585\n",
      "Loss 311.96307 237 8\n",
      "Training Accuracy 0.545\n",
      "Loss 303.6258 238 8\n",
      "Training Accuracy 0.54\n",
      "Loss 337.97354 239 8\n",
      "Training Accuracy 0.555\n",
      "Loss 309.3003 240 8\n",
      "Training Accuracy 0.5\n",
      "Loss 328.4452 241 8\n",
      "Training Accuracy 0.47\n",
      "Loss 276.2229 242 8\n",
      "Training Accuracy 0.555\n",
      "Loss 276.20325 243 8\n",
      "Training Accuracy 0.555\n",
      "Loss 314.3689 244 8\n",
      "Training Accuracy 0.5\n",
      "Loss 293.47247 245 8\n",
      "Training Accuracy 0.545\n",
      "Loss 320.3314 246 8\n",
      "Training Accuracy 0.5\n",
      "Loss 258.63605 247 8\n",
      "Training Accuracy 0.52\n",
      "Loss 292.73383 248 8\n",
      "Training Accuracy 0.5\n",
      "Loss 318.26114 249 8\n",
      "Training Accuracy 0.44\n",
      "Loss 334.373 250 8\n",
      "Training Accuracy 0.485\n",
      "Loss 326.43924 251 8\n",
      "Training Accuracy 0.47\n",
      "Loss 280.94446 252 8\n",
      "Training Accuracy 0.545\n",
      "Loss 292.91318 253 8\n",
      "Training Accuracy 0.54\n",
      "Loss 297.20535 254 8\n",
      "Training Accuracy 0.555\n",
      "Loss 277.5126 255 8\n",
      "Training Accuracy 0.565\n",
      "Loss 321.0121 256 8\n",
      "Training Accuracy 0.49\n",
      "Loss 300.5108 257 8\n",
      "Training Accuracy 0.545\n",
      "Loss 302.8769 258 8\n",
      "Training Accuracy 0.53\n",
      "Loss 316.08908 259 8\n",
      "Training Accuracy 0.49\n",
      "Loss 271.66986 260 8\n",
      "Training Accuracy 0.575\n",
      "Loss 321.21875 261 8\n",
      "Training Accuracy 0.515\n",
      "Loss 299.61707 262 8\n",
      "Training Accuracy 0.515\n",
      "Loss 383.87494 263 8\n",
      "Training Accuracy 0.44\n",
      "Loss 343.6646 264 8\n",
      "Training Accuracy 0.525\n",
      "Loss 308.64798 265 8\n",
      "Training Accuracy 0.545\n",
      "Loss 294.29468 266 8\n",
      "Training Accuracy 0.515\n",
      "Loss 320.97327 267 8\n",
      "Training Accuracy 0.54\n",
      "Loss 327.26715 268 8\n",
      "Training Accuracy 0.535\n",
      "Loss 277.9518 269 8\n",
      "Training Accuracy 0.53\n",
      "Loss 281.6262 270 8\n",
      "Training Accuracy 0.545\n",
      "Loss 346.19662 271 8\n",
      "Training Accuracy 0.45\n",
      "Loss 316.68158 272 8\n",
      "Training Accuracy 0.52\n",
      "Loss 315.0785 273 8\n",
      "Training Accuracy 0.525\n",
      "Loss 278.97733 274 8\n",
      "Training Accuracy 0.56\n",
      "Loss 336.46048 275 8\n",
      "Training Accuracy 0.455\n",
      "Loss 273.9589 276 8\n",
      "Training Accuracy 0.565\n",
      "Loss 363.19037 277 8\n",
      "Training Accuracy 0.475\n",
      "Loss 289.9337 278 8\n",
      "Training Accuracy 0.53\n",
      "Loss 301.93832 279 8\n",
      "Training Accuracy 0.515\n",
      "Loss 295.75858 280 8\n",
      "Training Accuracy 0.54\n",
      "Loss 309.23972 281 8\n",
      "Training Accuracy 0.5\n",
      "Loss 308.88135 282 8\n",
      "Training Accuracy 0.53\n",
      "Loss 292.2972 283 8\n",
      "Training Accuracy 0.54\n",
      "Loss 276.3127 284 8\n",
      "Training Accuracy 0.585\n",
      "Loss 349.9981 285 8\n",
      "Training Accuracy 0.465\n",
      "Loss 310.44012 286 8\n",
      "Training Accuracy 0.535\n",
      "Loss 294.29758 287 8\n",
      "Training Accuracy 0.57\n",
      "Loss 309.2617 288 8\n",
      "Training Accuracy 0.555\n",
      "Loss 277.02975 289 8\n",
      "Training Accuracy 0.54\n",
      "Loss 314.693 290 8\n",
      "Training Accuracy 0.485\n",
      "Loss 304.10745 291 8\n",
      "Training Accuracy 0.555\n",
      "Loss 197.66893 292 8\n",
      "Training Accuracy 0.54545456\n",
      "Loss 281.46426 1 9\n",
      "Training Accuracy 0.565\n",
      "Loss 311.52512 2 9\n",
      "Training Accuracy 0.525\n",
      "Loss 325.68542 3 9\n",
      "Training Accuracy 0.525\n",
      "Loss 303.23773 4 9\n",
      "Training Accuracy 0.545\n",
      "Loss 275.63724 5 9\n",
      "Training Accuracy 0.58\n",
      "Loss 307.14813 6 9\n",
      "Training Accuracy 0.55\n",
      "Loss 314.77167 7 9\n",
      "Training Accuracy 0.49\n",
      "Loss 353.28003 8 9\n",
      "Training Accuracy 0.525\n",
      "Loss 288.04745 9 9\n",
      "Training Accuracy 0.56\n",
      "Loss 320.21487 10 9\n",
      "Training Accuracy 0.48\n",
      "Loss 338.63666 11 9\n",
      "Training Accuracy 0.565\n",
      "Loss 293.4506 12 9\n",
      "Training Accuracy 0.525\n",
      "Loss 289.2517 13 9\n",
      "Training Accuracy 0.545\n",
      "Loss 325.66745 14 9\n",
      "Training Accuracy 0.51\n",
      "Loss 291.19052 15 9\n",
      "Training Accuracy 0.55\n",
      "Loss 334.9089 16 9\n",
      "Training Accuracy 0.48\n",
      "Loss 278.51328 17 9\n",
      "Training Accuracy 0.59\n",
      "Loss 302.4831 18 9\n",
      "Training Accuracy 0.545\n",
      "Loss 287.22842 19 9\n",
      "Training Accuracy 0.555\n",
      "Loss 304.81186 20 9\n",
      "Training Accuracy 0.51\n",
      "Loss 304.77667 21 9\n",
      "Training Accuracy 0.565\n",
      "Loss 326.6313 22 9\n",
      "Training Accuracy 0.52\n",
      "Loss 325.49005 23 9\n",
      "Training Accuracy 0.53\n",
      "Loss 324.59296 24 9\n",
      "Training Accuracy 0.465\n",
      "Loss 306.2185 25 9\n",
      "Training Accuracy 0.54\n",
      "Loss 331.6655 26 9\n",
      "Training Accuracy 0.475\n",
      "Loss 291.91345 27 9\n",
      "Training Accuracy 0.54\n",
      "Loss 306.00064 28 9\n",
      "Training Accuracy 0.47\n",
      "Loss 292.6054 29 9\n",
      "Training Accuracy 0.55\n",
      "Loss 319.29785 30 9\n",
      "Training Accuracy 0.505\n",
      "Loss 341.60986 31 9\n",
      "Training Accuracy 0.495\n",
      "Loss 312.251 32 9\n",
      "Training Accuracy 0.475\n",
      "Loss 315.77573 33 9\n",
      "Training Accuracy 0.53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 288.35748 34 9\n",
      "Training Accuracy 0.54\n",
      "Loss 265.4808 35 9\n",
      "Training Accuracy 0.54\n",
      "Loss 297.9171 36 9\n",
      "Training Accuracy 0.49\n",
      "Loss 308.88083 37 9\n",
      "Training Accuracy 0.53\n",
      "Loss 313.03973 38 9\n",
      "Training Accuracy 0.525\n",
      "Loss 266.56256 39 9\n",
      "Training Accuracy 0.555\n",
      "Loss 269.44897 40 9\n",
      "Training Accuracy 0.645\n",
      "Loss 292.3909 41 9\n",
      "Training Accuracy 0.505\n",
      "Loss 332.6778 42 9\n",
      "Training Accuracy 0.495\n",
      "Loss 302.11737 43 9\n",
      "Training Accuracy 0.505\n",
      "Loss 288.14246 44 9\n",
      "Training Accuracy 0.505\n",
      "Loss 308.10184 45 9\n",
      "Training Accuracy 0.48\n",
      "Loss 329.28366 46 9\n",
      "Training Accuracy 0.49\n",
      "Loss 290.81607 47 9\n",
      "Training Accuracy 0.59\n",
      "Loss 287.0982 48 9\n",
      "Training Accuracy 0.545\n",
      "Loss 313.72156 49 9\n",
      "Training Accuracy 0.495\n",
      "Loss 333.70215 50 9\n",
      "Training Accuracy 0.515\n",
      "Loss 288.62238 51 9\n",
      "Training Accuracy 0.575\n",
      "Loss 304.23944 52 9\n",
      "Training Accuracy 0.495\n",
      "Loss 301.43585 53 9\n",
      "Training Accuracy 0.505\n",
      "Loss 312.97595 54 9\n",
      "Training Accuracy 0.505\n",
      "Loss 314.6063 55 9\n",
      "Training Accuracy 0.49\n",
      "Loss 307.2706 56 9\n",
      "Training Accuracy 0.46\n",
      "Loss 275.8882 57 9\n",
      "Training Accuracy 0.57\n",
      "Loss 266.78046 58 9\n",
      "Training Accuracy 0.59\n",
      "Loss 325.85324 59 9\n",
      "Training Accuracy 0.485\n",
      "Loss 313.767 60 9\n",
      "Training Accuracy 0.52\n",
      "Loss 298.83182 61 9\n",
      "Training Accuracy 0.505\n",
      "Loss 295.43335 62 9\n",
      "Training Accuracy 0.565\n",
      "Loss 316.0896 63 9\n",
      "Training Accuracy 0.52\n",
      "Loss 316.49973 64 9\n",
      "Training Accuracy 0.535\n",
      "Loss 325.69226 65 9\n",
      "Training Accuracy 0.49\n",
      "Loss 298.1334 66 9\n",
      "Training Accuracy 0.53\n",
      "Loss 330.81985 67 9\n",
      "Training Accuracy 0.51\n",
      "Loss 303.24527 68 9\n",
      "Training Accuracy 0.475\n",
      "Loss 302.86102 69 9\n",
      "Training Accuracy 0.51\n",
      "Loss 309.18024 70 9\n",
      "Training Accuracy 0.53\n",
      "Loss 301.50653 71 9\n",
      "Training Accuracy 0.56\n",
      "Loss 305.9448 72 9\n",
      "Training Accuracy 0.54\n",
      "Loss 318.70245 73 9\n",
      "Training Accuracy 0.49\n",
      "Loss 344.26395 74 9\n",
      "Training Accuracy 0.54\n",
      "Loss 324.4949 75 9\n",
      "Training Accuracy 0.55\n",
      "Loss 284.2984 76 9\n",
      "Training Accuracy 0.57\n",
      "Loss 290.03354 77 9\n",
      "Training Accuracy 0.525\n",
      "Loss 296.5726 78 9\n",
      "Training Accuracy 0.555\n",
      "Loss 283.71115 79 9\n",
      "Training Accuracy 0.51\n",
      "Loss 298.32394 80 9\n",
      "Training Accuracy 0.495\n",
      "Loss 300.59836 81 9\n",
      "Training Accuracy 0.47\n",
      "Loss 300.3063 82 9\n",
      "Training Accuracy 0.525\n",
      "Loss 298.90335 83 9\n",
      "Training Accuracy 0.53\n",
      "Loss 346.95016 84 9\n",
      "Training Accuracy 0.44\n",
      "Loss 309.38217 85 9\n",
      "Training Accuracy 0.51\n",
      "Loss 305.1931 86 9\n",
      "Training Accuracy 0.535\n",
      "Loss 343.9348 87 9\n",
      "Training Accuracy 0.465\n",
      "Loss 334.4146 88 9\n",
      "Training Accuracy 0.48\n",
      "Loss 306.39056 89 9\n",
      "Training Accuracy 0.535\n",
      "Loss 306.4607 90 9\n",
      "Training Accuracy 0.52\n",
      "Loss 313.33728 91 9\n",
      "Training Accuracy 0.475\n",
      "Loss 320.78925 92 9\n",
      "Training Accuracy 0.53\n",
      "Loss 298.83084 93 9\n",
      "Training Accuracy 0.54\n",
      "Loss 311.02777 94 9\n",
      "Training Accuracy 0.535\n",
      "Loss 278.19968 95 9\n",
      "Training Accuracy 0.54\n",
      "Loss 287.08856 96 9\n",
      "Training Accuracy 0.565\n",
      "Loss 314.60175 97 9\n",
      "Training Accuracy 0.485\n",
      "Loss 306.2796 98 9\n",
      "Training Accuracy 0.505\n",
      "Loss 288.73477 99 9\n",
      "Training Accuracy 0.54\n",
      "Loss 321.41345 100 9\n",
      "Training Accuracy 0.54\n",
      "Loss 315.27887 101 9\n",
      "Training Accuracy 0.51\n",
      "Loss 271.1049 102 9\n",
      "Training Accuracy 0.54\n",
      "Loss 311.23306 103 9\n",
      "Training Accuracy 0.51\n",
      "Loss 284.3981 104 9\n",
      "Training Accuracy 0.52\n",
      "Loss 323.83844 105 9\n",
      "Training Accuracy 0.505\n",
      "Loss 319.42154 106 9\n",
      "Training Accuracy 0.51\n",
      "Loss 299.0334 107 9\n",
      "Training Accuracy 0.535\n",
      "Loss 306.93536 108 9\n",
      "Training Accuracy 0.495\n",
      "Loss 303.17102 109 9\n",
      "Training Accuracy 0.525\n",
      "Loss 312.43506 110 9\n",
      "Training Accuracy 0.54\n",
      "Loss 312.5852 111 9\n",
      "Training Accuracy 0.53\n",
      "Loss 340.85522 112 9\n",
      "Training Accuracy 0.525\n",
      "Loss 352.75977 113 9\n",
      "Training Accuracy 0.455\n",
      "Loss 301.40002 114 9\n",
      "Training Accuracy 0.455\n",
      "Loss 330.7214 115 9\n",
      "Training Accuracy 0.52\n",
      "Loss 343.84378 116 9\n",
      "Training Accuracy 0.49\n",
      "Loss 276.50906 117 9\n",
      "Training Accuracy 0.605\n",
      "Loss 322.90378 118 9\n",
      "Training Accuracy 0.54\n",
      "Loss 379.0453 119 9\n",
      "Training Accuracy 0.41\n",
      "Loss 332.2274 120 9\n",
      "Training Accuracy 0.465\n",
      "Loss 340.70288 121 9\n",
      "Training Accuracy 0.51\n",
      "Loss 265.45914 122 9\n",
      "Training Accuracy 0.575\n",
      "Loss 306.567 123 9\n",
      "Training Accuracy 0.475\n",
      "Loss 288.05316 124 9\n",
      "Training Accuracy 0.54\n",
      "Loss 269.09308 125 9\n",
      "Training Accuracy 0.58\n",
      "Loss 320.04422 126 9\n",
      "Training Accuracy 0.49\n",
      "Loss 306.61606 127 9\n",
      "Training Accuracy 0.525\n",
      "Loss 296.4876 128 9\n",
      "Training Accuracy 0.505\n",
      "Loss 285.19583 129 9\n",
      "Training Accuracy 0.6\n",
      "Loss 296.37457 130 9\n",
      "Training Accuracy 0.52\n",
      "Loss 277.39148 131 9\n",
      "Training Accuracy 0.575\n",
      "Loss 287.44592 132 9\n",
      "Training Accuracy 0.575\n",
      "Loss 307.06116 133 9\n",
      "Training Accuracy 0.56\n",
      "Loss 288.22543 134 9\n",
      "Training Accuracy 0.525\n",
      "Loss 267.3612 135 9\n",
      "Training Accuracy 0.56\n",
      "Loss 320.52008 136 9\n",
      "Training Accuracy 0.545\n",
      "Loss 320.94934 137 9\n",
      "Training Accuracy 0.475\n",
      "Loss 283.45413 138 9\n",
      "Training Accuracy 0.575\n",
      "Loss 327.11777 139 9\n",
      "Training Accuracy 0.565\n",
      "Loss 272.5329 140 9\n",
      "Training Accuracy 0.58\n",
      "Loss 321.41238 141 9\n",
      "Training Accuracy 0.515\n",
      "Loss 304.68503 142 9\n",
      "Training Accuracy 0.52\n",
      "Loss 269.53595 143 9\n",
      "Training Accuracy 0.5\n",
      "Loss 304.58752 144 9\n",
      "Training Accuracy 0.515\n",
      "Loss 302.80505 145 9\n",
      "Training Accuracy 0.535\n",
      "Loss 312.39395 146 9\n",
      "Training Accuracy 0.525\n",
      "Loss 301.30414 147 9\n",
      "Training Accuracy 0.505\n",
      "Loss 304.82767 148 9\n",
      "Training Accuracy 0.505\n",
      "Loss 291.67343 149 9\n",
      "Training Accuracy 0.54\n",
      "Loss 296.95126 150 9\n",
      "Training Accuracy 0.535\n",
      "Loss 314.52246 151 9\n",
      "Training Accuracy 0.5\n",
      "Loss 322.3677 152 9\n",
      "Training Accuracy 0.495\n",
      "Loss 294.82428 153 9\n",
      "Training Accuracy 0.53\n",
      "Loss 301.3839 154 9\n",
      "Training Accuracy 0.51\n",
      "Loss 277.4793 155 9\n",
      "Training Accuracy 0.575\n",
      "Loss 314.54858 156 9\n",
      "Training Accuracy 0.53\n",
      "Loss 254.98029 157 9\n",
      "Training Accuracy 0.615\n",
      "Loss 301.0675 158 9\n",
      "Training Accuracy 0.555\n",
      "Loss 337.7715 159 9\n",
      "Training Accuracy 0.525\n",
      "Loss 306.58395 160 9\n",
      "Training Accuracy 0.555\n",
      "Loss 332.93564 161 9\n",
      "Training Accuracy 0.47\n",
      "Loss 295.3227 162 9\n",
      "Training Accuracy 0.535\n",
      "Loss 322.19275 163 9\n",
      "Training Accuracy 0.53\n",
      "Loss 262.208 164 9\n",
      "Training Accuracy 0.565\n",
      "Loss 285.9941 165 9\n",
      "Training Accuracy 0.54\n",
      "Loss 317.38553 166 9\n",
      "Training Accuracy 0.515\n",
      "Loss 263.34116 167 9\n",
      "Training Accuracy 0.54\n",
      "Loss 321.82343 168 9\n",
      "Training Accuracy 0.535\n",
      "Loss 289.1381 169 9\n",
      "Training Accuracy 0.525\n",
      "Loss 285.25507 170 9\n",
      "Training Accuracy 0.575\n",
      "Loss 326.84225 171 9\n",
      "Training Accuracy 0.55\n",
      "Loss 284.11194 172 9\n",
      "Training Accuracy 0.545\n",
      "Loss 344.30704 173 9\n",
      "Training Accuracy 0.47\n",
      "Loss 259.49615 174 9\n",
      "Training Accuracy 0.545\n",
      "Loss 279.08255 175 9\n",
      "Training Accuracy 0.635\n",
      "Loss 258.52676 176 9\n",
      "Training Accuracy 0.6\n",
      "Loss 346.7405 177 9\n",
      "Training Accuracy 0.475\n",
      "Loss 280.223 178 9\n",
      "Training Accuracy 0.545\n",
      "Loss 324.39877 179 9\n",
      "Training Accuracy 0.525\n",
      "Loss 302.99313 180 9\n",
      "Training Accuracy 0.465\n",
      "Loss 267.0613 181 9\n",
      "Training Accuracy 0.525\n",
      "Loss 311.4881 182 9\n",
      "Training Accuracy 0.505\n",
      "Loss 326.9189 183 9\n",
      "Training Accuracy 0.495\n",
      "Loss 269.78598 184 9\n",
      "Training Accuracy 0.575\n",
      "Loss 281.43396 185 9\n",
      "Training Accuracy 0.53\n",
      "Loss 290.77567 186 9\n",
      "Training Accuracy 0.555\n",
      "Loss 335.89963 187 9\n",
      "Training Accuracy 0.46\n",
      "Loss 318.8695 188 9\n",
      "Training Accuracy 0.525\n",
      "Loss 304.07877 189 9\n",
      "Training Accuracy 0.55\n",
      "Loss 292.9969 190 9\n",
      "Training Accuracy 0.59\n",
      "Loss 292.60318 191 9\n",
      "Training Accuracy 0.555\n",
      "Loss 302.14008 192 9\n",
      "Training Accuracy 0.545\n",
      "Loss 280.8203 193 9\n",
      "Training Accuracy 0.57\n",
      "Loss 282.3042 194 9\n",
      "Training Accuracy 0.525\n",
      "Loss 283.95935 195 9\n",
      "Training Accuracy 0.565\n",
      "Loss 296.4681 196 9\n",
      "Training Accuracy 0.545\n",
      "Loss 313.14493 197 9\n",
      "Training Accuracy 0.545\n",
      "Loss 279.0852 198 9\n",
      "Training Accuracy 0.56\n",
      "Loss 251.90681 199 9\n",
      "Training Accuracy 0.605\n",
      "Loss 315.17477 200 9\n",
      "Training Accuracy 0.495\n",
      "Loss 286.5407 201 9\n",
      "Training Accuracy 0.53\n",
      "Loss 285.93024 202 9\n",
      "Training Accuracy 0.53\n",
      "Loss 310.42767 203 9\n",
      "Training Accuracy 0.495\n",
      "Loss 297.43707 204 9\n",
      "Training Accuracy 0.53\n",
      "Loss 319.4442 205 9\n",
      "Training Accuracy 0.505\n",
      "Loss 313.87408 206 9\n",
      "Training Accuracy 0.555\n",
      "Loss 294.99448 207 9\n",
      "Training Accuracy 0.52\n",
      "Loss 321.8958 208 9\n",
      "Training Accuracy 0.5\n",
      "Loss 330.88284 209 9\n",
      "Training Accuracy 0.52\n",
      "Loss 280.0289 210 9\n",
      "Training Accuracy 0.55\n",
      "Loss 308.45486 211 9\n",
      "Training Accuracy 0.57\n",
      "Loss 270.44043 212 9\n",
      "Training Accuracy 0.575\n",
      "Loss 347.65366 213 9\n",
      "Training Accuracy 0.465\n",
      "Loss 303.43735 214 9\n",
      "Training Accuracy 0.535\n",
      "Loss 319.10596 215 9\n",
      "Training Accuracy 0.48\n",
      "Loss 335.46756 216 9\n",
      "Training Accuracy 0.51\n",
      "Loss 291.61273 217 9\n",
      "Training Accuracy 0.51\n",
      "Loss 316.17175 218 9\n",
      "Training Accuracy 0.47\n",
      "Loss 300.0091 219 9\n",
      "Training Accuracy 0.575\n",
      "Loss 295.22992 220 9\n",
      "Training Accuracy 0.57\n",
      "Loss 309.64636 221 9\n",
      "Training Accuracy 0.52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 295.5326 222 9\n",
      "Training Accuracy 0.555\n",
      "Loss 322.52045 223 9\n",
      "Training Accuracy 0.505\n",
      "Loss 316.97928 224 9\n",
      "Training Accuracy 0.485\n",
      "Loss 323.98016 225 9\n",
      "Training Accuracy 0.535\n",
      "Loss 275.54462 226 9\n",
      "Training Accuracy 0.575\n",
      "Loss 339.71896 227 9\n",
      "Training Accuracy 0.495\n",
      "Loss 344.9415 228 9\n",
      "Training Accuracy 0.495\n",
      "Loss 296.3875 229 9\n",
      "Training Accuracy 0.57\n",
      "Loss 316.51373 230 9\n",
      "Training Accuracy 0.525\n",
      "Loss 262.42468 231 9\n",
      "Training Accuracy 0.585\n",
      "Loss 297.58667 232 9\n",
      "Training Accuracy 0.505\n",
      "Loss 330.3578 233 9\n",
      "Training Accuracy 0.48\n",
      "Loss 311.95108 234 9\n",
      "Training Accuracy 0.45\n",
      "Loss 306.5907 235 9\n",
      "Training Accuracy 0.535\n",
      "Loss 266.25134 236 9\n",
      "Training Accuracy 0.575\n",
      "Loss 307.5776 237 9\n",
      "Training Accuracy 0.53\n",
      "Loss 295.2823 238 9\n",
      "Training Accuracy 0.53\n",
      "Loss 329.62595 239 9\n",
      "Training Accuracy 0.545\n",
      "Loss 302.6133 240 9\n",
      "Training Accuracy 0.5\n",
      "Loss 327.2129 241 9\n",
      "Training Accuracy 0.47\n",
      "Loss 266.07434 242 9\n",
      "Training Accuracy 0.57\n",
      "Loss 263.83917 243 9\n",
      "Training Accuracy 0.555\n",
      "Loss 312.91727 244 9\n",
      "Training Accuracy 0.465\n",
      "Loss 289.57782 245 9\n",
      "Training Accuracy 0.57\n",
      "Loss 312.16043 246 9\n",
      "Training Accuracy 0.515\n",
      "Loss 245.88997 247 9\n",
      "Training Accuracy 0.575\n",
      "Loss 289.11514 248 9\n",
      "Training Accuracy 0.535\n",
      "Loss 300.06216 249 9\n",
      "Training Accuracy 0.505\n",
      "Loss 316.05527 250 9\n",
      "Training Accuracy 0.535\n",
      "Loss 309.11285 251 9\n",
      "Training Accuracy 0.48\n",
      "Loss 283.19785 252 9\n",
      "Training Accuracy 0.54\n",
      "Loss 290.19534 253 9\n",
      "Training Accuracy 0.555\n",
      "Loss 280.12878 254 9\n",
      "Training Accuracy 0.55\n",
      "Loss 268.2337 255 9\n",
      "Training Accuracy 0.595\n",
      "Loss 314.2961 256 9\n",
      "Training Accuracy 0.495\n",
      "Loss 286.86264 257 9\n",
      "Training Accuracy 0.58\n",
      "Loss 290.38318 258 9\n",
      "Training Accuracy 0.525\n",
      "Loss 301.5667 259 9\n",
      "Training Accuracy 0.545\n",
      "Loss 261.29617 260 9\n",
      "Training Accuracy 0.61\n",
      "Loss 311.4869 261 9\n",
      "Training Accuracy 0.545\n",
      "Loss 300.1412 262 9\n",
      "Training Accuracy 0.515\n",
      "Loss 378.25616 263 9\n",
      "Training Accuracy 0.435\n",
      "Loss 313.99695 264 9\n",
      "Training Accuracy 0.565\n",
      "Loss 298.48016 265 9\n",
      "Training Accuracy 0.555\n",
      "Loss 285.96646 266 9\n",
      "Training Accuracy 0.535\n",
      "Loss 314.92633 267 9\n",
      "Training Accuracy 0.535\n",
      "Loss 317.38382 268 9\n",
      "Training Accuracy 0.515\n",
      "Loss 274.68344 269 9\n",
      "Training Accuracy 0.525\n",
      "Loss 269.01758 270 9\n",
      "Training Accuracy 0.535\n",
      "Loss 341.4051 271 9\n",
      "Training Accuracy 0.465\n",
      "Loss 306.7161 272 9\n",
      "Training Accuracy 0.525\n",
      "Loss 309.44412 273 9\n",
      "Training Accuracy 0.51\n",
      "Loss 278.61502 274 9\n",
      "Training Accuracy 0.55\n",
      "Loss 323.29703 275 9\n",
      "Training Accuracy 0.45\n",
      "Loss 269.7494 276 9\n",
      "Training Accuracy 0.56\n",
      "Loss 353.43625 277 9\n",
      "Training Accuracy 0.495\n",
      "Loss 272.4022 278 9\n",
      "Training Accuracy 0.6\n",
      "Loss 287.751 279 9\n",
      "Training Accuracy 0.545\n",
      "Loss 287.0054 280 9\n",
      "Training Accuracy 0.545\n",
      "Loss 296.74683 281 9\n",
      "Training Accuracy 0.55\n",
      "Loss 295.70996 282 9\n",
      "Training Accuracy 0.57\n",
      "Loss 277.57034 283 9\n",
      "Training Accuracy 0.525\n",
      "Loss 273.84637 284 9\n",
      "Training Accuracy 0.56\n",
      "Loss 334.40506 285 9\n",
      "Training Accuracy 0.475\n",
      "Loss 298.07135 286 9\n",
      "Training Accuracy 0.54\n",
      "Loss 284.1089 287 9\n",
      "Training Accuracy 0.595\n",
      "Loss 310.73245 288 9\n",
      "Training Accuracy 0.55\n",
      "Loss 273.57227 289 9\n",
      "Training Accuracy 0.565\n",
      "Loss 307.1004 290 9\n",
      "Training Accuracy 0.52\n",
      "Loss 315.0844 291 9\n",
      "Training Accuracy 0.495\n",
      "Loss 194.31285 292 9\n",
      "Training Accuracy 0.5530303\n",
      "Loss 270.36032 1 10\n",
      "Training Accuracy 0.535\n",
      "Loss 298.8713 2 10\n",
      "Training Accuracy 0.525\n",
      "Loss 312.57626 3 10\n",
      "Training Accuracy 0.52\n",
      "Loss 296.19073 4 10\n",
      "Training Accuracy 0.58\n",
      "Loss 272.80502 5 10\n",
      "Training Accuracy 0.57\n",
      "Loss 311.24585 6 10\n",
      "Training Accuracy 0.515\n",
      "Loss 301.57416 7 10\n",
      "Training Accuracy 0.53\n",
      "Loss 348.06342 8 10\n",
      "Training Accuracy 0.545\n",
      "Loss 281.03143 9 10\n",
      "Training Accuracy 0.59\n",
      "Loss 313.2254 10 10\n",
      "Training Accuracy 0.51\n",
      "Loss 331.90308 11 10\n",
      "Training Accuracy 0.525\n",
      "Loss 286.25946 12 10\n",
      "Training Accuracy 0.565\n",
      "Loss 283.9617 13 10\n",
      "Training Accuracy 0.53\n",
      "Loss 313.719 14 10\n",
      "Training Accuracy 0.515\n",
      "Loss 278.793 15 10\n",
      "Training Accuracy 0.53\n",
      "Loss 321.40894 16 10\n",
      "Training Accuracy 0.49\n",
      "Loss 282.80466 17 10\n",
      "Training Accuracy 0.575\n",
      "Loss 298.85477 18 10\n",
      "Training Accuracy 0.52\n",
      "Loss 293.97018 19 10\n",
      "Training Accuracy 0.515\n",
      "Loss 302.4835 20 10\n",
      "Training Accuracy 0.53\n",
      "Loss 301.00104 21 10\n",
      "Training Accuracy 0.53\n",
      "Loss 317.49734 22 10\n",
      "Training Accuracy 0.52\n",
      "Loss 312.43 23 10\n",
      "Training Accuracy 0.525\n",
      "Loss 306.33124 24 10\n",
      "Training Accuracy 0.5\n",
      "Loss 300.2582 25 10\n",
      "Training Accuracy 0.535\n",
      "Loss 305.19693 26 10\n",
      "Training Accuracy 0.51\n",
      "Loss 282.93597 27 10\n",
      "Training Accuracy 0.555\n",
      "Loss 294.32132 28 10\n",
      "Training Accuracy 0.505\n",
      "Loss 288.11844 29 10\n",
      "Training Accuracy 0.54\n",
      "Loss 314.3157 30 10\n",
      "Training Accuracy 0.52\n",
      "Loss 322.6357 31 10\n",
      "Training Accuracy 0.51\n",
      "Loss 297.49338 32 10\n",
      "Training Accuracy 0.52\n",
      "Loss 307.73212 33 10\n",
      "Training Accuracy 0.54\n",
      "Loss 271.07996 34 10\n",
      "Training Accuracy 0.55\n",
      "Loss 260.25772 35 10\n",
      "Training Accuracy 0.55\n",
      "Loss 283.80353 36 10\n",
      "Training Accuracy 0.54\n",
      "Loss 307.7799 37 10\n",
      "Training Accuracy 0.505\n",
      "Loss 296.99988 38 10\n",
      "Training Accuracy 0.59\n",
      "Loss 271.29062 39 10\n",
      "Training Accuracy 0.555\n",
      "Loss 269.40146 40 10\n",
      "Training Accuracy 0.57\n",
      "Loss 289.0667 41 10\n",
      "Training Accuracy 0.525\n",
      "Loss 325.37033 42 10\n",
      "Training Accuracy 0.49\n",
      "Loss 287.73404 43 10\n",
      "Training Accuracy 0.57\n",
      "Loss 282.43756 44 10\n",
      "Training Accuracy 0.525\n",
      "Loss 300.18976 45 10\n",
      "Training Accuracy 0.52\n",
      "Loss 311.40533 46 10\n",
      "Training Accuracy 0.55\n",
      "Loss 275.7625 47 10\n",
      "Training Accuracy 0.575\n",
      "Loss 271.07385 48 10\n",
      "Training Accuracy 0.585\n",
      "Loss 304.74838 49 10\n",
      "Training Accuracy 0.525\n",
      "Loss 319.55453 50 10\n",
      "Training Accuracy 0.485\n",
      "Loss 281.62527 51 10\n",
      "Training Accuracy 0.56\n",
      "Loss 288.56607 52 10\n",
      "Training Accuracy 0.53\n",
      "Loss 283.4556 53 10\n",
      "Training Accuracy 0.545\n",
      "Loss 304.73706 54 10\n",
      "Training Accuracy 0.52\n",
      "Loss 305.1993 55 10\n",
      "Training Accuracy 0.47\n",
      "Loss 301.73303 56 10\n",
      "Training Accuracy 0.48\n",
      "Loss 268.10666 57 10\n",
      "Training Accuracy 0.57\n",
      "Loss 267.8102 58 10\n",
      "Training Accuracy 0.54\n",
      "Loss 312.7726 59 10\n",
      "Training Accuracy 0.5\n",
      "Loss 299.6566 60 10\n",
      "Training Accuracy 0.52\n",
      "Loss 290.2214 61 10\n",
      "Training Accuracy 0.51\n",
      "Loss 279.2726 62 10\n",
      "Training Accuracy 0.565\n",
      "Loss 295.96735 63 10\n",
      "Training Accuracy 0.56\n",
      "Loss 298.4313 64 10\n",
      "Training Accuracy 0.555\n",
      "Loss 325.34116 65 10\n",
      "Training Accuracy 0.47\n",
      "Loss 283.23822 66 10\n",
      "Training Accuracy 0.5\n",
      "Loss 319.6966 67 10\n",
      "Training Accuracy 0.52\n",
      "Loss 299.21564 68 10\n",
      "Training Accuracy 0.505\n",
      "Loss 302.44785 69 10\n",
      "Training Accuracy 0.535\n",
      "Loss 303.8383 70 10\n",
      "Training Accuracy 0.505\n",
      "Loss 292.32092 71 10\n",
      "Training Accuracy 0.565\n",
      "Loss 298.1906 72 10\n",
      "Training Accuracy 0.505\n",
      "Loss 308.0671 73 10\n",
      "Training Accuracy 0.51\n",
      "Loss 335.9295 74 10\n",
      "Training Accuracy 0.5\n",
      "Loss 303.3547 75 10\n",
      "Training Accuracy 0.535\n",
      "Loss 267.88382 76 10\n",
      "Training Accuracy 0.595\n",
      "Loss 289.02737 77 10\n",
      "Training Accuracy 0.525\n",
      "Loss 285.6416 78 10\n",
      "Training Accuracy 0.565\n",
      "Loss 279.25037 79 10\n",
      "Training Accuracy 0.49\n",
      "Loss 295.28882 80 10\n",
      "Training Accuracy 0.52\n",
      "Loss 290.11887 81 10\n",
      "Training Accuracy 0.535\n",
      "Loss 294.05048 82 10\n",
      "Training Accuracy 0.505\n",
      "Loss 277.44223 83 10\n",
      "Training Accuracy 0.58\n",
      "Loss 344.9177 84 10\n",
      "Training Accuracy 0.47\n",
      "Loss 303.69693 85 10\n",
      "Training Accuracy 0.505\n",
      "Loss 300.3842 86 10\n",
      "Training Accuracy 0.54\n",
      "Loss 340.9135 87 10\n",
      "Training Accuracy 0.46\n",
      "Loss 316.11603 88 10\n",
      "Training Accuracy 0.505\n",
      "Loss 288.76398 89 10\n",
      "Training Accuracy 0.515\n",
      "Loss 299.2092 90 10\n",
      "Training Accuracy 0.55\n",
      "Loss 314.83627 91 10\n",
      "Training Accuracy 0.485\n",
      "Loss 315.56027 92 10\n",
      "Training Accuracy 0.575\n",
      "Loss 289.79233 93 10\n",
      "Training Accuracy 0.545\n",
      "Loss 295.61935 94 10\n",
      "Training Accuracy 0.54\n",
      "Loss 278.71548 95 10\n",
      "Training Accuracy 0.51\n",
      "Loss 283.38077 96 10\n",
      "Training Accuracy 0.545\n",
      "Loss 301.93365 97 10\n",
      "Training Accuracy 0.485\n",
      "Loss 298.17596 98 10\n",
      "Training Accuracy 0.515\n",
      "Loss 288.4753 99 10\n",
      "Training Accuracy 0.545\n",
      "Loss 317.15698 100 10\n",
      "Training Accuracy 0.57\n",
      "Loss 315.49503 101 10\n",
      "Training Accuracy 0.47\n",
      "Loss 266.64566 102 10\n",
      "Training Accuracy 0.55\n",
      "Loss 297.2935 103 10\n",
      "Training Accuracy 0.515\n",
      "Loss 281.60272 104 10\n",
      "Training Accuracy 0.51\n",
      "Loss 307.44037 105 10\n",
      "Training Accuracy 0.525\n",
      "Loss 306.9389 106 10\n",
      "Training Accuracy 0.525\n",
      "Loss 303.1304 107 10\n",
      "Training Accuracy 0.51\n",
      "Loss 305.23636 108 10\n",
      "Training Accuracy 0.535\n",
      "Loss 295.49695 109 10\n",
      "Training Accuracy 0.515\n",
      "Loss 310.75705 110 10\n",
      "Training Accuracy 0.54\n",
      "Loss 304.4794 111 10\n",
      "Training Accuracy 0.51\n",
      "Loss 314.5059 112 10\n",
      "Training Accuracy 0.535\n",
      "Loss 336.75934 113 10\n",
      "Training Accuracy 0.52\n",
      "Loss 293.23868 114 10\n",
      "Training Accuracy 0.475\n",
      "Loss 327.98322 115 10\n",
      "Training Accuracy 0.5\n",
      "Loss 335.8762 116 10\n",
      "Training Accuracy 0.495\n",
      "Loss 262.8618 117 10\n",
      "Training Accuracy 0.64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 315.64264 118 10\n",
      "Training Accuracy 0.535\n",
      "Loss 353.30457 119 10\n",
      "Training Accuracy 0.43\n",
      "Loss 327.13284 120 10\n",
      "Training Accuracy 0.5\n",
      "Loss 318.0344 121 10\n",
      "Training Accuracy 0.49\n",
      "Loss 268.29352 122 10\n",
      "Training Accuracy 0.555\n",
      "Loss 307.0899 123 10\n",
      "Training Accuracy 0.5\n",
      "Loss 293.29874 124 10\n",
      "Training Accuracy 0.555\n",
      "Loss 267.9119 125 10\n",
      "Training Accuracy 0.59\n",
      "Loss 307.05786 126 10\n",
      "Training Accuracy 0.46\n",
      "Loss 282.56656 127 10\n",
      "Training Accuracy 0.535\n",
      "Loss 288.8733 128 10\n",
      "Training Accuracy 0.545\n",
      "Loss 274.85745 129 10\n",
      "Training Accuracy 0.59\n",
      "Loss 287.8546 130 10\n",
      "Training Accuracy 0.54\n",
      "Loss 276.08215 131 10\n",
      "Training Accuracy 0.55\n",
      "Loss 284.87585 132 10\n",
      "Training Accuracy 0.55\n",
      "Loss 296.62024 133 10\n",
      "Training Accuracy 0.565\n",
      "Loss 274.74475 134 10\n",
      "Training Accuracy 0.535\n",
      "Loss 268.32016 135 10\n",
      "Training Accuracy 0.575\n",
      "Loss 318.23746 136 10\n",
      "Training Accuracy 0.51\n",
      "Loss 312.07657 137 10\n",
      "Training Accuracy 0.495\n",
      "Loss 272.59396 138 10\n",
      "Training Accuracy 0.57\n",
      "Loss 322.9538 139 10\n",
      "Training Accuracy 0.545\n",
      "Loss 260.4125 140 10\n",
      "Training Accuracy 0.55\n",
      "Loss 316.3494 141 10\n",
      "Training Accuracy 0.49\n",
      "Loss 299.6476 142 10\n",
      "Training Accuracy 0.515\n",
      "Loss 259.5172 143 10\n",
      "Training Accuracy 0.55\n",
      "Loss 302.24176 144 10\n",
      "Training Accuracy 0.52\n",
      "Loss 285.48062 145 10\n",
      "Training Accuracy 0.58\n",
      "Loss 298.90182 146 10\n",
      "Training Accuracy 0.51\n",
      "Loss 283.9529 147 10\n",
      "Training Accuracy 0.555\n",
      "Loss 300.42947 148 10\n",
      "Training Accuracy 0.51\n",
      "Loss 281.8364 149 10\n",
      "Training Accuracy 0.585\n",
      "Loss 280.78384 150 10\n",
      "Training Accuracy 0.585\n",
      "Loss 303.83563 151 10\n",
      "Training Accuracy 0.565\n",
      "Loss 320.25208 152 10\n",
      "Training Accuracy 0.485\n",
      "Loss 285.10913 153 10\n",
      "Training Accuracy 0.545\n",
      "Loss 290.38882 154 10\n",
      "Training Accuracy 0.54\n",
      "Loss 267.00873 155 10\n",
      "Training Accuracy 0.605\n",
      "Loss 305.93994 156 10\n",
      "Training Accuracy 0.53\n",
      "Loss 254.29642 157 10\n",
      "Training Accuracy 0.58\n",
      "Loss 301.90274 158 10\n",
      "Training Accuracy 0.545\n",
      "Loss 335.0461 159 10\n",
      "Training Accuracy 0.485\n",
      "Loss 295.00644 160 10\n",
      "Training Accuracy 0.565\n",
      "Loss 315.76498 161 10\n",
      "Training Accuracy 0.475\n",
      "Loss 286.72104 162 10\n",
      "Training Accuracy 0.545\n",
      "Loss 305.92053 163 10\n",
      "Training Accuracy 0.505\n",
      "Loss 250.66563 164 10\n",
      "Training Accuracy 0.6\n",
      "Loss 281.30737 165 10\n",
      "Training Accuracy 0.565\n",
      "Loss 303.01715 166 10\n",
      "Training Accuracy 0.535\n",
      "Loss 244.99852 167 10\n",
      "Training Accuracy 0.585\n",
      "Loss 315.34116 168 10\n",
      "Training Accuracy 0.53\n",
      "Loss 273.92065 169 10\n",
      "Training Accuracy 0.525\n",
      "Loss 288.50345 170 10\n",
      "Training Accuracy 0.56\n",
      "Loss 307.18582 171 10\n",
      "Training Accuracy 0.585\n",
      "Loss 276.1957 172 10\n",
      "Training Accuracy 0.575\n",
      "Loss 342.9127 173 10\n",
      "Training Accuracy 0.47\n",
      "Loss 250.73882 174 10\n",
      "Training Accuracy 0.56\n",
      "Loss 273.6397 175 10\n",
      "Training Accuracy 0.605\n",
      "Loss 258.38025 176 10\n",
      "Training Accuracy 0.595\n",
      "Loss 329.10974 177 10\n",
      "Training Accuracy 0.475\n",
      "Loss 278.33032 178 10\n",
      "Training Accuracy 0.535\n",
      "Loss 322.862 179 10\n",
      "Training Accuracy 0.495\n",
      "Loss 297.6433 180 10\n",
      "Training Accuracy 0.5\n",
      "Loss 258.10556 181 10\n",
      "Training Accuracy 0.555\n",
      "Loss 317.1146 182 10\n",
      "Training Accuracy 0.495\n",
      "Loss 311.32285 183 10\n",
      "Training Accuracy 0.535\n",
      "Loss 264.41034 184 10\n",
      "Training Accuracy 0.615\n",
      "Loss 271.25757 185 10\n",
      "Training Accuracy 0.575\n",
      "Loss 276.5994 186 10\n",
      "Training Accuracy 0.57\n",
      "Loss 324.1178 187 10\n",
      "Training Accuracy 0.5\n",
      "Loss 309.04514 188 10\n",
      "Training Accuracy 0.53\n",
      "Loss 300.0365 189 10\n",
      "Training Accuracy 0.55\n",
      "Loss 290.6913 190 10\n",
      "Training Accuracy 0.57\n",
      "Loss 289.85333 191 10\n",
      "Training Accuracy 0.575\n",
      "Loss 296.31793 192 10\n",
      "Training Accuracy 0.545\n",
      "Loss 268.23956 193 10\n",
      "Training Accuracy 0.605\n",
      "Loss 284.38428 194 10\n",
      "Training Accuracy 0.505\n",
      "Loss 278.7454 195 10\n",
      "Training Accuracy 0.565\n",
      "Loss 289.63516 196 10\n",
      "Training Accuracy 0.55\n",
      "Loss 305.58936 197 10\n",
      "Training Accuracy 0.51\n",
      "Loss 271.46994 198 10\n",
      "Training Accuracy 0.545\n",
      "Loss 245.22249 199 10\n",
      "Training Accuracy 0.605\n",
      "Loss 307.6409 200 10\n",
      "Training Accuracy 0.505\n",
      "Loss 276.69406 201 10\n",
      "Training Accuracy 0.545\n",
      "Loss 278.4267 202 10\n",
      "Training Accuracy 0.48\n",
      "Loss 295.78815 203 10\n",
      "Training Accuracy 0.525\n",
      "Loss 293.18372 204 10\n",
      "Training Accuracy 0.5\n",
      "Loss 319.60355 205 10\n",
      "Training Accuracy 0.495\n",
      "Loss 303.31494 206 10\n",
      "Training Accuracy 0.565\n",
      "Loss 286.6814 207 10\n",
      "Training Accuracy 0.515\n",
      "Loss 315.61002 208 10\n",
      "Training Accuracy 0.55\n",
      "Loss 327.91098 209 10\n",
      "Training Accuracy 0.51\n",
      "Loss 267.0977 210 10\n",
      "Training Accuracy 0.545\n",
      "Loss 306.66898 211 10\n",
      "Training Accuracy 0.53\n",
      "Loss 260.97403 212 10\n",
      "Training Accuracy 0.575\n",
      "Loss 341.96265 213 10\n",
      "Training Accuracy 0.43\n",
      "Loss 292.55856 214 10\n",
      "Training Accuracy 0.59\n",
      "Loss 304.28918 215 10\n",
      "Training Accuracy 0.52\n",
      "Loss 328.1302 216 10\n",
      "Training Accuracy 0.485\n",
      "Loss 290.2671 217 10\n",
      "Training Accuracy 0.515\n",
      "Loss 300.21286 218 10\n",
      "Training Accuracy 0.53\n",
      "Loss 295.64542 219 10\n",
      "Training Accuracy 0.56\n",
      "Loss 279.91415 220 10\n",
      "Training Accuracy 0.565\n",
      "Loss 304.26593 221 10\n",
      "Training Accuracy 0.48\n",
      "Loss 291.58102 222 10\n",
      "Training Accuracy 0.54\n",
      "Loss 319.5957 223 10\n",
      "Training Accuracy 0.505\n",
      "Loss 307.9236 224 10\n",
      "Training Accuracy 0.465\n",
      "Loss 315.69437 225 10\n",
      "Training Accuracy 0.555\n",
      "Loss 274.316 226 10\n",
      "Training Accuracy 0.55\n",
      "Loss 330.34454 227 10\n",
      "Training Accuracy 0.53\n",
      "Loss 340.7961 228 10\n",
      "Training Accuracy 0.47\n",
      "Loss 285.29132 229 10\n",
      "Training Accuracy 0.545\n",
      "Loss 302.21088 230 10\n",
      "Training Accuracy 0.555\n",
      "Loss 251.08087 231 10\n",
      "Training Accuracy 0.625\n",
      "Loss 290.98767 232 10\n",
      "Training Accuracy 0.505\n",
      "Loss 307.3463 233 10\n",
      "Training Accuracy 0.51\n",
      "Loss 294.5283 234 10\n",
      "Training Accuracy 0.5\n",
      "Loss 286.67514 235 10\n",
      "Training Accuracy 0.535\n",
      "Loss 265.91357 236 10\n",
      "Training Accuracy 0.6\n",
      "Loss 300.727 237 10\n",
      "Training Accuracy 0.555\n",
      "Loss 282.30527 238 10\n",
      "Training Accuracy 0.52\n",
      "Loss 317.99567 239 10\n",
      "Training Accuracy 0.49\n",
      "Loss 292.2709 240 10\n",
      "Training Accuracy 0.495\n",
      "Loss 312.22714 241 10\n",
      "Training Accuracy 0.52\n",
      "Loss 263.37155 242 10\n",
      "Training Accuracy 0.59\n",
      "Loss 258.33292 243 10\n",
      "Training Accuracy 0.595\n",
      "Loss 296.2376 244 10\n",
      "Training Accuracy 0.5\n",
      "Loss 285.74265 245 10\n",
      "Training Accuracy 0.57\n",
      "Loss 307.05746 246 10\n",
      "Training Accuracy 0.51\n",
      "Loss 242.32652 247 10\n",
      "Training Accuracy 0.535\n",
      "Loss 279.818 248 10\n",
      "Training Accuracy 0.57\n",
      "Loss 291.62573 249 10\n",
      "Training Accuracy 0.505\n",
      "Loss 316.60962 250 10\n",
      "Training Accuracy 0.485\n",
      "Loss 309.07996 251 10\n",
      "Training Accuracy 0.495\n",
      "Loss 262.0995 252 10\n",
      "Training Accuracy 0.575\n",
      "Loss 275.10995 253 10\n",
      "Training Accuracy 0.54\n",
      "Loss 276.10345 254 10\n",
      "Training Accuracy 0.525\n",
      "Loss 265.00934 255 10\n",
      "Training Accuracy 0.59\n",
      "Loss 303.4188 256 10\n",
      "Training Accuracy 0.515\n",
      "Loss 280.9148 257 10\n",
      "Training Accuracy 0.605\n",
      "Loss 287.51535 258 10\n",
      "Training Accuracy 0.545\n",
      "Loss 301.33527 259 10\n",
      "Training Accuracy 0.52\n",
      "Loss 245.10854 260 10\n",
      "Training Accuracy 0.595\n",
      "Loss 293.6212 261 10\n",
      "Training Accuracy 0.545\n",
      "Loss 281.80396 262 10\n",
      "Training Accuracy 0.495\n",
      "Loss 367.7506 263 10\n",
      "Training Accuracy 0.485\n",
      "Loss 308.70618 264 10\n",
      "Training Accuracy 0.56\n",
      "Loss 290.16193 265 10\n",
      "Training Accuracy 0.575\n",
      "Loss 281.86792 266 10\n",
      "Training Accuracy 0.525\n",
      "Loss 305.0541 267 10\n",
      "Training Accuracy 0.555\n",
      "Loss 299.7734 268 10\n",
      "Training Accuracy 0.54\n",
      "Loss 261.97705 269 10\n",
      "Training Accuracy 0.525\n",
      "Loss 255.42157 270 10\n",
      "Training Accuracy 0.57\n",
      "Loss 320.8886 271 10\n",
      "Training Accuracy 0.48\n",
      "Loss 295.91513 272 10\n",
      "Training Accuracy 0.515\n",
      "Loss 299.31393 273 10\n",
      "Training Accuracy 0.54\n",
      "Loss 271.6041 274 10\n",
      "Training Accuracy 0.58\n",
      "Loss 310.3517 275 10\n",
      "Training Accuracy 0.475\n",
      "Loss 259.9679 276 10\n",
      "Training Accuracy 0.585\n",
      "Loss 349.45245 277 10\n",
      "Training Accuracy 0.49\n",
      "Loss 278.18042 278 10\n",
      "Training Accuracy 0.555\n",
      "Loss 292.2027 279 10\n",
      "Training Accuracy 0.53\n",
      "Loss 274.91605 280 10\n",
      "Training Accuracy 0.56\n",
      "Loss 283.8342 281 10\n",
      "Training Accuracy 0.535\n",
      "Loss 287.3385 282 10\n",
      "Training Accuracy 0.535\n",
      "Loss 274.61755 283 10\n",
      "Training Accuracy 0.585\n",
      "Loss 264.73065 284 10\n",
      "Training Accuracy 0.63\n",
      "Loss 331.45416 285 10\n",
      "Training Accuracy 0.44\n",
      "Loss 287.21066 286 10\n",
      "Training Accuracy 0.55\n",
      "Loss 283.63947 287 10\n",
      "Training Accuracy 0.6\n",
      "Loss 300.3208 288 10\n",
      "Training Accuracy 0.545\n",
      "Loss 268.72336 289 10\n",
      "Training Accuracy 0.545\n",
      "Loss 297.71326 290 10\n",
      "Training Accuracy 0.53\n",
      "Loss 293.5678 291 10\n",
      "Training Accuracy 0.545\n",
      "Loss 183.70801 292 10\n",
      "Training Accuracy 0.52272725\n",
      "Loss 261.32455 1 11\n",
      "Training Accuracy 0.555\n",
      "Loss 289.6002 2 11\n",
      "Training Accuracy 0.54\n",
      "Loss 302.9809 3 11\n",
      "Training Accuracy 0.56\n",
      "Loss 282.3852 4 11\n",
      "Training Accuracy 0.6\n",
      "Loss 259.3065 5 11\n",
      "Training Accuracy 0.595\n",
      "Loss 286.39957 6 11\n",
      "Training Accuracy 0.54\n",
      "Loss 294.65942 7 11\n",
      "Training Accuracy 0.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 330.754 8 11\n",
      "Training Accuracy 0.52\n",
      "Loss 282.6732 9 11\n",
      "Training Accuracy 0.575\n",
      "Loss 307.6148 10 11\n",
      "Training Accuracy 0.52\n",
      "Loss 319.26657 11 11\n",
      "Training Accuracy 0.565\n",
      "Loss 275.79288 12 11\n",
      "Training Accuracy 0.56\n",
      "Loss 281.43655 13 11\n",
      "Training Accuracy 0.545\n",
      "Loss 307.67667 14 11\n",
      "Training Accuracy 0.54\n",
      "Loss 270.4673 15 11\n",
      "Training Accuracy 0.56\n",
      "Loss 317.36145 16 11\n",
      "Training Accuracy 0.495\n",
      "Loss 278.18927 17 11\n",
      "Training Accuracy 0.545\n",
      "Loss 288.4829 18 11\n",
      "Training Accuracy 0.54\n",
      "Loss 267.74286 19 11\n",
      "Training Accuracy 0.535\n",
      "Loss 296.994 20 11\n",
      "Training Accuracy 0.53\n",
      "Loss 290.3882 21 11\n",
      "Training Accuracy 0.535\n",
      "Loss 305.21796 22 11\n",
      "Training Accuracy 0.515\n",
      "Loss 305.54807 23 11\n",
      "Training Accuracy 0.54\n",
      "Loss 300.86646 24 11\n",
      "Training Accuracy 0.515\n",
      "Loss 284.01535 25 11\n",
      "Training Accuracy 0.54\n",
      "Loss 307.31134 26 11\n",
      "Training Accuracy 0.45\n",
      "Loss 270.6301 27 11\n",
      "Training Accuracy 0.58\n",
      "Loss 284.73233 28 11\n",
      "Training Accuracy 0.55\n",
      "Loss 277.82648 29 11\n",
      "Training Accuracy 0.525\n",
      "Loss 297.81784 30 11\n",
      "Training Accuracy 0.53\n",
      "Loss 323.87933 31 11\n",
      "Training Accuracy 0.5\n",
      "Loss 291.94916 32 11\n",
      "Training Accuracy 0.545\n",
      "Loss 294.34265 33 11\n",
      "Training Accuracy 0.55\n",
      "Loss 269.54056 34 11\n",
      "Training Accuracy 0.55\n",
      "Loss 257.87744 35 11\n",
      "Training Accuracy 0.56\n",
      "Loss 276.0718 36 11\n",
      "Training Accuracy 0.525\n",
      "Loss 281.60547 37 11\n",
      "Training Accuracy 0.555\n",
      "Loss 295.54642 38 11\n",
      "Training Accuracy 0.535\n",
      "Loss 266.6474 39 11\n",
      "Training Accuracy 0.55\n",
      "Loss 258.44675 40 11\n",
      "Training Accuracy 0.595\n",
      "Loss 284.93344 41 11\n",
      "Training Accuracy 0.51\n",
      "Loss 329.21298 42 11\n",
      "Training Accuracy 0.47\n",
      "Loss 281.248 43 11\n",
      "Training Accuracy 0.535\n",
      "Loss 276.7258 44 11\n",
      "Training Accuracy 0.525\n",
      "Loss 289.07312 45 11\n",
      "Training Accuracy 0.555\n",
      "Loss 326.48734 46 11\n",
      "Training Accuracy 0.505\n",
      "Loss 270.36768 47 11\n",
      "Training Accuracy 0.555\n",
      "Loss 269.99927 48 11\n",
      "Training Accuracy 0.58\n",
      "Loss 290.69104 49 11\n",
      "Training Accuracy 0.55\n",
      "Loss 305.8939 50 11\n",
      "Training Accuracy 0.535\n",
      "Loss 273.006 51 11\n",
      "Training Accuracy 0.605\n",
      "Loss 277.52286 52 11\n",
      "Training Accuracy 0.525\n",
      "Loss 266.54947 53 11\n",
      "Training Accuracy 0.58\n",
      "Loss 311.11542 54 11\n",
      "Training Accuracy 0.46\n",
      "Loss 296.8794 55 11\n",
      "Training Accuracy 0.495\n",
      "Loss 294.14316 56 11\n",
      "Training Accuracy 0.5\n",
      "Loss 263.04947 57 11\n",
      "Training Accuracy 0.55\n",
      "Loss 258.8487 58 11\n",
      "Training Accuracy 0.565\n",
      "Loss 309.19406 59 11\n",
      "Training Accuracy 0.475\n",
      "Loss 274.82437 60 11\n",
      "Training Accuracy 0.545\n",
      "Loss 285.1048 61 11\n",
      "Training Accuracy 0.51\n",
      "Loss 284.32596 62 11\n",
      "Training Accuracy 0.54\n",
      "Loss 299.2551 63 11\n",
      "Training Accuracy 0.54\n",
      "Loss 281.58093 64 11\n",
      "Training Accuracy 0.535\n",
      "Loss 309.33392 65 11\n",
      "Training Accuracy 0.475\n",
      "Loss 267.88632 66 11\n",
      "Training Accuracy 0.565\n",
      "Loss 314.23196 67 11\n",
      "Training Accuracy 0.505\n",
      "Loss 287.30963 68 11\n",
      "Training Accuracy 0.505\n",
      "Loss 290.9735 69 11\n",
      "Training Accuracy 0.55\n",
      "Loss 295.42096 70 11\n",
      "Training Accuracy 0.56\n",
      "Loss 283.5809 71 11\n",
      "Training Accuracy 0.575\n",
      "Loss 290.73203 72 11\n",
      "Training Accuracy 0.53\n",
      "Loss 294.20395 73 11\n",
      "Training Accuracy 0.55\n",
      "Loss 320.74677 74 11\n",
      "Training Accuracy 0.55\n",
      "Loss 300.27084 75 11\n",
      "Training Accuracy 0.545\n",
      "Loss 271.31317 76 11\n",
      "Training Accuracy 0.56\n",
      "Loss 279.59387 77 11\n",
      "Training Accuracy 0.555\n",
      "Loss 277.94202 78 11\n",
      "Training Accuracy 0.55\n",
      "Loss 271.81512 79 11\n",
      "Training Accuracy 0.5\n",
      "Loss 289.7921 80 11\n",
      "Training Accuracy 0.52\n",
      "Loss 283.03787 81 11\n",
      "Training Accuracy 0.5\n",
      "Loss 280.68738 82 11\n",
      "Training Accuracy 0.555\n",
      "Loss 281.60403 83 11\n",
      "Training Accuracy 0.525\n",
      "Loss 330.3688 84 11\n",
      "Training Accuracy 0.5\n",
      "Loss 292.673 85 11\n",
      "Training Accuracy 0.51\n",
      "Loss 291.33017 86 11\n",
      "Training Accuracy 0.535\n",
      "Loss 334.1614 87 11\n",
      "Training Accuracy 0.525\n",
      "Loss 313.2242 88 11\n",
      "Training Accuracy 0.52\n",
      "Loss 282.12073 89 11\n",
      "Training Accuracy 0.575\n",
      "Loss 296.37003 90 11\n",
      "Training Accuracy 0.52\n",
      "Loss 301.55753 91 11\n",
      "Training Accuracy 0.5\n",
      "Loss 299.77725 92 11\n",
      "Training Accuracy 0.57\n",
      "Loss 281.729 93 11\n",
      "Training Accuracy 0.565\n",
      "Loss 288.8146 94 11\n",
      "Training Accuracy 0.52\n",
      "Loss 270.71405 95 11\n",
      "Training Accuracy 0.57\n",
      "Loss 284.13962 96 11\n",
      "Training Accuracy 0.53\n",
      "Loss 293.53925 97 11\n",
      "Training Accuracy 0.525\n",
      "Loss 282.26074 98 11\n",
      "Training Accuracy 0.55\n",
      "Loss 284.41107 99 11\n",
      "Training Accuracy 0.56\n",
      "Loss 307.40372 100 11\n",
      "Training Accuracy 0.56\n",
      "Loss 298.27188 101 11\n",
      "Training Accuracy 0.48\n",
      "Loss 257.0359 102 11\n",
      "Training Accuracy 0.575\n",
      "Loss 299.70593 103 11\n",
      "Training Accuracy 0.505\n",
      "Loss 272.61172 104 11\n",
      "Training Accuracy 0.54\n",
      "Loss 309.61658 105 11\n",
      "Training Accuracy 0.515\n",
      "Loss 304.8672 106 11\n",
      "Training Accuracy 0.525\n",
      "Loss 292.03473 107 11\n",
      "Training Accuracy 0.535\n",
      "Loss 305.76865 108 11\n",
      "Training Accuracy 0.51\n",
      "Loss 281.0233 109 11\n",
      "Training Accuracy 0.49\n",
      "Loss 292.27588 110 11\n",
      "Training Accuracy 0.595\n",
      "Loss 294.27542 111 11\n",
      "Training Accuracy 0.505\n",
      "Loss 319.14072 112 11\n",
      "Training Accuracy 0.53\n",
      "Loss 322.75357 113 11\n",
      "Training Accuracy 0.525\n",
      "Loss 277.26193 114 11\n",
      "Training Accuracy 0.535\n",
      "Loss 320.14908 115 11\n",
      "Training Accuracy 0.475\n",
      "Loss 323.68994 116 11\n",
      "Training Accuracy 0.51\n",
      "Loss 260.46518 117 11\n",
      "Training Accuracy 0.625\n",
      "Loss 306.903 118 11\n",
      "Training Accuracy 0.55\n",
      "Loss 351.8213 119 11\n",
      "Training Accuracy 0.44\n",
      "Loss 314.7233 120 11\n",
      "Training Accuracy 0.48\n",
      "Loss 304.51016 121 11\n",
      "Training Accuracy 0.545\n",
      "Loss 260.9311 122 11\n",
      "Training Accuracy 0.585\n",
      "Loss 299.2347 123 11\n",
      "Training Accuracy 0.515\n",
      "Loss 280.08105 124 11\n",
      "Training Accuracy 0.56\n",
      "Loss 257.66418 125 11\n",
      "Training Accuracy 0.62\n",
      "Loss 303.25842 126 11\n",
      "Training Accuracy 0.485\n",
      "Loss 272.61557 127 11\n",
      "Training Accuracy 0.52\n",
      "Loss 275.33255 128 11\n",
      "Training Accuracy 0.545\n",
      "Loss 275.75418 129 11\n",
      "Training Accuracy 0.585\n",
      "Loss 274.3182 130 11\n",
      "Training Accuracy 0.565\n",
      "Loss 266.76196 131 11\n",
      "Training Accuracy 0.575\n",
      "Loss 279.57404 132 11\n",
      "Training Accuracy 0.525\n",
      "Loss 283.17242 133 11\n",
      "Training Accuracy 0.565\n",
      "Loss 271.565 134 11\n",
      "Training Accuracy 0.57\n",
      "Loss 260.99548 135 11\n",
      "Training Accuracy 0.56\n",
      "Loss 309.07614 136 11\n",
      "Training Accuracy 0.585\n",
      "Loss 293.51007 137 11\n",
      "Training Accuracy 0.56\n",
      "Loss 281.83026 138 11\n",
      "Training Accuracy 0.515\n",
      "Loss 318.29852 139 11\n",
      "Training Accuracy 0.555\n",
      "Loss 250.5307 140 11\n",
      "Training Accuracy 0.59\n",
      "Loss 289.1614 141 11\n",
      "Training Accuracy 0.535\n",
      "Loss 298.6536 142 11\n",
      "Training Accuracy 0.51\n",
      "Loss 253.17265 143 11\n",
      "Training Accuracy 0.56\n",
      "Loss 293.04303 144 11\n",
      "Training Accuracy 0.53\n",
      "Loss 286.32285 145 11\n",
      "Training Accuracy 0.565\n",
      "Loss 287.94482 146 11\n",
      "Training Accuracy 0.575\n",
      "Loss 275.62973 147 11\n",
      "Training Accuracy 0.565\n",
      "Loss 291.47226 148 11\n",
      "Training Accuracy 0.545\n",
      "Loss 276.70026 149 11\n",
      "Training Accuracy 0.575\n",
      "Loss 286.99445 150 11\n",
      "Training Accuracy 0.56\n",
      "Loss 296.4305 151 11\n",
      "Training Accuracy 0.53\n",
      "Loss 301.86682 152 11\n",
      "Training Accuracy 0.48\n",
      "Loss 280.52722 153 11\n",
      "Training Accuracy 0.555\n",
      "Loss 283.67743 154 11\n",
      "Training Accuracy 0.56\n",
      "Loss 261.33783 155 11\n",
      "Training Accuracy 0.58\n",
      "Loss 291.15356 156 11\n",
      "Training Accuracy 0.515\n",
      "Loss 255.70302 157 11\n",
      "Training Accuracy 0.57\n",
      "Loss 295.1958 158 11\n",
      "Training Accuracy 0.55\n",
      "Loss 323.3371 159 11\n",
      "Training Accuracy 0.53\n",
      "Loss 309.78955 160 11\n",
      "Training Accuracy 0.485\n",
      "Loss 310.08643 161 11\n",
      "Training Accuracy 0.52\n",
      "Loss 282.2072 162 11\n",
      "Training Accuracy 0.55\n",
      "Loss 301.01965 163 11\n",
      "Training Accuracy 0.545\n",
      "Loss 254.29883 164 11\n",
      "Training Accuracy 0.54\n",
      "Loss 282.87442 165 11\n",
      "Training Accuracy 0.555\n",
      "Loss 296.11752 166 11\n",
      "Training Accuracy 0.565\n",
      "Loss 245.80363 167 11\n",
      "Training Accuracy 0.54\n",
      "Loss 314.92352 168 11\n",
      "Training Accuracy 0.52\n",
      "Loss 276.74274 169 11\n",
      "Training Accuracy 0.56\n",
      "Loss 281.01273 170 11\n",
      "Training Accuracy 0.555\n",
      "Loss 310.16504 171 11\n",
      "Training Accuracy 0.515\n",
      "Loss 269.99054 172 11\n",
      "Training Accuracy 0.56\n",
      "Loss 327.35526 173 11\n",
      "Training Accuracy 0.5\n",
      "Loss 252.59332 174 11\n",
      "Training Accuracy 0.55\n",
      "Loss 267.19257 175 11\n",
      "Training Accuracy 0.565\n",
      "Loss 245.66904 176 11\n",
      "Training Accuracy 0.645\n",
      "Loss 332.1086 177 11\n",
      "Training Accuracy 0.48\n",
      "Loss 267.17355 178 11\n",
      "Training Accuracy 0.555\n",
      "Loss 303.92206 179 11\n",
      "Training Accuracy 0.53\n",
      "Loss 295.72583 180 11\n",
      "Training Accuracy 0.51\n",
      "Loss 258.90942 181 11\n",
      "Training Accuracy 0.56\n",
      "Loss 307.34256 182 11\n",
      "Training Accuracy 0.485\n",
      "Loss 299.9907 183 11\n",
      "Training Accuracy 0.56\n",
      "Loss 257.41605 184 11\n",
      "Training Accuracy 0.62\n",
      "Loss 266.7899 185 11\n",
      "Training Accuracy 0.555\n",
      "Loss 267.87405 186 11\n",
      "Training Accuracy 0.605\n",
      "Loss 325.54172 187 11\n",
      "Training Accuracy 0.465\n",
      "Loss 305.2248 188 11\n",
      "Training Accuracy 0.525\n",
      "Loss 296.29767 189 11\n",
      "Training Accuracy 0.515\n",
      "Loss 265.63193 190 11\n",
      "Training Accuracy 0.58\n",
      "Loss 270.617 191 11\n",
      "Training Accuracy 0.625\n",
      "Loss 292.35367 192 11\n",
      "Training Accuracy 0.54\n",
      "Loss 270.07858 193 11\n",
      "Training Accuracy 0.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 269.34738 194 11\n",
      "Training Accuracy 0.58\n",
      "Loss 265.59393 195 11\n",
      "Training Accuracy 0.575\n",
      "Loss 272.09665 196 11\n",
      "Training Accuracy 0.595\n",
      "Loss 289.27298 197 11\n",
      "Training Accuracy 0.545\n",
      "Loss 272.59894 198 11\n",
      "Training Accuracy 0.54\n",
      "Loss 242.56006 199 11\n",
      "Training Accuracy 0.61\n",
      "Loss 301.38315 200 11\n",
      "Training Accuracy 0.5\n",
      "Loss 269.35767 201 11\n",
      "Training Accuracy 0.525\n",
      "Loss 278.12607 202 11\n",
      "Training Accuracy 0.52\n",
      "Loss 295.9374 203 11\n",
      "Training Accuracy 0.51\n",
      "Loss 281.8132 204 11\n",
      "Training Accuracy 0.5\n",
      "Loss 309.46136 205 11\n",
      "Training Accuracy 0.55\n",
      "Loss 300.3237 206 11\n",
      "Training Accuracy 0.535\n",
      "Loss 280.50476 207 11\n",
      "Training Accuracy 0.53\n",
      "Loss 303.96896 208 11\n",
      "Training Accuracy 0.565\n",
      "Loss 306.14166 209 11\n",
      "Training Accuracy 0.555\n",
      "Loss 264.96805 210 11\n",
      "Training Accuracy 0.585\n",
      "Loss 285.12646 211 11\n",
      "Training Accuracy 0.525\n",
      "Loss 258.5022 212 11\n",
      "Training Accuracy 0.575\n",
      "Loss 331.60474 213 11\n",
      "Training Accuracy 0.47\n",
      "Loss 294.2219 214 11\n",
      "Training Accuracy 0.575\n",
      "Loss 302.489 215 11\n",
      "Training Accuracy 0.52\n",
      "Loss 314.2815 216 11\n",
      "Training Accuracy 0.515\n",
      "Loss 274.62408 217 11\n",
      "Training Accuracy 0.55\n",
      "Loss 287.247 218 11\n",
      "Training Accuracy 0.545\n",
      "Loss 282.95877 219 11\n",
      "Training Accuracy 0.585\n",
      "Loss 272.6985 220 11\n",
      "Training Accuracy 0.57\n",
      "Loss 290.88916 221 11\n",
      "Training Accuracy 0.55\n",
      "Loss 286.21194 222 11\n",
      "Training Accuracy 0.535\n",
      "Loss 314.32236 223 11\n",
      "Training Accuracy 0.48\n",
      "Loss 306.9271 224 11\n",
      "Training Accuracy 0.5\n",
      "Loss 309.751 225 11\n",
      "Training Accuracy 0.525\n",
      "Loss 254.09637 226 11\n",
      "Training Accuracy 0.56\n",
      "Loss 327.28912 227 11\n",
      "Training Accuracy 0.51\n",
      "Loss 334.98398 228 11\n",
      "Training Accuracy 0.455\n",
      "Loss 280.2905 229 11\n",
      "Training Accuracy 0.555\n",
      "Loss 282.1943 230 11\n",
      "Training Accuracy 0.54\n",
      "Loss 249.46976 231 11\n",
      "Training Accuracy 0.625\n",
      "Loss 281.35876 232 11\n",
      "Training Accuracy 0.545\n",
      "Loss 314.0783 233 11\n",
      "Training Accuracy 0.48\n",
      "Loss 282.6693 234 11\n",
      "Training Accuracy 0.515\n",
      "Loss 297.74335 235 11\n",
      "Training Accuracy 0.49\n",
      "Loss 252.09409 236 11\n",
      "Training Accuracy 0.63\n",
      "Loss 291.89938 237 11\n",
      "Training Accuracy 0.57\n",
      "Loss 280.88315 238 11\n",
      "Training Accuracy 0.53\n",
      "Loss 304.53268 239 11\n",
      "Training Accuracy 0.545\n",
      "Loss 281.65845 240 11\n",
      "Training Accuracy 0.51\n",
      "Loss 306.2533 241 11\n",
      "Training Accuracy 0.51\n",
      "Loss 261.46356 242 11\n",
      "Training Accuracy 0.59\n",
      "Loss 251.08757 243 11\n",
      "Training Accuracy 0.625\n",
      "Loss 278.6046 244 11\n",
      "Training Accuracy 0.5\n",
      "Loss 268.4577 245 11\n",
      "Training Accuracy 0.6\n",
      "Loss 294.78842 246 11\n",
      "Training Accuracy 0.52\n",
      "Loss 232.85153 247 11\n",
      "Training Accuracy 0.59\n",
      "Loss 280.72824 248 11\n",
      "Training Accuracy 0.485\n",
      "Loss 282.7535 249 11\n",
      "Training Accuracy 0.515\n",
      "Loss 288.8223 250 11\n",
      "Training Accuracy 0.515\n",
      "Loss 295.84567 251 11\n",
      "Training Accuracy 0.51\n",
      "Loss 261.16592 252 11\n",
      "Training Accuracy 0.555\n",
      "Loss 264.3052 253 11\n",
      "Training Accuracy 0.595\n",
      "Loss 271.84274 254 11\n",
      "Training Accuracy 0.55\n",
      "Loss 258.7769 255 11\n",
      "Training Accuracy 0.57\n",
      "Loss 289.40164 256 11\n",
      "Training Accuracy 0.55\n",
      "Loss 278.909 257 11\n",
      "Training Accuracy 0.595\n",
      "Loss 278.3589 258 11\n",
      "Training Accuracy 0.555\n",
      "Loss 288.74103 259 11\n",
      "Training Accuracy 0.54\n",
      "Loss 238.73706 260 11\n",
      "Training Accuracy 0.59\n",
      "Loss 289.32712 261 11\n",
      "Training Accuracy 0.55\n",
      "Loss 280.0765 262 11\n",
      "Training Accuracy 0.545\n",
      "Loss 357.04053 263 11\n",
      "Training Accuracy 0.485\n",
      "Loss 293.5675 264 11\n",
      "Training Accuracy 0.6\n",
      "Loss 272.99493 265 11\n",
      "Training Accuracy 0.57\n",
      "Loss 270.9546 266 11\n",
      "Training Accuracy 0.555\n",
      "Loss 295.5875 267 11\n",
      "Training Accuracy 0.535\n",
      "Loss 304.5276 268 11\n",
      "Training Accuracy 0.51\n",
      "Loss 260.7602 269 11\n",
      "Training Accuracy 0.535\n",
      "Loss 244.53253 270 11\n",
      "Training Accuracy 0.6\n",
      "Loss 314.28452 271 11\n",
      "Training Accuracy 0.49\n",
      "Loss 297.79926 272 11\n",
      "Training Accuracy 0.58\n",
      "Loss 288.63434 273 11\n",
      "Training Accuracy 0.565\n",
      "Loss 266.9026 274 11\n",
      "Training Accuracy 0.61\n",
      "Loss 292.57013 275 11\n",
      "Training Accuracy 0.485\n",
      "Loss 257.00006 276 11\n",
      "Training Accuracy 0.585\n",
      "Loss 336.75003 277 11\n",
      "Training Accuracy 0.51\n",
      "Loss 260.37207 278 11\n",
      "Training Accuracy 0.575\n",
      "Loss 274.28214 279 11\n",
      "Training Accuracy 0.54\n",
      "Loss 271.5314 280 11\n",
      "Training Accuracy 0.57\n",
      "Loss 284.62265 281 11\n",
      "Training Accuracy 0.54\n",
      "Loss 284.2972 282 11\n",
      "Training Accuracy 0.555\n",
      "Loss 263.9826 283 11\n",
      "Training Accuracy 0.58\n",
      "Loss 264.25668 284 11\n",
      "Training Accuracy 0.605\n",
      "Loss 316.35477 285 11\n",
      "Training Accuracy 0.515\n",
      "Loss 283.59607 286 11\n",
      "Training Accuracy 0.575\n",
      "Loss 272.11975 287 11\n",
      "Training Accuracy 0.595\n",
      "Loss 282.1315 288 11\n",
      "Training Accuracy 0.565\n",
      "Loss 271.4647 289 11\n",
      "Training Accuracy 0.565\n",
      "Loss 287.5221 290 11\n",
      "Training Accuracy 0.565\n",
      "Loss 287.28275 291 11\n",
      "Training Accuracy 0.53\n",
      "Loss 177.70201 292 11\n",
      "Training Accuracy 0.57575756\n",
      "Loss 246.20525 1 12\n",
      "Training Accuracy 0.615\n",
      "Loss 285.5175 2 12\n",
      "Training Accuracy 0.535\n",
      "Loss 275.7579 3 12\n",
      "Training Accuracy 0.56\n",
      "Loss 285.23135 4 12\n",
      "Training Accuracy 0.58\n",
      "Loss 253.04448 5 12\n",
      "Training Accuracy 0.595\n",
      "Loss 276.69046 6 12\n",
      "Training Accuracy 0.58\n",
      "Loss 285.69534 7 12\n",
      "Training Accuracy 0.535\n",
      "Loss 315.65375 8 12\n",
      "Training Accuracy 0.545\n",
      "Loss 266.59628 9 12\n",
      "Training Accuracy 0.595\n",
      "Loss 299.0157 10 12\n",
      "Training Accuracy 0.505\n",
      "Loss 313.33142 11 12\n",
      "Training Accuracy 0.58\n",
      "Loss 282.72305 12 12\n",
      "Training Accuracy 0.535\n",
      "Loss 263.11984 13 12\n",
      "Training Accuracy 0.545\n",
      "Loss 296.88785 14 12\n",
      "Training Accuracy 0.565\n",
      "Loss 266.5277 15 12\n",
      "Training Accuracy 0.605\n",
      "Loss 328.24307 16 12\n",
      "Training Accuracy 0.47\n",
      "Loss 257.11786 17 12\n",
      "Training Accuracy 0.6\n",
      "Loss 279.75916 18 12\n",
      "Training Accuracy 0.58\n",
      "Loss 270.87045 19 12\n",
      "Training Accuracy 0.545\n",
      "Loss 276.15204 20 12\n",
      "Training Accuracy 0.535\n",
      "Loss 270.18848 21 12\n",
      "Training Accuracy 0.535\n",
      "Loss 299.2655 22 12\n",
      "Training Accuracy 0.5\n",
      "Loss 298.26285 23 12\n",
      "Training Accuracy 0.565\n",
      "Loss 297.6412 24 12\n",
      "Training Accuracy 0.51\n",
      "Loss 278.383 25 12\n",
      "Training Accuracy 0.535\n",
      "Loss 288.79434 26 12\n",
      "Training Accuracy 0.5\n",
      "Loss 263.595 27 12\n",
      "Training Accuracy 0.55\n",
      "Loss 285.68546 28 12\n",
      "Training Accuracy 0.52\n",
      "Loss 279.30334 29 12\n",
      "Training Accuracy 0.555\n",
      "Loss 290.06476 30 12\n",
      "Training Accuracy 0.545\n",
      "Loss 315.8745 31 12\n",
      "Training Accuracy 0.515\n",
      "Loss 285.7762 32 12\n",
      "Training Accuracy 0.53\n",
      "Loss 294.8067 33 12\n",
      "Training Accuracy 0.53\n",
      "Loss 257.7732 34 12\n",
      "Training Accuracy 0.59\n",
      "Loss 246.08054 35 12\n",
      "Training Accuracy 0.555\n",
      "Loss 283.64392 36 12\n",
      "Training Accuracy 0.49\n",
      "Loss 289.55124 37 12\n",
      "Training Accuracy 0.54\n",
      "Loss 282.74573 38 12\n",
      "Training Accuracy 0.58\n",
      "Loss 250.99237 39 12\n",
      "Training Accuracy 0.59\n",
      "Loss 255.83276 40 12\n",
      "Training Accuracy 0.62\n",
      "Loss 287.27142 41 12\n",
      "Training Accuracy 0.49\n",
      "Loss 326.6161 42 12\n",
      "Training Accuracy 0.49\n",
      "Loss 267.26553 43 12\n",
      "Training Accuracy 0.6\n",
      "Loss 265.65753 44 12\n",
      "Training Accuracy 0.52\n",
      "Loss 281.31808 45 12\n",
      "Training Accuracy 0.535\n",
      "Loss 308.98828 46 12\n",
      "Training Accuracy 0.52\n",
      "Loss 254.85135 47 12\n",
      "Training Accuracy 0.59\n",
      "Loss 257.0798 48 12\n",
      "Training Accuracy 0.565\n",
      "Loss 276.65063 49 12\n",
      "Training Accuracy 0.53\n",
      "Loss 302.82312 50 12\n",
      "Training Accuracy 0.54\n",
      "Loss 263.02612 51 12\n",
      "Training Accuracy 0.585\n",
      "Loss 259.75705 52 12\n",
      "Training Accuracy 0.545\n",
      "Loss 263.06537 53 12\n",
      "Training Accuracy 0.58\n",
      "Loss 297.00406 54 12\n",
      "Training Accuracy 0.515\n",
      "Loss 287.63217 55 12\n",
      "Training Accuracy 0.465\n",
      "Loss 288.4458 56 12\n",
      "Training Accuracy 0.49\n",
      "Loss 261.1113 57 12\n",
      "Training Accuracy 0.615\n",
      "Loss 246.21292 58 12\n",
      "Training Accuracy 0.57\n",
      "Loss 296.41956 59 12\n",
      "Training Accuracy 0.505\n",
      "Loss 287.59628 60 12\n",
      "Training Accuracy 0.58\n",
      "Loss 278.09796 61 12\n",
      "Training Accuracy 0.525\n",
      "Loss 266.93686 62 12\n",
      "Training Accuracy 0.58\n",
      "Loss 297.2152 63 12\n",
      "Training Accuracy 0.545\n",
      "Loss 280.58875 64 12\n",
      "Training Accuracy 0.575\n",
      "Loss 293.14264 65 12\n",
      "Training Accuracy 0.55\n",
      "Loss 268.49612 66 12\n",
      "Training Accuracy 0.59\n",
      "Loss 304.2678 67 12\n",
      "Training Accuracy 0.55\n",
      "Loss 277.52045 68 12\n",
      "Training Accuracy 0.51\n",
      "Loss 286.57693 69 12\n",
      "Training Accuracy 0.565\n",
      "Loss 280.92493 70 12\n",
      "Training Accuracy 0.585\n",
      "Loss 280.05765 71 12\n",
      "Training Accuracy 0.57\n",
      "Loss 280.22107 72 12\n",
      "Training Accuracy 0.555\n",
      "Loss 285.12216 73 12\n",
      "Training Accuracy 0.54\n",
      "Loss 316.60126 74 12\n",
      "Training Accuracy 0.515\n",
      "Loss 301.2504 75 12\n",
      "Training Accuracy 0.545\n",
      "Loss 261.683 76 12\n",
      "Training Accuracy 0.575\n",
      "Loss 285.14612 77 12\n",
      "Training Accuracy 0.53\n",
      "Loss 279.08847 78 12\n",
      "Training Accuracy 0.555\n",
      "Loss 265.58582 79 12\n",
      "Training Accuracy 0.5\n",
      "Loss 290.24713 80 12\n",
      "Training Accuracy 0.535\n",
      "Loss 270.21844 81 12\n",
      "Training Accuracy 0.57\n",
      "Loss 265.40253 82 12\n",
      "Training Accuracy 0.56\n",
      "Loss 271.0562 83 12\n",
      "Training Accuracy 0.57\n",
      "Loss 325.60336 84 12\n",
      "Training Accuracy 0.48\n",
      "Loss 283.25723 85 12\n",
      "Training Accuracy 0.53\n",
      "Loss 286.82516 86 12\n",
      "Training Accuracy 0.57\n",
      "Loss 324.7011 87 12\n",
      "Training Accuracy 0.5\n",
      "Loss 303.04474 88 12\n",
      "Training Accuracy 0.465\n",
      "Loss 282.63583 89 12\n",
      "Training Accuracy 0.57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 281.09415 90 12\n",
      "Training Accuracy 0.54\n",
      "Loss 279.792 91 12\n",
      "Training Accuracy 0.56\n",
      "Loss 290.08273 92 12\n",
      "Training Accuracy 0.55\n",
      "Loss 277.00516 93 12\n",
      "Training Accuracy 0.58\n",
      "Loss 295.10687 94 12\n",
      "Training Accuracy 0.54\n",
      "Loss 263.3288 95 12\n",
      "Training Accuracy 0.535\n",
      "Loss 280.8844 96 12\n",
      "Training Accuracy 0.57\n",
      "Loss 294.03815 97 12\n",
      "Training Accuracy 0.51\n",
      "Loss 279.27948 98 12\n",
      "Training Accuracy 0.545\n",
      "Loss 258.68008 99 12\n",
      "Training Accuracy 0.61\n",
      "Loss 298.23495 100 12\n",
      "Training Accuracy 0.56\n",
      "Loss 287.7041 101 12\n",
      "Training Accuracy 0.535\n",
      "Loss 256.553 102 12\n",
      "Training Accuracy 0.54\n",
      "Loss 286.961 103 12\n",
      "Training Accuracy 0.535\n",
      "Loss 275.8471 104 12\n",
      "Training Accuracy 0.56\n",
      "Loss 293.42532 105 12\n",
      "Training Accuracy 0.535\n",
      "Loss 287.54376 106 12\n",
      "Training Accuracy 0.54\n",
      "Loss 277.9171 107 12\n",
      "Training Accuracy 0.52\n",
      "Loss 286.07535 108 12\n",
      "Training Accuracy 0.54\n",
      "Loss 271.14725 109 12\n",
      "Training Accuracy 0.585\n",
      "Loss 288.12595 110 12\n",
      "Training Accuracy 0.62\n",
      "Loss 284.668 111 12\n",
      "Training Accuracy 0.54\n",
      "Loss 303.81506 112 12\n",
      "Training Accuracy 0.56\n",
      "Loss 323.5112 113 12\n",
      "Training Accuracy 0.51\n",
      "Loss 274.37155 114 12\n",
      "Training Accuracy 0.54\n",
      "Loss 314.44702 115 12\n",
      "Training Accuracy 0.515\n",
      "Loss 324.1883 116 12\n",
      "Training Accuracy 0.52\n",
      "Loss 256.85083 117 12\n",
      "Training Accuracy 0.63\n",
      "Loss 291.36377 118 12\n",
      "Training Accuracy 0.56\n",
      "Loss 331.96375 119 12\n",
      "Training Accuracy 0.45\n",
      "Loss 303.50394 120 12\n",
      "Training Accuracy 0.52\n",
      "Loss 300.4719 121 12\n",
      "Training Accuracy 0.53\n",
      "Loss 260.95923 122 12\n",
      "Training Accuracy 0.56\n",
      "Loss 281.41968 123 12\n",
      "Training Accuracy 0.51\n",
      "Loss 275.37793 124 12\n",
      "Training Accuracy 0.585\n",
      "Loss 250.03302 125 12\n",
      "Training Accuracy 0.6\n",
      "Loss 309.0893 126 12\n",
      "Training Accuracy 0.495\n",
      "Loss 275.04608 127 12\n",
      "Training Accuracy 0.525\n",
      "Loss 277.61115 128 12\n",
      "Training Accuracy 0.53\n",
      "Loss 268.13156 129 12\n",
      "Training Accuracy 0.575\n",
      "Loss 264.36908 130 12\n",
      "Training Accuracy 0.56\n",
      "Loss 261.19608 131 12\n",
      "Training Accuracy 0.575\n",
      "Loss 256.7746 132 12\n",
      "Training Accuracy 0.59\n",
      "Loss 276.00504 133 12\n",
      "Training Accuracy 0.58\n",
      "Loss 265.77097 134 12\n",
      "Training Accuracy 0.58\n",
      "Loss 253.31165 135 12\n",
      "Training Accuracy 0.56\n",
      "Loss 306.52197 136 12\n",
      "Training Accuracy 0.53\n",
      "Loss 292.31656 137 12\n",
      "Training Accuracy 0.56\n",
      "Loss 261.99567 138 12\n",
      "Training Accuracy 0.61\n",
      "Loss 297.51102 139 12\n",
      "Training Accuracy 0.59\n",
      "Loss 247.25974 140 12\n",
      "Training Accuracy 0.61\n",
      "Loss 285.77463 141 12\n",
      "Training Accuracy 0.57\n",
      "Loss 284.02075 142 12\n",
      "Training Accuracy 0.525\n",
      "Loss 251.94612 143 12\n",
      "Training Accuracy 0.58\n",
      "Loss 288.0779 144 12\n",
      "Training Accuracy 0.5\n",
      "Loss 269.3979 145 12\n",
      "Training Accuracy 0.565\n",
      "Loss 283.91687 146 12\n",
      "Training Accuracy 0.545\n",
      "Loss 277.19995 147 12\n",
      "Training Accuracy 0.56\n",
      "Loss 281.4919 148 12\n",
      "Training Accuracy 0.525\n",
      "Loss 265.67706 149 12\n",
      "Training Accuracy 0.61\n",
      "Loss 272.3391 150 12\n",
      "Training Accuracy 0.585\n",
      "Loss 285.25406 151 12\n",
      "Training Accuracy 0.545\n",
      "Loss 293.36414 152 12\n",
      "Training Accuracy 0.545\n",
      "Loss 278.7364 153 12\n",
      "Training Accuracy 0.54\n",
      "Loss 267.83377 154 12\n",
      "Training Accuracy 0.57\n",
      "Loss 265.1152 155 12\n",
      "Training Accuracy 0.57\n",
      "Loss 288.6282 156 12\n",
      "Training Accuracy 0.51\n",
      "Loss 250.23302 157 12\n",
      "Training Accuracy 0.59\n",
      "Loss 275.19778 158 12\n",
      "Training Accuracy 0.545\n",
      "Loss 315.04187 159 12\n",
      "Training Accuracy 0.54\n",
      "Loss 291.48126 160 12\n",
      "Training Accuracy 0.55\n",
      "Loss 303.78137 161 12\n",
      "Training Accuracy 0.525\n",
      "Loss 272.34137 162 12\n",
      "Training Accuracy 0.56\n",
      "Loss 299.16135 163 12\n",
      "Training Accuracy 0.495\n",
      "Loss 234.01274 164 12\n",
      "Training Accuracy 0.565\n",
      "Loss 265.73523 165 12\n",
      "Training Accuracy 0.575\n",
      "Loss 297.22333 166 12\n",
      "Training Accuracy 0.55\n",
      "Loss 242.70393 167 12\n",
      "Training Accuracy 0.575\n",
      "Loss 295.22858 168 12\n",
      "Training Accuracy 0.555\n",
      "Loss 269.03632 169 12\n",
      "Training Accuracy 0.505\n",
      "Loss 274.9444 170 12\n",
      "Training Accuracy 0.555\n",
      "Loss 293.0364 171 12\n",
      "Training Accuracy 0.58\n",
      "Loss 262.99942 172 12\n",
      "Training Accuracy 0.6\n",
      "Loss 315.56442 173 12\n",
      "Training Accuracy 0.515\n",
      "Loss 248.33815 174 12\n",
      "Training Accuracy 0.565\n",
      "Loss 257.94382 175 12\n",
      "Training Accuracy 0.6\n",
      "Loss 238.63419 176 12\n",
      "Training Accuracy 0.665\n",
      "Loss 326.20062 177 12\n",
      "Training Accuracy 0.45\n",
      "Loss 263.40414 178 12\n",
      "Training Accuracy 0.55\n",
      "Loss 289.08557 179 12\n",
      "Training Accuracy 0.555\n",
      "Loss 283.23138 180 12\n",
      "Training Accuracy 0.53\n",
      "Loss 236.37306 181 12\n",
      "Training Accuracy 0.59\n",
      "Loss 296.1025 182 12\n",
      "Training Accuracy 0.51\n",
      "Loss 292.64066 183 12\n",
      "Training Accuracy 0.545\n",
      "Loss 255.44002 184 12\n",
      "Training Accuracy 0.63\n",
      "Loss 264.71863 185 12\n",
      "Training Accuracy 0.6\n",
      "Loss 260.03473 186 12\n",
      "Training Accuracy 0.575\n",
      "Loss 303.21475 187 12\n",
      "Training Accuracy 0.51\n",
      "Loss 293.76672 188 12\n",
      "Training Accuracy 0.515\n",
      "Loss 276.41956 189 12\n",
      "Training Accuracy 0.56\n",
      "Loss 264.5812 190 12\n",
      "Training Accuracy 0.605\n",
      "Loss 269.23578 191 12\n",
      "Training Accuracy 0.585\n",
      "Loss 280.78128 192 12\n",
      "Training Accuracy 0.59\n",
      "Loss 258.1502 193 12\n",
      "Training Accuracy 0.58\n",
      "Loss 268.27698 194 12\n",
      "Training Accuracy 0.535\n",
      "Loss 260.74982 195 12\n",
      "Training Accuracy 0.61\n",
      "Loss 265.8813 196 12\n",
      "Training Accuracy 0.58\n",
      "Loss 272.0325 197 12\n",
      "Training Accuracy 0.575\n",
      "Loss 259.5435 198 12\n",
      "Training Accuracy 0.55\n",
      "Loss 231.75589 199 12\n",
      "Training Accuracy 0.65\n",
      "Loss 291.94922 200 12\n",
      "Training Accuracy 0.515\n",
      "Loss 263.52332 201 12\n",
      "Training Accuracy 0.555\n",
      "Loss 260.6714 202 12\n",
      "Training Accuracy 0.57\n",
      "Loss 287.03955 203 12\n",
      "Training Accuracy 0.55\n",
      "Loss 277.64893 204 12\n",
      "Training Accuracy 0.54\n",
      "Loss 300.44513 205 12\n",
      "Training Accuracy 0.56\n",
      "Loss 283.56454 206 12\n",
      "Training Accuracy 0.54\n",
      "Loss 266.32114 207 12\n",
      "Training Accuracy 0.565\n",
      "Loss 299.28397 208 12\n",
      "Training Accuracy 0.61\n",
      "Loss 309.3612 209 12\n",
      "Training Accuracy 0.54\n",
      "Loss 264.37848 210 12\n",
      "Training Accuracy 0.58\n",
      "Loss 279.3994 211 12\n",
      "Training Accuracy 0.58\n",
      "Loss 259.77917 212 12\n",
      "Training Accuracy 0.535\n",
      "Loss 331.72372 213 12\n",
      "Training Accuracy 0.485\n",
      "Loss 275.0503 214 12\n",
      "Training Accuracy 0.565\n",
      "Loss 295.2033 215 12\n",
      "Training Accuracy 0.51\n",
      "Loss 298.11774 216 12\n",
      "Training Accuracy 0.525\n",
      "Loss 270.85574 217 12\n",
      "Training Accuracy 0.575\n",
      "Loss 284.55038 218 12\n",
      "Training Accuracy 0.55\n",
      "Loss 269.42172 219 12\n",
      "Training Accuracy 0.6\n",
      "Loss 271.15634 220 12\n",
      "Training Accuracy 0.575\n",
      "Loss 282.78204 221 12\n",
      "Training Accuracy 0.535\n",
      "Loss 275.7892 222 12\n",
      "Training Accuracy 0.57\n",
      "Loss 303.22827 223 12\n",
      "Training Accuracy 0.525\n",
      "Loss 288.45087 224 12\n",
      "Training Accuracy 0.53\n",
      "Loss 303.12762 225 12\n",
      "Training Accuracy 0.525\n",
      "Loss 252.12929 226 12\n",
      "Training Accuracy 0.58\n",
      "Loss 315.17624 227 12\n",
      "Training Accuracy 0.49\n",
      "Loss 309.74658 228 12\n",
      "Training Accuracy 0.485\n",
      "Loss 270.7875 229 12\n",
      "Training Accuracy 0.58\n",
      "Loss 279.4956 230 12\n",
      "Training Accuracy 0.57\n",
      "Loss 244.64655 231 12\n",
      "Training Accuracy 0.655\n",
      "Loss 282.0491 232 12\n",
      "Training Accuracy 0.54\n",
      "Loss 301.12997 233 12\n",
      "Training Accuracy 0.515\n",
      "Loss 290.8586 234 12\n",
      "Training Accuracy 0.5\n",
      "Loss 281.6285 235 12\n",
      "Training Accuracy 0.545\n",
      "Loss 242.23994 236 12\n",
      "Training Accuracy 0.63\n",
      "Loss 287.26038 237 12\n",
      "Training Accuracy 0.545\n",
      "Loss 266.94016 238 12\n",
      "Training Accuracy 0.52\n",
      "Loss 304.96658 239 12\n",
      "Training Accuracy 0.525\n",
      "Loss 273.80942 240 12\n",
      "Training Accuracy 0.56\n",
      "Loss 297.26648 241 12\n",
      "Training Accuracy 0.49\n",
      "Loss 259.8128 242 12\n",
      "Training Accuracy 0.61\n",
      "Loss 240.55339 243 12\n",
      "Training Accuracy 0.61\n",
      "Loss 285.3315 244 12\n",
      "Training Accuracy 0.505\n",
      "Loss 269.88052 245 12\n",
      "Training Accuracy 0.61\n",
      "Loss 297.89886 246 12\n",
      "Training Accuracy 0.515\n",
      "Loss 228.3354 247 12\n",
      "Training Accuracy 0.58\n",
      "Loss 265.67612 248 12\n",
      "Training Accuracy 0.55\n",
      "Loss 286.18695 249 12\n",
      "Training Accuracy 0.51\n",
      "Loss 287.4558 250 12\n",
      "Training Accuracy 0.515\n",
      "Loss 294.6124 251 12\n",
      "Training Accuracy 0.505\n",
      "Loss 246.0585 252 12\n",
      "Training Accuracy 0.605\n",
      "Loss 269.47592 253 12\n",
      "Training Accuracy 0.545\n",
      "Loss 269.60062 254 12\n",
      "Training Accuracy 0.595\n",
      "Loss 250.27347 255 12\n",
      "Training Accuracy 0.61\n",
      "Loss 287.87003 256 12\n",
      "Training Accuracy 0.525\n",
      "Loss 263.05933 257 12\n",
      "Training Accuracy 0.58\n",
      "Loss 273.66504 258 12\n",
      "Training Accuracy 0.56\n",
      "Loss 269.0385 259 12\n",
      "Training Accuracy 0.52\n",
      "Loss 232.0772 260 12\n",
      "Training Accuracy 0.615\n",
      "Loss 288.91077 261 12\n",
      "Training Accuracy 0.54\n",
      "Loss 273.68707 262 12\n",
      "Training Accuracy 0.51\n",
      "Loss 341.36847 263 12\n",
      "Training Accuracy 0.45\n",
      "Loss 295.029 264 12\n",
      "Training Accuracy 0.595\n",
      "Loss 277.4001 265 12\n",
      "Training Accuracy 0.575\n",
      "Loss 270.6691 266 12\n",
      "Training Accuracy 0.575\n",
      "Loss 288.83942 267 12\n",
      "Training Accuracy 0.53\n",
      "Loss 291.20618 268 12\n",
      "Training Accuracy 0.575\n",
      "Loss 254.87921 269 12\n",
      "Training Accuracy 0.56\n",
      "Loss 236.47475 270 12\n",
      "Training Accuracy 0.595\n",
      "Loss 309.37384 271 12\n",
      "Training Accuracy 0.505\n",
      "Loss 282.79602 272 12\n",
      "Training Accuracy 0.575\n",
      "Loss 287.97925 273 12\n",
      "Training Accuracy 0.54\n",
      "Loss 255.29308 274 12\n",
      "Training Accuracy 0.57\n",
      "Loss 290.26947 275 12\n",
      "Training Accuracy 0.505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 245.23192 276 12\n",
      "Training Accuracy 0.6\n",
      "Loss 316.51184 277 12\n",
      "Training Accuracy 0.52\n",
      "Loss 257.9586 278 12\n",
      "Training Accuracy 0.59\n",
      "Loss 268.00995 279 12\n",
      "Training Accuracy 0.555\n",
      "Loss 262.80002 280 12\n",
      "Training Accuracy 0.535\n",
      "Loss 275.02313 281 12\n",
      "Training Accuracy 0.53\n",
      "Loss 274.69144 282 12\n",
      "Training Accuracy 0.54\n",
      "Loss 259.8149 283 12\n",
      "Training Accuracy 0.585\n",
      "Loss 248.97504 284 12\n",
      "Training Accuracy 0.59\n",
      "Loss 309.84766 285 12\n",
      "Training Accuracy 0.515\n",
      "Loss 274.19485 286 12\n",
      "Training Accuracy 0.57\n",
      "Loss 268.40048 287 12\n",
      "Training Accuracy 0.59\n",
      "Loss 283.12302 288 12\n",
      "Training Accuracy 0.58\n",
      "Loss 257.84906 289 12\n",
      "Training Accuracy 0.57\n",
      "Loss 278.72867 290 12\n",
      "Training Accuracy 0.56\n",
      "Loss 286.99838 291 12\n",
      "Training Accuracy 0.535\n",
      "Loss 176.53658 292 12\n",
      "Training Accuracy 0.56060606\n",
      "Loss 240.15152 1 13\n",
      "Training Accuracy 0.6\n",
      "Loss 279.92734 2 13\n",
      "Training Accuracy 0.53\n",
      "Loss 283.52426 3 13\n",
      "Training Accuracy 0.565\n",
      "Loss 283.62946 4 13\n",
      "Training Accuracy 0.555\n",
      "Loss 240.76382 5 13\n",
      "Training Accuracy 0.6\n",
      "Loss 278.8503 6 13\n",
      "Training Accuracy 0.52\n",
      "Loss 272.65768 7 13\n",
      "Training Accuracy 0.575\n",
      "Loss 321.50458 8 13\n",
      "Training Accuracy 0.54\n",
      "Loss 256.23602 9 13\n",
      "Training Accuracy 0.615\n",
      "Loss 287.30167 10 13\n",
      "Training Accuracy 0.54\n",
      "Loss 309.33273 11 13\n",
      "Training Accuracy 0.555\n",
      "Loss 264.85822 12 13\n",
      "Training Accuracy 0.57\n",
      "Loss 274.29822 13 13\n",
      "Training Accuracy 0.56\n",
      "Loss 295.95462 14 13\n",
      "Training Accuracy 0.55\n",
      "Loss 251.98163 15 13\n",
      "Training Accuracy 0.61\n",
      "Loss 310.77173 16 13\n",
      "Training Accuracy 0.505\n",
      "Loss 248.94344 17 13\n",
      "Training Accuracy 0.595\n",
      "Loss 269.37314 18 13\n",
      "Training Accuracy 0.57\n",
      "Loss 259.8564 19 13\n",
      "Training Accuracy 0.57\n",
      "Loss 276.35834 20 13\n",
      "Training Accuracy 0.58\n",
      "Loss 264.64328 21 13\n",
      "Training Accuracy 0.565\n",
      "Loss 282.22836 22 13\n",
      "Training Accuracy 0.535\n",
      "Loss 290.3517 23 13\n",
      "Training Accuracy 0.535\n",
      "Loss 293.45828 24 13\n",
      "Training Accuracy 0.495\n",
      "Loss 287.5879 25 13\n",
      "Training Accuracy 0.555\n",
      "Loss 294.5461 26 13\n",
      "Training Accuracy 0.505\n",
      "Loss 259.29117 27 13\n",
      "Training Accuracy 0.6\n",
      "Loss 270.89987 28 13\n",
      "Training Accuracy 0.56\n",
      "Loss 271.67624 29 13\n",
      "Training Accuracy 0.545\n",
      "Loss 281.10205 30 13\n",
      "Training Accuracy 0.535\n",
      "Loss 302.06802 31 13\n",
      "Training Accuracy 0.54\n",
      "Loss 279.33035 32 13\n",
      "Training Accuracy 0.565\n",
      "Loss 283.45047 33 13\n",
      "Training Accuracy 0.55\n",
      "Loss 249.69966 34 13\n",
      "Training Accuracy 0.635\n",
      "Loss 252.94624 35 13\n",
      "Training Accuracy 0.54\n",
      "Loss 267.29132 36 13\n",
      "Training Accuracy 0.55\n",
      "Loss 274.46854 37 13\n",
      "Training Accuracy 0.575\n",
      "Loss 279.74506 38 13\n",
      "Training Accuracy 0.575\n",
      "Loss 242.1454 39 13\n",
      "Training Accuracy 0.61\n",
      "Loss 246.10875 40 13\n",
      "Training Accuracy 0.62\n",
      "Loss 269.2395 41 13\n",
      "Training Accuracy 0.54\n",
      "Loss 314.63885 42 13\n",
      "Training Accuracy 0.52\n",
      "Loss 267.429 43 13\n",
      "Training Accuracy 0.57\n",
      "Loss 257.60132 44 13\n",
      "Training Accuracy 0.56\n",
      "Loss 273.1058 45 13\n",
      "Training Accuracy 0.51\n",
      "Loss 307.52792 46 13\n",
      "Training Accuracy 0.515\n",
      "Loss 254.1584 47 13\n",
      "Training Accuracy 0.57\n",
      "Loss 250.43379 48 13\n",
      "Training Accuracy 0.58\n",
      "Loss 272.44373 49 13\n",
      "Training Accuracy 0.545\n",
      "Loss 296.92938 50 13\n",
      "Training Accuracy 0.545\n",
      "Loss 262.39032 51 13\n",
      "Training Accuracy 0.59\n",
      "Loss 269.3879 52 13\n",
      "Training Accuracy 0.53\n",
      "Loss 260.84406 53 13\n",
      "Training Accuracy 0.575\n",
      "Loss 290.541 54 13\n",
      "Training Accuracy 0.545\n",
      "Loss 293.11978 55 13\n",
      "Training Accuracy 0.495\n",
      "Loss 268.36685 56 13\n",
      "Training Accuracy 0.52\n",
      "Loss 257.7247 57 13\n",
      "Training Accuracy 0.565\n",
      "Loss 248.42102 58 13\n",
      "Training Accuracy 0.565\n",
      "Loss 274.71588 59 13\n",
      "Training Accuracy 0.6\n",
      "Loss 269.8804 60 13\n",
      "Training Accuracy 0.565\n",
      "Loss 270.30618 61 13\n",
      "Training Accuracy 0.51\n",
      "Loss 264.71973 62 13\n",
      "Training Accuracy 0.595\n",
      "Loss 285.0759 63 13\n",
      "Training Accuracy 0.545\n",
      "Loss 272.07037 64 13\n",
      "Training Accuracy 0.595\n",
      "Loss 291.33704 65 13\n",
      "Training Accuracy 0.54\n",
      "Loss 266.08453 66 13\n",
      "Training Accuracy 0.53\n",
      "Loss 287.8929 67 13\n",
      "Training Accuracy 0.54\n",
      "Loss 263.97086 68 13\n",
      "Training Accuracy 0.515\n",
      "Loss 272.69815 69 13\n",
      "Training Accuracy 0.535\n",
      "Loss 278.19482 70 13\n",
      "Training Accuracy 0.575\n",
      "Loss 271.3811 71 13\n",
      "Training Accuracy 0.565\n",
      "Loss 269.20776 72 13\n",
      "Training Accuracy 0.54\n",
      "Loss 283.03366 73 13\n",
      "Training Accuracy 0.55\n",
      "Loss 307.0766 74 13\n",
      "Training Accuracy 0.51\n",
      "Loss 294.45822 75 13\n",
      "Training Accuracy 0.53\n",
      "Loss 252.07603 76 13\n",
      "Training Accuracy 0.58\n",
      "Loss 269.01218 77 13\n",
      "Training Accuracy 0.56\n",
      "Loss 272.15955 78 13\n",
      "Training Accuracy 0.54\n",
      "Loss 263.91794 79 13\n",
      "Training Accuracy 0.555\n",
      "Loss 279.8202 80 13\n",
      "Training Accuracy 0.51\n",
      "Loss 263.8243 81 13\n",
      "Training Accuracy 0.54\n",
      "Loss 260.01163 82 13\n",
      "Training Accuracy 0.55\n",
      "Loss 267.93347 83 13\n",
      "Training Accuracy 0.575\n",
      "Loss 320.6261 84 13\n",
      "Training Accuracy 0.515\n",
      "Loss 273.69962 85 13\n",
      "Training Accuracy 0.56\n",
      "Loss 278.91257 86 13\n",
      "Training Accuracy 0.56\n",
      "Loss 314.20856 87 13\n",
      "Training Accuracy 0.53\n",
      "Loss 298.64825 88 13\n",
      "Training Accuracy 0.5\n",
      "Loss 277.03345 89 13\n",
      "Training Accuracy 0.575\n",
      "Loss 278.89645 90 13\n",
      "Training Accuracy 0.52\n",
      "Loss 287.28748 91 13\n",
      "Training Accuracy 0.515\n",
      "Loss 281.62622 92 13\n",
      "Training Accuracy 0.555\n",
      "Loss 265.57996 93 13\n",
      "Training Accuracy 0.575\n",
      "Loss 286.1252 94 13\n",
      "Training Accuracy 0.525\n",
      "Loss 250.5476 95 13\n",
      "Training Accuracy 0.57\n",
      "Loss 276.9069 96 13\n",
      "Training Accuracy 0.56\n",
      "Loss 281.15918 97 13\n",
      "Training Accuracy 0.525\n",
      "Loss 258.0081 98 13\n",
      "Training Accuracy 0.575\n",
      "Loss 269.6871 99 13\n",
      "Training Accuracy 0.565\n",
      "Loss 283.65613 100 13\n",
      "Training Accuracy 0.58\n",
      "Loss 288.33618 101 13\n",
      "Training Accuracy 0.53\n",
      "Loss 248.76543 102 13\n",
      "Training Accuracy 0.565\n",
      "Loss 280.11642 103 13\n",
      "Training Accuracy 0.54\n",
      "Loss 265.99646 104 13\n",
      "Training Accuracy 0.555\n",
      "Loss 291.98346 105 13\n",
      "Training Accuracy 0.5\n",
      "Loss 277.20087 106 13\n",
      "Training Accuracy 0.575\n",
      "Loss 276.44107 107 13\n",
      "Training Accuracy 0.545\n",
      "Loss 284.5648 108 13\n",
      "Training Accuracy 0.52\n",
      "Loss 268.25043 109 13\n",
      "Training Accuracy 0.555\n",
      "Loss 277.0213 110 13\n",
      "Training Accuracy 0.58\n",
      "Loss 273.19388 111 13\n",
      "Training Accuracy 0.54\n",
      "Loss 295.9332 112 13\n",
      "Training Accuracy 0.575\n",
      "Loss 314.43018 113 13\n",
      "Training Accuracy 0.55\n",
      "Loss 266.24182 114 13\n",
      "Training Accuracy 0.525\n",
      "Loss 303.07117 115 13\n",
      "Training Accuracy 0.515\n",
      "Loss 309.61676 116 13\n",
      "Training Accuracy 0.535\n",
      "Loss 240.71732 117 13\n",
      "Training Accuracy 0.67\n",
      "Loss 278.20557 118 13\n",
      "Training Accuracy 0.58\n",
      "Loss 327.50076 119 13\n",
      "Training Accuracy 0.445\n",
      "Loss 301.56036 120 13\n",
      "Training Accuracy 0.505\n",
      "Loss 297.7775 121 13\n",
      "Training Accuracy 0.555\n",
      "Loss 242.15608 122 13\n",
      "Training Accuracy 0.615\n",
      "Loss 282.36105 123 13\n",
      "Training Accuracy 0.515\n",
      "Loss 268.10553 124 13\n",
      "Training Accuracy 0.57\n",
      "Loss 245.35588 125 13\n",
      "Training Accuracy 0.605\n",
      "Loss 299.87723 126 13\n",
      "Training Accuracy 0.545\n",
      "Loss 269.6674 127 13\n",
      "Training Accuracy 0.55\n",
      "Loss 268.54642 128 13\n",
      "Training Accuracy 0.565\n",
      "Loss 256.20422 129 13\n",
      "Training Accuracy 0.595\n",
      "Loss 264.99698 130 13\n",
      "Training Accuracy 0.545\n",
      "Loss 250.1503 131 13\n",
      "Training Accuracy 0.625\n",
      "Loss 263.45422 132 13\n",
      "Training Accuracy 0.565\n",
      "Loss 267.79602 133 13\n",
      "Training Accuracy 0.575\n",
      "Loss 260.55374 134 13\n",
      "Training Accuracy 0.6\n",
      "Loss 253.05858 135 13\n",
      "Training Accuracy 0.61\n",
      "Loss 292.5603 136 13\n",
      "Training Accuracy 0.545\n",
      "Loss 290.02945 137 13\n",
      "Training Accuracy 0.56\n",
      "Loss 250.07733 138 13\n",
      "Training Accuracy 0.6\n",
      "Loss 294.37885 139 13\n",
      "Training Accuracy 0.555\n",
      "Loss 236.49034 140 13\n",
      "Training Accuracy 0.6\n",
      "Loss 291.48615 141 13\n",
      "Training Accuracy 0.53\n",
      "Loss 270.53357 142 13\n",
      "Training Accuracy 0.565\n",
      "Loss 239.57793 143 13\n",
      "Training Accuracy 0.585\n",
      "Loss 280.2672 144 13\n",
      "Training Accuracy 0.56\n",
      "Loss 275.0339 145 13\n",
      "Training Accuracy 0.545\n",
      "Loss 278.2104 146 13\n",
      "Training Accuracy 0.54\n",
      "Loss 261.09085 147 13\n",
      "Training Accuracy 0.585\n",
      "Loss 278.16077 148 13\n",
      "Training Accuracy 0.51\n",
      "Loss 265.85483 149 13\n",
      "Training Accuracy 0.545\n",
      "Loss 260.41342 150 13\n",
      "Training Accuracy 0.545\n",
      "Loss 290.0138 151 13\n",
      "Training Accuracy 0.525\n",
      "Loss 292.90356 152 13\n",
      "Training Accuracy 0.505\n",
      "Loss 262.3195 153 13\n",
      "Training Accuracy 0.555\n",
      "Loss 265.36993 154 13\n",
      "Training Accuracy 0.555\n",
      "Loss 254.49532 155 13\n",
      "Training Accuracy 0.59\n",
      "Loss 276.88525 156 13\n",
      "Training Accuracy 0.56\n",
      "Loss 236.16077 157 13\n",
      "Training Accuracy 0.6\n",
      "Loss 277.6901 158 13\n",
      "Training Accuracy 0.6\n",
      "Loss 308.71786 159 13\n",
      "Training Accuracy 0.56\n",
      "Loss 278.33707 160 13\n",
      "Training Accuracy 0.555\n",
      "Loss 293.40445 161 13\n",
      "Training Accuracy 0.525\n",
      "Loss 260.26932 162 13\n",
      "Training Accuracy 0.58\n",
      "Loss 286.72696 163 13\n",
      "Training Accuracy 0.555\n",
      "Loss 235.09145 164 13\n",
      "Training Accuracy 0.62\n",
      "Loss 263.75262 165 13\n",
      "Training Accuracy 0.575\n",
      "Loss 281.68692 166 13\n",
      "Training Accuracy 0.56\n",
      "Loss 234.6741 167 13\n",
      "Training Accuracy 0.57\n",
      "Loss 294.82755 168 13\n",
      "Training Accuracy 0.54\n",
      "Loss 264.48624 169 13\n",
      "Training Accuracy 0.555\n",
      "Loss 264.0743 170 13\n",
      "Training Accuracy 0.565\n",
      "Loss 293.70544 171 13\n",
      "Training Accuracy 0.53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 264.72214 172 13\n",
      "Training Accuracy 0.6\n",
      "Loss 316.2422 173 13\n",
      "Training Accuracy 0.545\n",
      "Loss 234.0282 174 13\n",
      "Training Accuracy 0.565\n",
      "Loss 253.0684 175 13\n",
      "Training Accuracy 0.6\n",
      "Loss 234.74225 176 13\n",
      "Training Accuracy 0.635\n",
      "Loss 309.03113 177 13\n",
      "Training Accuracy 0.515\n",
      "Loss 246.00282 178 13\n",
      "Training Accuracy 0.59\n",
      "Loss 287.472 179 13\n",
      "Training Accuracy 0.53\n",
      "Loss 278.07675 180 13\n",
      "Training Accuracy 0.5\n",
      "Loss 244.86491 181 13\n",
      "Training Accuracy 0.585\n",
      "Loss 287.5759 182 13\n",
      "Training Accuracy 0.55\n",
      "Loss 283.74963 183 13\n",
      "Training Accuracy 0.565\n",
      "Loss 246.97966 184 13\n",
      "Training Accuracy 0.615\n",
      "Loss 249.5333 185 13\n",
      "Training Accuracy 0.6\n",
      "Loss 261.2049 186 13\n",
      "Training Accuracy 0.595\n",
      "Loss 308.68036 187 13\n",
      "Training Accuracy 0.485\n",
      "Loss 290.08755 188 13\n",
      "Training Accuracy 0.545\n",
      "Loss 272.4867 189 13\n",
      "Training Accuracy 0.59\n",
      "Loss 267.5727 190 13\n",
      "Training Accuracy 0.57\n",
      "Loss 272.8893 191 13\n",
      "Training Accuracy 0.61\n",
      "Loss 280.43912 192 13\n",
      "Training Accuracy 0.545\n",
      "Loss 258.9646 193 13\n",
      "Training Accuracy 0.6\n",
      "Loss 262.14984 194 13\n",
      "Training Accuracy 0.565\n",
      "Loss 250.76758 195 13\n",
      "Training Accuracy 0.645\n",
      "Loss 259.63663 196 13\n",
      "Training Accuracy 0.575\n",
      "Loss 277.06387 197 13\n",
      "Training Accuracy 0.55\n",
      "Loss 262.18298 198 13\n",
      "Training Accuracy 0.525\n",
      "Loss 224.6283 199 13\n",
      "Training Accuracy 0.63\n",
      "Loss 273.71945 200 13\n",
      "Training Accuracy 0.54\n",
      "Loss 261.42682 201 13\n",
      "Training Accuracy 0.555\n",
      "Loss 252.8945 202 13\n",
      "Training Accuracy 0.575\n",
      "Loss 270.86047 203 13\n",
      "Training Accuracy 0.56\n",
      "Loss 263.50687 204 13\n",
      "Training Accuracy 0.52\n",
      "Loss 300.1079 205 13\n",
      "Training Accuracy 0.505\n",
      "Loss 282.33096 206 13\n",
      "Training Accuracy 0.595\n",
      "Loss 264.57974 207 13\n",
      "Training Accuracy 0.555\n",
      "Loss 281.72946 208 13\n",
      "Training Accuracy 0.585\n",
      "Loss 295.18927 209 13\n",
      "Training Accuracy 0.555\n",
      "Loss 252.52591 210 13\n",
      "Training Accuracy 0.565\n",
      "Loss 275.0079 211 13\n",
      "Training Accuracy 0.555\n",
      "Loss 245.76259 212 13\n",
      "Training Accuracy 0.595\n",
      "Loss 328.31662 213 13\n",
      "Training Accuracy 0.525\n",
      "Loss 264.73303 214 13\n",
      "Training Accuracy 0.585\n",
      "Loss 292.61465 215 13\n",
      "Training Accuracy 0.53\n",
      "Loss 300.30624 216 13\n",
      "Training Accuracy 0.52\n",
      "Loss 274.69696 217 13\n",
      "Training Accuracy 0.52\n",
      "Loss 274.41342 218 13\n",
      "Training Accuracy 0.54\n",
      "Loss 273.02203 219 13\n",
      "Training Accuracy 0.57\n",
      "Loss 259.2493 220 13\n",
      "Training Accuracy 0.58\n",
      "Loss 277.1257 221 13\n",
      "Training Accuracy 0.57\n",
      "Loss 272.4547 222 13\n",
      "Training Accuracy 0.53\n",
      "Loss 286.8344 223 13\n",
      "Training Accuracy 0.525\n",
      "Loss 293.46194 224 13\n",
      "Training Accuracy 0.54\n",
      "Loss 292.8965 225 13\n",
      "Training Accuracy 0.535\n",
      "Loss 231.96297 226 13\n",
      "Training Accuracy 0.605\n",
      "Loss 303.8202 227 13\n",
      "Training Accuracy 0.515\n",
      "Loss 311.59622 228 13\n",
      "Training Accuracy 0.49\n",
      "Loss 264.97318 229 13\n",
      "Training Accuracy 0.595\n",
      "Loss 279.23892 230 13\n",
      "Training Accuracy 0.56\n",
      "Loss 246.49495 231 13\n",
      "Training Accuracy 0.61\n",
      "Loss 276.38226 232 13\n",
      "Training Accuracy 0.51\n",
      "Loss 296.41492 233 13\n",
      "Training Accuracy 0.48\n",
      "Loss 284.8336 234 13\n",
      "Training Accuracy 0.5\n",
      "Loss 277.7562 235 13\n",
      "Training Accuracy 0.53\n",
      "Loss 239.3416 236 13\n",
      "Training Accuracy 0.605\n",
      "Loss 278.75446 237 13\n",
      "Training Accuracy 0.56\n",
      "Loss 269.52283 238 13\n",
      "Training Accuracy 0.54\n",
      "Loss 297.6592 239 13\n",
      "Training Accuracy 0.53\n",
      "Loss 274.7888 240 13\n",
      "Training Accuracy 0.555\n",
      "Loss 288.47867 241 13\n",
      "Training Accuracy 0.52\n",
      "Loss 248.31941 242 13\n",
      "Training Accuracy 0.595\n",
      "Loss 239.44601 243 13\n",
      "Training Accuracy 0.64\n",
      "Loss 276.06537 244 13\n",
      "Training Accuracy 0.48\n",
      "Loss 265.45636 245 13\n",
      "Training Accuracy 0.595\n",
      "Loss 285.71878 246 13\n",
      "Training Accuracy 0.545\n",
      "Loss 229.66718 247 13\n",
      "Training Accuracy 0.575\n",
      "Loss 255.9745 248 13\n",
      "Training Accuracy 0.56\n",
      "Loss 281.50784 249 13\n",
      "Training Accuracy 0.5\n",
      "Loss 283.17572 250 13\n",
      "Training Accuracy 0.57\n",
      "Loss 276.72162 251 13\n",
      "Training Accuracy 0.495\n",
      "Loss 248.83437 252 13\n",
      "Training Accuracy 0.555\n",
      "Loss 251.6116 253 13\n",
      "Training Accuracy 0.59\n",
      "Loss 258.88522 254 13\n",
      "Training Accuracy 0.585\n",
      "Loss 240.62909 255 13\n",
      "Training Accuracy 0.585\n",
      "Loss 280.8572 256 13\n",
      "Training Accuracy 0.56\n",
      "Loss 264.03308 257 13\n",
      "Training Accuracy 0.61\n",
      "Loss 269.83484 258 13\n",
      "Training Accuracy 0.53\n",
      "Loss 281.12857 259 13\n",
      "Training Accuracy 0.545\n",
      "Loss 231.91393 260 13\n",
      "Training Accuracy 0.61\n",
      "Loss 275.9051 261 13\n",
      "Training Accuracy 0.545\n",
      "Loss 274.71817 262 13\n",
      "Training Accuracy 0.51\n",
      "Loss 335.52542 263 13\n",
      "Training Accuracy 0.44\n",
      "Loss 287.4002 264 13\n",
      "Training Accuracy 0.59\n",
      "Loss 263.4159 265 13\n",
      "Training Accuracy 0.58\n",
      "Loss 260.2897 266 13\n",
      "Training Accuracy 0.56\n",
      "Loss 296.2519 267 13\n",
      "Training Accuracy 0.525\n",
      "Loss 284.0685 268 13\n",
      "Training Accuracy 0.54\n",
      "Loss 241.35953 269 13\n",
      "Training Accuracy 0.565\n",
      "Loss 239.67996 270 13\n",
      "Training Accuracy 0.6\n",
      "Loss 299.72635 271 13\n",
      "Training Accuracy 0.54\n",
      "Loss 275.74197 272 13\n",
      "Training Accuracy 0.575\n",
      "Loss 293.16516 273 13\n",
      "Training Accuracy 0.51\n",
      "Loss 243.79556 274 13\n",
      "Training Accuracy 0.585\n",
      "Loss 279.04367 275 13\n",
      "Training Accuracy 0.53\n",
      "Loss 256.37234 276 13\n",
      "Training Accuracy 0.555\n",
      "Loss 310.32278 277 13\n",
      "Training Accuracy 0.49\n",
      "Loss 248.64171 278 13\n",
      "Training Accuracy 0.6\n",
      "Loss 266.37054 279 13\n",
      "Training Accuracy 0.57\n",
      "Loss 258.31708 280 13\n",
      "Training Accuracy 0.55\n",
      "Loss 265.18704 281 13\n",
      "Training Accuracy 0.605\n",
      "Loss 270.32782 282 13\n",
      "Training Accuracy 0.545\n",
      "Loss 252.57803 283 13\n",
      "Training Accuracy 0.59\n",
      "Loss 240.18033 284 13\n",
      "Training Accuracy 0.645\n",
      "Loss 301.61206 285 13\n",
      "Training Accuracy 0.53\n",
      "Loss 271.05142 286 13\n",
      "Training Accuracy 0.56\n",
      "Loss 250.18646 287 13\n",
      "Training Accuracy 0.635\n",
      "Loss 269.48026 288 13\n",
      "Training Accuracy 0.61\n",
      "Loss 242.23328 289 13\n",
      "Training Accuracy 0.62\n",
      "Loss 275.00763 290 13\n",
      "Training Accuracy 0.56\n",
      "Loss 269.19638 291 13\n",
      "Training Accuracy 0.565\n",
      "Loss 170.46994 292 13\n",
      "Training Accuracy 0.56060606\n",
      "Loss 237.92827 1 14\n",
      "Training Accuracy 0.58\n",
      "Loss 272.32947 2 14\n",
      "Training Accuracy 0.53\n",
      "Loss 267.10974 3 14\n",
      "Training Accuracy 0.58\n",
      "Loss 268.14542 4 14\n",
      "Training Accuracy 0.595\n",
      "Loss 243.85307 5 14\n",
      "Training Accuracy 0.62\n",
      "Loss 270.042 6 14\n",
      "Training Accuracy 0.555\n",
      "Loss 274.57837 7 14\n",
      "Training Accuracy 0.565\n",
      "Loss 302.5305 8 14\n",
      "Training Accuracy 0.585\n",
      "Loss 247.86441 9 14\n",
      "Training Accuracy 0.605\n",
      "Loss 284.13608 10 14\n",
      "Training Accuracy 0.545\n",
      "Loss 298.28027 11 14\n",
      "Training Accuracy 0.58\n",
      "Loss 261.02362 12 14\n",
      "Training Accuracy 0.545\n",
      "Loss 257.61346 13 14\n",
      "Training Accuracy 0.565\n",
      "Loss 291.1616 14 14\n",
      "Training Accuracy 0.57\n",
      "Loss 249.41556 15 14\n",
      "Training Accuracy 0.6\n",
      "Loss 299.84656 16 14\n",
      "Training Accuracy 0.535\n",
      "Loss 238.90294 17 14\n",
      "Training Accuracy 0.615\n",
      "Loss 263.5217 18 14\n",
      "Training Accuracy 0.575\n",
      "Loss 246.97922 19 14\n",
      "Training Accuracy 0.535\n",
      "Loss 267.08157 20 14\n",
      "Training Accuracy 0.595\n",
      "Loss 261.22546 21 14\n",
      "Training Accuracy 0.575\n",
      "Loss 281.24677 22 14\n",
      "Training Accuracy 0.56\n",
      "Loss 279.03268 23 14\n",
      "Training Accuracy 0.57\n",
      "Loss 284.44327 24 14\n",
      "Training Accuracy 0.51\n",
      "Loss 259.3982 25 14\n",
      "Training Accuracy 0.535\n",
      "Loss 280.4301 26 14\n",
      "Training Accuracy 0.515\n",
      "Loss 252.19882 27 14\n",
      "Training Accuracy 0.61\n",
      "Loss 256.9374 28 14\n",
      "Training Accuracy 0.605\n",
      "Loss 271.3321 29 14\n",
      "Training Accuracy 0.52\n",
      "Loss 287.38425 30 14\n",
      "Training Accuracy 0.55\n",
      "Loss 301.26178 31 14\n",
      "Training Accuracy 0.51\n",
      "Loss 272.58856 32 14\n",
      "Training Accuracy 0.54\n",
      "Loss 283.63504 33 14\n",
      "Training Accuracy 0.555\n",
      "Loss 241.40355 34 14\n",
      "Training Accuracy 0.595\n",
      "Loss 236.20697 35 14\n",
      "Training Accuracy 0.59\n",
      "Loss 261.1269 36 14\n",
      "Training Accuracy 0.52\n",
      "Loss 263.27353 37 14\n",
      "Training Accuracy 0.59\n",
      "Loss 271.3734 38 14\n",
      "Training Accuracy 0.59\n",
      "Loss 230.36606 39 14\n",
      "Training Accuracy 0.625\n",
      "Loss 241.70938 40 14\n",
      "Training Accuracy 0.635\n",
      "Loss 262.10062 41 14\n",
      "Training Accuracy 0.545\n",
      "Loss 310.76807 42 14\n",
      "Training Accuracy 0.475\n",
      "Loss 250.97813 43 14\n",
      "Training Accuracy 0.625\n",
      "Loss 240.41803 44 14\n",
      "Training Accuracy 0.595\n",
      "Loss 282.96112 45 14\n",
      "Training Accuracy 0.515\n",
      "Loss 292.388 46 14\n",
      "Training Accuracy 0.525\n",
      "Loss 244.33696 47 14\n",
      "Training Accuracy 0.645\n",
      "Loss 247.26375 48 14\n",
      "Training Accuracy 0.575\n",
      "Loss 266.17102 49 14\n",
      "Training Accuracy 0.54\n",
      "Loss 294.24893 50 14\n",
      "Training Accuracy 0.52\n",
      "Loss 249.91597 51 14\n",
      "Training Accuracy 0.63\n",
      "Loss 256.88055 52 14\n",
      "Training Accuracy 0.55\n",
      "Loss 251.49356 53 14\n",
      "Training Accuracy 0.57\n",
      "Loss 285.65533 54 14\n",
      "Training Accuracy 0.545\n",
      "Loss 283.8719 55 14\n",
      "Training Accuracy 0.505\n",
      "Loss 272.227 56 14\n",
      "Training Accuracy 0.51\n",
      "Loss 246.02469 57 14\n",
      "Training Accuracy 0.62\n",
      "Loss 251.05553 58 14\n",
      "Training Accuracy 0.55\n",
      "Loss 277.4432 59 14\n",
      "Training Accuracy 0.54\n",
      "Loss 277.17056 60 14\n",
      "Training Accuracy 0.53\n",
      "Loss 269.03476 61 14\n",
      "Training Accuracy 0.505\n",
      "Loss 258.12216 62 14\n",
      "Training Accuracy 0.58\n",
      "Loss 271.73422 63 14\n",
      "Training Accuracy 0.59\n",
      "Loss 277.43863 64 14\n",
      "Training Accuracy 0.545\n",
      "Loss 288.92892 65 14\n",
      "Training Accuracy 0.515\n",
      "Loss 259.99316 66 14\n",
      "Training Accuracy 0.535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 290.96637 67 14\n",
      "Training Accuracy 0.545\n",
      "Loss 256.36896 68 14\n",
      "Training Accuracy 0.53\n",
      "Loss 267.8656 69 14\n",
      "Training Accuracy 0.555\n",
      "Loss 268.94025 70 14\n",
      "Training Accuracy 0.56\n",
      "Loss 257.58176 71 14\n",
      "Training Accuracy 0.61\n",
      "Loss 272.8304 72 14\n",
      "Training Accuracy 0.555\n",
      "Loss 269.7579 73 14\n",
      "Training Accuracy 0.55\n",
      "Loss 296.78064 74 14\n",
      "Training Accuracy 0.515\n",
      "Loss 282.83093 75 14\n",
      "Training Accuracy 0.555\n",
      "Loss 247.88907 76 14\n",
      "Training Accuracy 0.61\n",
      "Loss 265.1834 77 14\n",
      "Training Accuracy 0.59\n",
      "Loss 263.3157 78 14\n",
      "Training Accuracy 0.595\n",
      "Loss 258.63165 79 14\n",
      "Training Accuracy 0.525\n",
      "Loss 278.566 80 14\n",
      "Training Accuracy 0.52\n",
      "Loss 260.76645 81 14\n",
      "Training Accuracy 0.53\n",
      "Loss 257.73343 82 14\n",
      "Training Accuracy 0.575\n",
      "Loss 252.47333 83 14\n",
      "Training Accuracy 0.61\n",
      "Loss 301.91132 84 14\n",
      "Training Accuracy 0.56\n",
      "Loss 265.37863 85 14\n",
      "Training Accuracy 0.575\n",
      "Loss 279.79358 86 14\n",
      "Training Accuracy 0.555\n",
      "Loss 308.54703 87 14\n",
      "Training Accuracy 0.54\n",
      "Loss 288.5313 88 14\n",
      "Training Accuracy 0.495\n",
      "Loss 259.2525 89 14\n",
      "Training Accuracy 0.605\n",
      "Loss 270.60382 90 14\n",
      "Training Accuracy 0.495\n",
      "Loss 286.27835 91 14\n",
      "Training Accuracy 0.565\n",
      "Loss 271.2056 92 14\n",
      "Training Accuracy 0.61\n",
      "Loss 271.5852 93 14\n",
      "Training Accuracy 0.54\n",
      "Loss 265.39813 94 14\n",
      "Training Accuracy 0.525\n",
      "Loss 246.57928 95 14\n",
      "Training Accuracy 0.575\n",
      "Loss 264.96606 96 14\n",
      "Training Accuracy 0.585\n",
      "Loss 279.1058 97 14\n",
      "Training Accuracy 0.51\n",
      "Loss 253.62729 98 14\n",
      "Training Accuracy 0.56\n",
      "Loss 254.98329 99 14\n",
      "Training Accuracy 0.56\n",
      "Loss 283.65234 100 14\n",
      "Training Accuracy 0.575\n",
      "Loss 289.04086 101 14\n",
      "Training Accuracy 0.51\n",
      "Loss 240.48445 102 14\n",
      "Training Accuracy 0.57\n",
      "Loss 270.4368 103 14\n",
      "Training Accuracy 0.535\n",
      "Loss 264.5387 104 14\n",
      "Training Accuracy 0.58\n",
      "Loss 277.22183 105 14\n",
      "Training Accuracy 0.55\n",
      "Loss 271.93723 106 14\n",
      "Training Accuracy 0.595\n",
      "Loss 263.68646 107 14\n",
      "Training Accuracy 0.59\n",
      "Loss 265.7699 108 14\n",
      "Training Accuracy 0.58\n",
      "Loss 259.04333 109 14\n",
      "Training Accuracy 0.57\n",
      "Loss 275.94635 110 14\n",
      "Training Accuracy 0.575\n",
      "Loss 263.29327 111 14\n",
      "Training Accuracy 0.555\n",
      "Loss 299.576 112 14\n",
      "Training Accuracy 0.545\n",
      "Loss 309.35345 113 14\n",
      "Training Accuracy 0.56\n",
      "Loss 260.82288 114 14\n",
      "Training Accuracy 0.555\n",
      "Loss 302.91132 115 14\n",
      "Training Accuracy 0.545\n",
      "Loss 301.66922 116 14\n",
      "Training Accuracy 0.535\n",
      "Loss 234.7966 117 14\n",
      "Training Accuracy 0.685\n",
      "Loss 284.74033 118 14\n",
      "Training Accuracy 0.55\n",
      "Loss 322.8665 119 14\n",
      "Training Accuracy 0.485\n",
      "Loss 295.50885 120 14\n",
      "Training Accuracy 0.54\n",
      "Loss 291.08963 121 14\n",
      "Training Accuracy 0.555\n",
      "Loss 241.99199 122 14\n",
      "Training Accuracy 0.565\n",
      "Loss 262.2341 123 14\n",
      "Training Accuracy 0.57\n",
      "Loss 265.04095 124 14\n",
      "Training Accuracy 0.57\n",
      "Loss 236.66148 125 14\n",
      "Training Accuracy 0.59\n",
      "Loss 292.471 126 14\n",
      "Training Accuracy 0.505\n",
      "Loss 271.8451 127 14\n",
      "Training Accuracy 0.535\n",
      "Loss 261.53284 128 14\n",
      "Training Accuracy 0.57\n",
      "Loss 246.57231 129 14\n",
      "Training Accuracy 0.64\n",
      "Loss 264.5739 130 14\n",
      "Training Accuracy 0.55\n",
      "Loss 250.6087 131 14\n",
      "Training Accuracy 0.62\n",
      "Loss 260.2152 132 14\n",
      "Training Accuracy 0.59\n",
      "Loss 273.1414 133 14\n",
      "Training Accuracy 0.56\n",
      "Loss 254.02348 134 14\n",
      "Training Accuracy 0.585\n",
      "Loss 253.2395 135 14\n",
      "Training Accuracy 0.595\n",
      "Loss 282.63962 136 14\n",
      "Training Accuracy 0.57\n",
      "Loss 287.09406 137 14\n",
      "Training Accuracy 0.54\n",
      "Loss 250.98497 138 14\n",
      "Training Accuracy 0.605\n",
      "Loss 295.00723 139 14\n",
      "Training Accuracy 0.57\n",
      "Loss 227.92131 140 14\n",
      "Training Accuracy 0.63\n",
      "Loss 267.6723 141 14\n",
      "Training Accuracy 0.59\n",
      "Loss 274.92242 142 14\n",
      "Training Accuracy 0.525\n",
      "Loss 233.66139 143 14\n",
      "Training Accuracy 0.625\n",
      "Loss 277.19208 144 14\n",
      "Training Accuracy 0.51\n",
      "Loss 252.64418 145 14\n",
      "Training Accuracy 0.605\n",
      "Loss 273.78018 146 14\n",
      "Training Accuracy 0.53\n",
      "Loss 262.4306 147 14\n",
      "Training Accuracy 0.585\n",
      "Loss 275.51907 148 14\n",
      "Training Accuracy 0.52\n",
      "Loss 256.80634 149 14\n",
      "Training Accuracy 0.61\n",
      "Loss 259.1047 150 14\n",
      "Training Accuracy 0.605\n",
      "Loss 276.77017 151 14\n",
      "Training Accuracy 0.575\n",
      "Loss 282.9357 152 14\n",
      "Training Accuracy 0.55\n",
      "Loss 265.942 153 14\n",
      "Training Accuracy 0.57\n",
      "Loss 251.59328 154 14\n",
      "Training Accuracy 0.61\n",
      "Loss 250.48434 155 14\n",
      "Training Accuracy 0.62\n",
      "Loss 271.77863 156 14\n",
      "Training Accuracy 0.535\n",
      "Loss 233.71454 157 14\n",
      "Training Accuracy 0.63\n",
      "Loss 261.67096 158 14\n",
      "Training Accuracy 0.59\n",
      "Loss 291.6051 159 14\n",
      "Training Accuracy 0.575\n",
      "Loss 273.59772 160 14\n",
      "Training Accuracy 0.54\n",
      "Loss 287.0555 161 14\n",
      "Training Accuracy 0.55\n",
      "Loss 267.3192 162 14\n",
      "Training Accuracy 0.555\n",
      "Loss 291.76813 163 14\n",
      "Training Accuracy 0.57\n",
      "Loss 243.36884 164 14\n",
      "Training Accuracy 0.575\n",
      "Loss 255.71373 165 14\n",
      "Training Accuracy 0.6\n",
      "Loss 271.84012 166 14\n",
      "Training Accuracy 0.55\n",
      "Loss 228.96846 167 14\n",
      "Training Accuracy 0.6\n",
      "Loss 283.05603 168 14\n",
      "Training Accuracy 0.55\n",
      "Loss 246.94153 169 14\n",
      "Training Accuracy 0.6\n",
      "Loss 258.00037 170 14\n",
      "Training Accuracy 0.615\n",
      "Loss 292.08737 171 14\n",
      "Training Accuracy 0.57\n",
      "Loss 247.22572 172 14\n",
      "Training Accuracy 0.61\n",
      "Loss 300.0964 173 14\n",
      "Training Accuracy 0.565\n",
      "Loss 236.29883 174 14\n",
      "Training Accuracy 0.59\n",
      "Loss 240.07928 175 14\n",
      "Training Accuracy 0.67\n",
      "Loss 223.1635 176 14\n",
      "Training Accuracy 0.665\n",
      "Loss 302.25848 177 14\n",
      "Training Accuracy 0.48\n",
      "Loss 239.8307 178 14\n",
      "Training Accuracy 0.59\n",
      "Loss 282.20508 179 14\n",
      "Training Accuracy 0.535\n",
      "Loss 267.20642 180 14\n",
      "Training Accuracy 0.57\n",
      "Loss 239.7079 181 14\n",
      "Training Accuracy 0.585\n",
      "Loss 279.76126 182 14\n",
      "Training Accuracy 0.5\n",
      "Loss 281.727 183 14\n",
      "Training Accuracy 0.53\n",
      "Loss 242.92584 184 14\n",
      "Training Accuracy 0.62\n",
      "Loss 253.77138 185 14\n",
      "Training Accuracy 0.595\n",
      "Loss 252.52211 186 14\n",
      "Training Accuracy 0.585\n",
      "Loss 298.28522 187 14\n",
      "Training Accuracy 0.525\n",
      "Loss 285.65576 188 14\n",
      "Training Accuracy 0.545\n",
      "Loss 258.54724 189 14\n",
      "Training Accuracy 0.56\n",
      "Loss 251.84131 190 14\n",
      "Training Accuracy 0.585\n",
      "Loss 256.86926 191 14\n",
      "Training Accuracy 0.59\n",
      "Loss 271.02838 192 14\n",
      "Training Accuracy 0.59\n",
      "Loss 247.15286 193 14\n",
      "Training Accuracy 0.62\n",
      "Loss 252.13092 194 14\n",
      "Training Accuracy 0.595\n",
      "Loss 254.77196 195 14\n",
      "Training Accuracy 0.575\n",
      "Loss 254.975 196 14\n",
      "Training Accuracy 0.58\n",
      "Loss 277.56357 197 14\n",
      "Training Accuracy 0.54\n",
      "Loss 249.6703 198 14\n",
      "Training Accuracy 0.55\n",
      "Loss 213.09953 199 14\n",
      "Training Accuracy 0.655\n",
      "Loss 267.7638 200 14\n",
      "Training Accuracy 0.575\n",
      "Loss 254.24371 201 14\n",
      "Training Accuracy 0.56\n",
      "Loss 250.20055 202 14\n",
      "Training Accuracy 0.595\n",
      "Loss 263.27322 203 14\n",
      "Training Accuracy 0.53\n",
      "Loss 267.38535 204 14\n",
      "Training Accuracy 0.52\n",
      "Loss 296.46344 205 14\n",
      "Training Accuracy 0.515\n",
      "Loss 269.39746 206 14\n",
      "Training Accuracy 0.565\n",
      "Loss 256.63583 207 14\n",
      "Training Accuracy 0.6\n",
      "Loss 283.3835 208 14\n",
      "Training Accuracy 0.585\n",
      "Loss 284.93762 209 14\n",
      "Training Accuracy 0.56\n",
      "Loss 245.01443 210 14\n",
      "Training Accuracy 0.59\n",
      "Loss 262.67834 211 14\n",
      "Training Accuracy 0.61\n",
      "Loss 238.23962 212 14\n",
      "Training Accuracy 0.6\n",
      "Loss 307.14954 213 14\n",
      "Training Accuracy 0.495\n",
      "Loss 267.82837 214 14\n",
      "Training Accuracy 0.585\n",
      "Loss 284.17374 215 14\n",
      "Training Accuracy 0.49\n",
      "Loss 289.99924 216 14\n",
      "Training Accuracy 0.525\n",
      "Loss 268.93976 217 14\n",
      "Training Accuracy 0.54\n",
      "Loss 268.49384 218 14\n",
      "Training Accuracy 0.545\n",
      "Loss 276.19812 219 14\n",
      "Training Accuracy 0.57\n",
      "Loss 251.95418 220 14\n",
      "Training Accuracy 0.6\n",
      "Loss 270.06375 221 14\n",
      "Training Accuracy 0.58\n",
      "Loss 268.94342 222 14\n",
      "Training Accuracy 0.54\n",
      "Loss 287.3032 223 14\n",
      "Training Accuracy 0.52\n",
      "Loss 278.90335 224 14\n",
      "Training Accuracy 0.54\n",
      "Loss 291.16647 225 14\n",
      "Training Accuracy 0.53\n",
      "Loss 236.03618 226 14\n",
      "Training Accuracy 0.59\n",
      "Loss 304.86365 227 14\n",
      "Training Accuracy 0.485\n",
      "Loss 295.75787 228 14\n",
      "Training Accuracy 0.53\n",
      "Loss 253.43166 229 14\n",
      "Training Accuracy 0.595\n",
      "Loss 270.30487 230 14\n",
      "Training Accuracy 0.57\n",
      "Loss 241.07379 231 14\n",
      "Training Accuracy 0.625\n",
      "Loss 264.39124 232 14\n",
      "Training Accuracy 0.56\n",
      "Loss 282.48764 233 14\n",
      "Training Accuracy 0.525\n",
      "Loss 272.41785 234 14\n",
      "Training Accuracy 0.555\n",
      "Loss 268.39838 235 14\n",
      "Training Accuracy 0.59\n",
      "Loss 229.82123 236 14\n",
      "Training Accuracy 0.625\n",
      "Loss 276.80295 237 14\n",
      "Training Accuracy 0.55\n",
      "Loss 261.1059 238 14\n",
      "Training Accuracy 0.53\n",
      "Loss 281.0076 239 14\n",
      "Training Accuracy 0.57\n",
      "Loss 268.81693 240 14\n",
      "Training Accuracy 0.555\n",
      "Loss 289.71988 241 14\n",
      "Training Accuracy 0.56\n",
      "Loss 238.51015 242 14\n",
      "Training Accuracy 0.625\n",
      "Loss 240.22183 243 14\n",
      "Training Accuracy 0.62\n",
      "Loss 271.52966 244 14\n",
      "Training Accuracy 0.505\n",
      "Loss 255.0395 245 14\n",
      "Training Accuracy 0.61\n",
      "Loss 275.8625 246 14\n",
      "Training Accuracy 0.55\n",
      "Loss 220.49963 247 14\n",
      "Training Accuracy 0.605\n",
      "Loss 252.84601 248 14\n",
      "Training Accuracy 0.575\n",
      "Loss 272.5115 249 14\n",
      "Training Accuracy 0.52\n",
      "Loss 276.50293 250 14\n",
      "Training Accuracy 0.545\n",
      "Loss 279.12314 251 14\n",
      "Training Accuracy 0.525\n",
      "Loss 244.42526 252 14\n",
      "Training Accuracy 0.56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 245.50923 253 14\n",
      "Training Accuracy 0.61\n",
      "Loss 261.42563 254 14\n",
      "Training Accuracy 0.6\n",
      "Loss 233.52249 255 14\n",
      "Training Accuracy 0.61\n",
      "Loss 280.08377 256 14\n",
      "Training Accuracy 0.57\n",
      "Loss 264.47665 257 14\n",
      "Training Accuracy 0.545\n",
      "Loss 262.08017 258 14\n",
      "Training Accuracy 0.57\n",
      "Loss 267.63147 259 14\n",
      "Training Accuracy 0.55\n",
      "Loss 235.73163 260 14\n",
      "Training Accuracy 0.625\n",
      "Loss 274.65332 261 14\n",
      "Training Accuracy 0.565\n",
      "Loss 264.3738 262 14\n",
      "Training Accuracy 0.52\n",
      "Loss 325.4773 263 14\n",
      "Training Accuracy 0.475\n",
      "Loss 278.4127 264 14\n",
      "Training Accuracy 0.63\n",
      "Loss 254.80496 265 14\n",
      "Training Accuracy 0.615\n",
      "Loss 263.10263 266 14\n",
      "Training Accuracy 0.525\n",
      "Loss 270.19745 267 14\n",
      "Training Accuracy 0.53\n",
      "Loss 289.06076 268 14\n",
      "Training Accuracy 0.55\n",
      "Loss 245.44193 269 14\n",
      "Training Accuracy 0.575\n",
      "Loss 232.65201 270 14\n",
      "Training Accuracy 0.605\n",
      "Loss 288.66843 271 14\n",
      "Training Accuracy 0.535\n",
      "Loss 264.37347 272 14\n",
      "Training Accuracy 0.57\n",
      "Loss 280.225 273 14\n",
      "Training Accuracy 0.555\n",
      "Loss 242.61601 274 14\n",
      "Training Accuracy 0.605\n",
      "Loss 267.69995 275 14\n",
      "Training Accuracy 0.51\n",
      "Loss 243.67804 276 14\n",
      "Training Accuracy 0.585\n",
      "Loss 296.86688 277 14\n",
      "Training Accuracy 0.53\n",
      "Loss 235.88673 278 14\n",
      "Training Accuracy 0.595\n",
      "Loss 257.80402 279 14\n",
      "Training Accuracy 0.6\n",
      "Loss 254.63147 280 14\n",
      "Training Accuracy 0.555\n",
      "Loss 273.57373 281 14\n",
      "Training Accuracy 0.585\n",
      "Loss 255.79036 282 14\n",
      "Training Accuracy 0.6\n",
      "Loss 245.55925 283 14\n",
      "Training Accuracy 0.605\n",
      "Loss 232.91699 284 14\n",
      "Training Accuracy 0.64\n",
      "Loss 308.6553 285 14\n",
      "Training Accuracy 0.485\n",
      "Loss 269.22214 286 14\n",
      "Training Accuracy 0.56\n",
      "Loss 256.87332 287 14\n",
      "Training Accuracy 0.635\n",
      "Loss 270.52728 288 14\n",
      "Training Accuracy 0.585\n",
      "Loss 244.1671 289 14\n",
      "Training Accuracy 0.605\n",
      "Loss 270.37415 290 14\n",
      "Training Accuracy 0.57\n",
      "Loss 272.4585 291 14\n",
      "Training Accuracy 0.565\n",
      "Loss 161.32217 292 14\n",
      "Training Accuracy 0.6287879\n",
      "Loss 224.53328 1 15\n",
      "Training Accuracy 0.615\n",
      "Loss 257.48608 2 15\n",
      "Training Accuracy 0.565\n",
      "Loss 257.58527 3 15\n",
      "Training Accuracy 0.6\n",
      "Loss 271.75168 4 15\n",
      "Training Accuracy 0.575\n",
      "Loss 231.31586 5 15\n",
      "Training Accuracy 0.59\n",
      "Loss 272.3928 6 15\n",
      "Training Accuracy 0.545\n",
      "Loss 265.62088 7 15\n",
      "Training Accuracy 0.57\n",
      "Loss 291.54105 8 15\n",
      "Training Accuracy 0.555\n",
      "Loss 250.19171 9 15\n",
      "Training Accuracy 0.595\n",
      "Loss 275.51132 10 15\n",
      "Training Accuracy 0.56\n",
      "Loss 286.13196 11 15\n",
      "Training Accuracy 0.615\n",
      "Loss 246.61931 12 15\n",
      "Training Accuracy 0.585\n",
      "Loss 253.8486 13 15\n",
      "Training Accuracy 0.575\n",
      "Loss 275.36728 14 15\n",
      "Training Accuracy 0.585\n",
      "Loss 242.07309 15 15\n",
      "Training Accuracy 0.58\n",
      "Loss 297.84933 16 15\n",
      "Training Accuracy 0.54\n",
      "Loss 242.87506 17 15\n",
      "Training Accuracy 0.59\n",
      "Loss 257.7687 18 15\n",
      "Training Accuracy 0.6\n",
      "Loss 244.07854 19 15\n",
      "Training Accuracy 0.57\n",
      "Loss 254.719 20 15\n",
      "Training Accuracy 0.545\n",
      "Loss 252.63757 21 15\n",
      "Training Accuracy 0.595\n",
      "Loss 270.1711 22 15\n",
      "Training Accuracy 0.585\n",
      "Loss 266.20374 23 15\n",
      "Training Accuracy 0.57\n",
      "Loss 288.08347 24 15\n",
      "Training Accuracy 0.52\n",
      "Loss 257.6546 25 15\n",
      "Training Accuracy 0.56\n",
      "Loss 274.10895 26 15\n",
      "Training Accuracy 0.54\n",
      "Loss 254.2043 27 15\n",
      "Training Accuracy 0.555\n",
      "Loss 259.18842 28 15\n",
      "Training Accuracy 0.59\n",
      "Loss 265.13727 29 15\n",
      "Training Accuracy 0.585\n",
      "Loss 283.47382 30 15\n",
      "Training Accuracy 0.535\n",
      "Loss 275.49564 31 15\n",
      "Training Accuracy 0.57\n",
      "Loss 266.572 32 15\n",
      "Training Accuracy 0.52\n",
      "Loss 267.54697 33 15\n",
      "Training Accuracy 0.575\n",
      "Loss 233.93243 34 15\n",
      "Training Accuracy 0.66\n",
      "Loss 244.92488 35 15\n",
      "Training Accuracy 0.545\n",
      "Loss 263.95605 36 15\n",
      "Training Accuracy 0.52\n",
      "Loss 256.87238 37 15\n",
      "Training Accuracy 0.61\n",
      "Loss 271.31125 38 15\n",
      "Training Accuracy 0.56\n",
      "Loss 236.2958 39 15\n",
      "Training Accuracy 0.615\n",
      "Loss 248.77345 40 15\n",
      "Training Accuracy 0.56\n",
      "Loss 262.79987 41 15\n",
      "Training Accuracy 0.525\n",
      "Loss 294.43973 42 15\n",
      "Training Accuracy 0.48\n",
      "Loss 253.46782 43 15\n",
      "Training Accuracy 0.565\n",
      "Loss 242.98283 44 15\n",
      "Training Accuracy 0.585\n",
      "Loss 267.5985 45 15\n",
      "Training Accuracy 0.55\n",
      "Loss 281.99313 46 15\n",
      "Training Accuracy 0.525\n",
      "Loss 248.6955 47 15\n",
      "Training Accuracy 0.605\n",
      "Loss 228.76286 48 15\n",
      "Training Accuracy 0.59\n",
      "Loss 255.55783 49 15\n",
      "Training Accuracy 0.585\n",
      "Loss 282.49246 50 15\n",
      "Training Accuracy 0.57\n",
      "Loss 235.00821 51 15\n",
      "Training Accuracy 0.6\n",
      "Loss 253.17354 52 15\n",
      "Training Accuracy 0.57\n",
      "Loss 237.09991 53 15\n",
      "Training Accuracy 0.615\n",
      "Loss 277.22565 54 15\n",
      "Training Accuracy 0.535\n",
      "Loss 275.34515 55 15\n",
      "Training Accuracy 0.515\n",
      "Loss 257.98233 56 15\n",
      "Training Accuracy 0.55\n",
      "Loss 249.28368 57 15\n",
      "Training Accuracy 0.585\n",
      "Loss 230.28726 58 15\n",
      "Training Accuracy 0.62\n",
      "Loss 272.29895 59 15\n",
      "Training Accuracy 0.535\n",
      "Loss 257.0364 60 15\n",
      "Training Accuracy 0.645\n",
      "Loss 257.69257 61 15\n",
      "Training Accuracy 0.555\n",
      "Loss 250.06459 62 15\n",
      "Training Accuracy 0.62\n",
      "Loss 265.08356 63 15\n",
      "Training Accuracy 0.57\n",
      "Loss 255.36078 64 15\n",
      "Training Accuracy 0.605\n",
      "Loss 279.48065 65 15\n",
      "Training Accuracy 0.525\n",
      "Loss 250.67348 66 15\n",
      "Training Accuracy 0.56\n",
      "Loss 272.45734 67 15\n",
      "Training Accuracy 0.54\n",
      "Loss 251.98883 68 15\n",
      "Training Accuracy 0.56\n",
      "Loss 263.8076 69 15\n",
      "Training Accuracy 0.57\n",
      "Loss 269.54355 70 15\n",
      "Training Accuracy 0.575\n",
      "Loss 266.75336 71 15\n",
      "Training Accuracy 0.585\n",
      "Loss 258.68796 72 15\n",
      "Training Accuracy 0.605\n",
      "Loss 259.5056 73 15\n",
      "Training Accuracy 0.58\n",
      "Loss 288.2939 74 15\n",
      "Training Accuracy 0.58\n",
      "Loss 267.19336 75 15\n",
      "Training Accuracy 0.575\n",
      "Loss 235.82588 76 15\n",
      "Training Accuracy 0.635\n",
      "Loss 265.69443 77 15\n",
      "Training Accuracy 0.585\n",
      "Loss 246.8094 78 15\n",
      "Training Accuracy 0.6\n",
      "Loss 254.44312 79 15\n",
      "Training Accuracy 0.55\n",
      "Loss 260.43814 80 15\n",
      "Training Accuracy 0.59\n",
      "Loss 246.03534 81 15\n",
      "Training Accuracy 0.545\n",
      "Loss 251.7987 82 15\n",
      "Training Accuracy 0.6\n",
      "Loss 254.37944 83 15\n",
      "Training Accuracy 0.565\n",
      "Loss 297.15735 84 15\n",
      "Training Accuracy 0.535\n",
      "Loss 263.48917 85 15\n",
      "Training Accuracy 0.56\n",
      "Loss 258.92923 86 15\n",
      "Training Accuracy 0.585\n",
      "Loss 309.25107 87 15\n",
      "Training Accuracy 0.525\n",
      "Loss 278.458 88 15\n",
      "Training Accuracy 0.57\n",
      "Loss 250.55855 89 15\n",
      "Training Accuracy 0.63\n",
      "Loss 261.67993 90 15\n",
      "Training Accuracy 0.535\n",
      "Loss 265.6635 91 15\n",
      "Training Accuracy 0.58\n",
      "Loss 261.9148 92 15\n",
      "Training Accuracy 0.59\n",
      "Loss 260.7199 93 15\n",
      "Training Accuracy 0.595\n",
      "Loss 271.0009 94 15\n",
      "Training Accuracy 0.515\n",
      "Loss 240.72398 95 15\n",
      "Training Accuracy 0.6\n",
      "Loss 258.1833 96 15\n",
      "Training Accuracy 0.605\n",
      "Loss 265.9055 97 15\n",
      "Training Accuracy 0.53\n",
      "Loss 251.85545 98 15\n",
      "Training Accuracy 0.55\n",
      "Loss 253.0023 99 15\n",
      "Training Accuracy 0.59\n",
      "Loss 267.12802 100 15\n",
      "Training Accuracy 0.58\n",
      "Loss 274.66437 101 15\n",
      "Training Accuracy 0.57\n",
      "Loss 239.1716 102 15\n",
      "Training Accuracy 0.61\n",
      "Loss 268.7496 103 15\n",
      "Training Accuracy 0.515\n",
      "Loss 255.07863 104 15\n",
      "Training Accuracy 0.565\n",
      "Loss 261.17096 105 15\n",
      "Training Accuracy 0.56\n",
      "Loss 262.3943 106 15\n",
      "Training Accuracy 0.555\n",
      "Loss 268.27896 107 15\n",
      "Training Accuracy 0.565\n",
      "Loss 271.86783 108 15\n",
      "Training Accuracy 0.565\n",
      "Loss 252.88663 109 15\n",
      "Training Accuracy 0.575\n",
      "Loss 270.13074 110 15\n",
      "Training Accuracy 0.595\n",
      "Loss 263.06754 111 15\n",
      "Training Accuracy 0.575\n",
      "Loss 289.99664 112 15\n",
      "Training Accuracy 0.58\n",
      "Loss 303.63257 113 15\n",
      "Training Accuracy 0.535\n",
      "Loss 255.40071 114 15\n",
      "Training Accuracy 0.55\n",
      "Loss 284.10147 115 15\n",
      "Training Accuracy 0.555\n",
      "Loss 288.85803 116 15\n",
      "Training Accuracy 0.565\n",
      "Loss 231.13055 117 15\n",
      "Training Accuracy 0.675\n",
      "Loss 278.11563 118 15\n",
      "Training Accuracy 0.555\n",
      "Loss 312.62527 119 15\n",
      "Training Accuracy 0.47\n",
      "Loss 284.11575 120 15\n",
      "Training Accuracy 0.545\n",
      "Loss 272.9033 121 15\n",
      "Training Accuracy 0.565\n",
      "Loss 239.95528 122 15\n",
      "Training Accuracy 0.595\n",
      "Loss 264.63394 123 15\n",
      "Training Accuracy 0.555\n",
      "Loss 261.9153 124 15\n",
      "Training Accuracy 0.56\n",
      "Loss 231.209 125 15\n",
      "Training Accuracy 0.59\n",
      "Loss 282.1499 126 15\n",
      "Training Accuracy 0.525\n",
      "Loss 262.9258 127 15\n",
      "Training Accuracy 0.56\n",
      "Loss 251.9004 128 15\n",
      "Training Accuracy 0.565\n",
      "Loss 241.22192 129 15\n",
      "Training Accuracy 0.64\n",
      "Loss 257.79123 130 15\n",
      "Training Accuracy 0.55\n",
      "Loss 244.23419 131 15\n",
      "Training Accuracy 0.615\n",
      "Loss 248.15253 132 15\n",
      "Training Accuracy 0.59\n",
      "Loss 263.46292 133 15\n",
      "Training Accuracy 0.56\n",
      "Loss 242.20554 134 15\n",
      "Training Accuracy 0.6\n",
      "Loss 241.47597 135 15\n",
      "Training Accuracy 0.605\n",
      "Loss 280.24136 136 15\n",
      "Training Accuracy 0.58\n",
      "Loss 280.01328 137 15\n",
      "Training Accuracy 0.56\n",
      "Loss 239.45866 138 15\n",
      "Training Accuracy 0.625\n",
      "Loss 287.23737 139 15\n",
      "Training Accuracy 0.555\n",
      "Loss 225.38477 140 15\n",
      "Training Accuracy 0.605\n",
      "Loss 267.7385 141 15\n",
      "Training Accuracy 0.58\n",
      "Loss 271.4275 142 15\n",
      "Training Accuracy 0.545\n",
      "Loss 230.32814 143 15\n",
      "Training Accuracy 0.605\n",
      "Loss 276.1697 144 15\n",
      "Training Accuracy 0.54\n",
      "Loss 254.31879 145 15\n",
      "Training Accuracy 0.62\n",
      "Loss 269.16315 146 15\n",
      "Training Accuracy 0.575\n",
      "Loss 258.2168 147 15\n",
      "Training Accuracy 0.555\n",
      "Loss 264.94537 148 15\n",
      "Training Accuracy 0.545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 254.78096 149 15\n",
      "Training Accuracy 0.585\n",
      "Loss 247.25424 150 15\n",
      "Training Accuracy 0.58\n",
      "Loss 269.04114 151 15\n",
      "Training Accuracy 0.575\n",
      "Loss 277.6286 152 15\n",
      "Training Accuracy 0.565\n",
      "Loss 254.73074 153 15\n",
      "Training Accuracy 0.58\n",
      "Loss 241.18272 154 15\n",
      "Training Accuracy 0.6\n",
      "Loss 241.46014 155 15\n",
      "Training Accuracy 0.595\n",
      "Loss 264.85092 156 15\n",
      "Training Accuracy 0.55\n",
      "Loss 225.75693 157 15\n",
      "Training Accuracy 0.565\n",
      "Loss 254.32466 158 15\n",
      "Training Accuracy 0.57\n",
      "Loss 286.68613 159 15\n",
      "Training Accuracy 0.56\n",
      "Loss 265.28326 160 15\n",
      "Training Accuracy 0.59\n",
      "Loss 299.86584 161 15\n",
      "Training Accuracy 0.495\n",
      "Loss 264.65567 162 15\n",
      "Training Accuracy 0.55\n",
      "Loss 282.42395 163 15\n",
      "Training Accuracy 0.575\n",
      "Loss 228.01591 164 15\n",
      "Training Accuracy 0.59\n",
      "Loss 251.32841 165 15\n",
      "Training Accuracy 0.59\n",
      "Loss 258.90677 166 15\n",
      "Training Accuracy 0.57\n",
      "Loss 225.0619 167 15\n",
      "Training Accuracy 0.61\n",
      "Loss 273.5865 168 15\n",
      "Training Accuracy 0.555\n",
      "Loss 253.92519 169 15\n",
      "Training Accuracy 0.545\n",
      "Loss 257.26163 170 15\n",
      "Training Accuracy 0.585\n",
      "Loss 276.15732 171 15\n",
      "Training Accuracy 0.57\n",
      "Loss 244.59436 172 15\n",
      "Training Accuracy 0.595\n",
      "Loss 297.99976 173 15\n",
      "Training Accuracy 0.54\n",
      "Loss 232.3974 174 15\n",
      "Training Accuracy 0.605\n",
      "Loss 236.45956 175 15\n",
      "Training Accuracy 0.63\n",
      "Loss 215.30408 176 15\n",
      "Training Accuracy 0.66\n",
      "Loss 289.6694 177 15\n",
      "Training Accuracy 0.52\n",
      "Loss 243.61615 178 15\n",
      "Training Accuracy 0.59\n",
      "Loss 277.88586 179 15\n",
      "Training Accuracy 0.57\n",
      "Loss 261.7235 180 15\n",
      "Training Accuracy 0.535\n",
      "Loss 230.40308 181 15\n",
      "Training Accuracy 0.64\n",
      "Loss 285.2123 182 15\n",
      "Training Accuracy 0.52\n",
      "Loss 279.49777 183 15\n",
      "Training Accuracy 0.52\n",
      "Loss 228.43373 184 15\n",
      "Training Accuracy 0.675\n",
      "Loss 245.17813 185 15\n",
      "Training Accuracy 0.6\n",
      "Loss 242.5531 186 15\n",
      "Training Accuracy 0.61\n",
      "Loss 289.98138 187 15\n",
      "Training Accuracy 0.52\n",
      "Loss 278.47574 188 15\n",
      "Training Accuracy 0.55\n",
      "Loss 256.48856 189 15\n",
      "Training Accuracy 0.555\n",
      "Loss 250.4395 190 15\n",
      "Training Accuracy 0.605\n",
      "Loss 266.11923 191 15\n",
      "Training Accuracy 0.58\n",
      "Loss 269.0254 192 15\n",
      "Training Accuracy 0.53\n",
      "Loss 239.52399 193 15\n",
      "Training Accuracy 0.625\n",
      "Loss 242.54892 194 15\n",
      "Training Accuracy 0.575\n",
      "Loss 242.42221 195 15\n",
      "Training Accuracy 0.625\n",
      "Loss 252.88542 196 15\n",
      "Training Accuracy 0.61\n",
      "Loss 271.17282 197 15\n",
      "Training Accuracy 0.555\n",
      "Loss 248.08339 198 15\n",
      "Training Accuracy 0.535\n",
      "Loss 210.17548 199 15\n",
      "Training Accuracy 0.645\n",
      "Loss 275.12885 200 15\n",
      "Training Accuracy 0.535\n",
      "Loss 245.38666 201 15\n",
      "Training Accuracy 0.54\n",
      "Loss 239.98419 202 15\n",
      "Training Accuracy 0.59\n",
      "Loss 260.18137 203 15\n",
      "Training Accuracy 0.585\n",
      "Loss 264.20874 204 15\n",
      "Training Accuracy 0.51\n",
      "Loss 278.55692 205 15\n",
      "Training Accuracy 0.545\n",
      "Loss 257.621 206 15\n",
      "Training Accuracy 0.59\n",
      "Loss 243.77489 207 15\n",
      "Training Accuracy 0.645\n",
      "Loss 276.50543 208 15\n",
      "Training Accuracy 0.595\n",
      "Loss 285.741 209 15\n",
      "Training Accuracy 0.54\n",
      "Loss 244.49916 210 15\n",
      "Training Accuracy 0.58\n",
      "Loss 259.6753 211 15\n",
      "Training Accuracy 0.595\n",
      "Loss 237.17102 212 15\n",
      "Training Accuracy 0.58\n",
      "Loss 295.4148 213 15\n",
      "Training Accuracy 0.52\n",
      "Loss 260.50912 214 15\n",
      "Training Accuracy 0.625\n",
      "Loss 282.8542 215 15\n",
      "Training Accuracy 0.55\n",
      "Loss 279.87973 216 15\n",
      "Training Accuracy 0.57\n",
      "Loss 255.73996 217 15\n",
      "Training Accuracy 0.56\n",
      "Loss 267.04196 218 15\n",
      "Training Accuracy 0.56\n",
      "Loss 263.00592 219 15\n",
      "Training Accuracy 0.575\n",
      "Loss 240.6574 220 15\n",
      "Training Accuracy 0.615\n",
      "Loss 267.42532 221 15\n",
      "Training Accuracy 0.57\n",
      "Loss 257.35913 222 15\n",
      "Training Accuracy 0.57\n",
      "Loss 276.62936 223 15\n",
      "Training Accuracy 0.535\n",
      "Loss 278.1907 224 15\n",
      "Training Accuracy 0.53\n",
      "Loss 289.29575 225 15\n",
      "Training Accuracy 0.545\n",
      "Loss 230.60028 226 15\n",
      "Training Accuracy 0.63\n",
      "Loss 293.51187 227 15\n",
      "Training Accuracy 0.525\n",
      "Loss 294.05643 228 15\n",
      "Training Accuracy 0.53\n",
      "Loss 254.52473 229 15\n",
      "Training Accuracy 0.58\n",
      "Loss 260.44684 230 15\n",
      "Training Accuracy 0.55\n",
      "Loss 228.12465 231 15\n",
      "Training Accuracy 0.63\n",
      "Loss 252.86815 232 15\n",
      "Training Accuracy 0.565\n",
      "Loss 287.30563 233 15\n",
      "Training Accuracy 0.49\n",
      "Loss 262.13943 234 15\n",
      "Training Accuracy 0.53\n",
      "Loss 272.54794 235 15\n",
      "Training Accuracy 0.585\n",
      "Loss 232.91127 236 15\n",
      "Training Accuracy 0.64\n",
      "Loss 266.19553 237 15\n",
      "Training Accuracy 0.57\n",
      "Loss 249.02422 238 15\n",
      "Training Accuracy 0.545\n",
      "Loss 276.32538 239 15\n",
      "Training Accuracy 0.57\n",
      "Loss 261.61346 240 15\n",
      "Training Accuracy 0.56\n",
      "Loss 282.8247 241 15\n",
      "Training Accuracy 0.545\n",
      "Loss 246.95833 242 15\n",
      "Training Accuracy 0.62\n",
      "Loss 233.02824 243 15\n",
      "Training Accuracy 0.605\n",
      "Loss 258.5965 244 15\n",
      "Training Accuracy 0.555\n",
      "Loss 257.15924 245 15\n",
      "Training Accuracy 0.545\n",
      "Loss 279.02814 246 15\n",
      "Training Accuracy 0.58\n",
      "Loss 218.98383 247 15\n",
      "Training Accuracy 0.58\n",
      "Loss 241.17204 248 15\n",
      "Training Accuracy 0.585\n",
      "Loss 274.60373 249 15\n",
      "Training Accuracy 0.535\n",
      "Loss 274.83966 250 15\n",
      "Training Accuracy 0.475\n",
      "Loss 266.26846 251 15\n",
      "Training Accuracy 0.525\n",
      "Loss 236.16861 252 15\n",
      "Training Accuracy 0.595\n",
      "Loss 245.07481 253 15\n",
      "Training Accuracy 0.62\n",
      "Loss 251.91536 254 15\n",
      "Training Accuracy 0.575\n",
      "Loss 230.80489 255 15\n",
      "Training Accuracy 0.64\n",
      "Loss 275.6705 256 15\n",
      "Training Accuracy 0.56\n",
      "Loss 252.0556 257 15\n",
      "Training Accuracy 0.575\n",
      "Loss 260.68164 258 15\n",
      "Training Accuracy 0.575\n",
      "Loss 260.35614 259 15\n",
      "Training Accuracy 0.57\n",
      "Loss 217.2779 260 15\n",
      "Training Accuracy 0.655\n",
      "Loss 271.88232 261 15\n",
      "Training Accuracy 0.575\n",
      "Loss 255.81009 262 15\n",
      "Training Accuracy 0.55\n",
      "Loss 314.64764 263 15\n",
      "Training Accuracy 0.47\n",
      "Loss 279.84454 264 15\n",
      "Training Accuracy 0.595\n",
      "Loss 248.25008 265 15\n",
      "Training Accuracy 0.63\n",
      "Loss 248.83575 266 15\n",
      "Training Accuracy 0.58\n",
      "Loss 269.74286 267 15\n",
      "Training Accuracy 0.57\n",
      "Loss 271.20734 268 15\n",
      "Training Accuracy 0.595\n",
      "Loss 234.79713 269 15\n",
      "Training Accuracy 0.575\n",
      "Loss 232.36412 270 15\n",
      "Training Accuracy 0.625\n",
      "Loss 288.13184 271 15\n",
      "Training Accuracy 0.545\n",
      "Loss 264.863 272 15\n",
      "Training Accuracy 0.595\n",
      "Loss 270.80383 273 15\n",
      "Training Accuracy 0.53\n",
      "Loss 240.94902 274 15\n",
      "Training Accuracy 0.605\n",
      "Loss 273.12573 275 15\n",
      "Training Accuracy 0.51\n",
      "Loss 239.97221 276 15\n",
      "Training Accuracy 0.57\n",
      "Loss 289.82568 277 15\n",
      "Training Accuracy 0.545\n",
      "Loss 244.89052 278 15\n",
      "Training Accuracy 0.57\n",
      "Loss 256.71967 279 15\n",
      "Training Accuracy 0.58\n",
      "Loss 240.74919 280 15\n",
      "Training Accuracy 0.595\n",
      "Loss 254.98744 281 15\n",
      "Training Accuracy 0.605\n",
      "Loss 259.0949 282 15\n",
      "Training Accuracy 0.585\n",
      "Loss 250.40082 283 15\n",
      "Training Accuracy 0.62\n",
      "Loss 236.80093 284 15\n",
      "Training Accuracy 0.64\n",
      "Loss 297.9057 285 15\n",
      "Training Accuracy 0.51\n",
      "Loss 259.21442 286 15\n",
      "Training Accuracy 0.595\n",
      "Loss 243.90208 287 15\n",
      "Training Accuracy 0.62\n",
      "Loss 249.49043 288 15\n",
      "Training Accuracy 0.63\n",
      "Loss 249.62956 289 15\n",
      "Training Accuracy 0.57\n",
      "Loss 252.62195 290 15\n",
      "Training Accuracy 0.585\n",
      "Loss 268.7875 291 15\n",
      "Training Accuracy 0.525\n",
      "Loss 156.24768 292 15\n",
      "Training Accuracy 0.6287879\n",
      "Loss 224.13177 1 16\n",
      "Training Accuracy 0.615\n",
      "Loss 254.31133 2 16\n",
      "Training Accuracy 0.585\n",
      "Loss 251.25171 3 16\n",
      "Training Accuracy 0.585\n",
      "Loss 257.1293 4 16\n",
      "Training Accuracy 0.62\n",
      "Loss 226.16585 5 16\n",
      "Training Accuracy 0.655\n",
      "Loss 267.64734 6 16\n",
      "Training Accuracy 0.58\n",
      "Loss 265.7567 7 16\n",
      "Training Accuracy 0.555\n",
      "Loss 285.06354 8 16\n",
      "Training Accuracy 0.59\n",
      "Loss 240.71042 9 16\n",
      "Training Accuracy 0.605\n",
      "Loss 275.8873 10 16\n",
      "Training Accuracy 0.515\n",
      "Loss 293.7281 11 16\n",
      "Training Accuracy 0.61\n",
      "Loss 251.52393 12 16\n",
      "Training Accuracy 0.595\n",
      "Loss 253.14482 13 16\n",
      "Training Accuracy 0.575\n",
      "Loss 275.77676 14 16\n",
      "Training Accuracy 0.585\n",
      "Loss 240.40028 15 16\n",
      "Training Accuracy 0.63\n",
      "Loss 288.69916 16 16\n",
      "Training Accuracy 0.565\n",
      "Loss 240.07791 17 16\n",
      "Training Accuracy 0.62\n",
      "Loss 262.8302 18 16\n",
      "Training Accuracy 0.565\n",
      "Loss 240.02802 19 16\n",
      "Training Accuracy 0.54\n",
      "Loss 249.45699 20 16\n",
      "Training Accuracy 0.62\n",
      "Loss 247.13573 21 16\n",
      "Training Accuracy 0.585\n",
      "Loss 262.56796 22 16\n",
      "Training Accuracy 0.575\n",
      "Loss 264.95444 23 16\n",
      "Training Accuracy 0.555\n",
      "Loss 276.38724 24 16\n",
      "Training Accuracy 0.575\n",
      "Loss 246.80786 25 16\n",
      "Training Accuracy 0.59\n",
      "Loss 270.99185 26 16\n",
      "Training Accuracy 0.535\n",
      "Loss 239.62692 27 16\n",
      "Training Accuracy 0.61\n",
      "Loss 251.32484 28 16\n",
      "Training Accuracy 0.565\n",
      "Loss 255.37344 29 16\n",
      "Training Accuracy 0.55\n",
      "Loss 264.5721 30 16\n",
      "Training Accuracy 0.575\n",
      "Loss 279.59656 31 16\n",
      "Training Accuracy 0.515\n",
      "Loss 257.259 32 16\n",
      "Training Accuracy 0.57\n",
      "Loss 264.955 33 16\n",
      "Training Accuracy 0.625\n",
      "Loss 224.96907 34 16\n",
      "Training Accuracy 0.64\n",
      "Loss 242.21063 35 16\n",
      "Training Accuracy 0.555\n",
      "Loss 253.86847 36 16\n",
      "Training Accuracy 0.54\n",
      "Loss 249.31673 37 16\n",
      "Training Accuracy 0.595\n",
      "Loss 260.71716 38 16\n",
      "Training Accuracy 0.585\n",
      "Loss 225.85544 39 16\n",
      "Training Accuracy 0.615\n",
      "Loss 233.03856 40 16\n",
      "Training Accuracy 0.64\n",
      "Loss 253.92572 41 16\n",
      "Training Accuracy 0.555\n",
      "Loss 298.62643 42 16\n",
      "Training Accuracy 0.505\n",
      "Loss 246.8395 43 16\n",
      "Training Accuracy 0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 241.877 44 16\n",
      "Training Accuracy 0.605\n",
      "Loss 251.34845 45 16\n",
      "Training Accuracy 0.615\n",
      "Loss 278.22058 46 16\n",
      "Training Accuracy 0.58\n",
      "Loss 229.8634 47 16\n",
      "Training Accuracy 0.64\n",
      "Loss 226.36932 48 16\n",
      "Training Accuracy 0.625\n",
      "Loss 254.4014 49 16\n",
      "Training Accuracy 0.57\n",
      "Loss 283.43954 50 16\n",
      "Training Accuracy 0.545\n",
      "Loss 238.29341 51 16\n",
      "Training Accuracy 0.61\n",
      "Loss 239.45819 52 16\n",
      "Training Accuracy 0.615\n",
      "Loss 229.82251 53 16\n",
      "Training Accuracy 0.62\n",
      "Loss 274.65668 54 16\n",
      "Training Accuracy 0.56\n",
      "Loss 268.4369 55 16\n",
      "Training Accuracy 0.53\n",
      "Loss 256.90866 56 16\n",
      "Training Accuracy 0.56\n",
      "Loss 244.90993 57 16\n",
      "Training Accuracy 0.605\n",
      "Loss 231.0278 58 16\n",
      "Training Accuracy 0.615\n",
      "Loss 267.13602 59 16\n",
      "Training Accuracy 0.54\n",
      "Loss 254.8096 60 16\n",
      "Training Accuracy 0.6\n",
      "Loss 251.4593 61 16\n",
      "Training Accuracy 0.57\n",
      "Loss 245.95413 62 16\n",
      "Training Accuracy 0.575\n",
      "Loss 259.11685 63 16\n",
      "Training Accuracy 0.61\n",
      "Loss 258.28824 64 16\n",
      "Training Accuracy 0.62\n",
      "Loss 271.6157 65 16\n",
      "Training Accuracy 0.55\n",
      "Loss 240.26817 66 16\n",
      "Training Accuracy 0.58\n",
      "Loss 269.3952 67 16\n",
      "Training Accuracy 0.58\n",
      "Loss 261.47006 68 16\n",
      "Training Accuracy 0.555\n",
      "Loss 254.75902 69 16\n",
      "Training Accuracy 0.605\n",
      "Loss 263.80927 70 16\n",
      "Training Accuracy 0.6\n",
      "Loss 247.47694 71 16\n",
      "Training Accuracy 0.61\n",
      "Loss 243.33708 72 16\n",
      "Training Accuracy 0.58\n",
      "Loss 261.08408 73 16\n",
      "Training Accuracy 0.545\n",
      "Loss 290.07974 74 16\n",
      "Training Accuracy 0.525\n",
      "Loss 268.04678 75 16\n",
      "Training Accuracy 0.59\n",
      "Loss 231.58926 76 16\n",
      "Training Accuracy 0.6\n",
      "Loss 259.26523 77 16\n",
      "Training Accuracy 0.555\n",
      "Loss 246.42543 78 16\n",
      "Training Accuracy 0.615\n",
      "Loss 250.5185 79 16\n",
      "Training Accuracy 0.535\n",
      "Loss 277.50436 80 16\n",
      "Training Accuracy 0.565\n",
      "Loss 246.76195 81 16\n",
      "Training Accuracy 0.555\n",
      "Loss 246.0774 82 16\n",
      "Training Accuracy 0.6\n",
      "Loss 250.58493 83 16\n",
      "Training Accuracy 0.615\n",
      "Loss 295.91656 84 16\n",
      "Training Accuracy 0.505\n",
      "Loss 259.8659 85 16\n",
      "Training Accuracy 0.56\n",
      "Loss 266.93448 86 16\n",
      "Training Accuracy 0.55\n",
      "Loss 306.6163 87 16\n",
      "Training Accuracy 0.49\n",
      "Loss 273.97894 88 16\n",
      "Training Accuracy 0.55\n",
      "Loss 253.68869 89 16\n",
      "Training Accuracy 0.6\n",
      "Loss 255.83313 90 16\n",
      "Training Accuracy 0.55\n",
      "Loss 260.84778 91 16\n",
      "Training Accuracy 0.575\n",
      "Loss 257.4998 92 16\n",
      "Training Accuracy 0.605\n",
      "Loss 255.33455 93 16\n",
      "Training Accuracy 0.595\n",
      "Loss 262.22556 94 16\n",
      "Training Accuracy 0.555\n",
      "Loss 247.93901 95 16\n",
      "Training Accuracy 0.595\n",
      "Loss 248.69514 96 16\n",
      "Training Accuracy 0.585\n",
      "Loss 266.44333 97 16\n",
      "Training Accuracy 0.515\n",
      "Loss 245.74898 98 16\n",
      "Training Accuracy 0.585\n",
      "Loss 241.54391 99 16\n",
      "Training Accuracy 0.595\n",
      "Loss 262.43457 100 16\n",
      "Training Accuracy 0.595\n",
      "Loss 264.50842 101 16\n",
      "Training Accuracy 0.54\n",
      "Loss 236.21454 102 16\n",
      "Training Accuracy 0.57\n",
      "Loss 255.24309 103 16\n",
      "Training Accuracy 0.56\n",
      "Loss 252.03502 104 16\n",
      "Training Accuracy 0.555\n",
      "Loss 267.62097 105 16\n",
      "Training Accuracy 0.56\n",
      "Loss 250.37547 106 16\n",
      "Training Accuracy 0.59\n",
      "Loss 259.78085 107 16\n",
      "Training Accuracy 0.53\n",
      "Loss 255.56824 108 16\n",
      "Training Accuracy 0.555\n",
      "Loss 251.27815 109 16\n",
      "Training Accuracy 0.57\n",
      "Loss 264.78033 110 16\n",
      "Training Accuracy 0.59\n",
      "Loss 268.1687 111 16\n",
      "Training Accuracy 0.555\n",
      "Loss 283.90057 112 16\n",
      "Training Accuracy 0.56\n",
      "Loss 295.94473 113 16\n",
      "Training Accuracy 0.55\n",
      "Loss 254.59271 114 16\n",
      "Training Accuracy 0.56\n",
      "Loss 281.82022 115 16\n",
      "Training Accuracy 0.58\n",
      "Loss 290.27258 116 16\n",
      "Training Accuracy 0.565\n",
      "Loss 216.33061 117 16\n",
      "Training Accuracy 0.695\n",
      "Loss 269.41623 118 16\n",
      "Training Accuracy 0.56\n",
      "Loss 297.44794 119 16\n",
      "Training Accuracy 0.505\n",
      "Loss 292.0403 120 16\n",
      "Training Accuracy 0.48\n",
      "Loss 261.05164 121 16\n",
      "Training Accuracy 0.59\n",
      "Loss 228.68626 122 16\n",
      "Training Accuracy 0.615\n",
      "Loss 257.11447 123 16\n",
      "Training Accuracy 0.58\n",
      "Loss 249.98474 124 16\n",
      "Training Accuracy 0.585\n",
      "Loss 225.4301 125 16\n",
      "Training Accuracy 0.62\n",
      "Loss 283.14282 126 16\n",
      "Training Accuracy 0.505\n",
      "Loss 259.83438 127 16\n",
      "Training Accuracy 0.565\n",
      "Loss 247.1681 128 16\n",
      "Training Accuracy 0.575\n",
      "Loss 240.1032 129 16\n",
      "Training Accuracy 0.605\n",
      "Loss 242.33205 130 16\n",
      "Training Accuracy 0.595\n",
      "Loss 237.52577 131 16\n",
      "Training Accuracy 0.595\n",
      "Loss 236.2286 132 16\n",
      "Training Accuracy 0.6\n",
      "Loss 246.1971 133 16\n",
      "Training Accuracy 0.65\n",
      "Loss 245.36688 134 16\n",
      "Training Accuracy 0.58\n",
      "Loss 242.01387 135 16\n",
      "Training Accuracy 0.635\n",
      "Loss 273.36304 136 16\n",
      "Training Accuracy 0.55\n",
      "Loss 269.51285 137 16\n",
      "Training Accuracy 0.605\n",
      "Loss 245.3576 138 16\n",
      "Training Accuracy 0.6\n",
      "Loss 287.56754 139 16\n",
      "Training Accuracy 0.585\n",
      "Loss 214.06758 140 16\n",
      "Training Accuracy 0.615\n",
      "Loss 269.79947 141 16\n",
      "Training Accuracy 0.58\n",
      "Loss 261.41177 142 16\n",
      "Training Accuracy 0.55\n",
      "Loss 225.3488 143 16\n",
      "Training Accuracy 0.635\n",
      "Loss 259.13016 144 16\n",
      "Training Accuracy 0.55\n",
      "Loss 252.26747 145 16\n",
      "Training Accuracy 0.59\n",
      "Loss 260.8808 146 16\n",
      "Training Accuracy 0.565\n",
      "Loss 250.88489 147 16\n",
      "Training Accuracy 0.585\n",
      "Loss 255.449 148 16\n",
      "Training Accuracy 0.58\n",
      "Loss 256.22437 149 16\n",
      "Training Accuracy 0.605\n",
      "Loss 239.71739 150 16\n",
      "Training Accuracy 0.635\n",
      "Loss 269.3782 151 16\n",
      "Training Accuracy 0.555\n",
      "Loss 264.94934 152 16\n",
      "Training Accuracy 0.585\n",
      "Loss 249.46082 153 16\n",
      "Training Accuracy 0.605\n",
      "Loss 245.89854 154 16\n",
      "Training Accuracy 0.61\n",
      "Loss 227.88974 155 16\n",
      "Training Accuracy 0.635\n",
      "Loss 258.2794 156 16\n",
      "Training Accuracy 0.585\n",
      "Loss 229.04335 157 16\n",
      "Training Accuracy 0.58\n",
      "Loss 253.41922 158 16\n",
      "Training Accuracy 0.61\n",
      "Loss 279.37003 159 16\n",
      "Training Accuracy 0.595\n",
      "Loss 258.0312 160 16\n",
      "Training Accuracy 0.575\n",
      "Loss 281.68094 161 16\n",
      "Training Accuracy 0.56\n",
      "Loss 259.01813 162 16\n",
      "Training Accuracy 0.55\n",
      "Loss 275.66226 163 16\n",
      "Training Accuracy 0.545\n",
      "Loss 213.21126 164 16\n",
      "Training Accuracy 0.62\n",
      "Loss 243.90768 165 16\n",
      "Training Accuracy 0.605\n",
      "Loss 247.84418 166 16\n",
      "Training Accuracy 0.6\n",
      "Loss 218.21762 167 16\n",
      "Training Accuracy 0.58\n",
      "Loss 273.89484 168 16\n",
      "Training Accuracy 0.56\n",
      "Loss 248.49184 169 16\n",
      "Training Accuracy 0.58\n",
      "Loss 246.49895 170 16\n",
      "Training Accuracy 0.6\n",
      "Loss 270.4604 171 16\n",
      "Training Accuracy 0.54\n",
      "Loss 246.179 172 16\n",
      "Training Accuracy 0.61\n",
      "Loss 290.1006 173 16\n",
      "Training Accuracy 0.54\n",
      "Loss 225.91695 174 16\n",
      "Training Accuracy 0.61\n",
      "Loss 226.31908 175 16\n",
      "Training Accuracy 0.68\n",
      "Loss 210.48866 176 16\n",
      "Training Accuracy 0.65\n",
      "Loss 292.74036 177 16\n",
      "Training Accuracy 0.505\n",
      "Loss 237.1469 178 16\n",
      "Training Accuracy 0.58\n",
      "Loss 271.6991 179 16\n",
      "Training Accuracy 0.595\n",
      "Loss 258.8083 180 16\n",
      "Training Accuracy 0.56\n",
      "Loss 224.66048 181 16\n",
      "Training Accuracy 0.655\n",
      "Loss 275.93167 182 16\n",
      "Training Accuracy 0.55\n",
      "Loss 272.74796 183 16\n",
      "Training Accuracy 0.53\n",
      "Loss 234.87585 184 16\n",
      "Training Accuracy 0.655\n",
      "Loss 236.47836 185 16\n",
      "Training Accuracy 0.62\n",
      "Loss 246.53658 186 16\n",
      "Training Accuracy 0.585\n",
      "Loss 294.8508 187 16\n",
      "Training Accuracy 0.52\n",
      "Loss 270.7801 188 16\n",
      "Training Accuracy 0.58\n",
      "Loss 254.28319 189 16\n",
      "Training Accuracy 0.615\n",
      "Loss 230.73137 190 16\n",
      "Training Accuracy 0.635\n",
      "Loss 238.37563 191 16\n",
      "Training Accuracy 0.615\n",
      "Loss 267.3533 192 16\n",
      "Training Accuracy 0.58\n",
      "Loss 235.26125 193 16\n",
      "Training Accuracy 0.61\n",
      "Loss 245.56609 194 16\n",
      "Training Accuracy 0.585\n",
      "Loss 244.1531 195 16\n",
      "Training Accuracy 0.59\n",
      "Loss 249.9624 196 16\n",
      "Training Accuracy 0.6\n",
      "Loss 260.7772 197 16\n",
      "Training Accuracy 0.56\n",
      "Loss 234.15572 198 16\n",
      "Training Accuracy 0.61\n",
      "Loss 201.52177 199 16\n",
      "Training Accuracy 0.69\n",
      "Loss 265.98062 200 16\n",
      "Training Accuracy 0.535\n",
      "Loss 235.9587 201 16\n",
      "Training Accuracy 0.61\n",
      "Loss 249.1121 202 16\n",
      "Training Accuracy 0.565\n",
      "Loss 265.06705 203 16\n",
      "Training Accuracy 0.555\n",
      "Loss 250.99155 204 16\n",
      "Training Accuracy 0.55\n",
      "Loss 266.59616 205 16\n",
      "Training Accuracy 0.575\n",
      "Loss 261.10275 206 16\n",
      "Training Accuracy 0.585\n",
      "Loss 253.65604 207 16\n",
      "Training Accuracy 0.6\n",
      "Loss 273.60986 208 16\n",
      "Training Accuracy 0.57\n",
      "Loss 276.2943 209 16\n",
      "Training Accuracy 0.575\n",
      "Loss 236.30632 210 16\n",
      "Training Accuracy 0.585\n",
      "Loss 250.92857 211 16\n",
      "Training Accuracy 0.62\n",
      "Loss 228.08719 212 16\n",
      "Training Accuracy 0.615\n",
      "Loss 294.06662 213 16\n",
      "Training Accuracy 0.5\n",
      "Loss 252.0275 214 16\n",
      "Training Accuracy 0.575\n",
      "Loss 273.6097 215 16\n",
      "Training Accuracy 0.545\n",
      "Loss 284.83408 216 16\n",
      "Training Accuracy 0.525\n",
      "Loss 256.41617 217 16\n",
      "Training Accuracy 0.52\n",
      "Loss 261.1984 218 16\n",
      "Training Accuracy 0.545\n",
      "Loss 262.9945 219 16\n",
      "Training Accuracy 0.6\n",
      "Loss 256.06116 220 16\n",
      "Training Accuracy 0.58\n",
      "Loss 254.38097 221 16\n",
      "Training Accuracy 0.62\n",
      "Loss 256.09546 222 16\n",
      "Training Accuracy 0.555\n",
      "Loss 275.56036 223 16\n",
      "Training Accuracy 0.555\n",
      "Loss 274.40793 224 16\n",
      "Training Accuracy 0.495\n",
      "Loss 273.13336 225 16\n",
      "Training Accuracy 0.545\n",
      "Loss 222.99779 226 16\n",
      "Training Accuracy 0.605\n",
      "Loss 287.8216 227 16\n",
      "Training Accuracy 0.525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 281.22787 228 16\n",
      "Training Accuracy 0.56\n",
      "Loss 246.87056 229 16\n",
      "Training Accuracy 0.605\n",
      "Loss 250.03268 230 16\n",
      "Training Accuracy 0.635\n",
      "Loss 230.38094 231 16\n",
      "Training Accuracy 0.605\n",
      "Loss 248.21333 232 16\n",
      "Training Accuracy 0.53\n",
      "Loss 280.5335 233 16\n",
      "Training Accuracy 0.505\n",
      "Loss 255.75168 234 16\n",
      "Training Accuracy 0.56\n",
      "Loss 254.56413 235 16\n",
      "Training Accuracy 0.555\n",
      "Loss 231.19945 236 16\n",
      "Training Accuracy 0.605\n",
      "Loss 264.9885 237 16\n",
      "Training Accuracy 0.57\n",
      "Loss 235.09038 238 16\n",
      "Training Accuracy 0.555\n",
      "Loss 276.77603 239 16\n",
      "Training Accuracy 0.56\n",
      "Loss 255.23691 240 16\n",
      "Training Accuracy 0.55\n",
      "Loss 278.59406 241 16\n",
      "Training Accuracy 0.535\n",
      "Loss 238.19594 242 16\n",
      "Training Accuracy 0.605\n",
      "Loss 228.45912 243 16\n",
      "Training Accuracy 0.625\n",
      "Loss 251.74805 244 16\n",
      "Training Accuracy 0.59\n",
      "Loss 246.98026 245 16\n",
      "Training Accuracy 0.585\n",
      "Loss 255.64226 246 16\n",
      "Training Accuracy 0.615\n",
      "Loss 208.92206 247 16\n",
      "Training Accuracy 0.625\n",
      "Loss 234.01204 248 16\n",
      "Training Accuracy 0.615\n",
      "Loss 264.40533 249 16\n",
      "Training Accuracy 0.53\n",
      "Loss 279.56558 250 16\n",
      "Training Accuracy 0.515\n",
      "Loss 265.01776 251 16\n",
      "Training Accuracy 0.48\n",
      "Loss 230.04073 252 16\n",
      "Training Accuracy 0.635\n",
      "Loss 234.30632 253 16\n",
      "Training Accuracy 0.615\n",
      "Loss 245.12721 254 16\n",
      "Training Accuracy 0.635\n",
      "Loss 230.44443 255 16\n",
      "Training Accuracy 0.595\n",
      "Loss 274.83502 256 16\n",
      "Training Accuracy 0.545\n",
      "Loss 245.20125 257 16\n",
      "Training Accuracy 0.615\n",
      "Loss 256.2752 258 16\n",
      "Training Accuracy 0.59\n",
      "Loss 257.39566 259 16\n",
      "Training Accuracy 0.545\n",
      "Loss 215.84186 260 16\n",
      "Training Accuracy 0.675\n",
      "Loss 249.8938 261 16\n",
      "Training Accuracy 0.605\n",
      "Loss 253.67197 262 16\n",
      "Training Accuracy 0.545\n",
      "Loss 306.50476 263 16\n",
      "Training Accuracy 0.54\n",
      "Loss 266.31357 264 16\n",
      "Training Accuracy 0.625\n",
      "Loss 243.41338 265 16\n",
      "Training Accuracy 0.595\n",
      "Loss 249.53185 266 16\n",
      "Training Accuracy 0.59\n",
      "Loss 269.82962 267 16\n",
      "Training Accuracy 0.55\n",
      "Loss 262.2423 268 16\n",
      "Training Accuracy 0.595\n",
      "Loss 224.99399 269 16\n",
      "Training Accuracy 0.595\n",
      "Loss 218.52382 270 16\n",
      "Training Accuracy 0.62\n",
      "Loss 281.97928 271 16\n",
      "Training Accuracy 0.555\n",
      "Loss 263.50333 272 16\n",
      "Training Accuracy 0.595\n",
      "Loss 257.43912 273 16\n",
      "Training Accuracy 0.585\n",
      "Loss 233.4862 274 16\n",
      "Training Accuracy 0.645\n",
      "Loss 261.4899 275 16\n",
      "Training Accuracy 0.54\n",
      "Loss 227.77486 276 16\n",
      "Training Accuracy 0.63\n",
      "Loss 278.7518 277 16\n",
      "Training Accuracy 0.555\n",
      "Loss 236.38826 278 16\n",
      "Training Accuracy 0.57\n",
      "Loss 254.72609 279 16\n",
      "Training Accuracy 0.57\n",
      "Loss 239.27007 280 16\n",
      "Training Accuracy 0.58\n",
      "Loss 246.49802 281 16\n",
      "Training Accuracy 0.61\n",
      "Loss 259.26337 282 16\n",
      "Training Accuracy 0.565\n",
      "Loss 242.0875 283 16\n",
      "Training Accuracy 0.635\n",
      "Loss 230.3022 284 16\n",
      "Training Accuracy 0.65\n",
      "Loss 288.4583 285 16\n",
      "Training Accuracy 0.57\n",
      "Loss 254.75931 286 16\n",
      "Training Accuracy 0.58\n",
      "Loss 233.94249 287 16\n",
      "Training Accuracy 0.655\n",
      "Loss 254.71948 288 16\n",
      "Training Accuracy 0.575\n",
      "Loss 238.13638 289 16\n",
      "Training Accuracy 0.605\n",
      "Loss 253.85445 290 16\n",
      "Training Accuracy 0.555\n",
      "Loss 264.00455 291 16\n",
      "Training Accuracy 0.54\n",
      "Loss 153.66328 292 16\n",
      "Training Accuracy 0.6287879\n",
      "Loss 212.61626 1 17\n",
      "Training Accuracy 0.645\n",
      "Loss 246.04256 2 17\n",
      "Training Accuracy 0.605\n",
      "Loss 236.05264 3 17\n",
      "Training Accuracy 0.635\n",
      "Loss 257.0543 4 17\n",
      "Training Accuracy 0.585\n",
      "Loss 221.81122 5 17\n",
      "Training Accuracy 0.64\n",
      "Loss 260.84662 6 17\n",
      "Training Accuracy 0.59\n",
      "Loss 251.58884 7 17\n",
      "Training Accuracy 0.585\n",
      "Loss 281.37296 8 17\n",
      "Training Accuracy 0.595\n",
      "Loss 230.7765 9 17\n",
      "Training Accuracy 0.62\n",
      "Loss 263.56372 10 17\n",
      "Training Accuracy 0.56\n",
      "Loss 286.31223 11 17\n",
      "Training Accuracy 0.595\n",
      "Loss 240.99635 12 17\n",
      "Training Accuracy 0.595\n",
      "Loss 242.80196 13 17\n",
      "Training Accuracy 0.565\n",
      "Loss 268.40125 14 17\n",
      "Training Accuracy 0.585\n",
      "Loss 227.22151 15 17\n",
      "Training Accuracy 0.59\n",
      "Loss 282.43323 16 17\n",
      "Training Accuracy 0.55\n",
      "Loss 230.2638 17 17\n",
      "Training Accuracy 0.625\n",
      "Loss 241.28653 18 17\n",
      "Training Accuracy 0.59\n",
      "Loss 236.553 19 17\n",
      "Training Accuracy 0.595\n",
      "Loss 242.56454 20 17\n",
      "Training Accuracy 0.62\n",
      "Loss 236.51382 21 17\n",
      "Training Accuracy 0.605\n",
      "Loss 264.69827 22 17\n",
      "Training Accuracy 0.6\n",
      "Loss 255.14972 23 17\n",
      "Training Accuracy 0.605\n",
      "Loss 260.67444 24 17\n",
      "Training Accuracy 0.57\n",
      "Loss 249.07413 25 17\n",
      "Training Accuracy 0.58\n",
      "Loss 262.10657 26 17\n",
      "Training Accuracy 0.54\n",
      "Loss 246.66026 27 17\n",
      "Training Accuracy 0.56\n",
      "Loss 244.81184 28 17\n",
      "Training Accuracy 0.57\n",
      "Loss 256.77222 29 17\n",
      "Training Accuracy 0.555\n",
      "Loss 259.51865 30 17\n",
      "Training Accuracy 0.61\n",
      "Loss 275.33862 31 17\n",
      "Training Accuracy 0.565\n",
      "Loss 258.2614 32 17\n",
      "Training Accuracy 0.545\n",
      "Loss 245.32785 33 17\n",
      "Training Accuracy 0.625\n",
      "Loss 219.59235 34 17\n",
      "Training Accuracy 0.635\n",
      "Loss 231.57404 35 17\n",
      "Training Accuracy 0.555\n",
      "Loss 242.94296 36 17\n",
      "Training Accuracy 0.59\n",
      "Loss 243.97607 37 17\n",
      "Training Accuracy 0.615\n",
      "Loss 261.33777 38 17\n",
      "Training Accuracy 0.575\n",
      "Loss 221.39276 39 17\n",
      "Training Accuracy 0.645\n",
      "Loss 226.70123 40 17\n",
      "Training Accuracy 0.67\n",
      "Loss 252.25392 41 17\n",
      "Training Accuracy 0.535\n",
      "Loss 289.92102 42 17\n",
      "Training Accuracy 0.505\n",
      "Loss 232.42331 43 17\n",
      "Training Accuracy 0.625\n",
      "Loss 234.09016 44 17\n",
      "Training Accuracy 0.585\n",
      "Loss 248.98027 45 17\n",
      "Training Accuracy 0.585\n",
      "Loss 269.58203 46 17\n",
      "Training Accuracy 0.575\n",
      "Loss 240.213 47 17\n",
      "Training Accuracy 0.62\n",
      "Loss 223.83266 48 17\n",
      "Training Accuracy 0.6\n",
      "Loss 250.86836 49 17\n",
      "Training Accuracy 0.55\n",
      "Loss 286.81024 50 17\n",
      "Training Accuracy 0.56\n",
      "Loss 231.48993 51 17\n",
      "Training Accuracy 0.64\n",
      "Loss 246.31296 52 17\n",
      "Training Accuracy 0.6\n",
      "Loss 223.55515 53 17\n",
      "Training Accuracy 0.64\n",
      "Loss 265.72162 54 17\n",
      "Training Accuracy 0.555\n",
      "Loss 268.16315 55 17\n",
      "Training Accuracy 0.525\n",
      "Loss 254.43217 56 17\n",
      "Training Accuracy 0.555\n",
      "Loss 235.35724 57 17\n",
      "Training Accuracy 0.625\n",
      "Loss 230.9399 58 17\n",
      "Training Accuracy 0.59\n",
      "Loss 261.4046 59 17\n",
      "Training Accuracy 0.555\n",
      "Loss 250.6181 60 17\n",
      "Training Accuracy 0.62\n",
      "Loss 252.18372 61 17\n",
      "Training Accuracy 0.58\n",
      "Loss 237.24098 62 17\n",
      "Training Accuracy 0.615\n",
      "Loss 256.18323 63 17\n",
      "Training Accuracy 0.615\n",
      "Loss 246.52 64 17\n",
      "Training Accuracy 0.625\n",
      "Loss 271.8857 65 17\n",
      "Training Accuracy 0.56\n",
      "Loss 237.80014 66 17\n",
      "Training Accuracy 0.55\n",
      "Loss 275.4397 67 17\n",
      "Training Accuracy 0.58\n",
      "Loss 242.81471 68 17\n",
      "Training Accuracy 0.58\n",
      "Loss 249.66624 69 17\n",
      "Training Accuracy 0.595\n",
      "Loss 248.2128 70 17\n",
      "Training Accuracy 0.6\n",
      "Loss 239.83911 71 17\n",
      "Training Accuracy 0.66\n",
      "Loss 251.11069 72 17\n",
      "Training Accuracy 0.595\n",
      "Loss 248.81567 73 17\n",
      "Training Accuracy 0.6\n",
      "Loss 276.1073 74 17\n",
      "Training Accuracy 0.58\n",
      "Loss 261.64224 75 17\n",
      "Training Accuracy 0.575\n",
      "Loss 235.81482 76 17\n",
      "Training Accuracy 0.62\n",
      "Loss 253.84555 77 17\n",
      "Training Accuracy 0.58\n",
      "Loss 248.01033 78 17\n",
      "Training Accuracy 0.605\n",
      "Loss 242.77869 79 17\n",
      "Training Accuracy 0.535\n",
      "Loss 261.3557 80 17\n",
      "Training Accuracy 0.595\n",
      "Loss 243.03232 81 17\n",
      "Training Accuracy 0.585\n",
      "Loss 241.00851 82 17\n",
      "Training Accuracy 0.6\n",
      "Loss 241.9665 83 17\n",
      "Training Accuracy 0.6\n",
      "Loss 283.90146 84 17\n",
      "Training Accuracy 0.545\n",
      "Loss 248.78264 85 17\n",
      "Training Accuracy 0.535\n",
      "Loss 249.33746 86 17\n",
      "Training Accuracy 0.62\n",
      "Loss 298.40527 87 17\n",
      "Training Accuracy 0.55\n",
      "Loss 273.9756 88 17\n",
      "Training Accuracy 0.57\n",
      "Loss 250.19781 89 17\n",
      "Training Accuracy 0.625\n",
      "Loss 254.95317 90 17\n",
      "Training Accuracy 0.54\n",
      "Loss 256.7129 91 17\n",
      "Training Accuracy 0.575\n",
      "Loss 253.95815 92 17\n",
      "Training Accuracy 0.62\n",
      "Loss 253.36841 93 17\n",
      "Training Accuracy 0.595\n",
      "Loss 257.0415 94 17\n",
      "Training Accuracy 0.54\n",
      "Loss 232.92967 95 17\n",
      "Training Accuracy 0.595\n",
      "Loss 248.84132 96 17\n",
      "Training Accuracy 0.605\n",
      "Loss 263.3808 97 17\n",
      "Training Accuracy 0.565\n",
      "Loss 242.84721 98 17\n",
      "Training Accuracy 0.55\n",
      "Loss 244.34605 99 17\n",
      "Training Accuracy 0.615\n",
      "Loss 261.6074 100 17\n",
      "Training Accuracy 0.58\n",
      "Loss 262.84247 101 17\n",
      "Training Accuracy 0.575\n",
      "Loss 225.55956 102 17\n",
      "Training Accuracy 0.57\n",
      "Loss 247.63133 103 17\n",
      "Training Accuracy 0.55\n",
      "Loss 245.8379 104 17\n",
      "Training Accuracy 0.58\n",
      "Loss 258.28772 105 17\n",
      "Training Accuracy 0.565\n",
      "Loss 246.89249 106 17\n",
      "Training Accuracy 0.615\n",
      "Loss 253.43437 107 17\n",
      "Training Accuracy 0.56\n",
      "Loss 251.81181 108 17\n",
      "Training Accuracy 0.575\n",
      "Loss 243.2822 109 17\n",
      "Training Accuracy 0.565\n",
      "Loss 262.92142 110 17\n",
      "Training Accuracy 0.56\n",
      "Loss 257.47205 111 17\n",
      "Training Accuracy 0.555\n",
      "Loss 275.7346 112 17\n",
      "Training Accuracy 0.585\n",
      "Loss 284.86826 113 17\n",
      "Training Accuracy 0.545\n",
      "Loss 246.5174 114 17\n",
      "Training Accuracy 0.57\n",
      "Loss 282.82205 115 17\n",
      "Training Accuracy 0.545\n",
      "Loss 282.0589 116 17\n",
      "Training Accuracy 0.57\n",
      "Loss 218.62581 117 17\n",
      "Training Accuracy 0.66\n",
      "Loss 260.90546 118 17\n",
      "Training Accuracy 0.595\n",
      "Loss 294.1308 119 17\n",
      "Training Accuracy 0.45\n",
      "Loss 275.02008 120 17\n",
      "Training Accuracy 0.525\n",
      "Loss 265.93814 121 17\n",
      "Training Accuracy 0.57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 228.37532 122 17\n",
      "Training Accuracy 0.65\n",
      "Loss 246.20987 123 17\n",
      "Training Accuracy 0.6\n",
      "Loss 249.80237 124 17\n",
      "Training Accuracy 0.62\n",
      "Loss 231.59116 125 17\n",
      "Training Accuracy 0.635\n",
      "Loss 287.417 126 17\n",
      "Training Accuracy 0.505\n",
      "Loss 251.85413 127 17\n",
      "Training Accuracy 0.55\n",
      "Loss 255.11748 128 17\n",
      "Training Accuracy 0.58\n",
      "Loss 231.4746 129 17\n",
      "Training Accuracy 0.65\n",
      "Loss 237.7518 130 17\n",
      "Training Accuracy 0.585\n",
      "Loss 229.8802 131 17\n",
      "Training Accuracy 0.62\n",
      "Loss 233.56985 132 17\n",
      "Training Accuracy 0.585\n",
      "Loss 238.4817 133 17\n",
      "Training Accuracy 0.645\n",
      "Loss 239.28944 134 17\n",
      "Training Accuracy 0.61\n",
      "Loss 230.88177 135 17\n",
      "Training Accuracy 0.6\n",
      "Loss 271.79172 136 17\n",
      "Training Accuracy 0.55\n",
      "Loss 271.9569 137 17\n",
      "Training Accuracy 0.575\n",
      "Loss 238.5651 138 17\n",
      "Training Accuracy 0.59\n",
      "Loss 276.62457 139 17\n",
      "Training Accuracy 0.58\n",
      "Loss 215.77359 140 17\n",
      "Training Accuracy 0.64\n",
      "Loss 267.90253 141 17\n",
      "Training Accuracy 0.555\n",
      "Loss 256.5369 142 17\n",
      "Training Accuracy 0.57\n",
      "Loss 218.13535 143 17\n",
      "Training Accuracy 0.63\n",
      "Loss 256.04517 144 17\n",
      "Training Accuracy 0.595\n",
      "Loss 244.4781 145 17\n",
      "Training Accuracy 0.585\n",
      "Loss 265.6466 146 17\n",
      "Training Accuracy 0.535\n",
      "Loss 246.69083 147 17\n",
      "Training Accuracy 0.63\n",
      "Loss 255.32092 148 17\n",
      "Training Accuracy 0.535\n",
      "Loss 245.12167 149 17\n",
      "Training Accuracy 0.59\n",
      "Loss 234.2151 150 17\n",
      "Training Accuracy 0.635\n",
      "Loss 264.63687 151 17\n",
      "Training Accuracy 0.56\n",
      "Loss 262.56403 152 17\n",
      "Training Accuracy 0.59\n",
      "Loss 248.19904 153 17\n",
      "Training Accuracy 0.565\n",
      "Loss 232.49895 154 17\n",
      "Training Accuracy 0.635\n",
      "Loss 242.94514 155 17\n",
      "Training Accuracy 0.58\n",
      "Loss 260.05975 156 17\n",
      "Training Accuracy 0.57\n",
      "Loss 222.30273 157 17\n",
      "Training Accuracy 0.565\n",
      "Loss 247.65164 158 17\n",
      "Training Accuracy 0.6\n",
      "Loss 280.5338 159 17\n",
      "Training Accuracy 0.545\n",
      "Loss 260.2312 160 17\n",
      "Training Accuracy 0.63\n",
      "Loss 284.26425 161 17\n",
      "Training Accuracy 0.5\n",
      "Loss 246.86653 162 17\n",
      "Training Accuracy 0.585\n",
      "Loss 272.88513 163 17\n",
      "Training Accuracy 0.545\n",
      "Loss 226.69455 164 17\n",
      "Training Accuracy 0.595\n",
      "Loss 242.92358 165 17\n",
      "Training Accuracy 0.585\n",
      "Loss 254.64587 166 17\n",
      "Training Accuracy 0.625\n",
      "Loss 204.0468 167 17\n",
      "Training Accuracy 0.66\n",
      "Loss 267.4051 168 17\n",
      "Training Accuracy 0.575\n",
      "Loss 240.05759 169 17\n",
      "Training Accuracy 0.6\n",
      "Loss 236.99588 170 17\n",
      "Training Accuracy 0.615\n",
      "Loss 269.64035 171 17\n",
      "Training Accuracy 0.59\n",
      "Loss 232.11626 172 17\n",
      "Training Accuracy 0.6\n",
      "Loss 283.7045 173 17\n",
      "Training Accuracy 0.57\n",
      "Loss 209.50363 174 17\n",
      "Training Accuracy 0.615\n",
      "Loss 222.50108 175 17\n",
      "Training Accuracy 0.665\n",
      "Loss 214.09717 176 17\n",
      "Training Accuracy 0.675\n",
      "Loss 290.0882 177 17\n",
      "Training Accuracy 0.5\n",
      "Loss 227.77982 178 17\n",
      "Training Accuracy 0.615\n",
      "Loss 251.74751 179 17\n",
      "Training Accuracy 0.61\n",
      "Loss 265.42624 180 17\n",
      "Training Accuracy 0.575\n",
      "Loss 236.32037 181 17\n",
      "Training Accuracy 0.61\n",
      "Loss 265.90082 182 17\n",
      "Training Accuracy 0.535\n",
      "Loss 267.0433 183 17\n",
      "Training Accuracy 0.535\n",
      "Loss 229.81735 184 17\n",
      "Training Accuracy 0.65\n",
      "Loss 233.6729 185 17\n",
      "Training Accuracy 0.625\n",
      "Loss 233.51059 186 17\n",
      "Training Accuracy 0.605\n",
      "Loss 290.6626 187 17\n",
      "Training Accuracy 0.525\n",
      "Loss 264.11646 188 17\n",
      "Training Accuracy 0.595\n",
      "Loss 254.5294 189 17\n",
      "Training Accuracy 0.58\n",
      "Loss 233.32565 190 17\n",
      "Training Accuracy 0.635\n",
      "Loss 247.08151 191 17\n",
      "Training Accuracy 0.605\n",
      "Loss 257.5218 192 17\n",
      "Training Accuracy 0.575\n",
      "Loss 239.45477 193 17\n",
      "Training Accuracy 0.61\n",
      "Loss 239.01115 194 17\n",
      "Training Accuracy 0.62\n",
      "Loss 236.08028 195 17\n",
      "Training Accuracy 0.605\n",
      "Loss 235.34442 196 17\n",
      "Training Accuracy 0.63\n",
      "Loss 247.54521 197 17\n",
      "Training Accuracy 0.62\n",
      "Loss 232.96376 198 17\n",
      "Training Accuracy 0.575\n",
      "Loss 203.72404 199 17\n",
      "Training Accuracy 0.665\n",
      "Loss 263.76385 200 17\n",
      "Training Accuracy 0.55\n",
      "Loss 227.85909 201 17\n",
      "Training Accuracy 0.64\n",
      "Loss 231.3691 202 17\n",
      "Training Accuracy 0.595\n",
      "Loss 246.8754 203 17\n",
      "Training Accuracy 0.6\n",
      "Loss 250.97081 204 17\n",
      "Training Accuracy 0.52\n",
      "Loss 259.65726 205 17\n",
      "Training Accuracy 0.615\n",
      "Loss 254.03497 206 17\n",
      "Training Accuracy 0.585\n",
      "Loss 240.35027 207 17\n",
      "Training Accuracy 0.58\n",
      "Loss 277.34592 208 17\n",
      "Training Accuracy 0.57\n",
      "Loss 269.27167 209 17\n",
      "Training Accuracy 0.59\n",
      "Loss 223.13225 210 17\n",
      "Training Accuracy 0.615\n",
      "Loss 248.92435 211 17\n",
      "Training Accuracy 0.6\n",
      "Loss 226.17386 212 17\n",
      "Training Accuracy 0.61\n",
      "Loss 284.38 213 17\n",
      "Training Accuracy 0.55\n",
      "Loss 254.71758 214 17\n",
      "Training Accuracy 0.575\n",
      "Loss 271.91516 215 17\n",
      "Training Accuracy 0.515\n",
      "Loss 272.6629 216 17\n",
      "Training Accuracy 0.585\n",
      "Loss 246.19511 217 17\n",
      "Training Accuracy 0.56\n",
      "Loss 268.566 218 17\n",
      "Training Accuracy 0.545\n",
      "Loss 241.14778 219 17\n",
      "Training Accuracy 0.615\n",
      "Loss 244.84268 220 17\n",
      "Training Accuracy 0.625\n",
      "Loss 249.80537 221 17\n",
      "Training Accuracy 0.605\n",
      "Loss 246.19789 222 17\n",
      "Training Accuracy 0.575\n",
      "Loss 264.38895 223 17\n",
      "Training Accuracy 0.565\n",
      "Loss 266.8263 224 17\n",
      "Training Accuracy 0.575\n",
      "Loss 272.33405 225 17\n",
      "Training Accuracy 0.56\n",
      "Loss 218.40889 226 17\n",
      "Training Accuracy 0.59\n",
      "Loss 281.88318 227 17\n",
      "Training Accuracy 0.56\n",
      "Loss 286.54163 228 17\n",
      "Training Accuracy 0.545\n",
      "Loss 244.73357 229 17\n",
      "Training Accuracy 0.62\n",
      "Loss 249.00105 230 17\n",
      "Training Accuracy 0.585\n",
      "Loss 215.3449 231 17\n",
      "Training Accuracy 0.665\n",
      "Loss 244.11588 232 17\n",
      "Training Accuracy 0.575\n",
      "Loss 277.58398 233 17\n",
      "Training Accuracy 0.5\n",
      "Loss 248.92557 234 17\n",
      "Training Accuracy 0.57\n",
      "Loss 260.68594 235 17\n",
      "Training Accuracy 0.52\n",
      "Loss 215.28629 236 17\n",
      "Training Accuracy 0.615\n",
      "Loss 258.73776 237 17\n",
      "Training Accuracy 0.555\n",
      "Loss 246.9985 238 17\n",
      "Training Accuracy 0.55\n",
      "Loss 270.60736 239 17\n",
      "Training Accuracy 0.57\n",
      "Loss 246.65463 240 17\n",
      "Training Accuracy 0.57\n",
      "Loss 279.81216 241 17\n",
      "Training Accuracy 0.54\n",
      "Loss 238.78433 242 17\n",
      "Training Accuracy 0.615\n",
      "Loss 216.61302 243 17\n",
      "Training Accuracy 0.66\n",
      "Loss 260.76828 244 17\n",
      "Training Accuracy 0.525\n",
      "Loss 246.62523 245 17\n",
      "Training Accuracy 0.58\n",
      "Loss 257.64047 246 17\n",
      "Training Accuracy 0.595\n",
      "Loss 205.49611 247 17\n",
      "Training Accuracy 0.63\n",
      "Loss 234.29512 248 17\n",
      "Training Accuracy 0.615\n",
      "Loss 258.14154 249 17\n",
      "Training Accuracy 0.515\n",
      "Loss 256.3893 250 17\n",
      "Training Accuracy 0.58\n",
      "Loss 257.8707 251 17\n",
      "Training Accuracy 0.555\n",
      "Loss 220.13145 252 17\n",
      "Training Accuracy 0.63\n",
      "Loss 228.6329 253 17\n",
      "Training Accuracy 0.625\n",
      "Loss 245.06725 254 17\n",
      "Training Accuracy 0.585\n",
      "Loss 220.59142 255 17\n",
      "Training Accuracy 0.58\n",
      "Loss 257.9774 256 17\n",
      "Training Accuracy 0.57\n",
      "Loss 239.09953 257 17\n",
      "Training Accuracy 0.61\n",
      "Loss 246.56012 258 17\n",
      "Training Accuracy 0.575\n",
      "Loss 252.50508 259 17\n",
      "Training Accuracy 0.545\n",
      "Loss 216.66527 260 17\n",
      "Training Accuracy 0.655\n",
      "Loss 258.1991 261 17\n",
      "Training Accuracy 0.585\n",
      "Loss 243.31435 262 17\n",
      "Training Accuracy 0.555\n",
      "Loss 315.32254 263 17\n",
      "Training Accuracy 0.505\n",
      "Loss 269.45657 264 17\n",
      "Training Accuracy 0.605\n",
      "Loss 238.34087 265 17\n",
      "Training Accuracy 0.61\n",
      "Loss 234.02531 266 17\n",
      "Training Accuracy 0.6\n",
      "Loss 272.32632 267 17\n",
      "Training Accuracy 0.535\n",
      "Loss 267.5902 268 17\n",
      "Training Accuracy 0.6\n",
      "Loss 222.38667 269 17\n",
      "Training Accuracy 0.62\n",
      "Loss 222.04906 270 17\n",
      "Training Accuracy 0.645\n",
      "Loss 280.53342 271 17\n",
      "Training Accuracy 0.55\n",
      "Loss 246.72038 272 17\n",
      "Training Accuracy 0.625\n",
      "Loss 257.2746 273 17\n",
      "Training Accuracy 0.555\n",
      "Loss 226.70964 274 17\n",
      "Training Accuracy 0.64\n",
      "Loss 258.57434 275 17\n",
      "Training Accuracy 0.525\n",
      "Loss 226.4082 276 17\n",
      "Training Accuracy 0.615\n",
      "Loss 271.91888 277 17\n",
      "Training Accuracy 0.535\n",
      "Loss 225.2249 278 17\n",
      "Training Accuracy 0.63\n",
      "Loss 239.05344 279 17\n",
      "Training Accuracy 0.625\n",
      "Loss 231.79944 280 17\n",
      "Training Accuracy 0.615\n",
      "Loss 233.29788 281 17\n",
      "Training Accuracy 0.615\n",
      "Loss 244.67358 282 17\n",
      "Training Accuracy 0.575\n",
      "Loss 237.80136 283 17\n",
      "Training Accuracy 0.62\n",
      "Loss 222.10066 284 17\n",
      "Training Accuracy 0.65\n",
      "Loss 279.27347 285 17\n",
      "Training Accuracy 0.525\n",
      "Loss 254.1401 286 17\n",
      "Training Accuracy 0.575\n",
      "Loss 229.99884 287 17\n",
      "Training Accuracy 0.68\n",
      "Loss 251.12546 288 17\n",
      "Training Accuracy 0.62\n",
      "Loss 242.37689 289 17\n",
      "Training Accuracy 0.61\n",
      "Loss 252.92291 290 17\n",
      "Training Accuracy 0.565\n",
      "Loss 253.01636 291 17\n",
      "Training Accuracy 0.575\n",
      "Loss 152.51878 292 17\n",
      "Training Accuracy 0.5984849\n",
      "Loss 213.27306 1 18\n",
      "Training Accuracy 0.61\n",
      "Loss 243.99564 2 18\n",
      "Training Accuracy 0.585\n",
      "Loss 236.08827 3 18\n",
      "Training Accuracy 0.625\n",
      "Loss 254.85979 4 18\n",
      "Training Accuracy 0.59\n",
      "Loss 217.46452 5 18\n",
      "Training Accuracy 0.68\n",
      "Loss 255.6973 6 18\n",
      "Training Accuracy 0.58\n",
      "Loss 245.6409 7 18\n",
      "Training Accuracy 0.63\n",
      "Loss 275.50604 8 18\n",
      "Training Accuracy 0.58\n",
      "Loss 230.94168 9 18\n",
      "Training Accuracy 0.65\n",
      "Loss 241.646 10 18\n",
      "Training Accuracy 0.64\n",
      "Loss 278.09195 11 18\n",
      "Training Accuracy 0.62\n",
      "Loss 236.20744 12 18\n",
      "Training Accuracy 0.6\n",
      "Loss 238.50694 13 18\n",
      "Training Accuracy 0.585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 269.42813 14 18\n",
      "Training Accuracy 0.555\n",
      "Loss 230.61536 15 18\n",
      "Training Accuracy 0.6\n",
      "Loss 283.16998 16 18\n",
      "Training Accuracy 0.57\n",
      "Loss 216.28409 17 18\n",
      "Training Accuracy 0.665\n",
      "Loss 240.04323 18 18\n",
      "Training Accuracy 0.6\n",
      "Loss 221.11285 19 18\n",
      "Training Accuracy 0.59\n",
      "Loss 244.9228 20 18\n",
      "Training Accuracy 0.605\n",
      "Loss 236.28662 21 18\n",
      "Training Accuracy 0.585\n",
      "Loss 251.13237 22 18\n",
      "Training Accuracy 0.6\n",
      "Loss 254.05582 23 18\n",
      "Training Accuracy 0.61\n",
      "Loss 267.03278 24 18\n",
      "Training Accuracy 0.565\n",
      "Loss 247.14326 25 18\n",
      "Training Accuracy 0.585\n",
      "Loss 249.50285 26 18\n",
      "Training Accuracy 0.615\n",
      "Loss 233.00957 27 18\n",
      "Training Accuracy 0.605\n",
      "Loss 236.37245 28 18\n",
      "Training Accuracy 0.61\n",
      "Loss 246.37505 29 18\n",
      "Training Accuracy 0.58\n",
      "Loss 256.81268 30 18\n",
      "Training Accuracy 0.6\n",
      "Loss 262.97845 31 18\n",
      "Training Accuracy 0.61\n",
      "Loss 256.22675 32 18\n",
      "Training Accuracy 0.55\n",
      "Loss 246.98499 33 18\n",
      "Training Accuracy 0.6\n",
      "Loss 214.90141 34 18\n",
      "Training Accuracy 0.645\n",
      "Loss 226.58742 35 18\n",
      "Training Accuracy 0.585\n",
      "Loss 243.85907 36 18\n",
      "Training Accuracy 0.635\n",
      "Loss 241.6565 37 18\n",
      "Training Accuracy 0.615\n",
      "Loss 252.76346 38 18\n",
      "Training Accuracy 0.61\n",
      "Loss 218.87996 39 18\n",
      "Training Accuracy 0.655\n",
      "Loss 232.63866 40 18\n",
      "Training Accuracy 0.625\n",
      "Loss 241.5814 41 18\n",
      "Training Accuracy 0.575\n",
      "Loss 280.00314 42 18\n",
      "Training Accuracy 0.515\n",
      "Loss 227.63116 43 18\n",
      "Training Accuracy 0.615\n",
      "Loss 225.08664 44 18\n",
      "Training Accuracy 0.63\n",
      "Loss 241.92522 45 18\n",
      "Training Accuracy 0.6\n",
      "Loss 268.78818 46 18\n",
      "Training Accuracy 0.53\n",
      "Loss 230.24045 47 18\n",
      "Training Accuracy 0.63\n",
      "Loss 222.82425 48 18\n",
      "Training Accuracy 0.62\n",
      "Loss 238.9003 49 18\n",
      "Training Accuracy 0.625\n",
      "Loss 267.42493 50 18\n",
      "Training Accuracy 0.595\n",
      "Loss 226.54367 51 18\n",
      "Training Accuracy 0.645\n",
      "Loss 233.30254 52 18\n",
      "Training Accuracy 0.645\n",
      "Loss 221.78911 53 18\n",
      "Training Accuracy 0.64\n",
      "Loss 262.89706 54 18\n",
      "Training Accuracy 0.54\n",
      "Loss 255.54683 55 18\n",
      "Training Accuracy 0.56\n",
      "Loss 252.2955 56 18\n",
      "Training Accuracy 0.55\n",
      "Loss 227.44853 57 18\n",
      "Training Accuracy 0.64\n",
      "Loss 220.15138 58 18\n",
      "Training Accuracy 0.64\n",
      "Loss 251.88342 59 18\n",
      "Training Accuracy 0.57\n",
      "Loss 243.34529 60 18\n",
      "Training Accuracy 0.625\n",
      "Loss 249.93506 61 18\n",
      "Training Accuracy 0.58\n",
      "Loss 238.1994 62 18\n",
      "Training Accuracy 0.62\n",
      "Loss 252.78581 63 18\n",
      "Training Accuracy 0.58\n",
      "Loss 243.37491 64 18\n",
      "Training Accuracy 0.615\n",
      "Loss 246.80312 65 18\n",
      "Training Accuracy 0.565\n",
      "Loss 225.41495 66 18\n",
      "Training Accuracy 0.645\n",
      "Loss 250.20416 67 18\n",
      "Training Accuracy 0.605\n",
      "Loss 241.4358 68 18\n",
      "Training Accuracy 0.575\n",
      "Loss 244.49715 69 18\n",
      "Training Accuracy 0.615\n",
      "Loss 245.50188 70 18\n",
      "Training Accuracy 0.63\n",
      "Loss 246.29279 71 18\n",
      "Training Accuracy 0.64\n",
      "Loss 247.05045 72 18\n",
      "Training Accuracy 0.59\n",
      "Loss 251.2313 73 18\n",
      "Training Accuracy 0.58\n",
      "Loss 280.4149 74 18\n",
      "Training Accuracy 0.565\n",
      "Loss 247.38857 75 18\n",
      "Training Accuracy 0.63\n",
      "Loss 228.02832 76 18\n",
      "Training Accuracy 0.605\n",
      "Loss 251.21118 77 18\n",
      "Training Accuracy 0.605\n",
      "Loss 243.6868 78 18\n",
      "Training Accuracy 0.58\n",
      "Loss 240.5715 79 18\n",
      "Training Accuracy 0.575\n",
      "Loss 250.43611 80 18\n",
      "Training Accuracy 0.565\n",
      "Loss 239.81998 81 18\n",
      "Training Accuracy 0.555\n",
      "Loss 235.47403 82 18\n",
      "Training Accuracy 0.64\n",
      "Loss 243.74352 83 18\n",
      "Training Accuracy 0.61\n",
      "Loss 277.6071 84 18\n",
      "Training Accuracy 0.54\n",
      "Loss 247.3202 85 18\n",
      "Training Accuracy 0.58\n",
      "Loss 254.15111 86 18\n",
      "Training Accuracy 0.605\n",
      "Loss 285.5517 87 18\n",
      "Training Accuracy 0.545\n",
      "Loss 279.72296 88 18\n",
      "Training Accuracy 0.54\n",
      "Loss 244.3616 89 18\n",
      "Training Accuracy 0.6\n",
      "Loss 251.47516 90 18\n",
      "Training Accuracy 0.56\n",
      "Loss 244.8972 91 18\n",
      "Training Accuracy 0.57\n",
      "Loss 262.89673 92 18\n",
      "Training Accuracy 0.585\n",
      "Loss 247.04536 93 18\n",
      "Training Accuracy 0.6\n",
      "Loss 254.64235 94 18\n",
      "Training Accuracy 0.56\n",
      "Loss 235.23175 95 18\n",
      "Training Accuracy 0.575\n",
      "Loss 235.12279 96 18\n",
      "Training Accuracy 0.63\n",
      "Loss 257.76755 97 18\n",
      "Training Accuracy 0.55\n",
      "Loss 224.323 98 18\n",
      "Training Accuracy 0.6\n",
      "Loss 245.48007 99 18\n",
      "Training Accuracy 0.575\n",
      "Loss 254.19742 100 18\n",
      "Training Accuracy 0.59\n",
      "Loss 250.62169 101 18\n",
      "Training Accuracy 0.57\n",
      "Loss 216.60397 102 18\n",
      "Training Accuracy 0.625\n",
      "Loss 250.37047 103 18\n",
      "Training Accuracy 0.565\n",
      "Loss 246.72887 104 18\n",
      "Training Accuracy 0.545\n",
      "Loss 250.00761 105 18\n",
      "Training Accuracy 0.555\n",
      "Loss 241.00493 106 18\n",
      "Training Accuracy 0.6\n",
      "Loss 237.12273 107 18\n",
      "Training Accuracy 0.6\n",
      "Loss 253.20506 108 18\n",
      "Training Accuracy 0.56\n",
      "Loss 234.13434 109 18\n",
      "Training Accuracy 0.61\n",
      "Loss 262.4671 110 18\n",
      "Training Accuracy 0.565\n",
      "Loss 258.82724 111 18\n",
      "Training Accuracy 0.565\n",
      "Loss 266.06873 112 18\n",
      "Training Accuracy 0.59\n",
      "Loss 288.79868 113 18\n",
      "Training Accuracy 0.56\n",
      "Loss 235.94978 114 18\n",
      "Training Accuracy 0.61\n",
      "Loss 277.9503 115 18\n",
      "Training Accuracy 0.555\n",
      "Loss 278.48013 116 18\n",
      "Training Accuracy 0.57\n",
      "Loss 199.904 117 18\n",
      "Training Accuracy 0.75\n",
      "Loss 252.60179 118 18\n",
      "Training Accuracy 0.59\n",
      "Loss 305.2345 119 18\n",
      "Training Accuracy 0.465\n",
      "Loss 271.1107 120 18\n",
      "Training Accuracy 0.515\n",
      "Loss 261.43793 121 18\n",
      "Training Accuracy 0.575\n",
      "Loss 220.3635 122 18\n",
      "Training Accuracy 0.595\n",
      "Loss 255.93784 123 18\n",
      "Training Accuracy 0.565\n",
      "Loss 241.75574 124 18\n",
      "Training Accuracy 0.57\n",
      "Loss 222.89433 125 18\n",
      "Training Accuracy 0.65\n",
      "Loss 269.6649 126 18\n",
      "Training Accuracy 0.565\n",
      "Loss 255.19994 127 18\n",
      "Training Accuracy 0.575\n",
      "Loss 242.66342 128 18\n",
      "Training Accuracy 0.6\n",
      "Loss 219.69386 129 18\n",
      "Training Accuracy 0.645\n",
      "Loss 226.0338 130 18\n",
      "Training Accuracy 0.625\n",
      "Loss 217.86206 131 18\n",
      "Training Accuracy 0.66\n",
      "Loss 227.97197 132 18\n",
      "Training Accuracy 0.61\n",
      "Loss 243.36517 133 18\n",
      "Training Accuracy 0.62\n",
      "Loss 229.15804 134 18\n",
      "Training Accuracy 0.63\n",
      "Loss 233.31554 135 18\n",
      "Training Accuracy 0.6\n",
      "Loss 266.22656 136 18\n",
      "Training Accuracy 0.59\n",
      "Loss 258.90927 137 18\n",
      "Training Accuracy 0.59\n",
      "Loss 229.54659 138 18\n",
      "Training Accuracy 0.645\n",
      "Loss 267.43982 139 18\n",
      "Training Accuracy 0.595\n",
      "Loss 205.55049 140 18\n",
      "Training Accuracy 0.67\n",
      "Loss 244.13264 141 18\n",
      "Training Accuracy 0.61\n",
      "Loss 251.4163 142 18\n",
      "Training Accuracy 0.55\n",
      "Loss 218.63628 143 18\n",
      "Training Accuracy 0.645\n",
      "Loss 248.03398 144 18\n",
      "Training Accuracy 0.545\n",
      "Loss 240.17331 145 18\n",
      "Training Accuracy 0.595\n",
      "Loss 254.52365 146 18\n",
      "Training Accuracy 0.58\n",
      "Loss 244.02788 147 18\n",
      "Training Accuracy 0.585\n",
      "Loss 249.63821 148 18\n",
      "Training Accuracy 0.565\n",
      "Loss 245.62643 149 18\n",
      "Training Accuracy 0.615\n",
      "Loss 231.55591 150 18\n",
      "Training Accuracy 0.64\n",
      "Loss 260.68948 151 18\n",
      "Training Accuracy 0.58\n",
      "Loss 258.22305 152 18\n",
      "Training Accuracy 0.6\n",
      "Loss 232.80498 153 18\n",
      "Training Accuracy 0.625\n",
      "Loss 242.15775 154 18\n",
      "Training Accuracy 0.615\n",
      "Loss 236.39026 155 18\n",
      "Training Accuracy 0.63\n",
      "Loss 252.11604 156 18\n",
      "Training Accuracy 0.575\n",
      "Loss 216.8005 157 18\n",
      "Training Accuracy 0.635\n",
      "Loss 239.9813 158 18\n",
      "Training Accuracy 0.625\n",
      "Loss 274.19803 159 18\n",
      "Training Accuracy 0.6\n",
      "Loss 257.5249 160 18\n",
      "Training Accuracy 0.605\n",
      "Loss 271.3992 161 18\n",
      "Training Accuracy 0.51\n",
      "Loss 242.1677 162 18\n",
      "Training Accuracy 0.605\n",
      "Loss 269.49817 163 18\n",
      "Training Accuracy 0.585\n",
      "Loss 213.71532 164 18\n",
      "Training Accuracy 0.61\n",
      "Loss 233.00594 165 18\n",
      "Training Accuracy 0.635\n",
      "Loss 258.08478 166 18\n",
      "Training Accuracy 0.61\n",
      "Loss 210.58052 167 18\n",
      "Training Accuracy 0.61\n",
      "Loss 252.88422 168 18\n",
      "Training Accuracy 0.59\n",
      "Loss 239.852 169 18\n",
      "Training Accuracy 0.57\n",
      "Loss 235.7296 170 18\n",
      "Training Accuracy 0.61\n",
      "Loss 274.49915 171 18\n",
      "Training Accuracy 0.57\n",
      "Loss 232.16586 172 18\n",
      "Training Accuracy 0.575\n",
      "Loss 274.3202 173 18\n",
      "Training Accuracy 0.6\n",
      "Loss 212.26802 174 18\n",
      "Training Accuracy 0.615\n",
      "Loss 215.73993 175 18\n",
      "Training Accuracy 0.65\n",
      "Loss 212.97 176 18\n",
      "Training Accuracy 0.655\n",
      "Loss 275.1539 177 18\n",
      "Training Accuracy 0.555\n",
      "Loss 217.28972 178 18\n",
      "Training Accuracy 0.595\n",
      "Loss 267.03268 179 18\n",
      "Training Accuracy 0.55\n",
      "Loss 257.83646 180 18\n",
      "Training Accuracy 0.505\n",
      "Loss 213.64902 181 18\n",
      "Training Accuracy 0.675\n",
      "Loss 261.22546 182 18\n",
      "Training Accuracy 0.53\n",
      "Loss 262.36398 183 18\n",
      "Training Accuracy 0.535\n",
      "Loss 234.60646 184 18\n",
      "Training Accuracy 0.65\n",
      "Loss 233.19234 185 18\n",
      "Training Accuracy 0.62\n",
      "Loss 234.7659 186 18\n",
      "Training Accuracy 0.605\n",
      "Loss 286.9637 187 18\n",
      "Training Accuracy 0.525\n",
      "Loss 254.42056 188 18\n",
      "Training Accuracy 0.615\n",
      "Loss 241.16748 189 18\n",
      "Training Accuracy 0.605\n",
      "Loss 234.82275 190 18\n",
      "Training Accuracy 0.58\n",
      "Loss 227.1462 191 18\n",
      "Training Accuracy 0.63\n",
      "Loss 259.93512 192 18\n",
      "Training Accuracy 0.545\n",
      "Loss 223.0887 193 18\n",
      "Training Accuracy 0.645\n",
      "Loss 236.9578 194 18\n",
      "Training Accuracy 0.6\n",
      "Loss 226.01683 195 18\n",
      "Training Accuracy 0.645\n",
      "Loss 230.52296 196 18\n",
      "Training Accuracy 0.64\n",
      "Loss 242.98648 197 18\n",
      "Training Accuracy 0.58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 228.20624 198 18\n",
      "Training Accuracy 0.595\n",
      "Loss 197.37328 199 18\n",
      "Training Accuracy 0.675\n",
      "Loss 251.77495 200 18\n",
      "Training Accuracy 0.55\n",
      "Loss 229.88676 201 18\n",
      "Training Accuracy 0.61\n",
      "Loss 223.33679 202 18\n",
      "Training Accuracy 0.585\n",
      "Loss 246.42694 203 18\n",
      "Training Accuracy 0.565\n",
      "Loss 241.69699 204 18\n",
      "Training Accuracy 0.56\n",
      "Loss 266.5494 205 18\n",
      "Training Accuracy 0.56\n",
      "Loss 239.83636 206 18\n",
      "Training Accuracy 0.615\n",
      "Loss 233.80426 207 18\n",
      "Training Accuracy 0.59\n",
      "Loss 255.41656 208 18\n",
      "Training Accuracy 0.61\n",
      "Loss 266.2875 209 18\n",
      "Training Accuracy 0.56\n",
      "Loss 228.90616 210 18\n",
      "Training Accuracy 0.605\n",
      "Loss 252.24768 211 18\n",
      "Training Accuracy 0.615\n",
      "Loss 220.84735 212 18\n",
      "Training Accuracy 0.615\n",
      "Loss 286.34604 213 18\n",
      "Training Accuracy 0.555\n",
      "Loss 245.05348 214 18\n",
      "Training Accuracy 0.585\n",
      "Loss 263.26538 215 18\n",
      "Training Accuracy 0.565\n",
      "Loss 264.008 216 18\n",
      "Training Accuracy 0.55\n",
      "Loss 245.6322 217 18\n",
      "Training Accuracy 0.535\n",
      "Loss 250.20914 218 18\n",
      "Training Accuracy 0.58\n",
      "Loss 241.14406 219 18\n",
      "Training Accuracy 0.615\n",
      "Loss 233.11406 220 18\n",
      "Training Accuracy 0.61\n",
      "Loss 243.63548 221 18\n",
      "Training Accuracy 0.57\n",
      "Loss 247.30377 222 18\n",
      "Training Accuracy 0.57\n",
      "Loss 264.92047 223 18\n",
      "Training Accuracy 0.555\n",
      "Loss 265.73483 224 18\n",
      "Training Accuracy 0.55\n",
      "Loss 266.76202 225 18\n",
      "Training Accuracy 0.565\n",
      "Loss 212.81993 226 18\n",
      "Training Accuracy 0.64\n",
      "Loss 273.0736 227 18\n",
      "Training Accuracy 0.54\n",
      "Loss 270.56967 228 18\n",
      "Training Accuracy 0.585\n",
      "Loss 236.47342 229 18\n",
      "Training Accuracy 0.62\n",
      "Loss 246.85196 230 18\n",
      "Training Accuracy 0.655\n",
      "Loss 212.39583 231 18\n",
      "Training Accuracy 0.655\n",
      "Loss 250.76344 232 18\n",
      "Training Accuracy 0.56\n",
      "Loss 266.022 233 18\n",
      "Training Accuracy 0.53\n",
      "Loss 249.95511 234 18\n",
      "Training Accuracy 0.555\n",
      "Loss 250.15698 235 18\n",
      "Training Accuracy 0.565\n",
      "Loss 225.76286 236 18\n",
      "Training Accuracy 0.62\n",
      "Loss 254.7349 237 18\n",
      "Training Accuracy 0.585\n",
      "Loss 238.33594 238 18\n",
      "Training Accuracy 0.55\n",
      "Loss 264.34213 239 18\n",
      "Training Accuracy 0.56\n",
      "Loss 239.77911 240 18\n",
      "Training Accuracy 0.585\n",
      "Loss 273.8574 241 18\n",
      "Training Accuracy 0.53\n",
      "Loss 228.95186 242 18\n",
      "Training Accuracy 0.655\n",
      "Loss 215.7277 243 18\n",
      "Training Accuracy 0.655\n",
      "Loss 252.29976 244 18\n",
      "Training Accuracy 0.565\n",
      "Loss 244.573 245 18\n",
      "Training Accuracy 0.585\n",
      "Loss 257.87573 246 18\n",
      "Training Accuracy 0.59\n",
      "Loss 210.6707 247 18\n",
      "Training Accuracy 0.595\n",
      "Loss 234.09296 248 18\n",
      "Training Accuracy 0.655\n",
      "Loss 250.2006 249 18\n",
      "Training Accuracy 0.55\n",
      "Loss 258.5918 250 18\n",
      "Training Accuracy 0.555\n",
      "Loss 254.48735 251 18\n",
      "Training Accuracy 0.55\n",
      "Loss 227.92944 252 18\n",
      "Training Accuracy 0.61\n",
      "Loss 225.59015 253 18\n",
      "Training Accuracy 0.61\n",
      "Loss 241.76608 254 18\n",
      "Training Accuracy 0.595\n",
      "Loss 216.5115 255 18\n",
      "Training Accuracy 0.625\n",
      "Loss 263.8614 256 18\n",
      "Training Accuracy 0.565\n",
      "Loss 236.07243 257 18\n",
      "Training Accuracy 0.615\n",
      "Loss 238.09132 258 18\n",
      "Training Accuracy 0.595\n",
      "Loss 252.57368 259 18\n",
      "Training Accuracy 0.585\n",
      "Loss 210.31203 260 18\n",
      "Training Accuracy 0.655\n",
      "Loss 243.60846 261 18\n",
      "Training Accuracy 0.605\n",
      "Loss 237.80104 262 18\n",
      "Training Accuracy 0.585\n",
      "Loss 296.92755 263 18\n",
      "Training Accuracy 0.535\n",
      "Loss 251.37645 264 18\n",
      "Training Accuracy 0.665\n",
      "Loss 227.9749 265 18\n",
      "Training Accuracy 0.65\n",
      "Loss 231.75421 266 18\n",
      "Training Accuracy 0.58\n",
      "Loss 262.24643 267 18\n",
      "Training Accuracy 0.555\n",
      "Loss 264.1573 268 18\n",
      "Training Accuracy 0.535\n",
      "Loss 227.12189 269 18\n",
      "Training Accuracy 0.585\n",
      "Loss 207.23874 270 18\n",
      "Training Accuracy 0.64\n",
      "Loss 261.06625 271 18\n",
      "Training Accuracy 0.55\n",
      "Loss 237.06209 272 18\n",
      "Training Accuracy 0.61\n",
      "Loss 264.65656 273 18\n",
      "Training Accuracy 0.585\n",
      "Loss 230.80751 274 18\n",
      "Training Accuracy 0.59\n",
      "Loss 247.9482 275 18\n",
      "Training Accuracy 0.56\n",
      "Loss 216.86807 276 18\n",
      "Training Accuracy 0.655\n",
      "Loss 259.3243 277 18\n",
      "Training Accuracy 0.585\n",
      "Loss 227.87466 278 18\n",
      "Training Accuracy 0.63\n",
      "Loss 237.93034 279 18\n",
      "Training Accuracy 0.58\n",
      "Loss 231.55405 280 18\n",
      "Training Accuracy 0.605\n",
      "Loss 233.79834 281 18\n",
      "Training Accuracy 0.61\n",
      "Loss 235.73358 282 18\n",
      "Training Accuracy 0.62\n",
      "Loss 228.58812 283 18\n",
      "Training Accuracy 0.66\n",
      "Loss 215.34744 284 18\n",
      "Training Accuracy 0.675\n",
      "Loss 270.67154 285 18\n",
      "Training Accuracy 0.575\n",
      "Loss 241.5329 286 18\n",
      "Training Accuracy 0.625\n",
      "Loss 227.17871 287 18\n",
      "Training Accuracy 0.645\n",
      "Loss 243.0086 288 18\n",
      "Training Accuracy 0.63\n",
      "Loss 233.3498 289 18\n",
      "Training Accuracy 0.635\n",
      "Loss 249.37222 290 18\n",
      "Training Accuracy 0.585\n",
      "Loss 240.23938 291 18\n",
      "Training Accuracy 0.59\n",
      "Loss 155.92749 292 18\n",
      "Training Accuracy 0.59090906\n",
      "Loss 202.52591 1 19\n",
      "Training Accuracy 0.63\n",
      "Loss 246.15201 2 19\n",
      "Training Accuracy 0.55\n",
      "Loss 226.89455 3 19\n",
      "Training Accuracy 0.645\n",
      "Loss 243.23459 4 19\n",
      "Training Accuracy 0.63\n",
      "Loss 205.82935 5 19\n",
      "Training Accuracy 0.63\n",
      "Loss 250.24539 6 19\n",
      "Training Accuracy 0.58\n",
      "Loss 246.64615 7 19\n",
      "Training Accuracy 0.58\n",
      "Loss 273.2377 8 19\n",
      "Training Accuracy 0.58\n",
      "Loss 228.88881 9 19\n",
      "Training Accuracy 0.595\n",
      "Loss 247.76968 10 19\n",
      "Training Accuracy 0.585\n",
      "Loss 267.44824 11 19\n",
      "Training Accuracy 0.645\n",
      "Loss 235.79198 12 19\n",
      "Training Accuracy 0.6\n",
      "Loss 238.81377 13 19\n",
      "Training Accuracy 0.59\n",
      "Loss 250.96657 14 19\n",
      "Training Accuracy 0.575\n",
      "Loss 222.51471 15 19\n",
      "Training Accuracy 0.595\n",
      "Loss 281.39606 16 19\n",
      "Training Accuracy 0.54\n",
      "Loss 220.59149 17 19\n",
      "Training Accuracy 0.62\n",
      "Loss 231.93872 18 19\n",
      "Training Accuracy 0.63\n",
      "Loss 226.84726 19 19\n",
      "Training Accuracy 0.585\n",
      "Loss 234.77321 20 19\n",
      "Training Accuracy 0.635\n",
      "Loss 236.24779 21 19\n",
      "Training Accuracy 0.595\n",
      "Loss 245.19865 22 19\n",
      "Training Accuracy 0.585\n",
      "Loss 251.64577 23 19\n",
      "Training Accuracy 0.595\n",
      "Loss 240.74365 24 19\n",
      "Training Accuracy 0.59\n",
      "Loss 233.27472 25 19\n",
      "Training Accuracy 0.575\n",
      "Loss 256.69232 26 19\n",
      "Training Accuracy 0.545\n",
      "Loss 234.97581 27 19\n",
      "Training Accuracy 0.62\n",
      "Loss 240.60268 28 19\n",
      "Training Accuracy 0.61\n",
      "Loss 243.47557 29 19\n",
      "Training Accuracy 0.56\n",
      "Loss 250.45561 30 19\n",
      "Training Accuracy 0.59\n",
      "Loss 257.99167 31 19\n",
      "Training Accuracy 0.57\n",
      "Loss 245.44707 32 19\n",
      "Training Accuracy 0.565\n",
      "Loss 252.83981 33 19\n",
      "Training Accuracy 0.61\n",
      "Loss 204.80746 34 19\n",
      "Training Accuracy 0.68\n",
      "Loss 218.17941 35 19\n",
      "Training Accuracy 0.585\n",
      "Loss 246.0497 36 19\n",
      "Training Accuracy 0.535\n",
      "Loss 228.37744 37 19\n",
      "Training Accuracy 0.61\n",
      "Loss 249.18878 38 19\n",
      "Training Accuracy 0.61\n",
      "Loss 209.892 39 19\n",
      "Training Accuracy 0.625\n",
      "Loss 219.67444 40 19\n",
      "Training Accuracy 0.675\n",
      "Loss 228.5657 41 19\n",
      "Training Accuracy 0.61\n",
      "Loss 277.89804 42 19\n",
      "Training Accuracy 0.56\n",
      "Loss 238.29158 43 19\n",
      "Training Accuracy 0.605\n",
      "Loss 225.63232 44 19\n",
      "Training Accuracy 0.595\n",
      "Loss 234.59328 45 19\n",
      "Training Accuracy 0.62\n",
      "Loss 271.39465 46 19\n",
      "Training Accuracy 0.54\n",
      "Loss 224.94963 47 19\n",
      "Training Accuracy 0.635\n",
      "Loss 210.90515 48 19\n",
      "Training Accuracy 0.64\n",
      "Loss 249.19563 49 19\n",
      "Training Accuracy 0.58\n",
      "Loss 270.39532 50 19\n",
      "Training Accuracy 0.535\n",
      "Loss 216.48137 51 19\n",
      "Training Accuracy 0.64\n",
      "Loss 230.82231 52 19\n",
      "Training Accuracy 0.61\n",
      "Loss 215.58954 53 19\n",
      "Training Accuracy 0.61\n",
      "Loss 268.24127 54 19\n",
      "Training Accuracy 0.55\n",
      "Loss 258.8114 55 19\n",
      "Training Accuracy 0.53\n",
      "Loss 242.67989 56 19\n",
      "Training Accuracy 0.605\n",
      "Loss 226.48679 57 19\n",
      "Training Accuracy 0.62\n",
      "Loss 216.87703 58 19\n",
      "Training Accuracy 0.63\n",
      "Loss 261.3543 59 19\n",
      "Training Accuracy 0.555\n",
      "Loss 247.73576 60 19\n",
      "Training Accuracy 0.59\n",
      "Loss 233.35294 61 19\n",
      "Training Accuracy 0.62\n",
      "Loss 237.56535 62 19\n",
      "Training Accuracy 0.59\n",
      "Loss 249.12263 63 19\n",
      "Training Accuracy 0.62\n",
      "Loss 235.46988 64 19\n",
      "Training Accuracy 0.625\n",
      "Loss 261.6057 65 19\n",
      "Training Accuracy 0.545\n",
      "Loss 229.88544 66 19\n",
      "Training Accuracy 0.61\n",
      "Loss 251.49866 67 19\n",
      "Training Accuracy 0.59\n",
      "Loss 220.41931 68 19\n",
      "Training Accuracy 0.58\n",
      "Loss 245.03186 69 19\n",
      "Training Accuracy 0.625\n",
      "Loss 247.01169 70 19\n",
      "Training Accuracy 0.615\n",
      "Loss 232.30968 71 19\n",
      "Training Accuracy 0.635\n",
      "Loss 237.27034 72 19\n",
      "Training Accuracy 0.615\n",
      "Loss 243.85391 73 19\n",
      "Training Accuracy 0.56\n",
      "Loss 257.3917 74 19\n",
      "Training Accuracy 0.605\n",
      "Loss 241.63992 75 19\n",
      "Training Accuracy 0.565\n",
      "Loss 215.5425 76 19\n",
      "Training Accuracy 0.655\n",
      "Loss 246.34467 77 19\n",
      "Training Accuracy 0.635\n",
      "Loss 233.70277 78 19\n",
      "Training Accuracy 0.62\n",
      "Loss 233.25974 79 19\n",
      "Training Accuracy 0.595\n",
      "Loss 254.16289 80 19\n",
      "Training Accuracy 0.57\n",
      "Loss 227.35352 81 19\n",
      "Training Accuracy 0.585\n",
      "Loss 237.6997 82 19\n",
      "Training Accuracy 0.63\n",
      "Loss 236.93161 83 19\n",
      "Training Accuracy 0.615\n",
      "Loss 265.69263 84 19\n",
      "Training Accuracy 0.55\n",
      "Loss 243.97577 85 19\n",
      "Training Accuracy 0.565\n",
      "Loss 255.55223 86 19\n",
      "Training Accuracy 0.595\n",
      "Loss 288.29034 87 19\n",
      "Training Accuracy 0.58\n",
      "Loss 271.1075 88 19\n",
      "Training Accuracy 0.545\n",
      "Loss 237.88979 89 19\n",
      "Training Accuracy 0.605\n",
      "Loss 251.28192 90 19\n",
      "Training Accuracy 0.53\n",
      "Loss 237.59251 91 19\n",
      "Training Accuracy 0.61\n",
      "Loss 253.83943 92 19\n",
      "Training Accuracy 0.605\n",
      "Loss 239.03706 93 19\n",
      "Training Accuracy 0.61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 246.56218 94 19\n",
      "Training Accuracy 0.58\n",
      "Loss 226.73851 95 19\n",
      "Training Accuracy 0.595\n",
      "Loss 244.9958 96 19\n",
      "Training Accuracy 0.59\n",
      "Loss 247.49832 97 19\n",
      "Training Accuracy 0.58\n",
      "Loss 224.94026 98 19\n",
      "Training Accuracy 0.605\n",
      "Loss 223.3891 99 19\n",
      "Training Accuracy 0.62\n",
      "Loss 248.8225 100 19\n",
      "Training Accuracy 0.615\n",
      "Loss 260.60626 101 19\n",
      "Training Accuracy 0.545\n",
      "Loss 215.86214 102 19\n",
      "Training Accuracy 0.62\n",
      "Loss 238.14136 103 19\n",
      "Training Accuracy 0.61\n",
      "Loss 235.63197 104 19\n",
      "Training Accuracy 0.565\n",
      "Loss 248.41539 105 19\n",
      "Training Accuracy 0.585\n",
      "Loss 248.49959 106 19\n",
      "Training Accuracy 0.61\n",
      "Loss 244.9409 107 19\n",
      "Training Accuracy 0.58\n",
      "Loss 248.53685 108 19\n",
      "Training Accuracy 0.6\n",
      "Loss 242.16275 109 19\n",
      "Training Accuracy 0.57\n",
      "Loss 243.76033 110 19\n",
      "Training Accuracy 0.605\n",
      "Loss 246.06935 111 19\n",
      "Training Accuracy 0.575\n",
      "Loss 261.89624 112 19\n",
      "Training Accuracy 0.59\n",
      "Loss 278.3136 113 19\n",
      "Training Accuracy 0.56\n",
      "Loss 245.03789 114 19\n",
      "Training Accuracy 0.555\n",
      "Loss 257.8424 115 19\n",
      "Training Accuracy 0.63\n",
      "Loss 271.59143 116 19\n",
      "Training Accuracy 0.595\n",
      "Loss 206.05637 117 19\n",
      "Training Accuracy 0.705\n",
      "Loss 248.21346 118 19\n",
      "Training Accuracy 0.615\n",
      "Loss 292.0907 119 19\n",
      "Training Accuracy 0.5\n",
      "Loss 263.60464 120 19\n",
      "Training Accuracy 0.58\n",
      "Loss 265.73 121 19\n",
      "Training Accuracy 0.595\n",
      "Loss 227.7262 122 19\n",
      "Training Accuracy 0.625\n",
      "Loss 248.91162 123 19\n",
      "Training Accuracy 0.57\n",
      "Loss 236.3269 124 19\n",
      "Training Accuracy 0.6\n",
      "Loss 207.83485 125 19\n",
      "Training Accuracy 0.66\n",
      "Loss 262.20084 126 19\n",
      "Training Accuracy 0.52\n",
      "Loss 245.90587 127 19\n",
      "Training Accuracy 0.58\n",
      "Loss 235.69017 128 19\n",
      "Training Accuracy 0.59\n",
      "Loss 220.82574 129 19\n",
      "Training Accuracy 0.635\n",
      "Loss 235.48798 130 19\n",
      "Training Accuracy 0.59\n",
      "Loss 222.33064 131 19\n",
      "Training Accuracy 0.65\n",
      "Loss 222.20616 132 19\n",
      "Training Accuracy 0.645\n",
      "Loss 235.15196 133 19\n",
      "Training Accuracy 0.625\n",
      "Loss 219.09526 134 19\n",
      "Training Accuracy 0.645\n",
      "Loss 227.56654 135 19\n",
      "Training Accuracy 0.615\n",
      "Loss 261.5424 136 19\n",
      "Training Accuracy 0.595\n",
      "Loss 263.05753 137 19\n",
      "Training Accuracy 0.59\n",
      "Loss 237.16815 138 19\n",
      "Training Accuracy 0.625\n",
      "Loss 255.486 139 19\n",
      "Training Accuracy 0.61\n",
      "Loss 214.03065 140 19\n",
      "Training Accuracy 0.64\n",
      "Loss 250.09195 141 19\n",
      "Training Accuracy 0.6\n",
      "Loss 248.36638 142 19\n",
      "Training Accuracy 0.56\n",
      "Loss 220.54572 143 19\n",
      "Training Accuracy 0.6\n",
      "Loss 262.5307 144 19\n",
      "Training Accuracy 0.555\n",
      "Loss 240.25676 145 19\n",
      "Training Accuracy 0.625\n",
      "Loss 248.07498 146 19\n",
      "Training Accuracy 0.565\n",
      "Loss 242.22925 147 19\n",
      "Training Accuracy 0.59\n",
      "Loss 237.84921 148 19\n",
      "Training Accuracy 0.56\n",
      "Loss 234.39601 149 19\n",
      "Training Accuracy 0.625\n",
      "Loss 228.61664 150 19\n",
      "Training Accuracy 0.635\n",
      "Loss 244.16803 151 19\n",
      "Training Accuracy 0.665\n",
      "Loss 257.25696 152 19\n",
      "Training Accuracy 0.58\n",
      "Loss 240.87177 153 19\n",
      "Training Accuracy 0.6\n",
      "Loss 225.15378 154 19\n",
      "Training Accuracy 0.6\n",
      "Loss 236.48224 155 19\n",
      "Training Accuracy 0.615\n",
      "Loss 242.89584 156 19\n",
      "Training Accuracy 0.63\n",
      "Loss 205.64087 157 19\n",
      "Training Accuracy 0.635\n",
      "Loss 233.15186 158 19\n",
      "Training Accuracy 0.595\n",
      "Loss 264.22552 159 19\n",
      "Training Accuracy 0.585\n",
      "Loss 241.18895 160 19\n",
      "Training Accuracy 0.61\n",
      "Loss 262.08307 161 19\n",
      "Training Accuracy 0.555\n",
      "Loss 235.62247 162 19\n",
      "Training Accuracy 0.615\n",
      "Loss 260.92975 163 19\n",
      "Training Accuracy 0.605\n",
      "Loss 214.04967 164 19\n",
      "Training Accuracy 0.61\n",
      "Loss 232.38889 165 19\n",
      "Training Accuracy 0.62\n",
      "Loss 236.99869 166 19\n",
      "Training Accuracy 0.66\n",
      "Loss 195.61249 167 19\n",
      "Training Accuracy 0.685\n",
      "Loss 252.65518 168 19\n",
      "Training Accuracy 0.61\n",
      "Loss 233.02473 169 19\n",
      "Training Accuracy 0.585\n",
      "Loss 237.13518 170 19\n",
      "Training Accuracy 0.595\n",
      "Loss 246.71114 171 19\n",
      "Training Accuracy 0.585\n",
      "Loss 223.09178 172 19\n",
      "Training Accuracy 0.635\n",
      "Loss 270.58136 173 19\n",
      "Training Accuracy 0.585\n",
      "Loss 202.70615 174 19\n",
      "Training Accuracy 0.67\n",
      "Loss 212.50002 175 19\n",
      "Training Accuracy 0.67\n",
      "Loss 204.88315 176 19\n",
      "Training Accuracy 0.69\n",
      "Loss 274.55368 177 19\n",
      "Training Accuracy 0.525\n",
      "Loss 224.46483 178 19\n",
      "Training Accuracy 0.64\n",
      "Loss 250.85486 179 19\n",
      "Training Accuracy 0.575\n",
      "Loss 251.35326 180 19\n",
      "Training Accuracy 0.565\n",
      "Loss 215.47882 181 19\n",
      "Training Accuracy 0.63\n",
      "Loss 251.59445 182 19\n",
      "Training Accuracy 0.59\n",
      "Loss 247.2361 183 19\n",
      "Training Accuracy 0.595\n",
      "Loss 231.58066 184 19\n",
      "Training Accuracy 0.615\n",
      "Loss 221.27829 185 19\n",
      "Training Accuracy 0.645\n",
      "Loss 232.0209 186 19\n",
      "Training Accuracy 0.625\n",
      "Loss 275.36847 187 19\n",
      "Training Accuracy 0.545\n",
      "Loss 258.21484 188 19\n",
      "Training Accuracy 0.61\n",
      "Loss 240.27252 189 19\n",
      "Training Accuracy 0.595\n",
      "Loss 226.04224 190 19\n",
      "Training Accuracy 0.61\n",
      "Loss 227.45099 191 19\n",
      "Training Accuracy 0.62\n",
      "Loss 244.6448 192 19\n",
      "Training Accuracy 0.62\n",
      "Loss 230.05681 193 19\n",
      "Training Accuracy 0.66\n",
      "Loss 230.04059 194 19\n",
      "Training Accuracy 0.61\n",
      "Loss 223.829 195 19\n",
      "Training Accuracy 0.63\n",
      "Loss 228.80043 196 19\n",
      "Training Accuracy 0.615\n",
      "Loss 247.04373 197 19\n",
      "Training Accuracy 0.615\n",
      "Loss 227.93304 198 19\n",
      "Training Accuracy 0.6\n",
      "Loss 200.6983 199 19\n",
      "Training Accuracy 0.635\n",
      "Loss 247.46498 200 19\n",
      "Training Accuracy 0.55\n",
      "Loss 226.00012 201 19\n",
      "Training Accuracy 0.635\n",
      "Loss 212.9634 202 19\n",
      "Training Accuracy 0.61\n",
      "Loss 232.24878 203 19\n",
      "Training Accuracy 0.6\n",
      "Loss 228.02768 204 19\n",
      "Training Accuracy 0.575\n",
      "Loss 254.63513 205 19\n",
      "Training Accuracy 0.605\n",
      "Loss 244.75612 206 19\n",
      "Training Accuracy 0.585\n",
      "Loss 230.85025 207 19\n",
      "Training Accuracy 0.645\n",
      "Loss 255.6856 208 19\n",
      "Training Accuracy 0.585\n",
      "Loss 269.26584 209 19\n",
      "Training Accuracy 0.565\n",
      "Loss 221.45418 210 19\n",
      "Training Accuracy 0.64\n",
      "Loss 234.42953 211 19\n",
      "Training Accuracy 0.6\n",
      "Loss 234.31534 212 19\n",
      "Training Accuracy 0.59\n",
      "Loss 271.6246 213 19\n",
      "Training Accuracy 0.565\n",
      "Loss 237.9816 214 19\n",
      "Training Accuracy 0.575\n",
      "Loss 249.5284 215 19\n",
      "Training Accuracy 0.57\n",
      "Loss 268.63306 216 19\n",
      "Training Accuracy 0.555\n",
      "Loss 252.37659 217 19\n",
      "Training Accuracy 0.56\n",
      "Loss 253.47829 218 19\n",
      "Training Accuracy 0.57\n",
      "Loss 242.47826 219 19\n",
      "Training Accuracy 0.59\n",
      "Loss 225.00264 220 19\n",
      "Training Accuracy 0.66\n",
      "Loss 243.61964 221 19\n",
      "Training Accuracy 0.56\n",
      "Loss 248.09587 222 19\n",
      "Training Accuracy 0.57\n",
      "Loss 253.05983 223 19\n",
      "Training Accuracy 0.555\n",
      "Loss 252.53062 224 19\n",
      "Training Accuracy 0.625\n",
      "Loss 272.51883 225 19\n",
      "Training Accuracy 0.545\n",
      "Loss 215.06989 226 19\n",
      "Training Accuracy 0.615\n",
      "Loss 268.24557 227 19\n",
      "Training Accuracy 0.58\n",
      "Loss 276.0035 228 19\n",
      "Training Accuracy 0.555\n",
      "Loss 232.38649 229 19\n",
      "Training Accuracy 0.605\n",
      "Loss 249.57874 230 19\n",
      "Training Accuracy 0.635\n",
      "Loss 208.55605 231 19\n",
      "Training Accuracy 0.68\n",
      "Loss 236.47731 232 19\n",
      "Training Accuracy 0.625\n",
      "Loss 257.14233 233 19\n",
      "Training Accuracy 0.535\n",
      "Loss 234.07468 234 19\n",
      "Training Accuracy 0.59\n",
      "Loss 236.64027 235 19\n",
      "Training Accuracy 0.605\n",
      "Loss 214.05281 236 19\n",
      "Training Accuracy 0.675\n",
      "Loss 250.49118 237 19\n",
      "Training Accuracy 0.57\n",
      "Loss 230.35602 238 19\n",
      "Training Accuracy 0.565\n",
      "Loss 254.77718 239 19\n",
      "Training Accuracy 0.58\n",
      "Loss 244.57202 240 19\n",
      "Training Accuracy 0.55\n",
      "Loss 269.0727 241 19\n",
      "Training Accuracy 0.57\n",
      "Loss 223.88846 242 19\n",
      "Training Accuracy 0.625\n",
      "Loss 221.36952 243 19\n",
      "Training Accuracy 0.635\n",
      "Loss 235.65747 244 19\n",
      "Training Accuracy 0.56\n",
      "Loss 231.02353 245 19\n",
      "Training Accuracy 0.63\n",
      "Loss 255.04305 246 19\n",
      "Training Accuracy 0.585\n",
      "Loss 203.90118 247 19\n",
      "Training Accuracy 0.595\n",
      "Loss 220.41806 248 19\n",
      "Training Accuracy 0.63\n",
      "Loss 259.28503 249 19\n",
      "Training Accuracy 0.555\n",
      "Loss 258.6277 250 19\n",
      "Training Accuracy 0.555\n",
      "Loss 244.85155 251 19\n",
      "Training Accuracy 0.57\n",
      "Loss 219.21758 252 19\n",
      "Training Accuracy 0.62\n",
      "Loss 214.82925 253 19\n",
      "Training Accuracy 0.645\n",
      "Loss 240.0072 254 19\n",
      "Training Accuracy 0.605\n",
      "Loss 207.5967 255 19\n",
      "Training Accuracy 0.645\n",
      "Loss 255.8867 256 19\n",
      "Training Accuracy 0.6\n",
      "Loss 238.55678 257 19\n",
      "Training Accuracy 0.585\n",
      "Loss 241.40201 258 19\n",
      "Training Accuracy 0.595\n",
      "Loss 244.67758 259 19\n",
      "Training Accuracy 0.59\n",
      "Loss 198.81747 260 19\n",
      "Training Accuracy 0.675\n",
      "Loss 240.72281 261 19\n",
      "Training Accuracy 0.595\n",
      "Loss 243.47414 262 19\n",
      "Training Accuracy 0.54\n",
      "Loss 293.68918 263 19\n",
      "Training Accuracy 0.52\n",
      "Loss 254.24765 264 19\n",
      "Training Accuracy 0.575\n",
      "Loss 220.83653 265 19\n",
      "Training Accuracy 0.645\n",
      "Loss 225.44519 266 19\n",
      "Training Accuracy 0.595\n",
      "Loss 249.55095 267 19\n",
      "Training Accuracy 0.56\n",
      "Loss 249.65239 268 19\n",
      "Training Accuracy 0.59\n",
      "Loss 216.82147 269 19\n",
      "Training Accuracy 0.595\n",
      "Loss 211.76385 270 19\n",
      "Training Accuracy 0.63\n",
      "Loss 268.38104 271 19\n",
      "Training Accuracy 0.535\n",
      "Loss 242.3636 272 19\n",
      "Training Accuracy 0.63\n",
      "Loss 259.0742 273 19\n",
      "Training Accuracy 0.56\n",
      "Loss 220.8341 274 19\n",
      "Training Accuracy 0.665\n",
      "Loss 248.78702 275 19\n",
      "Training Accuracy 0.565\n",
      "Loss 217.99803 276 19\n",
      "Training Accuracy 0.645\n",
      "Loss 255.22586 277 19\n",
      "Training Accuracy 0.63\n",
      "Loss 227.81316 278 19\n",
      "Training Accuracy 0.62\n",
      "Loss 237.79599 279 19\n",
      "Training Accuracy 0.63\n",
      "Loss 238.04765 280 19\n",
      "Training Accuracy 0.58\n",
      "Loss 246.56352 281 19\n",
      "Training Accuracy 0.585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 242.76111 282 19\n",
      "Training Accuracy 0.55\n",
      "Loss 218.63269 283 19\n",
      "Training Accuracy 0.67\n",
      "Loss 209.5642 284 19\n",
      "Training Accuracy 0.67\n",
      "Loss 260.819 285 19\n",
      "Training Accuracy 0.585\n",
      "Loss 234.48236 286 19\n",
      "Training Accuracy 0.65\n",
      "Loss 227.93443 287 19\n",
      "Training Accuracy 0.625\n",
      "Loss 245.67216 288 19\n",
      "Training Accuracy 0.61\n",
      "Loss 224.60464 289 19\n",
      "Training Accuracy 0.655\n",
      "Loss 249.7932 290 19\n",
      "Training Accuracy 0.55\n",
      "Loss 246.96976 291 19\n",
      "Training Accuracy 0.6\n",
      "Loss 149.07567 292 19\n",
      "Training Accuracy 0.65909094\n",
      "Loss 191.56685 1 20\n",
      "Training Accuracy 0.665\n",
      "Loss 237.63696 2 20\n",
      "Training Accuracy 0.605\n",
      "Loss 227.06494 3 20\n",
      "Training Accuracy 0.65\n",
      "Loss 251.96826 4 20\n",
      "Training Accuracy 0.56\n",
      "Loss 219.26154 5 20\n",
      "Training Accuracy 0.635\n",
      "Loss 236.7816 6 20\n",
      "Training Accuracy 0.595\n",
      "Loss 238.21593 7 20\n",
      "Training Accuracy 0.58\n",
      "Loss 265.89316 8 20\n",
      "Training Accuracy 0.615\n",
      "Loss 224.53093 9 20\n",
      "Training Accuracy 0.62\n",
      "Loss 244.84555 10 20\n",
      "Training Accuracy 0.59\n",
      "Loss 262.87506 11 20\n",
      "Training Accuracy 0.58\n",
      "Loss 229.99983 12 20\n",
      "Training Accuracy 0.575\n",
      "Loss 229.80118 13 20\n",
      "Training Accuracy 0.585\n",
      "Loss 248.83087 14 20\n",
      "Training Accuracy 0.605\n",
      "Loss 213.07062 15 20\n",
      "Training Accuracy 0.645\n",
      "Loss 266.08157 16 20\n",
      "Training Accuracy 0.585\n",
      "Loss 206.64282 17 20\n",
      "Training Accuracy 0.66\n",
      "Loss 229.73969 18 20\n",
      "Training Accuracy 0.625\n",
      "Loss 224.9243 19 20\n",
      "Training Accuracy 0.585\n",
      "Loss 237.3579 20 20\n",
      "Training Accuracy 0.605\n",
      "Loss 227.20804 21 20\n",
      "Training Accuracy 0.6\n",
      "Loss 244.21898 22 20\n",
      "Training Accuracy 0.605\n",
      "Loss 248.26614 23 20\n",
      "Training Accuracy 0.615\n",
      "Loss 253.24217 24 20\n",
      "Training Accuracy 0.57\n",
      "Loss 228.66704 25 20\n",
      "Training Accuracy 0.625\n",
      "Loss 244.10567 26 20\n",
      "Training Accuracy 0.57\n",
      "Loss 212.804 27 20\n",
      "Training Accuracy 0.64\n",
      "Loss 229.22675 28 20\n",
      "Training Accuracy 0.61\n",
      "Loss 228.10544 29 20\n",
      "Training Accuracy 0.6\n",
      "Loss 242.48232 30 20\n",
      "Training Accuracy 0.58\n",
      "Loss 253.38934 31 20\n",
      "Training Accuracy 0.58\n",
      "Loss 233.80243 32 20\n",
      "Training Accuracy 0.635\n",
      "Loss 256.09796 33 20\n",
      "Training Accuracy 0.58\n",
      "Loss 215.82475 34 20\n",
      "Training Accuracy 0.615\n",
      "Loss 213.63272 35 20\n",
      "Training Accuracy 0.615\n",
      "Loss 236.95003 36 20\n",
      "Training Accuracy 0.54\n",
      "Loss 231.72217 37 20\n",
      "Training Accuracy 0.615\n",
      "Loss 233.40031 38 20\n",
      "Training Accuracy 0.63\n",
      "Loss 201.24713 39 20\n",
      "Training Accuracy 0.665\n",
      "Loss 217.4625 40 20\n",
      "Training Accuracy 0.65\n",
      "Loss 238.57468 41 20\n",
      "Training Accuracy 0.59\n",
      "Loss 285.17694 42 20\n",
      "Training Accuracy 0.56\n",
      "Loss 223.90335 43 20\n",
      "Training Accuracy 0.63\n",
      "Loss 228.02153 44 20\n",
      "Training Accuracy 0.585\n",
      "Loss 240.09201 45 20\n",
      "Training Accuracy 0.6\n",
      "Loss 266.57947 46 20\n",
      "Training Accuracy 0.56\n",
      "Loss 224.26468 47 20\n",
      "Training Accuracy 0.63\n",
      "Loss 213.42235 48 20\n",
      "Training Accuracy 0.64\n",
      "Loss 227.27704 49 20\n",
      "Training Accuracy 0.635\n",
      "Loss 254.61339 50 20\n",
      "Training Accuracy 0.58\n",
      "Loss 204.47525 51 20\n",
      "Training Accuracy 0.665\n",
      "Loss 216.754 52 20\n",
      "Training Accuracy 0.665\n",
      "Loss 205.18935 53 20\n",
      "Training Accuracy 0.67\n",
      "Loss 254.16449 54 20\n",
      "Training Accuracy 0.585\n",
      "Loss 246.37105 55 20\n",
      "Training Accuracy 0.575\n",
      "Loss 231.07709 56 20\n",
      "Training Accuracy 0.615\n",
      "Loss 222.93039 57 20\n",
      "Training Accuracy 0.64\n",
      "Loss 222.72328 58 20\n",
      "Training Accuracy 0.63\n",
      "Loss 249.21077 59 20\n",
      "Training Accuracy 0.595\n",
      "Loss 234.57718 60 20\n",
      "Training Accuracy 0.595\n",
      "Loss 237.35556 61 20\n",
      "Training Accuracy 0.6\n",
      "Loss 226.10938 62 20\n",
      "Training Accuracy 0.6\n",
      "Loss 238.57677 63 20\n",
      "Training Accuracy 0.68\n",
      "Loss 229.71155 64 20\n",
      "Training Accuracy 0.67\n",
      "Loss 245.43639 65 20\n",
      "Training Accuracy 0.55\n",
      "Loss 214.8529 66 20\n",
      "Training Accuracy 0.635\n",
      "Loss 246.55951 67 20\n",
      "Training Accuracy 0.57\n",
      "Loss 235.78952 68 20\n",
      "Training Accuracy 0.56\n",
      "Loss 242.76183 69 20\n",
      "Training Accuracy 0.56\n",
      "Loss 242.31061 70 20\n",
      "Training Accuracy 0.625\n",
      "Loss 226.53113 71 20\n",
      "Training Accuracy 0.645\n",
      "Loss 234.31505 72 20\n",
      "Training Accuracy 0.635\n",
      "Loss 238.69803 73 20\n",
      "Training Accuracy 0.61\n",
      "Loss 261.85947 74 20\n",
      "Training Accuracy 0.61\n",
      "Loss 230.6406 75 20\n",
      "Training Accuracy 0.63\n",
      "Loss 219.10802 76 20\n",
      "Training Accuracy 0.64\n",
      "Loss 248.02895 77 20\n",
      "Training Accuracy 0.59\n",
      "Loss 233.78593 78 20\n",
      "Training Accuracy 0.62\n",
      "Loss 245.95935 79 20\n",
      "Training Accuracy 0.55\n",
      "Loss 240.15698 80 20\n",
      "Training Accuracy 0.6\n",
      "Loss 238.27199 81 20\n",
      "Training Accuracy 0.58\n",
      "Loss 219.55992 82 20\n",
      "Training Accuracy 0.625\n",
      "Loss 237.57333 83 20\n",
      "Training Accuracy 0.59\n",
      "Loss 256.89606 84 20\n",
      "Training Accuracy 0.57\n",
      "Loss 238.87274 85 20\n",
      "Training Accuracy 0.605\n",
      "Loss 258.371 86 20\n",
      "Training Accuracy 0.565\n",
      "Loss 276.33514 87 20\n",
      "Training Accuracy 0.53\n",
      "Loss 260.74368 88 20\n",
      "Training Accuracy 0.555\n",
      "Loss 246.07574 89 20\n",
      "Training Accuracy 0.59\n",
      "Loss 243.9451 90 20\n",
      "Training Accuracy 0.545\n",
      "Loss 233.7768 91 20\n",
      "Training Accuracy 0.595\n",
      "Loss 243.10559 92 20\n",
      "Training Accuracy 0.64\n",
      "Loss 231.23233 93 20\n",
      "Training Accuracy 0.64\n",
      "Loss 251.67104 94 20\n",
      "Training Accuracy 0.605\n",
      "Loss 216.10916 95 20\n",
      "Training Accuracy 0.61\n",
      "Loss 240.0849 96 20\n",
      "Training Accuracy 0.59\n",
      "Loss 240.68512 97 20\n",
      "Training Accuracy 0.6\n",
      "Loss 221.94083 98 20\n",
      "Training Accuracy 0.62\n",
      "Loss 220.76013 99 20\n",
      "Training Accuracy 0.63\n",
      "Loss 234.2501 100 20\n",
      "Training Accuracy 0.63\n",
      "Loss 248.38863 101 20\n",
      "Training Accuracy 0.58\n",
      "Loss 214.89545 102 20\n",
      "Training Accuracy 0.575\n",
      "Loss 238.23648 103 20\n",
      "Training Accuracy 0.6\n",
      "Loss 224.32497 104 20\n",
      "Training Accuracy 0.615\n",
      "Loss 243.94821 105 20\n",
      "Training Accuracy 0.58\n",
      "Loss 230.97893 106 20\n",
      "Training Accuracy 0.62\n",
      "Loss 233.25322 107 20\n",
      "Training Accuracy 0.61\n",
      "Loss 248.88872 108 20\n",
      "Training Accuracy 0.555\n",
      "Loss 238.79027 109 20\n",
      "Training Accuracy 0.555\n",
      "Loss 251.32458 110 20\n",
      "Training Accuracy 0.605\n",
      "Loss 232.29572 111 20\n",
      "Training Accuracy 0.635\n",
      "Loss 260.4339 112 20\n",
      "Training Accuracy 0.59\n",
      "Loss 271.44077 113 20\n",
      "Training Accuracy 0.57\n",
      "Loss 235.26598 114 20\n",
      "Training Accuracy 0.585\n",
      "Loss 262.01273 115 20\n",
      "Training Accuracy 0.59\n",
      "Loss 258.8886 116 20\n",
      "Training Accuracy 0.59\n",
      "Loss 193.27556 117 20\n",
      "Training Accuracy 0.715\n",
      "Loss 240.5319 118 20\n",
      "Training Accuracy 0.59\n",
      "Loss 276.11484 119 20\n",
      "Training Accuracy 0.505\n",
      "Loss 247.07217 120 20\n",
      "Training Accuracy 0.605\n",
      "Loss 250.02917 121 20\n",
      "Training Accuracy 0.6\n",
      "Loss 219.25552 122 20\n",
      "Training Accuracy 0.635\n",
      "Loss 229.7825 123 20\n",
      "Training Accuracy 0.605\n",
      "Loss 217.05391 124 20\n",
      "Training Accuracy 0.635\n",
      "Loss 210.88347 125 20\n",
      "Training Accuracy 0.635\n",
      "Loss 255.55954 126 20\n",
      "Training Accuracy 0.59\n",
      "Loss 244.42194 127 20\n",
      "Training Accuracy 0.59\n",
      "Loss 230.86996 128 20\n",
      "Training Accuracy 0.575\n",
      "Loss 216.93402 129 20\n",
      "Training Accuracy 0.65\n",
      "Loss 228.17726 130 20\n",
      "Training Accuracy 0.605\n",
      "Loss 215.98448 131 20\n",
      "Training Accuracy 0.63\n",
      "Loss 220.45633 132 20\n",
      "Training Accuracy 0.62\n",
      "Loss 230.99423 133 20\n",
      "Training Accuracy 0.61\n",
      "Loss 230.31117 134 20\n",
      "Training Accuracy 0.59\n",
      "Loss 229.67392 135 20\n",
      "Training Accuracy 0.615\n",
      "Loss 258.29233 136 20\n",
      "Training Accuracy 0.57\n",
      "Loss 258.27768 137 20\n",
      "Training Accuracy 0.56\n",
      "Loss 220.17218 138 20\n",
      "Training Accuracy 0.66\n",
      "Loss 259.18768 139 20\n",
      "Training Accuracy 0.64\n",
      "Loss 202.87206 140 20\n",
      "Training Accuracy 0.635\n",
      "Loss 246.55351 141 20\n",
      "Training Accuracy 0.63\n",
      "Loss 241.71722 142 20\n",
      "Training Accuracy 0.55\n",
      "Loss 213.56781 143 20\n",
      "Training Accuracy 0.61\n",
      "Loss 252.24347 144 20\n",
      "Training Accuracy 0.57\n",
      "Loss 239.16357 145 20\n",
      "Training Accuracy 0.625\n",
      "Loss 240.29364 146 20\n",
      "Training Accuracy 0.57\n",
      "Loss 232.4506 147 20\n",
      "Training Accuracy 0.62\n",
      "Loss 239.95448 148 20\n",
      "Training Accuracy 0.61\n",
      "Loss 236.91026 149 20\n",
      "Training Accuracy 0.61\n",
      "Loss 221.44728 150 20\n",
      "Training Accuracy 0.665\n",
      "Loss 258.00827 151 20\n",
      "Training Accuracy 0.54\n",
      "Loss 255.37 152 20\n",
      "Training Accuracy 0.6\n",
      "Loss 228.18199 153 20\n",
      "Training Accuracy 0.625\n",
      "Loss 217.69917 154 20\n",
      "Training Accuracy 0.665\n",
      "Loss 224.79358 155 20\n",
      "Training Accuracy 0.62\n",
      "Loss 236.32841 156 20\n",
      "Training Accuracy 0.585\n",
      "Loss 208.33696 157 20\n",
      "Training Accuracy 0.635\n",
      "Loss 220.56082 158 20\n",
      "Training Accuracy 0.64\n",
      "Loss 261.33444 159 20\n",
      "Training Accuracy 0.58\n",
      "Loss 240.44724 160 20\n",
      "Training Accuracy 0.605\n",
      "Loss 253.89934 161 20\n",
      "Training Accuracy 0.585\n",
      "Loss 243.6374 162 20\n",
      "Training Accuracy 0.59\n",
      "Loss 254.87541 163 20\n",
      "Training Accuracy 0.585\n",
      "Loss 206.37317 164 20\n",
      "Training Accuracy 0.63\n",
      "Loss 229.35156 165 20\n",
      "Training Accuracy 0.605\n",
      "Loss 231.38948 166 20\n",
      "Training Accuracy 0.665\n",
      "Loss 210.32771 167 20\n",
      "Training Accuracy 0.655\n",
      "Loss 256.45386 168 20\n",
      "Training Accuracy 0.585\n",
      "Loss 227.03914 169 20\n",
      "Training Accuracy 0.605\n",
      "Loss 224.85532 170 20\n",
      "Training Accuracy 0.65\n",
      "Loss 261.1035 171 20\n",
      "Training Accuracy 0.555\n",
      "Loss 217.71024 172 20\n",
      "Training Accuracy 0.66\n",
      "Loss 265.56857 173 20\n",
      "Training Accuracy 0.59\n",
      "Loss 212.06462 174 20\n",
      "Training Accuracy 0.62\n",
      "Loss 213.84232 175 20\n",
      "Training Accuracy 0.635\n",
      "Loss 184.98782 176 20\n",
      "Training Accuracy 0.695\n",
      "Loss 267.5623 177 20\n",
      "Training Accuracy 0.57\n",
      "Loss 214.3303 178 20\n",
      "Training Accuracy 0.63\n",
      "Loss 248.60535 179 20\n",
      "Training Accuracy 0.58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 247.04655 180 20\n",
      "Training Accuracy 0.545\n",
      "Loss 205.82465 181 20\n",
      "Training Accuracy 0.675\n",
      "Loss 253.32129 182 20\n",
      "Training Accuracy 0.585\n",
      "Loss 247.29323 183 20\n",
      "Training Accuracy 0.59\n",
      "Loss 213.40163 184 20\n",
      "Training Accuracy 0.675\n",
      "Loss 229.69868 185 20\n",
      "Training Accuracy 0.61\n",
      "Loss 225.31915 186 20\n",
      "Training Accuracy 0.61\n",
      "Loss 265.77814 187 20\n",
      "Training Accuracy 0.55\n",
      "Loss 254.70798 188 20\n",
      "Training Accuracy 0.575\n",
      "Loss 233.74258 189 20\n",
      "Training Accuracy 0.605\n",
      "Loss 215.008 190 20\n",
      "Training Accuracy 0.63\n",
      "Loss 223.61047 191 20\n",
      "Training Accuracy 0.615\n",
      "Loss 251.73639 192 20\n",
      "Training Accuracy 0.58\n",
      "Loss 218.02615 193 20\n",
      "Training Accuracy 0.64\n",
      "Loss 219.7609 194 20\n",
      "Training Accuracy 0.64\n",
      "Loss 216.20294 195 20\n",
      "Training Accuracy 0.665\n",
      "Loss 228.57704 196 20\n",
      "Training Accuracy 0.63\n",
      "Loss 244.54295 197 20\n",
      "Training Accuracy 0.61\n",
      "Loss 225.17404 198 20\n",
      "Training Accuracy 0.565\n",
      "Loss 194.81958 199 20\n",
      "Training Accuracy 0.68\n",
      "Loss 235.6543 200 20\n",
      "Training Accuracy 0.605\n",
      "Loss 222.25246 201 20\n",
      "Training Accuracy 0.62\n",
      "Loss 217.46776 202 20\n",
      "Training Accuracy 0.625\n",
      "Loss 225.59071 203 20\n",
      "Training Accuracy 0.6\n",
      "Loss 223.64084 204 20\n",
      "Training Accuracy 0.58\n",
      "Loss 253.80824 205 20\n",
      "Training Accuracy 0.6\n",
      "Loss 224.94551 206 20\n",
      "Training Accuracy 0.635\n",
      "Loss 227.19382 207 20\n",
      "Training Accuracy 0.65\n",
      "Loss 250.19977 208 20\n",
      "Training Accuracy 0.605\n",
      "Loss 264.773 209 20\n",
      "Training Accuracy 0.58\n",
      "Loss 220.10538 210 20\n",
      "Training Accuracy 0.6\n",
      "Loss 223.0837 211 20\n",
      "Training Accuracy 0.64\n",
      "Loss 213.81604 212 20\n",
      "Training Accuracy 0.625\n",
      "Loss 265.0676 213 20\n",
      "Training Accuracy 0.535\n",
      "Loss 234.5652 214 20\n",
      "Training Accuracy 0.595\n",
      "Loss 262.52405 215 20\n",
      "Training Accuracy 0.55\n",
      "Loss 245.37088 216 20\n",
      "Training Accuracy 0.56\n",
      "Loss 256.17773 217 20\n",
      "Training Accuracy 0.535\n",
      "Loss 247.71042 218 20\n",
      "Training Accuracy 0.59\n",
      "Loss 243.07326 219 20\n",
      "Training Accuracy 0.59\n",
      "Loss 230.81215 220 20\n",
      "Training Accuracy 0.6\n",
      "Loss 229.06557 221 20\n",
      "Training Accuracy 0.625\n",
      "Loss 229.56519 222 20\n",
      "Training Accuracy 0.58\n",
      "Loss 257.15613 223 20\n",
      "Training Accuracy 0.59\n",
      "Loss 255.77618 224 20\n",
      "Training Accuracy 0.55\n",
      "Loss 259.40326 225 20\n",
      "Training Accuracy 0.59\n",
      "Loss 198.77678 226 20\n",
      "Training Accuracy 0.64\n",
      "Loss 259.41107 227 20\n",
      "Training Accuracy 0.525\n",
      "Loss 264.79343 228 20\n",
      "Training Accuracy 0.565\n",
      "Loss 225.29529 229 20\n",
      "Training Accuracy 0.595\n",
      "Loss 237.46559 230 20\n",
      "Training Accuracy 0.615\n",
      "Loss 208.8703 231 20\n",
      "Training Accuracy 0.63\n",
      "Loss 238.29968 232 20\n",
      "Training Accuracy 0.585\n",
      "Loss 253.284 233 20\n",
      "Training Accuracy 0.555\n",
      "Loss 251.50636 234 20\n",
      "Training Accuracy 0.545\n",
      "Loss 235.66397 235 20\n",
      "Training Accuracy 0.62\n",
      "Loss 199.3042 236 20\n",
      "Training Accuracy 0.685\n",
      "Loss 242.29453 237 20\n",
      "Training Accuracy 0.58\n",
      "Loss 221.4943 238 20\n",
      "Training Accuracy 0.595\n",
      "Loss 253.08813 239 20\n",
      "Training Accuracy 0.585\n",
      "Loss 232.38681 240 20\n",
      "Training Accuracy 0.58\n",
      "Loss 258.39264 241 20\n",
      "Training Accuracy 0.585\n",
      "Loss 227.9292 242 20\n",
      "Training Accuracy 0.625\n",
      "Loss 205.55608 243 20\n",
      "Training Accuracy 0.655\n",
      "Loss 229.69392 244 20\n",
      "Training Accuracy 0.58\n",
      "Loss 228.19351 245 20\n",
      "Training Accuracy 0.615\n",
      "Loss 249.71796 246 20\n",
      "Training Accuracy 0.56\n",
      "Loss 201.90817 247 20\n",
      "Training Accuracy 0.595\n",
      "Loss 225.67137 248 20\n",
      "Training Accuracy 0.6\n",
      "Loss 248.25407 249 20\n",
      "Training Accuracy 0.58\n",
      "Loss 247.47122 250 20\n",
      "Training Accuracy 0.565\n",
      "Loss 242.46103 251 20\n",
      "Training Accuracy 0.555\n",
      "Loss 205.59521 252 20\n",
      "Training Accuracy 0.635\n",
      "Loss 209.26523 253 20\n",
      "Training Accuracy 0.645\n",
      "Loss 231.26245 254 20\n",
      "Training Accuracy 0.58\n",
      "Loss 217.81177 255 20\n",
      "Training Accuracy 0.65\n",
      "Loss 249.03484 256 20\n",
      "Training Accuracy 0.585\n",
      "Loss 234.97437 257 20\n",
      "Training Accuracy 0.64\n",
      "Loss 231.41278 258 20\n",
      "Training Accuracy 0.62\n",
      "Loss 233.36906 259 20\n",
      "Training Accuracy 0.57\n",
      "Loss 196.58076 260 20\n",
      "Training Accuracy 0.705\n",
      "Loss 237.69016 261 20\n",
      "Training Accuracy 0.6\n",
      "Loss 229.50243 262 20\n",
      "Training Accuracy 0.605\n",
      "Loss 278.76202 263 20\n",
      "Training Accuracy 0.545\n",
      "Loss 243.17615 264 20\n",
      "Training Accuracy 0.64\n",
      "Loss 228.00946 265 20\n",
      "Training Accuracy 0.635\n",
      "Loss 225.87897 266 20\n",
      "Training Accuracy 0.595\n",
      "Loss 243.791 267 20\n",
      "Training Accuracy 0.58\n",
      "Loss 253.96513 268 20\n",
      "Training Accuracy 0.59\n",
      "Loss 216.83197 269 20\n",
      "Training Accuracy 0.595\n",
      "Loss 205.91115 270 20\n",
      "Training Accuracy 0.615\n",
      "Loss 252.86038 271 20\n",
      "Training Accuracy 0.57\n",
      "Loss 234.83879 272 20\n",
      "Training Accuracy 0.59\n",
      "Loss 251.73659 273 20\n",
      "Training Accuracy 0.595\n",
      "Loss 213.72621 274 20\n",
      "Training Accuracy 0.66\n",
      "Loss 236.3905 275 20\n",
      "Training Accuracy 0.61\n",
      "Loss 221.07144 276 20\n",
      "Training Accuracy 0.62\n",
      "Loss 247.45445 277 20\n",
      "Training Accuracy 0.625\n",
      "Loss 215.95859 278 20\n",
      "Training Accuracy 0.635\n",
      "Loss 232.73112 279 20\n",
      "Training Accuracy 0.6\n",
      "Loss 218.62769 280 20\n",
      "Training Accuracy 0.585\n",
      "Loss 243.49591 281 20\n",
      "Training Accuracy 0.55\n",
      "Loss 224.05794 282 20\n",
      "Training Accuracy 0.63\n",
      "Loss 227.49103 283 20\n",
      "Training Accuracy 0.65\n",
      "Loss 199.3092 284 20\n",
      "Training Accuracy 0.68\n",
      "Loss 266.4972 285 20\n",
      "Training Accuracy 0.565\n",
      "Loss 220.69374 286 20\n",
      "Training Accuracy 0.645\n",
      "Loss 210.26503 287 20\n",
      "Training Accuracy 0.675\n",
      "Loss 227.66428 288 20\n",
      "Training Accuracy 0.65\n",
      "Loss 218.82999 289 20\n",
      "Training Accuracy 0.64\n",
      "Loss 243.44374 290 20\n",
      "Training Accuracy 0.57\n",
      "Loss 247.5352 291 20\n",
      "Training Accuracy 0.59\n",
      "Loss 137.41008 292 20\n",
      "Training Accuracy 0.6439394\n",
      "Loss 197.19293 1 21\n",
      "Training Accuracy 0.685\n",
      "Loss 232.54437 2 21\n",
      "Training Accuracy 0.595\n",
      "Loss 223.55319 3 21\n",
      "Training Accuracy 0.62\n",
      "Loss 235.2651 4 21\n",
      "Training Accuracy 0.635\n",
      "Loss 197.28426 5 21\n",
      "Training Accuracy 0.7\n",
      "Loss 240.59866 6 21\n",
      "Training Accuracy 0.565\n",
      "Loss 244.30226 7 21\n",
      "Training Accuracy 0.615\n",
      "Loss 249.22926 8 21\n",
      "Training Accuracy 0.595\n",
      "Loss 225.60571 9 21\n",
      "Training Accuracy 0.62\n",
      "Loss 250.57755 10 21\n",
      "Training Accuracy 0.59\n",
      "Loss 264.31525 11 21\n",
      "Training Accuracy 0.61\n",
      "Loss 217.90714 12 21\n",
      "Training Accuracy 0.62\n",
      "Loss 217.43051 13 21\n",
      "Training Accuracy 0.635\n",
      "Loss 244.99226 14 21\n",
      "Training Accuracy 0.59\n",
      "Loss 212.78377 15 21\n",
      "Training Accuracy 0.645\n",
      "Loss 275.09564 16 21\n",
      "Training Accuracy 0.57\n",
      "Loss 208.49493 17 21\n",
      "Training Accuracy 0.625\n",
      "Loss 221.10364 18 21\n",
      "Training Accuracy 0.65\n",
      "Loss 214.70602 19 21\n",
      "Training Accuracy 0.6\n",
      "Loss 233.75572 20 21\n",
      "Training Accuracy 0.615\n",
      "Loss 224.32469 21 21\n",
      "Training Accuracy 0.635\n",
      "Loss 237.3196 22 21\n",
      "Training Accuracy 0.59\n",
      "Loss 224.0568 23 21\n",
      "Training Accuracy 0.625\n",
      "Loss 251.61185 24 21\n",
      "Training Accuracy 0.575\n",
      "Loss 218.70718 25 21\n",
      "Training Accuracy 0.655\n",
      "Loss 248.15628 26 21\n",
      "Training Accuracy 0.555\n",
      "Loss 222.8528 27 21\n",
      "Training Accuracy 0.625\n",
      "Loss 215.89708 28 21\n",
      "Training Accuracy 0.605\n",
      "Loss 234.87038 29 21\n",
      "Training Accuracy 0.57\n",
      "Loss 238.95915 30 21\n",
      "Training Accuracy 0.62\n",
      "Loss 248.78723 31 21\n",
      "Training Accuracy 0.61\n",
      "Loss 235.0164 32 21\n",
      "Training Accuracy 0.58\n",
      "Loss 232.93843 33 21\n",
      "Training Accuracy 0.65\n",
      "Loss 199.26263 34 21\n",
      "Training Accuracy 0.665\n",
      "Loss 216.623 35 21\n",
      "Training Accuracy 0.605\n",
      "Loss 236.89987 36 21\n",
      "Training Accuracy 0.565\n",
      "Loss 226.59146 37 21\n",
      "Training Accuracy 0.63\n",
      "Loss 237.13046 38 21\n",
      "Training Accuracy 0.615\n",
      "Loss 199.78738 39 21\n",
      "Training Accuracy 0.65\n",
      "Loss 219.67877 40 21\n",
      "Training Accuracy 0.66\n",
      "Loss 229.306 41 21\n",
      "Training Accuracy 0.615\n",
      "Loss 271.18948 42 21\n",
      "Training Accuracy 0.555\n",
      "Loss 221.20467 43 21\n",
      "Training Accuracy 0.62\n",
      "Loss 218.02393 44 21\n",
      "Training Accuracy 0.61\n",
      "Loss 224.27565 45 21\n",
      "Training Accuracy 0.64\n",
      "Loss 272.1005 46 21\n",
      "Training Accuracy 0.54\n",
      "Loss 213.17117 47 21\n",
      "Training Accuracy 0.68\n",
      "Loss 210.10086 48 21\n",
      "Training Accuracy 0.635\n",
      "Loss 236.26546 49 21\n",
      "Training Accuracy 0.535\n",
      "Loss 257.2554 50 21\n",
      "Training Accuracy 0.58\n",
      "Loss 214.90402 51 21\n",
      "Training Accuracy 0.635\n",
      "Loss 215.94576 52 21\n",
      "Training Accuracy 0.635\n",
      "Loss 204.3888 53 21\n",
      "Training Accuracy 0.665\n",
      "Loss 252.6983 54 21\n",
      "Training Accuracy 0.54\n",
      "Loss 247.0359 55 21\n",
      "Training Accuracy 0.555\n",
      "Loss 227.75996 56 21\n",
      "Training Accuracy 0.595\n",
      "Loss 219.41605 57 21\n",
      "Training Accuracy 0.625\n",
      "Loss 216.92403 58 21\n",
      "Training Accuracy 0.59\n",
      "Loss 256.91122 59 21\n",
      "Training Accuracy 0.59\n",
      "Loss 231.25955 60 21\n",
      "Training Accuracy 0.63\n",
      "Loss 232.44962 61 21\n",
      "Training Accuracy 0.6\n",
      "Loss 209.38477 62 21\n",
      "Training Accuracy 0.645\n",
      "Loss 232.59396 63 21\n",
      "Training Accuracy 0.59\n",
      "Loss 230.07358 64 21\n",
      "Training Accuracy 0.64\n",
      "Loss 234.57303 65 21\n",
      "Training Accuracy 0.635\n",
      "Loss 220.07735 66 21\n",
      "Training Accuracy 0.6\n",
      "Loss 239.9817 67 21\n",
      "Training Accuracy 0.575\n",
      "Loss 225.89767 68 21\n",
      "Training Accuracy 0.605\n",
      "Loss 235.9271 69 21\n",
      "Training Accuracy 0.605\n",
      "Loss 228.81496 70 21\n",
      "Training Accuracy 0.63\n",
      "Loss 221.81525 71 21\n",
      "Training Accuracy 0.66\n",
      "Loss 234.40681 72 21\n",
      "Training Accuracy 0.61\n",
      "Loss 248.43962 73 21\n",
      "Training Accuracy 0.57\n",
      "Loss 260.0631 74 21\n",
      "Training Accuracy 0.57\n",
      "Loss 237.69527 75 21\n",
      "Training Accuracy 0.56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 210.5724 76 21\n",
      "Training Accuracy 0.65\n",
      "Loss 237.18185 77 21\n",
      "Training Accuracy 0.58\n",
      "Loss 228.31723 78 21\n",
      "Training Accuracy 0.645\n",
      "Loss 231.03174 79 21\n",
      "Training Accuracy 0.58\n",
      "Loss 240.6852 80 21\n",
      "Training Accuracy 0.595\n",
      "Loss 223.39813 81 21\n",
      "Training Accuracy 0.595\n",
      "Loss 218.9031 82 21\n",
      "Training Accuracy 0.62\n",
      "Loss 228.68098 83 21\n",
      "Training Accuracy 0.625\n",
      "Loss 257.50684 84 21\n",
      "Training Accuracy 0.58\n",
      "Loss 230.57893 85 21\n",
      "Training Accuracy 0.605\n",
      "Loss 237.16637 86 21\n",
      "Training Accuracy 0.58\n",
      "Loss 278.26053 87 21\n",
      "Training Accuracy 0.545\n",
      "Loss 257.468 88 21\n",
      "Training Accuracy 0.545\n",
      "Loss 231.3287 89 21\n",
      "Training Accuracy 0.615\n",
      "Loss 235.82594 90 21\n",
      "Training Accuracy 0.59\n",
      "Loss 241.48436 91 21\n",
      "Training Accuracy 0.59\n",
      "Loss 245.3321 92 21\n",
      "Training Accuracy 0.635\n",
      "Loss 234.80962 93 21\n",
      "Training Accuracy 0.625\n",
      "Loss 237.45848 94 21\n",
      "Training Accuracy 0.605\n",
      "Loss 221.53702 95 21\n",
      "Training Accuracy 0.6\n",
      "Loss 236.86388 96 21\n",
      "Training Accuracy 0.57\n",
      "Loss 235.10124 97 21\n",
      "Training Accuracy 0.585\n",
      "Loss 214.08723 98 21\n",
      "Training Accuracy 0.64\n",
      "Loss 225.9903 99 21\n",
      "Training Accuracy 0.595\n",
      "Loss 235.41942 100 21\n",
      "Training Accuracy 0.625\n",
      "Loss 231.89647 101 21\n",
      "Training Accuracy 0.59\n",
      "Loss 205.49744 102 21\n",
      "Training Accuracy 0.62\n",
      "Loss 234.62364 103 21\n",
      "Training Accuracy 0.54\n",
      "Loss 223.88284 104 21\n",
      "Training Accuracy 0.625\n",
      "Loss 240.06418 105 21\n",
      "Training Accuracy 0.62\n",
      "Loss 236.38123 106 21\n",
      "Training Accuracy 0.615\n",
      "Loss 229.28308 107 21\n",
      "Training Accuracy 0.63\n",
      "Loss 232.26714 108 21\n",
      "Training Accuracy 0.555\n",
      "Loss 232.29756 109 21\n",
      "Training Accuracy 0.585\n",
      "Loss 236.87233 110 21\n",
      "Training Accuracy 0.6\n",
      "Loss 239.1393 111 21\n",
      "Training Accuracy 0.565\n",
      "Loss 244.0345 112 21\n",
      "Training Accuracy 0.61\n",
      "Loss 257.53455 113 21\n",
      "Training Accuracy 0.615\n",
      "Loss 240.72691 114 21\n",
      "Training Accuracy 0.545\n",
      "Loss 255.39468 115 21\n",
      "Training Accuracy 0.605\n",
      "Loss 260.1548 116 21\n",
      "Training Accuracy 0.595\n",
      "Loss 196.36365 117 21\n",
      "Training Accuracy 0.695\n",
      "Loss 239.00935 118 21\n",
      "Training Accuracy 0.595\n",
      "Loss 267.56378 119 21\n",
      "Training Accuracy 0.555\n",
      "Loss 251.1109 120 21\n",
      "Training Accuracy 0.605\n",
      "Loss 253.94171 121 21\n",
      "Training Accuracy 0.63\n",
      "Loss 210.16927 122 21\n",
      "Training Accuracy 0.675\n",
      "Loss 238.72437 123 21\n",
      "Training Accuracy 0.58\n",
      "Loss 223.10684 124 21\n",
      "Training Accuracy 0.63\n",
      "Loss 198.61852 125 21\n",
      "Training Accuracy 0.69\n",
      "Loss 254.14275 126 21\n",
      "Training Accuracy 0.59\n",
      "Loss 234.01376 127 21\n",
      "Training Accuracy 0.585\n",
      "Loss 231.57193 128 21\n",
      "Training Accuracy 0.615\n",
      "Loss 221.45914 129 21\n",
      "Training Accuracy 0.63\n",
      "Loss 225.92004 130 21\n",
      "Training Accuracy 0.615\n",
      "Loss 208.17981 131 21\n",
      "Training Accuracy 0.685\n",
      "Loss 222.34277 132 21\n",
      "Training Accuracy 0.6\n",
      "Loss 220.58414 133 21\n",
      "Training Accuracy 0.65\n",
      "Loss 223.91246 134 21\n",
      "Training Accuracy 0.64\n",
      "Loss 221.616 135 21\n",
      "Training Accuracy 0.65\n",
      "Loss 249.10999 136 21\n",
      "Training Accuracy 0.575\n",
      "Loss 242.67119 137 21\n",
      "Training Accuracy 0.625\n",
      "Loss 226.52132 138 21\n",
      "Training Accuracy 0.645\n",
      "Loss 242.84671 139 21\n",
      "Training Accuracy 0.655\n",
      "Loss 193.591 140 21\n",
      "Training Accuracy 0.665\n",
      "Loss 246.77652 141 21\n",
      "Training Accuracy 0.605\n",
      "Loss 236.5754 142 21\n",
      "Training Accuracy 0.565\n",
      "Loss 199.45729 143 21\n",
      "Training Accuracy 0.64\n",
      "Loss 251.70193 144 21\n",
      "Training Accuracy 0.59\n",
      "Loss 227.96841 145 21\n",
      "Training Accuracy 0.62\n",
      "Loss 243.80351 146 21\n",
      "Training Accuracy 0.565\n",
      "Loss 238.84926 147 21\n",
      "Training Accuracy 0.57\n",
      "Loss 233.2763 148 21\n",
      "Training Accuracy 0.565\n",
      "Loss 239.49396 149 21\n",
      "Training Accuracy 0.595\n",
      "Loss 213.36673 150 21\n",
      "Training Accuracy 0.645\n",
      "Loss 240.80684 151 21\n",
      "Training Accuracy 0.605\n",
      "Loss 236.4156 152 21\n",
      "Training Accuracy 0.64\n",
      "Loss 221.81192 153 21\n",
      "Training Accuracy 0.615\n",
      "Loss 223.0272 154 21\n",
      "Training Accuracy 0.65\n",
      "Loss 217.61893 155 21\n",
      "Training Accuracy 0.63\n",
      "Loss 235.17812 156 21\n",
      "Training Accuracy 0.62\n",
      "Loss 202.80302 157 21\n",
      "Training Accuracy 0.665\n",
      "Loss 224.77937 158 21\n",
      "Training Accuracy 0.63\n",
      "Loss 257.28607 159 21\n",
      "Training Accuracy 0.58\n",
      "Loss 235.35503 160 21\n",
      "Training Accuracy 0.59\n",
      "Loss 247.49025 161 21\n",
      "Training Accuracy 0.595\n",
      "Loss 231.03468 162 21\n",
      "Training Accuracy 0.62\n",
      "Loss 255.28094 163 21\n",
      "Training Accuracy 0.605\n",
      "Loss 203.59682 164 21\n",
      "Training Accuracy 0.62\n",
      "Loss 228.16559 165 21\n",
      "Training Accuracy 0.61\n",
      "Loss 234.94534 166 21\n",
      "Training Accuracy 0.61\n",
      "Loss 196.26772 167 21\n",
      "Training Accuracy 0.695\n",
      "Loss 245.2998 168 21\n",
      "Training Accuracy 0.615\n",
      "Loss 213.8818 169 21\n",
      "Training Accuracy 0.635\n",
      "Loss 226.0441 170 21\n",
      "Training Accuracy 0.625\n",
      "Loss 253.63266 171 21\n",
      "Training Accuracy 0.585\n",
      "Loss 206.7445 172 21\n",
      "Training Accuracy 0.69\n",
      "Loss 255.76884 173 21\n",
      "Training Accuracy 0.635\n",
      "Loss 196.41325 174 21\n",
      "Training Accuracy 0.66\n",
      "Loss 205.79227 175 21\n",
      "Training Accuracy 0.69\n",
      "Loss 186.18143 176 21\n",
      "Training Accuracy 0.715\n",
      "Loss 250.86487 177 21\n",
      "Training Accuracy 0.585\n",
      "Loss 212.13222 178 21\n",
      "Training Accuracy 0.655\n",
      "Loss 243.2578 179 21\n",
      "Training Accuracy 0.58\n",
      "Loss 237.31844 180 21\n",
      "Training Accuracy 0.595\n",
      "Loss 199.74425 181 21\n",
      "Training Accuracy 0.68\n",
      "Loss 242.5548 182 21\n",
      "Training Accuracy 0.6\n",
      "Loss 238.94273 183 21\n",
      "Training Accuracy 0.615\n",
      "Loss 201.19347 184 21\n",
      "Training Accuracy 0.725\n",
      "Loss 227.00977 185 21\n",
      "Training Accuracy 0.67\n",
      "Loss 219.67169 186 21\n",
      "Training Accuracy 0.69\n",
      "Loss 262.2101 187 21\n",
      "Training Accuracy 0.555\n",
      "Loss 241.39075 188 21\n",
      "Training Accuracy 0.61\n",
      "Loss 227.76163 189 21\n",
      "Training Accuracy 0.63\n",
      "Loss 224.75723 190 21\n",
      "Training Accuracy 0.635\n",
      "Loss 221.15768 191 21\n",
      "Training Accuracy 0.625\n",
      "Loss 245.9801 192 21\n",
      "Training Accuracy 0.56\n",
      "Loss 205.94997 193 21\n",
      "Training Accuracy 0.67\n",
      "Loss 209.72287 194 21\n",
      "Training Accuracy 0.675\n",
      "Loss 215.13622 195 21\n",
      "Training Accuracy 0.63\n",
      "Loss 219.23329 196 21\n",
      "Training Accuracy 0.6\n",
      "Loss 235.29155 197 21\n",
      "Training Accuracy 0.595\n",
      "Loss 211.32439 198 21\n",
      "Training Accuracy 0.63\n",
      "Loss 191.42252 199 21\n",
      "Training Accuracy 0.65\n",
      "Loss 223.72159 200 21\n",
      "Training Accuracy 0.615\n",
      "Loss 216.60487 201 21\n",
      "Training Accuracy 0.62\n",
      "Loss 218.0412 202 21\n",
      "Training Accuracy 0.6\n",
      "Loss 232.89346 203 21\n",
      "Training Accuracy 0.545\n",
      "Loss 220.3108 204 21\n",
      "Training Accuracy 0.565\n",
      "Loss 250.68599 205 21\n",
      "Training Accuracy 0.62\n",
      "Loss 230.54161 206 21\n",
      "Training Accuracy 0.61\n",
      "Loss 221.34973 207 21\n",
      "Training Accuracy 0.665\n",
      "Loss 245.66528 208 21\n",
      "Training Accuracy 0.595\n",
      "Loss 249.70325 209 21\n",
      "Training Accuracy 0.605\n",
      "Loss 215.80937 210 21\n",
      "Training Accuracy 0.635\n",
      "Loss 208.94415 211 21\n",
      "Training Accuracy 0.665\n",
      "Loss 215.1307 212 21\n",
      "Training Accuracy 0.61\n",
      "Loss 273.7213 213 21\n",
      "Training Accuracy 0.565\n",
      "Loss 231.00546 214 21\n",
      "Training Accuracy 0.59\n",
      "Loss 255.81502 215 21\n",
      "Training Accuracy 0.56\n",
      "Loss 246.57864 216 21\n",
      "Training Accuracy 0.615\n",
      "Loss 231.80264 217 21\n",
      "Training Accuracy 0.59\n",
      "Loss 234.85526 218 21\n",
      "Training Accuracy 0.57\n",
      "Loss 233.21068 219 21\n",
      "Training Accuracy 0.59\n",
      "Loss 220.91942 220 21\n",
      "Training Accuracy 0.65\n",
      "Loss 231.6381 221 21\n",
      "Training Accuracy 0.62\n",
      "Loss 235.63187 222 21\n",
      "Training Accuracy 0.55\n",
      "Loss 246.39774 223 21\n",
      "Training Accuracy 0.585\n",
      "Loss 245.26122 224 21\n",
      "Training Accuracy 0.555\n",
      "Loss 250.84404 225 21\n",
      "Training Accuracy 0.575\n",
      "Loss 199.02666 226 21\n",
      "Training Accuracy 0.655\n",
      "Loss 259.4793 227 21\n",
      "Training Accuracy 0.555\n",
      "Loss 266.32288 228 21\n",
      "Training Accuracy 0.565\n",
      "Loss 222.84497 229 21\n",
      "Training Accuracy 0.635\n",
      "Loss 241.29083 230 21\n",
      "Training Accuracy 0.61\n",
      "Loss 201.80627 231 21\n",
      "Training Accuracy 0.675\n",
      "Loss 237.08904 232 21\n",
      "Training Accuracy 0.585\n",
      "Loss 242.59021 233 21\n",
      "Training Accuracy 0.56\n",
      "Loss 241.74709 234 21\n",
      "Training Accuracy 0.585\n",
      "Loss 232.86003 235 21\n",
      "Training Accuracy 0.61\n",
      "Loss 204.0694 236 21\n",
      "Training Accuracy 0.67\n",
      "Loss 246.92085 237 21\n",
      "Training Accuracy 0.6\n",
      "Loss 217.8612 238 21\n",
      "Training Accuracy 0.6\n",
      "Loss 245.52208 239 21\n",
      "Training Accuracy 0.585\n",
      "Loss 233.1677 240 21\n",
      "Training Accuracy 0.6\n",
      "Loss 258.33157 241 21\n",
      "Training Accuracy 0.525\n",
      "Loss 210.87097 242 21\n",
      "Training Accuracy 0.65\n",
      "Loss 205.83583 243 21\n",
      "Training Accuracy 0.665\n",
      "Loss 237.8913 244 21\n",
      "Training Accuracy 0.545\n",
      "Loss 222.04707 245 21\n",
      "Training Accuracy 0.635\n",
      "Loss 239.10863 246 21\n",
      "Training Accuracy 0.585\n",
      "Loss 197.59306 247 21\n",
      "Training Accuracy 0.645\n",
      "Loss 212.87372 248 21\n",
      "Training Accuracy 0.66\n",
      "Loss 249.01067 249 21\n",
      "Training Accuracy 0.565\n",
      "Loss 246.07109 250 21\n",
      "Training Accuracy 0.56\n",
      "Loss 240.41765 251 21\n",
      "Training Accuracy 0.57\n",
      "Loss 203.96002 252 21\n",
      "Training Accuracy 0.61\n",
      "Loss 205.21463 253 21\n",
      "Training Accuracy 0.655\n",
      "Loss 228.47462 254 21\n",
      "Training Accuracy 0.63\n",
      "Loss 206.51682 255 21\n",
      "Training Accuracy 0.635\n",
      "Loss 244.25534 256 21\n",
      "Training Accuracy 0.61\n",
      "Loss 214.0354 257 21\n",
      "Training Accuracy 0.665\n",
      "Loss 237.72626 258 21\n",
      "Training Accuracy 0.625\n",
      "Loss 241.19534 259 21\n",
      "Training Accuracy 0.575\n",
      "Loss 198.77863 260 21\n",
      "Training Accuracy 0.64\n",
      "Loss 240.92964 261 21\n",
      "Training Accuracy 0.595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 229.8578 262 21\n",
      "Training Accuracy 0.55\n",
      "Loss 276.76855 263 21\n",
      "Training Accuracy 0.59\n",
      "Loss 241.28435 264 21\n",
      "Training Accuracy 0.645\n",
      "Loss 226.35156 265 21\n",
      "Training Accuracy 0.635\n",
      "Loss 216.9258 266 21\n",
      "Training Accuracy 0.615\n",
      "Loss 246.04189 267 21\n",
      "Training Accuracy 0.57\n",
      "Loss 247.74709 268 21\n",
      "Training Accuracy 0.595\n",
      "Loss 209.7025 269 21\n",
      "Training Accuracy 0.6\n",
      "Loss 198.27835 270 21\n",
      "Training Accuracy 0.655\n",
      "Loss 249.0882 271 21\n",
      "Training Accuracy 0.59\n",
      "Loss 232.4674 272 21\n",
      "Training Accuracy 0.63\n",
      "Loss 246.23512 273 21\n",
      "Training Accuracy 0.58\n",
      "Loss 214.15744 274 21\n",
      "Training Accuracy 0.665\n",
      "Loss 221.50105 275 21\n",
      "Training Accuracy 0.625\n",
      "Loss 213.94986 276 21\n",
      "Training Accuracy 0.625\n",
      "Loss 248.47475 277 21\n",
      "Training Accuracy 0.615\n",
      "Loss 210.33076 278 21\n",
      "Training Accuracy 0.65\n",
      "Loss 222.08794 279 21\n",
      "Training Accuracy 0.66\n",
      "Loss 217.15091 280 21\n",
      "Training Accuracy 0.585\n",
      "Loss 221.55164 281 21\n",
      "Training Accuracy 0.605\n",
      "Loss 235.17249 282 21\n",
      "Training Accuracy 0.635\n",
      "Loss 221.84277 283 21\n",
      "Training Accuracy 0.66\n",
      "Loss 195.89877 284 21\n",
      "Training Accuracy 0.69\n",
      "Loss 263.2538 285 21\n",
      "Training Accuracy 0.56\n",
      "Loss 230.34412 286 21\n",
      "Training Accuracy 0.62\n",
      "Loss 212.30597 287 21\n",
      "Training Accuracy 0.655\n",
      "Loss 223.35872 288 21\n",
      "Training Accuracy 0.68\n",
      "Loss 222.30605 289 21\n",
      "Training Accuracy 0.65\n",
      "Loss 216.93744 290 21\n",
      "Training Accuracy 0.655\n",
      "Loss 250.27824 291 21\n",
      "Training Accuracy 0.56\n",
      "Loss 140.49973 292 21\n",
      "Training Accuracy 0.6060606\n",
      "Loss 189.35135 1 22\n",
      "Training Accuracy 0.665\n",
      "Loss 228.08566 2 22\n",
      "Training Accuracy 0.635\n",
      "Loss 209.3259 3 22\n",
      "Training Accuracy 0.665\n",
      "Loss 236.43962 4 22\n",
      "Training Accuracy 0.63\n",
      "Loss 190.16269 5 22\n",
      "Training Accuracy 0.705\n",
      "Loss 236.04637 6 22\n",
      "Training Accuracy 0.62\n",
      "Loss 235.49048 7 22\n",
      "Training Accuracy 0.62\n",
      "Loss 250.716 8 22\n",
      "Training Accuracy 0.6\n",
      "Loss 213.82274 9 22\n",
      "Training Accuracy 0.645\n",
      "Loss 234.50342 10 22\n",
      "Training Accuracy 0.575\n",
      "Loss 259.34308 11 22\n",
      "Training Accuracy 0.61\n",
      "Loss 203.98383 12 22\n",
      "Training Accuracy 0.65\n",
      "Loss 215.36844 13 22\n",
      "Training Accuracy 0.63\n",
      "Loss 232.1063 14 22\n",
      "Training Accuracy 0.575\n",
      "Loss 204.90662 15 22\n",
      "Training Accuracy 0.665\n",
      "Loss 274.30365 16 22\n",
      "Training Accuracy 0.56\n",
      "Loss 207.58029 17 22\n",
      "Training Accuracy 0.645\n",
      "Loss 215.75455 18 22\n",
      "Training Accuracy 0.635\n",
      "Loss 209.42522 19 22\n",
      "Training Accuracy 0.65\n",
      "Loss 229.88612 20 22\n",
      "Training Accuracy 0.63\n",
      "Loss 226.63017 21 22\n",
      "Training Accuracy 0.605\n",
      "Loss 224.9331 22 22\n",
      "Training Accuracy 0.605\n",
      "Loss 233.07788 23 22\n",
      "Training Accuracy 0.58\n",
      "Loss 247.73775 24 22\n",
      "Training Accuracy 0.585\n",
      "Loss 223.1883 25 22\n",
      "Training Accuracy 0.635\n",
      "Loss 242.67969 26 22\n",
      "Training Accuracy 0.54\n",
      "Loss 223.17856 27 22\n",
      "Training Accuracy 0.585\n",
      "Loss 216.57721 28 22\n",
      "Training Accuracy 0.61\n",
      "Loss 225.2998 29 22\n",
      "Training Accuracy 0.615\n",
      "Loss 241.01987 30 22\n",
      "Training Accuracy 0.615\n",
      "Loss 242.5416 31 22\n",
      "Training Accuracy 0.615\n",
      "Loss 220.31209 32 22\n",
      "Training Accuracy 0.62\n",
      "Loss 236.61606 33 22\n",
      "Training Accuracy 0.63\n",
      "Loss 206.30113 34 22\n",
      "Training Accuracy 0.645\n",
      "Loss 205.23921 35 22\n",
      "Training Accuracy 0.66\n",
      "Loss 230.92401 36 22\n",
      "Training Accuracy 0.55\n",
      "Loss 221.54279 37 22\n",
      "Training Accuracy 0.595\n",
      "Loss 235.43018 38 22\n",
      "Training Accuracy 0.595\n",
      "Loss 194.64764 39 22\n",
      "Training Accuracy 0.67\n",
      "Loss 221.10861 40 22\n",
      "Training Accuracy 0.66\n",
      "Loss 237.83794 41 22\n",
      "Training Accuracy 0.545\n",
      "Loss 270.1815 42 22\n",
      "Training Accuracy 0.56\n",
      "Loss 215.14093 43 22\n",
      "Training Accuracy 0.665\n",
      "Loss 219.53893 44 22\n",
      "Training Accuracy 0.605\n",
      "Loss 218.70694 45 22\n",
      "Training Accuracy 0.65\n",
      "Loss 257.66525 46 22\n",
      "Training Accuracy 0.56\n",
      "Loss 210.68826 47 22\n",
      "Training Accuracy 0.665\n",
      "Loss 202.05408 48 22\n",
      "Training Accuracy 0.66\n",
      "Loss 241.22012 49 22\n",
      "Training Accuracy 0.58\n",
      "Loss 257.57047 50 22\n",
      "Training Accuracy 0.615\n",
      "Loss 216.17274 51 22\n",
      "Training Accuracy 0.615\n",
      "Loss 208.01244 52 22\n",
      "Training Accuracy 0.66\n",
      "Loss 191.4101 53 22\n",
      "Training Accuracy 0.685\n",
      "Loss 255.02702 54 22\n",
      "Training Accuracy 0.56\n",
      "Loss 239.30707 55 22\n",
      "Training Accuracy 0.59\n",
      "Loss 225.73709 56 22\n",
      "Training Accuracy 0.62\n",
      "Loss 214.7746 57 22\n",
      "Training Accuracy 0.645\n",
      "Loss 219.2736 58 22\n",
      "Training Accuracy 0.585\n",
      "Loss 229.7443 59 22\n",
      "Training Accuracy 0.585\n",
      "Loss 222.50597 60 22\n",
      "Training Accuracy 0.645\n",
      "Loss 230.47006 61 22\n",
      "Training Accuracy 0.595\n",
      "Loss 213.10223 62 22\n",
      "Training Accuracy 0.62\n",
      "Loss 229.38684 63 22\n",
      "Training Accuracy 0.62\n",
      "Loss 230.7225 64 22\n",
      "Training Accuracy 0.635\n",
      "Loss 234.94048 65 22\n",
      "Training Accuracy 0.61\n",
      "Loss 212.95178 66 22\n",
      "Training Accuracy 0.615\n",
      "Loss 227.87537 67 22\n",
      "Training Accuracy 0.615\n",
      "Loss 226.74538 68 22\n",
      "Training Accuracy 0.615\n",
      "Loss 217.18755 69 22\n",
      "Training Accuracy 0.66\n",
      "Loss 226.09264 70 22\n",
      "Training Accuracy 0.62\n",
      "Loss 225.07492 71 22\n",
      "Training Accuracy 0.65\n",
      "Loss 223.99602 72 22\n",
      "Training Accuracy 0.625\n",
      "Loss 238.07887 73 22\n",
      "Training Accuracy 0.6\n",
      "Loss 250.70908 74 22\n",
      "Training Accuracy 0.595\n",
      "Loss 230.62946 75 22\n",
      "Training Accuracy 0.58\n",
      "Loss 204.34914 76 22\n",
      "Training Accuracy 0.68\n",
      "Loss 239.136 77 22\n",
      "Training Accuracy 0.62\n",
      "Loss 227.08607 78 22\n",
      "Training Accuracy 0.62\n",
      "Loss 216.5598 79 22\n",
      "Training Accuracy 0.615\n",
      "Loss 233.80728 80 22\n",
      "Training Accuracy 0.635\n",
      "Loss 211.04663 81 22\n",
      "Training Accuracy 0.625\n",
      "Loss 210.53273 82 22\n",
      "Training Accuracy 0.635\n",
      "Loss 225.13959 83 22\n",
      "Training Accuracy 0.645\n",
      "Loss 256.94293 84 22\n",
      "Training Accuracy 0.57\n",
      "Loss 214.72198 85 22\n",
      "Training Accuracy 0.67\n",
      "Loss 226.16516 86 22\n",
      "Training Accuracy 0.665\n",
      "Loss 274.89572 87 22\n",
      "Training Accuracy 0.575\n",
      "Loss 255.99934 88 22\n",
      "Training Accuracy 0.59\n",
      "Loss 234.93105 89 22\n",
      "Training Accuracy 0.6\n",
      "Loss 228.53236 90 22\n",
      "Training Accuracy 0.595\n",
      "Loss 228.1857 91 22\n",
      "Training Accuracy 0.615\n",
      "Loss 240.32985 92 22\n",
      "Training Accuracy 0.605\n",
      "Loss 226.95023 93 22\n",
      "Training Accuracy 0.595\n",
      "Loss 227.75365 94 22\n",
      "Training Accuracy 0.59\n",
      "Loss 220.56406 95 22\n",
      "Training Accuracy 0.62\n",
      "Loss 233.66304 96 22\n",
      "Training Accuracy 0.61\n",
      "Loss 231.37592 97 22\n",
      "Training Accuracy 0.605\n",
      "Loss 206.5795 98 22\n",
      "Training Accuracy 0.63\n",
      "Loss 221.69763 99 22\n",
      "Training Accuracy 0.64\n",
      "Loss 227.23724 100 22\n",
      "Training Accuracy 0.64\n",
      "Loss 248.029 101 22\n",
      "Training Accuracy 0.54\n",
      "Loss 205.79321 102 22\n",
      "Training Accuracy 0.66\n",
      "Loss 221.406 103 22\n",
      "Training Accuracy 0.62\n",
      "Loss 220.35808 104 22\n",
      "Training Accuracy 0.6\n",
      "Loss 233.45607 105 22\n",
      "Training Accuracy 0.615\n",
      "Loss 224.66728 106 22\n",
      "Training Accuracy 0.605\n",
      "Loss 227.81947 107 22\n",
      "Training Accuracy 0.63\n",
      "Loss 224.68704 108 22\n",
      "Training Accuracy 0.605\n",
      "Loss 225.22101 109 22\n",
      "Training Accuracy 0.605\n",
      "Loss 233.60815 110 22\n",
      "Training Accuracy 0.64\n",
      "Loss 236.33423 111 22\n",
      "Training Accuracy 0.61\n",
      "Loss 244.65251 112 22\n",
      "Training Accuracy 0.585\n",
      "Loss 252.1353 113 22\n",
      "Training Accuracy 0.61\n",
      "Loss 223.64429 114 22\n",
      "Training Accuracy 0.595\n",
      "Loss 254.0301 115 22\n",
      "Training Accuracy 0.565\n",
      "Loss 258.84363 116 22\n",
      "Training Accuracy 0.585\n",
      "Loss 185.59892 117 22\n",
      "Training Accuracy 0.725\n",
      "Loss 236.12265 118 22\n",
      "Training Accuracy 0.6\n",
      "Loss 272.0092 119 22\n",
      "Training Accuracy 0.55\n",
      "Loss 249.1902 120 22\n",
      "Training Accuracy 0.575\n",
      "Loss 246.693 121 22\n",
      "Training Accuracy 0.575\n",
      "Loss 205.5465 122 22\n",
      "Training Accuracy 0.655\n",
      "Loss 233.09724 123 22\n",
      "Training Accuracy 0.615\n",
      "Loss 222.07892 124 22\n",
      "Training Accuracy 0.62\n",
      "Loss 215.69627 125 22\n",
      "Training Accuracy 0.615\n",
      "Loss 250.31108 126 22\n",
      "Training Accuracy 0.575\n",
      "Loss 234.80511 127 22\n",
      "Training Accuracy 0.605\n",
      "Loss 218.40048 128 22\n",
      "Training Accuracy 0.635\n",
      "Loss 215.14093 129 22\n",
      "Training Accuracy 0.665\n",
      "Loss 211.19498 130 22\n",
      "Training Accuracy 0.645\n",
      "Loss 208.88998 131 22\n",
      "Training Accuracy 0.66\n",
      "Loss 214.10907 132 22\n",
      "Training Accuracy 0.655\n",
      "Loss 226.90164 133 22\n",
      "Training Accuracy 0.635\n",
      "Loss 207.92789 134 22\n",
      "Training Accuracy 0.66\n",
      "Loss 220.39085 135 22\n",
      "Training Accuracy 0.625\n",
      "Loss 237.53398 136 22\n",
      "Training Accuracy 0.655\n",
      "Loss 244.79192 137 22\n",
      "Training Accuracy 0.615\n",
      "Loss 238.16098 138 22\n",
      "Training Accuracy 0.585\n",
      "Loss 246.14557 139 22\n",
      "Training Accuracy 0.635\n",
      "Loss 197.39984 140 22\n",
      "Training Accuracy 0.655\n",
      "Loss 227.67754 141 22\n",
      "Training Accuracy 0.635\n",
      "Loss 226.53856 142 22\n",
      "Training Accuracy 0.61\n",
      "Loss 198.96603 143 22\n",
      "Training Accuracy 0.665\n",
      "Loss 237.81096 144 22\n",
      "Training Accuracy 0.58\n",
      "Loss 224.86331 145 22\n",
      "Training Accuracy 0.615\n",
      "Loss 237.67267 146 22\n",
      "Training Accuracy 0.63\n",
      "Loss 230.76509 147 22\n",
      "Training Accuracy 0.595\n",
      "Loss 238.44214 148 22\n",
      "Training Accuracy 0.585\n",
      "Loss 217.59738 149 22\n",
      "Training Accuracy 0.64\n",
      "Loss 218.65324 150 22\n",
      "Training Accuracy 0.63\n",
      "Loss 234.03242 151 22\n",
      "Training Accuracy 0.635\n",
      "Loss 240.47661 152 22\n",
      "Training Accuracy 0.63\n",
      "Loss 224.4476 153 22\n",
      "Training Accuracy 0.61\n",
      "Loss 221.70859 154 22\n",
      "Training Accuracy 0.645\n",
      "Loss 214.67838 155 22\n",
      "Training Accuracy 0.645\n",
      "Loss 239.01717 156 22\n",
      "Training Accuracy 0.58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 203.34903 157 22\n",
      "Training Accuracy 0.625\n",
      "Loss 213.25893 158 22\n",
      "Training Accuracy 0.65\n",
      "Loss 258.1729 159 22\n",
      "Training Accuracy 0.6\n",
      "Loss 241.72649 160 22\n",
      "Training Accuracy 0.625\n",
      "Loss 259.66962 161 22\n",
      "Training Accuracy 0.555\n",
      "Loss 217.25464 162 22\n",
      "Training Accuracy 0.64\n",
      "Loss 252.58386 163 22\n",
      "Training Accuracy 0.59\n",
      "Loss 200.69817 164 22\n",
      "Training Accuracy 0.605\n",
      "Loss 219.37268 165 22\n",
      "Training Accuracy 0.62\n",
      "Loss 227.98944 166 22\n",
      "Training Accuracy 0.615\n",
      "Loss 201.5975 167 22\n",
      "Training Accuracy 0.69\n",
      "Loss 231.9671 168 22\n",
      "Training Accuracy 0.61\n",
      "Loss 226.86394 169 22\n",
      "Training Accuracy 0.64\n",
      "Loss 232.79953 170 22\n",
      "Training Accuracy 0.64\n",
      "Loss 240.28677 171 22\n",
      "Training Accuracy 0.605\n",
      "Loss 222.20958 172 22\n",
      "Training Accuracy 0.59\n",
      "Loss 244.1297 173 22\n",
      "Training Accuracy 0.645\n",
      "Loss 189.34775 174 22\n",
      "Training Accuracy 0.655\n",
      "Loss 202.87949 175 22\n",
      "Training Accuracy 0.685\n",
      "Loss 178.09334 176 22\n",
      "Training Accuracy 0.69\n",
      "Loss 239.75627 177 22\n",
      "Training Accuracy 0.615\n",
      "Loss 202.57875 178 22\n",
      "Training Accuracy 0.675\n",
      "Loss 239.93008 179 22\n",
      "Training Accuracy 0.62\n",
      "Loss 241.00299 180 22\n",
      "Training Accuracy 0.545\n",
      "Loss 208.51859 181 22\n",
      "Training Accuracy 0.67\n",
      "Loss 245.86815 182 22\n",
      "Training Accuracy 0.575\n",
      "Loss 238.13379 183 22\n",
      "Training Accuracy 0.59\n",
      "Loss 206.11163 184 22\n",
      "Training Accuracy 0.655\n",
      "Loss 219.62976 185 22\n",
      "Training Accuracy 0.645\n",
      "Loss 209.27231 186 22\n",
      "Training Accuracy 0.68\n",
      "Loss 263.08188 187 22\n",
      "Training Accuracy 0.575\n",
      "Loss 243.34724 188 22\n",
      "Training Accuracy 0.605\n",
      "Loss 225.97476 189 22\n",
      "Training Accuracy 0.615\n",
      "Loss 208.77782 190 22\n",
      "Training Accuracy 0.625\n",
      "Loss 206.6935 191 22\n",
      "Training Accuracy 0.66\n",
      "Loss 249.47969 192 22\n",
      "Training Accuracy 0.565\n",
      "Loss 210.12465 193 22\n",
      "Training Accuracy 0.64\n",
      "Loss 222.4914 194 22\n",
      "Training Accuracy 0.64\n",
      "Loss 205.82135 195 22\n",
      "Training Accuracy 0.665\n",
      "Loss 222.85303 196 22\n",
      "Training Accuracy 0.635\n",
      "Loss 230.12746 197 22\n",
      "Training Accuracy 0.62\n",
      "Loss 214.86388 198 22\n",
      "Training Accuracy 0.605\n",
      "Loss 191.74353 199 22\n",
      "Training Accuracy 0.67\n",
      "Loss 221.28912 200 22\n",
      "Training Accuracy 0.605\n",
      "Loss 212.12207 201 22\n",
      "Training Accuracy 0.605\n",
      "Loss 210.67714 202 22\n",
      "Training Accuracy 0.62\n",
      "Loss 215.80103 203 22\n",
      "Training Accuracy 0.61\n",
      "Loss 222.87973 204 22\n",
      "Training Accuracy 0.595\n",
      "Loss 247.74393 205 22\n",
      "Training Accuracy 0.62\n",
      "Loss 225.41809 206 22\n",
      "Training Accuracy 0.625\n",
      "Loss 226.94627 207 22\n",
      "Training Accuracy 0.615\n",
      "Loss 243.19342 208 22\n",
      "Training Accuracy 0.605\n",
      "Loss 241.01622 209 22\n",
      "Training Accuracy 0.59\n",
      "Loss 206.2571 210 22\n",
      "Training Accuracy 0.63\n",
      "Loss 215.89081 211 22\n",
      "Training Accuracy 0.63\n",
      "Loss 212.12318 212 22\n",
      "Training Accuracy 0.635\n",
      "Loss 253.34917 213 22\n",
      "Training Accuracy 0.61\n",
      "Loss 224.97987 214 22\n",
      "Training Accuracy 0.585\n",
      "Loss 233.82999 215 22\n",
      "Training Accuracy 0.58\n",
      "Loss 235.40926 216 22\n",
      "Training Accuracy 0.625\n",
      "Loss 229.30087 217 22\n",
      "Training Accuracy 0.56\n",
      "Loss 238.85574 218 22\n",
      "Training Accuracy 0.565\n",
      "Loss 224.31506 219 22\n",
      "Training Accuracy 0.635\n",
      "Loss 217.78876 220 22\n",
      "Training Accuracy 0.645\n",
      "Loss 218.95076 221 22\n",
      "Training Accuracy 0.655\n",
      "Loss 224.60408 222 22\n",
      "Training Accuracy 0.615\n",
      "Loss 245.3133 223 22\n",
      "Training Accuracy 0.595\n",
      "Loss 243.36809 224 22\n",
      "Training Accuracy 0.575\n",
      "Loss 240.703 225 22\n",
      "Training Accuracy 0.635\n",
      "Loss 196.32234 226 22\n",
      "Training Accuracy 0.67\n",
      "Loss 255.38123 227 22\n",
      "Training Accuracy 0.55\n",
      "Loss 259.16885 228 22\n",
      "Training Accuracy 0.58\n",
      "Loss 218.82373 229 22\n",
      "Training Accuracy 0.6\n",
      "Loss 235.28607 230 22\n",
      "Training Accuracy 0.62\n",
      "Loss 199.63098 231 22\n",
      "Training Accuracy 0.67\n",
      "Loss 229.54376 232 22\n",
      "Training Accuracy 0.56\n",
      "Loss 252.0675 233 22\n",
      "Training Accuracy 0.57\n",
      "Loss 233.88116 234 22\n",
      "Training Accuracy 0.54\n",
      "Loss 229.36494 235 22\n",
      "Training Accuracy 0.585\n",
      "Loss 199.315 236 22\n",
      "Training Accuracy 0.695\n",
      "Loss 233.41608 237 22\n",
      "Training Accuracy 0.6\n",
      "Loss 209.49873 238 22\n",
      "Training Accuracy 0.615\n",
      "Loss 249.47536 239 22\n",
      "Training Accuracy 0.58\n",
      "Loss 214.43005 240 22\n",
      "Training Accuracy 0.64\n",
      "Loss 249.28723 241 22\n",
      "Training Accuracy 0.575\n",
      "Loss 221.76114 242 22\n",
      "Training Accuracy 0.63\n",
      "Loss 201.9795 243 22\n",
      "Training Accuracy 0.675\n",
      "Loss 224.49574 244 22\n",
      "Training Accuracy 0.605\n",
      "Loss 230.11075 245 22\n",
      "Training Accuracy 0.63\n",
      "Loss 232.88937 246 22\n",
      "Training Accuracy 0.615\n",
      "Loss 194.08347 247 22\n",
      "Training Accuracy 0.64\n",
      "Loss 201.7307 248 22\n",
      "Training Accuracy 0.675\n",
      "Loss 242.5221 249 22\n",
      "Training Accuracy 0.585\n",
      "Loss 232.46501 250 22\n",
      "Training Accuracy 0.59\n",
      "Loss 231.00946 251 22\n",
      "Training Accuracy 0.57\n",
      "Loss 203.4939 252 22\n",
      "Training Accuracy 0.67\n",
      "Loss 194.5758 253 22\n",
      "Training Accuracy 0.705\n",
      "Loss 229.7934 254 22\n",
      "Training Accuracy 0.61\n",
      "Loss 200.31934 255 22\n",
      "Training Accuracy 0.665\n",
      "Loss 238.06975 256 22\n",
      "Training Accuracy 0.6\n",
      "Loss 218.2587 257 22\n",
      "Training Accuracy 0.64\n",
      "Loss 234.57301 258 22\n",
      "Training Accuracy 0.625\n",
      "Loss 227.9112 259 22\n",
      "Training Accuracy 0.575\n",
      "Loss 184.15627 260 22\n",
      "Training Accuracy 0.67\n",
      "Loss 234.06137 261 22\n",
      "Training Accuracy 0.635\n",
      "Loss 223.08751 262 22\n",
      "Training Accuracy 0.605\n",
      "Loss 264.37442 263 22\n",
      "Training Accuracy 0.55\n",
      "Loss 238.85472 264 22\n",
      "Training Accuracy 0.61\n",
      "Loss 208.594 265 22\n",
      "Training Accuracy 0.64\n",
      "Loss 216.4125 266 22\n",
      "Training Accuracy 0.59\n",
      "Loss 249.74236 267 22\n",
      "Training Accuracy 0.57\n",
      "Loss 242.75635 268 22\n",
      "Training Accuracy 0.59\n",
      "Loss 205.64456 269 22\n",
      "Training Accuracy 0.62\n",
      "Loss 186.47566 270 22\n",
      "Training Accuracy 0.665\n",
      "Loss 243.35632 271 22\n",
      "Training Accuracy 0.585\n",
      "Loss 220.88571 272 22\n",
      "Training Accuracy 0.66\n",
      "Loss 233.38538 273 22\n",
      "Training Accuracy 0.64\n",
      "Loss 219.2586 274 22\n",
      "Training Accuracy 0.65\n",
      "Loss 226.9782 275 22\n",
      "Training Accuracy 0.63\n",
      "Loss 214.13611 276 22\n",
      "Training Accuracy 0.665\n",
      "Loss 234.73459 277 22\n",
      "Training Accuracy 0.63\n",
      "Loss 206.68248 278 22\n",
      "Training Accuracy 0.615\n",
      "Loss 218.35957 279 22\n",
      "Training Accuracy 0.605\n",
      "Loss 216.31192 280 22\n",
      "Training Accuracy 0.595\n",
      "Loss 215.2491 281 22\n",
      "Training Accuracy 0.64\n",
      "Loss 221.37161 282 22\n",
      "Training Accuracy 0.62\n",
      "Loss 221.56743 283 22\n",
      "Training Accuracy 0.665\n",
      "Loss 192.75269 284 22\n",
      "Training Accuracy 0.685\n",
      "Loss 247.65065 285 22\n",
      "Training Accuracy 0.58\n",
      "Loss 230.86072 286 22\n",
      "Training Accuracy 0.64\n",
      "Loss 209.67346 287 22\n",
      "Training Accuracy 0.69\n",
      "Loss 222.44046 288 22\n",
      "Training Accuracy 0.675\n",
      "Loss 207.39714 289 22\n",
      "Training Accuracy 0.66\n",
      "Loss 223.12231 290 22\n",
      "Training Accuracy 0.62\n",
      "Loss 234.65517 291 22\n",
      "Training Accuracy 0.625\n",
      "Loss 146.61101 292 22\n",
      "Training Accuracy 0.6287879\n",
      "Loss 185.5087 1 23\n",
      "Training Accuracy 0.7\n",
      "Loss 210.35007 2 23\n",
      "Training Accuracy 0.65\n",
      "Loss 213.43167 3 23\n",
      "Training Accuracy 0.655\n",
      "Loss 225.27141 4 23\n",
      "Training Accuracy 0.65\n",
      "Loss 199.03722 5 23\n",
      "Training Accuracy 0.705\n",
      "Loss 230.34418 6 23\n",
      "Training Accuracy 0.615\n",
      "Loss 224.43173 7 23\n",
      "Training Accuracy 0.63\n",
      "Loss 242.64247 8 23\n",
      "Training Accuracy 0.615\n",
      "Loss 207.64906 9 23\n",
      "Training Accuracy 0.65\n",
      "Loss 245.67651 10 23\n",
      "Training Accuracy 0.595\n",
      "Loss 257.45605 11 23\n",
      "Training Accuracy 0.635\n",
      "Loss 221.77213 12 23\n",
      "Training Accuracy 0.605\n",
      "Loss 214.13692 13 23\n",
      "Training Accuracy 0.635\n",
      "Loss 230.13818 14 23\n",
      "Training Accuracy 0.585\n",
      "Loss 200.1119 15 23\n",
      "Training Accuracy 0.64\n",
      "Loss 264.33292 16 23\n",
      "Training Accuracy 0.58\n",
      "Loss 202.15042 17 23\n",
      "Training Accuracy 0.67\n",
      "Loss 212.05513 18 23\n",
      "Training Accuracy 0.66\n",
      "Loss 203.28612 19 23\n",
      "Training Accuracy 0.615\n",
      "Loss 211.25383 20 23\n",
      "Training Accuracy 0.645\n",
      "Loss 215.37872 21 23\n",
      "Training Accuracy 0.605\n",
      "Loss 228.34866 22 23\n",
      "Training Accuracy 0.62\n",
      "Loss 223.09251 23 23\n",
      "Training Accuracy 0.645\n",
      "Loss 238.48097 24 23\n",
      "Training Accuracy 0.59\n",
      "Loss 218.021 25 23\n",
      "Training Accuracy 0.635\n",
      "Loss 217.27678 26 23\n",
      "Training Accuracy 0.62\n",
      "Loss 208.88301 27 23\n",
      "Training Accuracy 0.615\n",
      "Loss 217.2789 28 23\n",
      "Training Accuracy 0.65\n",
      "Loss 216.44899 29 23\n",
      "Training Accuracy 0.6\n",
      "Loss 233.64662 30 23\n",
      "Training Accuracy 0.595\n",
      "Loss 237.80327 31 23\n",
      "Training Accuracy 0.6\n",
      "Loss 220.21819 32 23\n",
      "Training Accuracy 0.62\n",
      "Loss 232.16524 33 23\n",
      "Training Accuracy 0.62\n",
      "Loss 201.33594 34 23\n",
      "Training Accuracy 0.665\n",
      "Loss 209.00314 35 23\n",
      "Training Accuracy 0.61\n",
      "Loss 229.24802 36 23\n",
      "Training Accuracy 0.585\n",
      "Loss 227.36009 37 23\n",
      "Training Accuracy 0.64\n",
      "Loss 226.1804 38 23\n",
      "Training Accuracy 0.66\n",
      "Loss 193.96246 39 23\n",
      "Training Accuracy 0.67\n",
      "Loss 211.66644 40 23\n",
      "Training Accuracy 0.66\n",
      "Loss 218.54684 41 23\n",
      "Training Accuracy 0.6\n",
      "Loss 259.9042 42 23\n",
      "Training Accuracy 0.535\n",
      "Loss 206.61537 43 23\n",
      "Training Accuracy 0.65\n",
      "Loss 209.9853 44 23\n",
      "Training Accuracy 0.63\n",
      "Loss 218.31631 45 23\n",
      "Training Accuracy 0.62\n",
      "Loss 250.64662 46 23\n",
      "Training Accuracy 0.57\n",
      "Loss 213.4633 47 23\n",
      "Training Accuracy 0.67\n",
      "Loss 202.00763 48 23\n",
      "Training Accuracy 0.615\n",
      "Loss 226.13791 49 23\n",
      "Training Accuracy 0.63\n",
      "Loss 245.26141 50 23\n",
      "Training Accuracy 0.605\n",
      "Loss 203.25858 51 23\n",
      "Training Accuracy 0.65\n",
      "Loss 211.88426 52 23\n",
      "Training Accuracy 0.635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 198.1468 53 23\n",
      "Training Accuracy 0.665\n",
      "Loss 241.30392 54 23\n",
      "Training Accuracy 0.625\n",
      "Loss 232.14807 55 23\n",
      "Training Accuracy 0.58\n",
      "Loss 213.95053 56 23\n",
      "Training Accuracy 0.61\n",
      "Loss 210.0897 57 23\n",
      "Training Accuracy 0.66\n",
      "Loss 210.09135 58 23\n",
      "Training Accuracy 0.63\n",
      "Loss 246.9878 59 23\n",
      "Training Accuracy 0.605\n",
      "Loss 213.94052 60 23\n",
      "Training Accuracy 0.655\n",
      "Loss 222.2975 61 23\n",
      "Training Accuracy 0.59\n",
      "Loss 217.18193 62 23\n",
      "Training Accuracy 0.625\n",
      "Loss 223.66135 63 23\n",
      "Training Accuracy 0.63\n",
      "Loss 212.76938 64 23\n",
      "Training Accuracy 0.66\n",
      "Loss 230.46426 65 23\n",
      "Training Accuracy 0.57\n",
      "Loss 215.48697 66 23\n",
      "Training Accuracy 0.635\n",
      "Loss 232.29778 67 23\n",
      "Training Accuracy 0.605\n",
      "Loss 214.93192 68 23\n",
      "Training Accuracy 0.6\n",
      "Loss 223.14563 69 23\n",
      "Training Accuracy 0.61\n",
      "Loss 220.86452 70 23\n",
      "Training Accuracy 0.635\n",
      "Loss 229.27765 71 23\n",
      "Training Accuracy 0.63\n",
      "Loss 232.41725 72 23\n",
      "Training Accuracy 0.605\n",
      "Loss 220.95532 73 23\n",
      "Training Accuracy 0.65\n",
      "Loss 243.92572 74 23\n",
      "Training Accuracy 0.57\n",
      "Loss 219.04337 75 23\n",
      "Training Accuracy 0.66\n",
      "Loss 197.84067 76 23\n",
      "Training Accuracy 0.63\n",
      "Loss 238.09576 77 23\n",
      "Training Accuracy 0.625\n",
      "Loss 217.87114 78 23\n",
      "Training Accuracy 0.655\n",
      "Loss 227.57993 79 23\n",
      "Training Accuracy 0.565\n",
      "Loss 242.10475 80 23\n",
      "Training Accuracy 0.59\n",
      "Loss 216.81804 81 23\n",
      "Training Accuracy 0.64\n",
      "Loss 212.42093 82 23\n",
      "Training Accuracy 0.62\n",
      "Loss 210.90565 83 23\n",
      "Training Accuracy 0.65\n",
      "Loss 250.76581 84 23\n",
      "Training Accuracy 0.585\n",
      "Loss 220.5797 85 23\n",
      "Training Accuracy 0.605\n",
      "Loss 215.54094 86 23\n",
      "Training Accuracy 0.67\n",
      "Loss 274.36398 87 23\n",
      "Training Accuracy 0.56\n",
      "Loss 261.20462 88 23\n",
      "Training Accuracy 0.59\n",
      "Loss 219.68848 89 23\n",
      "Training Accuracy 0.64\n",
      "Loss 236.32149 90 23\n",
      "Training Accuracy 0.535\n",
      "Loss 225.69304 91 23\n",
      "Training Accuracy 0.595\n",
      "Loss 234.30495 92 23\n",
      "Training Accuracy 0.615\n",
      "Loss 222.30763 93 23\n",
      "Training Accuracy 0.615\n",
      "Loss 224.38715 94 23\n",
      "Training Accuracy 0.655\n",
      "Loss 218.66608 95 23\n",
      "Training Accuracy 0.585\n",
      "Loss 230.47943 96 23\n",
      "Training Accuracy 0.625\n",
      "Loss 233.2171 97 23\n",
      "Training Accuracy 0.59\n",
      "Loss 212.41873 98 23\n",
      "Training Accuracy 0.635\n",
      "Loss 213.3754 99 23\n",
      "Training Accuracy 0.62\n",
      "Loss 217.79776 100 23\n",
      "Training Accuracy 0.635\n",
      "Loss 238.98865 101 23\n",
      "Training Accuracy 0.57\n",
      "Loss 207.80118 102 23\n",
      "Training Accuracy 0.59\n",
      "Loss 227.22903 103 23\n",
      "Training Accuracy 0.62\n",
      "Loss 219.27626 104 23\n",
      "Training Accuracy 0.675\n",
      "Loss 222.33015 105 23\n",
      "Training Accuracy 0.665\n",
      "Loss 217.13716 106 23\n",
      "Training Accuracy 0.64\n",
      "Loss 213.42319 107 23\n",
      "Training Accuracy 0.64\n",
      "Loss 228.36249 108 23\n",
      "Training Accuracy 0.59\n",
      "Loss 229.96869 109 23\n",
      "Training Accuracy 0.58\n",
      "Loss 225.04175 110 23\n",
      "Training Accuracy 0.64\n",
      "Loss 225.4171 111 23\n",
      "Training Accuracy 0.63\n",
      "Loss 235.5479 112 23\n",
      "Training Accuracy 0.615\n",
      "Loss 257.1505 113 23\n",
      "Training Accuracy 0.625\n",
      "Loss 227.36034 114 23\n",
      "Training Accuracy 0.585\n",
      "Loss 249.32361 115 23\n",
      "Training Accuracy 0.56\n",
      "Loss 254.94012 116 23\n",
      "Training Accuracy 0.58\n",
      "Loss 182.10896 117 23\n",
      "Training Accuracy 0.705\n",
      "Loss 227.91278 118 23\n",
      "Training Accuracy 0.64\n",
      "Loss 255.71216 119 23\n",
      "Training Accuracy 0.57\n",
      "Loss 247.02966 120 23\n",
      "Training Accuracy 0.55\n",
      "Loss 242.12088 121 23\n",
      "Training Accuracy 0.595\n",
      "Loss 205.94626 122 23\n",
      "Training Accuracy 0.645\n",
      "Loss 230.00233 123 23\n",
      "Training Accuracy 0.625\n",
      "Loss 217.36824 124 23\n",
      "Training Accuracy 0.63\n",
      "Loss 202.79462 125 23\n",
      "Training Accuracy 0.655\n",
      "Loss 250.39783 126 23\n",
      "Training Accuracy 0.585\n",
      "Loss 228.48883 127 23\n",
      "Training Accuracy 0.595\n",
      "Loss 214.06807 128 23\n",
      "Training Accuracy 0.64\n",
      "Loss 204.79442 129 23\n",
      "Training Accuracy 0.72\n",
      "Loss 211.61433 130 23\n",
      "Training Accuracy 0.63\n",
      "Loss 213.26617 131 23\n",
      "Training Accuracy 0.625\n",
      "Loss 213.51614 132 23\n",
      "Training Accuracy 0.625\n",
      "Loss 219.36673 133 23\n",
      "Training Accuracy 0.64\n",
      "Loss 221.56937 134 23\n",
      "Training Accuracy 0.585\n",
      "Loss 215.31982 135 23\n",
      "Training Accuracy 0.67\n",
      "Loss 236.86415 136 23\n",
      "Training Accuracy 0.63\n",
      "Loss 250.07729 137 23\n",
      "Training Accuracy 0.59\n",
      "Loss 221.28317 138 23\n",
      "Training Accuracy 0.655\n",
      "Loss 245.96141 139 23\n",
      "Training Accuracy 0.625\n",
      "Loss 191.40799 140 23\n",
      "Training Accuracy 0.665\n",
      "Loss 234.29929 141 23\n",
      "Training Accuracy 0.615\n",
      "Loss 218.7899 142 23\n",
      "Training Accuracy 0.615\n",
      "Loss 203.24031 143 23\n",
      "Training Accuracy 0.625\n",
      "Loss 235.64124 144 23\n",
      "Training Accuracy 0.585\n",
      "Loss 216.88069 145 23\n",
      "Training Accuracy 0.635\n",
      "Loss 233.75377 146 23\n",
      "Training Accuracy 0.62\n",
      "Loss 225.9104 147 23\n",
      "Training Accuracy 0.635\n",
      "Loss 225.23477 148 23\n",
      "Training Accuracy 0.585\n",
      "Loss 218.3095 149 23\n",
      "Training Accuracy 0.635\n",
      "Loss 208.02353 150 23\n",
      "Training Accuracy 0.675\n",
      "Loss 227.27397 151 23\n",
      "Training Accuracy 0.615\n",
      "Loss 236.81273 152 23\n",
      "Training Accuracy 0.64\n",
      "Loss 216.51468 153 23\n",
      "Training Accuracy 0.64\n",
      "Loss 216.28581 154 23\n",
      "Training Accuracy 0.66\n",
      "Loss 221.57217 155 23\n",
      "Training Accuracy 0.62\n",
      "Loss 226.71501 156 23\n",
      "Training Accuracy 0.6\n",
      "Loss 193.38657 157 23\n",
      "Training Accuracy 0.63\n",
      "Loss 213.14992 158 23\n",
      "Training Accuracy 0.63\n",
      "Loss 244.46779 159 23\n",
      "Training Accuracy 0.64\n",
      "Loss 239.32047 160 23\n",
      "Training Accuracy 0.595\n",
      "Loss 248.82532 161 23\n",
      "Training Accuracy 0.55\n",
      "Loss 220.65614 162 23\n",
      "Training Accuracy 0.605\n",
      "Loss 248.51796 163 23\n",
      "Training Accuracy 0.63\n",
      "Loss 199.67133 164 23\n",
      "Training Accuracy 0.615\n",
      "Loss 211.60663 165 23\n",
      "Training Accuracy 0.64\n",
      "Loss 233.4538 166 23\n",
      "Training Accuracy 0.655\n",
      "Loss 192.19858 167 23\n",
      "Training Accuracy 0.675\n",
      "Loss 240.32335 168 23\n",
      "Training Accuracy 0.6\n",
      "Loss 224.98433 169 23\n",
      "Training Accuracy 0.62\n",
      "Loss 218.36803 170 23\n",
      "Training Accuracy 0.63\n",
      "Loss 237.5259 171 23\n",
      "Training Accuracy 0.63\n",
      "Loss 219.65533 172 23\n",
      "Training Accuracy 0.66\n",
      "Loss 244.96834 173 23\n",
      "Training Accuracy 0.615\n",
      "Loss 198.34448 174 23\n",
      "Training Accuracy 0.655\n",
      "Loss 199.03209 175 23\n",
      "Training Accuracy 0.715\n",
      "Loss 182.82513 176 23\n",
      "Training Accuracy 0.72\n",
      "Loss 254.0304 177 23\n",
      "Training Accuracy 0.555\n",
      "Loss 212.43817 178 23\n",
      "Training Accuracy 0.615\n",
      "Loss 231.25696 179 23\n",
      "Training Accuracy 0.625\n",
      "Loss 238.17708 180 23\n",
      "Training Accuracy 0.575\n",
      "Loss 197.4625 181 23\n",
      "Training Accuracy 0.675\n",
      "Loss 229.25427 182 23\n",
      "Training Accuracy 0.6\n",
      "Loss 231.70921 183 23\n",
      "Training Accuracy 0.575\n",
      "Loss 202.83014 184 23\n",
      "Training Accuracy 0.645\n",
      "Loss 213.15248 185 23\n",
      "Training Accuracy 0.635\n",
      "Loss 212.96822 186 23\n",
      "Training Accuracy 0.65\n",
      "Loss 269.32187 187 23\n",
      "Training Accuracy 0.54\n",
      "Loss 255.522 188 23\n",
      "Training Accuracy 0.55\n",
      "Loss 213.19157 189 23\n",
      "Training Accuracy 0.65\n",
      "Loss 204.65593 190 23\n",
      "Training Accuracy 0.65\n",
      "Loss 211.1523 191 23\n",
      "Training Accuracy 0.625\n",
      "Loss 245.50653 192 23\n",
      "Training Accuracy 0.58\n",
      "Loss 205.64546 193 23\n",
      "Training Accuracy 0.69\n",
      "Loss 215.50626 194 23\n",
      "Training Accuracy 0.65\n",
      "Loss 203.93442 195 23\n",
      "Training Accuracy 0.665\n",
      "Loss 206.4622 196 23\n",
      "Training Accuracy 0.66\n",
      "Loss 220.3374 197 23\n",
      "Training Accuracy 0.59\n",
      "Loss 205.41928 198 23\n",
      "Training Accuracy 0.61\n",
      "Loss 181.26732 199 23\n",
      "Training Accuracy 0.7\n",
      "Loss 214.46823 200 23\n",
      "Training Accuracy 0.62\n",
      "Loss 209.9125 201 23\n",
      "Training Accuracy 0.66\n",
      "Loss 195.58063 202 23\n",
      "Training Accuracy 0.63\n",
      "Loss 224.74763 203 23\n",
      "Training Accuracy 0.62\n",
      "Loss 221.79247 204 23\n",
      "Training Accuracy 0.585\n",
      "Loss 242.36931 205 23\n",
      "Training Accuracy 0.61\n",
      "Loss 215.27458 206 23\n",
      "Training Accuracy 0.635\n",
      "Loss 220.0467 207 23\n",
      "Training Accuracy 0.635\n",
      "Loss 227.30647 208 23\n",
      "Training Accuracy 0.65\n",
      "Loss 234.11975 209 23\n",
      "Training Accuracy 0.62\n",
      "Loss 216.25095 210 23\n",
      "Training Accuracy 0.63\n",
      "Loss 211.97032 211 23\n",
      "Training Accuracy 0.645\n",
      "Loss 201.92502 212 23\n",
      "Training Accuracy 0.695\n",
      "Loss 255.25116 213 23\n",
      "Training Accuracy 0.59\n",
      "Loss 222.6474 214 23\n",
      "Training Accuracy 0.635\n",
      "Loss 240.27115 215 23\n",
      "Training Accuracy 0.59\n",
      "Loss 243.4293 216 23\n",
      "Training Accuracy 0.605\n",
      "Loss 239.25139 217 23\n",
      "Training Accuracy 0.555\n",
      "Loss 228.98787 218 23\n",
      "Training Accuracy 0.605\n",
      "Loss 219.8178 219 23\n",
      "Training Accuracy 0.64\n",
      "Loss 213.29619 220 23\n",
      "Training Accuracy 0.66\n",
      "Loss 215.08469 221 23\n",
      "Training Accuracy 0.65\n",
      "Loss 224.32054 222 23\n",
      "Training Accuracy 0.61\n",
      "Loss 231.43346 223 23\n",
      "Training Accuracy 0.595\n",
      "Loss 239.37424 224 23\n",
      "Training Accuracy 0.565\n",
      "Loss 242.84984 225 23\n",
      "Training Accuracy 0.61\n",
      "Loss 183.13213 226 23\n",
      "Training Accuracy 0.66\n",
      "Loss 248.28647 227 23\n",
      "Training Accuracy 0.575\n",
      "Loss 261.04855 228 23\n",
      "Training Accuracy 0.55\n",
      "Loss 212.42006 229 23\n",
      "Training Accuracy 0.63\n",
      "Loss 220.09885 230 23\n",
      "Training Accuracy 0.64\n",
      "Loss 201.72884 231 23\n",
      "Training Accuracy 0.665\n",
      "Loss 221.96407 232 23\n",
      "Training Accuracy 0.61\n",
      "Loss 252.47702 233 23\n",
      "Training Accuracy 0.56\n",
      "Loss 224.27243 234 23\n",
      "Training Accuracy 0.59\n",
      "Loss 235.64294 235 23\n",
      "Training Accuracy 0.6\n",
      "Loss 191.94078 236 23\n",
      "Training Accuracy 0.695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 231.93446 237 23\n",
      "Training Accuracy 0.615\n",
      "Loss 202.15543 238 23\n",
      "Training Accuracy 0.635\n",
      "Loss 230.20389 239 23\n",
      "Training Accuracy 0.59\n",
      "Loss 231.05173 240 23\n",
      "Training Accuracy 0.56\n",
      "Loss 250.5128 241 23\n",
      "Training Accuracy 0.6\n",
      "Loss 210.91882 242 23\n",
      "Training Accuracy 0.63\n",
      "Loss 192.61404 243 23\n",
      "Training Accuracy 0.675\n",
      "Loss 224.8894 244 23\n",
      "Training Accuracy 0.575\n",
      "Loss 222.86775 245 23\n",
      "Training Accuracy 0.59\n",
      "Loss 229.27078 246 23\n",
      "Training Accuracy 0.625\n",
      "Loss 195.52182 247 23\n",
      "Training Accuracy 0.65\n",
      "Loss 208.5906 248 23\n",
      "Training Accuracy 0.645\n",
      "Loss 230.98398 249 23\n",
      "Training Accuracy 0.57\n",
      "Loss 227.29144 250 23\n",
      "Training Accuracy 0.585\n",
      "Loss 224.1257 251 23\n",
      "Training Accuracy 0.62\n",
      "Loss 195.78215 252 23\n",
      "Training Accuracy 0.675\n",
      "Loss 205.0707 253 23\n",
      "Training Accuracy 0.645\n",
      "Loss 224.80899 254 23\n",
      "Training Accuracy 0.64\n",
      "Loss 198.16568 255 23\n",
      "Training Accuracy 0.655\n",
      "Loss 250.56804 256 23\n",
      "Training Accuracy 0.56\n",
      "Loss 216.49194 257 23\n",
      "Training Accuracy 0.65\n",
      "Loss 224.145 258 23\n",
      "Training Accuracy 0.605\n",
      "Loss 227.73253 259 23\n",
      "Training Accuracy 0.585\n",
      "Loss 189.82442 260 23\n",
      "Training Accuracy 0.69\n",
      "Loss 234.9838 261 23\n",
      "Training Accuracy 0.6\n",
      "Loss 219.87343 262 23\n",
      "Training Accuracy 0.6\n",
      "Loss 272.24887 263 23\n",
      "Training Accuracy 0.55\n",
      "Loss 237.0108 264 23\n",
      "Training Accuracy 0.63\n",
      "Loss 198.46623 265 23\n",
      "Training Accuracy 0.66\n",
      "Loss 210.86717 266 23\n",
      "Training Accuracy 0.605\n",
      "Loss 234.3649 267 23\n",
      "Training Accuracy 0.585\n",
      "Loss 231.58905 268 23\n",
      "Training Accuracy 0.61\n",
      "Loss 202.83061 269 23\n",
      "Training Accuracy 0.625\n",
      "Loss 185.38083 270 23\n",
      "Training Accuracy 0.68\n",
      "Loss 239.59743 271 23\n",
      "Training Accuracy 0.585\n",
      "Loss 222.56473 272 23\n",
      "Training Accuracy 0.66\n",
      "Loss 229.83456 273 23\n",
      "Training Accuracy 0.66\n",
      "Loss 210.21841 274 23\n",
      "Training Accuracy 0.64\n",
      "Loss 222.71875 275 23\n",
      "Training Accuracy 0.57\n",
      "Loss 212.25021 276 23\n",
      "Training Accuracy 0.625\n",
      "Loss 235.60646 277 23\n",
      "Training Accuracy 0.61\n",
      "Loss 208.66847 278 23\n",
      "Training Accuracy 0.635\n",
      "Loss 216.16403 279 23\n",
      "Training Accuracy 0.68\n",
      "Loss 208.89557 280 23\n",
      "Training Accuracy 0.625\n",
      "Loss 214.2074 281 23\n",
      "Training Accuracy 0.635\n",
      "Loss 216.3524 282 23\n",
      "Training Accuracy 0.63\n",
      "Loss 209.66939 283 23\n",
      "Training Accuracy 0.665\n",
      "Loss 189.9023 284 23\n",
      "Training Accuracy 0.695\n",
      "Loss 249.19301 285 23\n",
      "Training Accuracy 0.6\n",
      "Loss 226.2124 286 23\n",
      "Training Accuracy 0.64\n",
      "Loss 214.7125 287 23\n",
      "Training Accuracy 0.66\n",
      "Loss 223.47655 288 23\n",
      "Training Accuracy 0.655\n",
      "Loss 213.2636 289 23\n",
      "Training Accuracy 0.64\n",
      "Loss 229.5558 290 23\n",
      "Training Accuracy 0.58\n",
      "Loss 234.90619 291 23\n",
      "Training Accuracy 0.595\n",
      "Loss 139.69165 292 23\n",
      "Training Accuracy 0.6515151\n",
      "Loss 183.28108 1 24\n",
      "Training Accuracy 0.665\n",
      "Loss 209.2869 2 24\n",
      "Training Accuracy 0.68\n",
      "Loss 200.48038 3 24\n",
      "Training Accuracy 0.69\n",
      "Loss 226.9135 4 24\n",
      "Training Accuracy 0.61\n",
      "Loss 190.65277 5 24\n",
      "Training Accuracy 0.66\n",
      "Loss 233.8246 6 24\n",
      "Training Accuracy 0.58\n",
      "Loss 224.263 7 24\n",
      "Training Accuracy 0.625\n",
      "Loss 248.16623 8 24\n",
      "Training Accuracy 0.61\n",
      "Loss 207.22878 9 24\n",
      "Training Accuracy 0.655\n",
      "Loss 238.43388 10 24\n",
      "Training Accuracy 0.615\n",
      "Loss 244.31444 11 24\n",
      "Training Accuracy 0.61\n",
      "Loss 212.88934 12 24\n",
      "Training Accuracy 0.625\n",
      "Loss 202.81842 13 24\n",
      "Training Accuracy 0.67\n",
      "Loss 231.60892 14 24\n",
      "Training Accuracy 0.61\n",
      "Loss 209.48459 15 24\n",
      "Training Accuracy 0.675\n",
      "Loss 267.72964 16 24\n",
      "Training Accuracy 0.58\n",
      "Loss 198.47473 17 24\n",
      "Training Accuracy 0.68\n",
      "Loss 203.82611 18 24\n",
      "Training Accuracy 0.65\n",
      "Loss 205.78041 19 24\n",
      "Training Accuracy 0.645\n",
      "Loss 212.7158 20 24\n",
      "Training Accuracy 0.63\n",
      "Loss 208.41971 21 24\n",
      "Training Accuracy 0.655\n",
      "Loss 224.24744 22 24\n",
      "Training Accuracy 0.625\n",
      "Loss 217.53654 23 24\n",
      "Training Accuracy 0.64\n",
      "Loss 236.7223 24 24\n",
      "Training Accuracy 0.59\n",
      "Loss 210.1989 25 24\n",
      "Training Accuracy 0.625\n",
      "Loss 239.63602 26 24\n",
      "Training Accuracy 0.595\n",
      "Loss 206.4346 27 24\n",
      "Training Accuracy 0.64\n",
      "Loss 218.44981 28 24\n",
      "Training Accuracy 0.63\n",
      "Loss 212.10756 29 24\n",
      "Training Accuracy 0.6\n",
      "Loss 227.02573 30 24\n",
      "Training Accuracy 0.61\n",
      "Loss 225.38197 31 24\n",
      "Training Accuracy 0.615\n",
      "Loss 221.5472 32 24\n",
      "Training Accuracy 0.615\n",
      "Loss 227.24774 33 24\n",
      "Training Accuracy 0.665\n",
      "Loss 200.77875 34 24\n",
      "Training Accuracy 0.665\n",
      "Loss 200.90521 35 24\n",
      "Training Accuracy 0.635\n",
      "Loss 226.0257 36 24\n",
      "Training Accuracy 0.57\n",
      "Loss 207.62018 37 24\n",
      "Training Accuracy 0.62\n",
      "Loss 226.01595 38 24\n",
      "Training Accuracy 0.605\n",
      "Loss 191.77843 39 24\n",
      "Training Accuracy 0.68\n",
      "Loss 203.83241 40 24\n",
      "Training Accuracy 0.67\n",
      "Loss 223.81148 41 24\n",
      "Training Accuracy 0.58\n",
      "Loss 257.17593 42 24\n",
      "Training Accuracy 0.555\n",
      "Loss 203.92989 43 24\n",
      "Training Accuracy 0.65\n",
      "Loss 201.37106 44 24\n",
      "Training Accuracy 0.655\n",
      "Loss 220.93129 45 24\n",
      "Training Accuracy 0.635\n",
      "Loss 241.72055 46 24\n",
      "Training Accuracy 0.595\n",
      "Loss 205.26099 47 24\n",
      "Training Accuracy 0.68\n",
      "Loss 191.49103 48 24\n",
      "Training Accuracy 0.62\n",
      "Loss 215.92334 49 24\n",
      "Training Accuracy 0.625\n",
      "Loss 242.19447 50 24\n",
      "Training Accuracy 0.625\n",
      "Loss 198.85326 51 24\n",
      "Training Accuracy 0.675\n",
      "Loss 195.69937 52 24\n",
      "Training Accuracy 0.695\n",
      "Loss 192.03214 53 24\n",
      "Training Accuracy 0.66\n",
      "Loss 242.76093 54 24\n",
      "Training Accuracy 0.605\n",
      "Loss 218.47745 55 24\n",
      "Training Accuracy 0.625\n",
      "Loss 220.55705 56 24\n",
      "Training Accuracy 0.59\n",
      "Loss 218.44205 57 24\n",
      "Training Accuracy 0.605\n",
      "Loss 208.9424 58 24\n",
      "Training Accuracy 0.6\n",
      "Loss 232.35591 59 24\n",
      "Training Accuracy 0.61\n",
      "Loss 218.75516 60 24\n",
      "Training Accuracy 0.67\n",
      "Loss 223.94652 61 24\n",
      "Training Accuracy 0.625\n",
      "Loss 216.1525 62 24\n",
      "Training Accuracy 0.63\n",
      "Loss 222.10367 63 24\n",
      "Training Accuracy 0.65\n",
      "Loss 217.35785 64 24\n",
      "Training Accuracy 0.65\n",
      "Loss 229.22455 65 24\n",
      "Training Accuracy 0.58\n",
      "Loss 205.29347 66 24\n",
      "Training Accuracy 0.635\n",
      "Loss 218.52888 67 24\n",
      "Training Accuracy 0.635\n",
      "Loss 207.707 68 24\n",
      "Training Accuracy 0.645\n",
      "Loss 206.15578 69 24\n",
      "Training Accuracy 0.655\n",
      "Loss 208.39026 70 24\n",
      "Training Accuracy 0.66\n",
      "Loss 210.61975 71 24\n",
      "Training Accuracy 0.685\n",
      "Loss 212.58565 72 24\n",
      "Training Accuracy 0.66\n",
      "Loss 218.39452 73 24\n",
      "Training Accuracy 0.61\n",
      "Loss 227.4352 74 24\n",
      "Training Accuracy 0.625\n",
      "Loss 206.78104 75 24\n",
      "Training Accuracy 0.655\n",
      "Loss 197.42789 76 24\n",
      "Training Accuracy 0.66\n",
      "Loss 231.3703 77 24\n",
      "Training Accuracy 0.645\n",
      "Loss 215.43112 78 24\n",
      "Training Accuracy 0.63\n",
      "Loss 219.21992 79 24\n",
      "Training Accuracy 0.595\n",
      "Loss 229.66307 80 24\n",
      "Training Accuracy 0.625\n",
      "Loss 192.49384 81 24\n",
      "Training Accuracy 0.68\n",
      "Loss 206.2185 82 24\n",
      "Training Accuracy 0.63\n",
      "Loss 212.48029 83 24\n",
      "Training Accuracy 0.66\n",
      "Loss 243.55962 84 24\n",
      "Training Accuracy 0.595\n",
      "Loss 234.0531 85 24\n",
      "Training Accuracy 0.59\n",
      "Loss 230.50655 86 24\n",
      "Training Accuracy 0.61\n",
      "Loss 264.72415 87 24\n",
      "Training Accuracy 0.595\n",
      "Loss 247.58057 88 24\n",
      "Training Accuracy 0.6\n",
      "Loss 220.67079 89 24\n",
      "Training Accuracy 0.625\n",
      "Loss 225.45248 90 24\n",
      "Training Accuracy 0.59\n",
      "Loss 231.77644 91 24\n",
      "Training Accuracy 0.61\n",
      "Loss 217.1404 92 24\n",
      "Training Accuracy 0.63\n",
      "Loss 216.14392 93 24\n",
      "Training Accuracy 0.615\n",
      "Loss 219.4645 94 24\n",
      "Training Accuracy 0.63\n",
      "Loss 200.32846 95 24\n",
      "Training Accuracy 0.64\n",
      "Loss 213.50731 96 24\n",
      "Training Accuracy 0.625\n",
      "Loss 229.93242 97 24\n",
      "Training Accuracy 0.605\n",
      "Loss 197.77914 98 24\n",
      "Training Accuracy 0.68\n",
      "Loss 211.2885 99 24\n",
      "Training Accuracy 0.65\n",
      "Loss 219.93367 100 24\n",
      "Training Accuracy 0.64\n",
      "Loss 234.66484 101 24\n",
      "Training Accuracy 0.6\n",
      "Loss 203.83273 102 24\n",
      "Training Accuracy 0.655\n",
      "Loss 220.87856 103 24\n",
      "Training Accuracy 0.62\n",
      "Loss 214.78683 104 24\n",
      "Training Accuracy 0.655\n",
      "Loss 228.12422 105 24\n",
      "Training Accuracy 0.59\n",
      "Loss 207.25435 106 24\n",
      "Training Accuracy 0.67\n",
      "Loss 209.01514 107 24\n",
      "Training Accuracy 0.655\n",
      "Loss 222.14804 108 24\n",
      "Training Accuracy 0.58\n",
      "Loss 224.39227 109 24\n",
      "Training Accuracy 0.63\n",
      "Loss 228.96434 110 24\n",
      "Training Accuracy 0.66\n",
      "Loss 222.2005 111 24\n",
      "Training Accuracy 0.62\n",
      "Loss 243.64238 112 24\n",
      "Training Accuracy 0.615\n",
      "Loss 240.29254 113 24\n",
      "Training Accuracy 0.64\n",
      "Loss 224.4941 114 24\n",
      "Training Accuracy 0.595\n",
      "Loss 237.00885 115 24\n",
      "Training Accuracy 0.615\n",
      "Loss 247.59702 116 24\n",
      "Training Accuracy 0.63\n",
      "Loss 185.50377 117 24\n",
      "Training Accuracy 0.705\n",
      "Loss 222.78589 118 24\n",
      "Training Accuracy 0.61\n",
      "Loss 246.13725 119 24\n",
      "Training Accuracy 0.575\n",
      "Loss 236.75757 120 24\n",
      "Training Accuracy 0.585\n",
      "Loss 235.9928 121 24\n",
      "Training Accuracy 0.625\n",
      "Loss 203.41266 122 24\n",
      "Training Accuracy 0.66\n",
      "Loss 215.93248 123 24\n",
      "Training Accuracy 0.615\n",
      "Loss 216.91249 124 24\n",
      "Training Accuracy 0.635\n",
      "Loss 196.2995 125 24\n",
      "Training Accuracy 0.68\n",
      "Loss 244.60164 126 24\n",
      "Training Accuracy 0.58\n",
      "Loss 227.95738 127 24\n",
      "Training Accuracy 0.585\n",
      "Loss 218.07466 128 24\n",
      "Training Accuracy 0.61\n",
      "Loss 206.65979 129 24\n",
      "Training Accuracy 0.685\n",
      "Loss 214.31105 130 24\n",
      "Training Accuracy 0.595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 208.60336 131 24\n",
      "Training Accuracy 0.645\n",
      "Loss 215.20264 132 24\n",
      "Training Accuracy 0.64\n",
      "Loss 209.63611 133 24\n",
      "Training Accuracy 0.675\n",
      "Loss 208.41313 134 24\n",
      "Training Accuracy 0.64\n",
      "Loss 215.5805 135 24\n",
      "Training Accuracy 0.61\n",
      "Loss 251.73975 136 24\n",
      "Training Accuracy 0.6\n",
      "Loss 244.9576 137 24\n",
      "Training Accuracy 0.61\n",
      "Loss 221.93353 138 24\n",
      "Training Accuracy 0.635\n",
      "Loss 244.0682 139 24\n",
      "Training Accuracy 0.625\n",
      "Loss 186.68951 140 24\n",
      "Training Accuracy 0.665\n",
      "Loss 223.54901 141 24\n",
      "Training Accuracy 0.625\n",
      "Loss 223.52911 142 24\n",
      "Training Accuracy 0.6\n",
      "Loss 187.30139 143 24\n",
      "Training Accuracy 0.69\n",
      "Loss 229.83644 144 24\n",
      "Training Accuracy 0.605\n",
      "Loss 212.38023 145 24\n",
      "Training Accuracy 0.625\n",
      "Loss 229.29723 146 24\n",
      "Training Accuracy 0.605\n",
      "Loss 226.35846 147 24\n",
      "Training Accuracy 0.6\n",
      "Loss 213.22661 148 24\n",
      "Training Accuracy 0.66\n",
      "Loss 225.2072 149 24\n",
      "Training Accuracy 0.605\n",
      "Loss 207.85939 150 24\n",
      "Training Accuracy 0.675\n",
      "Loss 233.69977 151 24\n",
      "Training Accuracy 0.655\n",
      "Loss 245.19751 152 24\n",
      "Training Accuracy 0.62\n",
      "Loss 215.49619 153 24\n",
      "Training Accuracy 0.605\n",
      "Loss 205.32454 154 24\n",
      "Training Accuracy 0.63\n",
      "Loss 205.44017 155 24\n",
      "Training Accuracy 0.67\n",
      "Loss 211.07355 156 24\n",
      "Training Accuracy 0.61\n",
      "Loss 199.54942 157 24\n",
      "Training Accuracy 0.625\n",
      "Loss 208.93193 158 24\n",
      "Training Accuracy 0.655\n",
      "Loss 238.58601 159 24\n",
      "Training Accuracy 0.575\n",
      "Loss 228.79305 160 24\n",
      "Training Accuracy 0.62\n",
      "Loss 231.06235 161 24\n",
      "Training Accuracy 0.595\n",
      "Loss 209.90169 162 24\n",
      "Training Accuracy 0.615\n",
      "Loss 239.2145 163 24\n",
      "Training Accuracy 0.64\n",
      "Loss 204.40573 164 24\n",
      "Training Accuracy 0.635\n",
      "Loss 215.41972 165 24\n",
      "Training Accuracy 0.635\n",
      "Loss 220.9568 166 24\n",
      "Training Accuracy 0.655\n",
      "Loss 201.02817 167 24\n",
      "Training Accuracy 0.64\n",
      "Loss 239.33453 168 24\n",
      "Training Accuracy 0.61\n",
      "Loss 226.70752 169 24\n",
      "Training Accuracy 0.595\n",
      "Loss 218.87546 170 24\n",
      "Training Accuracy 0.645\n",
      "Loss 236.25154 171 24\n",
      "Training Accuracy 0.635\n",
      "Loss 203.90353 172 24\n",
      "Training Accuracy 0.65\n",
      "Loss 242.39877 173 24\n",
      "Training Accuracy 0.605\n",
      "Loss 182.2069 174 24\n",
      "Training Accuracy 0.67\n",
      "Loss 182.36101 175 24\n",
      "Training Accuracy 0.745\n",
      "Loss 170.56157 176 24\n",
      "Training Accuracy 0.735\n",
      "Loss 243.5889 177 24\n",
      "Training Accuracy 0.59\n",
      "Loss 196.92307 178 24\n",
      "Training Accuracy 0.695\n",
      "Loss 231.23547 179 24\n",
      "Training Accuracy 0.575\n",
      "Loss 230.9743 180 24\n",
      "Training Accuracy 0.58\n",
      "Loss 193.56787 181 24\n",
      "Training Accuracy 0.685\n",
      "Loss 236.27864 182 24\n",
      "Training Accuracy 0.605\n",
      "Loss 233.21547 183 24\n",
      "Training Accuracy 0.59\n",
      "Loss 192.87128 184 24\n",
      "Training Accuracy 0.68\n",
      "Loss 201.30643 185 24\n",
      "Training Accuracy 0.675\n",
      "Loss 202.5796 186 24\n",
      "Training Accuracy 0.665\n",
      "Loss 241.62704 187 24\n",
      "Training Accuracy 0.59\n",
      "Loss 230.16469 188 24\n",
      "Training Accuracy 0.61\n",
      "Loss 222.60735 189 24\n",
      "Training Accuracy 0.605\n",
      "Loss 204.31726 190 24\n",
      "Training Accuracy 0.635\n",
      "Loss 202.01169 191 24\n",
      "Training Accuracy 0.655\n",
      "Loss 243.75381 192 24\n",
      "Training Accuracy 0.595\n",
      "Loss 194.55884 193 24\n",
      "Training Accuracy 0.7\n",
      "Loss 208.93915 194 24\n",
      "Training Accuracy 0.665\n",
      "Loss 199.30353 195 24\n",
      "Training Accuracy 0.66\n",
      "Loss 199.38164 196 24\n",
      "Training Accuracy 0.66\n",
      "Loss 214.19035 197 24\n",
      "Training Accuracy 0.635\n",
      "Loss 203.7052 198 24\n",
      "Training Accuracy 0.635\n",
      "Loss 176.3181 199 24\n",
      "Training Accuracy 0.71\n",
      "Loss 209.5888 200 24\n",
      "Training Accuracy 0.655\n",
      "Loss 204.1031 201 24\n",
      "Training Accuracy 0.61\n",
      "Loss 201.43228 202 24\n",
      "Training Accuracy 0.625\n",
      "Loss 220.45691 203 24\n",
      "Training Accuracy 0.63\n",
      "Loss 204.27354 204 24\n",
      "Training Accuracy 0.635\n",
      "Loss 241.90106 205 24\n",
      "Training Accuracy 0.6\n",
      "Loss 217.5487 206 24\n",
      "Training Accuracy 0.655\n",
      "Loss 221.11798 207 24\n",
      "Training Accuracy 0.68\n",
      "Loss 224.83392 208 24\n",
      "Training Accuracy 0.61\n",
      "Loss 231.21213 209 24\n",
      "Training Accuracy 0.615\n",
      "Loss 201.71954 210 24\n",
      "Training Accuracy 0.635\n",
      "Loss 199.84024 211 24\n",
      "Training Accuracy 0.715\n",
      "Loss 211.38112 212 24\n",
      "Training Accuracy 0.63\n",
      "Loss 244.25543 213 24\n",
      "Training Accuracy 0.595\n",
      "Loss 217.23828 214 24\n",
      "Training Accuracy 0.64\n",
      "Loss 234.362 215 24\n",
      "Training Accuracy 0.59\n",
      "Loss 228.44348 216 24\n",
      "Training Accuracy 0.625\n",
      "Loss 220.54541 217 24\n",
      "Training Accuracy 0.61\n",
      "Loss 230.24545 218 24\n",
      "Training Accuracy 0.57\n",
      "Loss 226.29535 219 24\n",
      "Training Accuracy 0.645\n",
      "Loss 207.91376 220 24\n",
      "Training Accuracy 0.65\n",
      "Loss 221.24086 221 24\n",
      "Training Accuracy 0.63\n",
      "Loss 218.10632 222 24\n",
      "Training Accuracy 0.6\n",
      "Loss 234.11658 223 24\n",
      "Training Accuracy 0.605\n",
      "Loss 236.01532 224 24\n",
      "Training Accuracy 0.575\n",
      "Loss 231.6017 225 24\n",
      "Training Accuracy 0.645\n",
      "Loss 185.56752 226 24\n",
      "Training Accuracy 0.7\n",
      "Loss 249.9189 227 24\n",
      "Training Accuracy 0.545\n",
      "Loss 249.11186 228 24\n",
      "Training Accuracy 0.575\n",
      "Loss 211.7209 229 24\n",
      "Training Accuracy 0.655\n",
      "Loss 229.3845 230 24\n",
      "Training Accuracy 0.625\n",
      "Loss 201.7844 231 24\n",
      "Training Accuracy 0.65\n",
      "Loss 231.172 232 24\n",
      "Training Accuracy 0.585\n",
      "Loss 249.19972 233 24\n",
      "Training Accuracy 0.585\n",
      "Loss 223.51016 234 24\n",
      "Training Accuracy 0.575\n",
      "Loss 221.15273 235 24\n",
      "Training Accuracy 0.625\n",
      "Loss 200.02455 236 24\n",
      "Training Accuracy 0.655\n",
      "Loss 226.7154 237 24\n",
      "Training Accuracy 0.6\n",
      "Loss 201.5678 238 24\n",
      "Training Accuracy 0.64\n",
      "Loss 240.79381 239 24\n",
      "Training Accuracy 0.59\n",
      "Loss 217.45747 240 24\n",
      "Training Accuracy 0.62\n",
      "Loss 246.2407 241 24\n",
      "Training Accuracy 0.59\n",
      "Loss 204.13194 242 24\n",
      "Training Accuracy 0.675\n",
      "Loss 197.91777 243 24\n",
      "Training Accuracy 0.67\n",
      "Loss 221.33351 244 24\n",
      "Training Accuracy 0.57\n",
      "Loss 218.48965 245 24\n",
      "Training Accuracy 0.62\n",
      "Loss 230.5657 246 24\n",
      "Training Accuracy 0.625\n",
      "Loss 188.43826 247 24\n",
      "Training Accuracy 0.61\n",
      "Loss 206.98715 248 24\n",
      "Training Accuracy 0.625\n",
      "Loss 224.36551 249 24\n",
      "Training Accuracy 0.585\n",
      "Loss 225.61058 250 24\n",
      "Training Accuracy 0.59\n",
      "Loss 226.89766 251 24\n",
      "Training Accuracy 0.585\n",
      "Loss 199.29654 252 24\n",
      "Training Accuracy 0.65\n",
      "Loss 189.67426 253 24\n",
      "Training Accuracy 0.715\n",
      "Loss 213.04774 254 24\n",
      "Training Accuracy 0.64\n",
      "Loss 195.65796 255 24\n",
      "Training Accuracy 0.685\n",
      "Loss 241.99335 256 24\n",
      "Training Accuracy 0.62\n",
      "Loss 202.61322 257 24\n",
      "Training Accuracy 0.65\n",
      "Loss 227.22298 258 24\n",
      "Training Accuracy 0.64\n",
      "Loss 213.6443 259 24\n",
      "Training Accuracy 0.62\n",
      "Loss 185.31825 260 24\n",
      "Training Accuracy 0.655\n",
      "Loss 217.4145 261 24\n",
      "Training Accuracy 0.67\n",
      "Loss 217.09566 262 24\n",
      "Training Accuracy 0.575\n",
      "Loss 277.8286 263 24\n",
      "Training Accuracy 0.55\n",
      "Loss 221.6283 264 24\n",
      "Training Accuracy 0.66\n",
      "Loss 202.50229 265 24\n",
      "Training Accuracy 0.67\n",
      "Loss 200.85126 266 24\n",
      "Training Accuracy 0.645\n",
      "Loss 225.99184 267 24\n",
      "Training Accuracy 0.585\n",
      "Loss 228.11931 268 24\n",
      "Training Accuracy 0.635\n",
      "Loss 198.61575 269 24\n",
      "Training Accuracy 0.655\n",
      "Loss 193.57135 270 24\n",
      "Training Accuracy 0.66\n",
      "Loss 236.69765 271 24\n",
      "Training Accuracy 0.595\n",
      "Loss 217.78104 272 24\n",
      "Training Accuracy 0.635\n",
      "Loss 227.87224 273 24\n",
      "Training Accuracy 0.61\n",
      "Loss 208.52449 274 24\n",
      "Training Accuracy 0.63\n",
      "Loss 213.1292 275 24\n",
      "Training Accuracy 0.64\n",
      "Loss 202.60423 276 24\n",
      "Training Accuracy 0.645\n",
      "Loss 237.2613 277 24\n",
      "Training Accuracy 0.63\n",
      "Loss 209.76692 278 24\n",
      "Training Accuracy 0.635\n",
      "Loss 213.58498 279 24\n",
      "Training Accuracy 0.655\n",
      "Loss 213.95097 280 24\n",
      "Training Accuracy 0.625\n",
      "Loss 205.32372 281 24\n",
      "Training Accuracy 0.6\n",
      "Loss 207.7717 282 24\n",
      "Training Accuracy 0.65\n",
      "Loss 210.16125 283 24\n",
      "Training Accuracy 0.67\n",
      "Loss 185.33224 284 24\n",
      "Training Accuracy 0.715\n",
      "Loss 240.12625 285 24\n",
      "Training Accuracy 0.62\n",
      "Loss 220.93152 286 24\n",
      "Training Accuracy 0.605\n",
      "Loss 203.41074 287 24\n",
      "Training Accuracy 0.69\n",
      "Loss 214.26068 288 24\n",
      "Training Accuracy 0.66\n",
      "Loss 201.41284 289 24\n",
      "Training Accuracy 0.675\n",
      "Loss 216.72365 290 24\n",
      "Training Accuracy 0.635\n",
      "Loss 230.97581 291 24\n",
      "Training Accuracy 0.64\n",
      "Loss 140.9511 292 24\n",
      "Training Accuracy 0.6136364\n",
      "Loss 175.08652 1 25\n",
      "Training Accuracy 0.73\n",
      "Loss 229.27493 2 25\n",
      "Training Accuracy 0.61\n",
      "Loss 202.66852 3 25\n",
      "Training Accuracy 0.685\n",
      "Loss 227.71709 4 25\n",
      "Training Accuracy 0.65\n",
      "Loss 181.65196 5 25\n",
      "Training Accuracy 0.72\n",
      "Loss 217.87062 6 25\n",
      "Training Accuracy 0.62\n",
      "Loss 223.33725 7 25\n",
      "Training Accuracy 0.635\n",
      "Loss 229.95787 8 25\n",
      "Training Accuracy 0.65\n",
      "Loss 206.4496 9 25\n",
      "Training Accuracy 0.66\n",
      "Loss 231.612 10 25\n",
      "Training Accuracy 0.6\n",
      "Loss 238.84232 11 25\n",
      "Training Accuracy 0.65\n",
      "Loss 214.22717 12 25\n",
      "Training Accuracy 0.61\n",
      "Loss 202.19455 13 25\n",
      "Training Accuracy 0.66\n",
      "Loss 213.95305 14 25\n",
      "Training Accuracy 0.635\n",
      "Loss 198.71632 15 25\n",
      "Training Accuracy 0.65\n",
      "Loss 263.72983 16 25\n",
      "Training Accuracy 0.58\n",
      "Loss 191.22578 17 25\n",
      "Training Accuracy 0.69\n",
      "Loss 204.42986 18 25\n",
      "Training Accuracy 0.645\n",
      "Loss 192.89883 19 25\n",
      "Training Accuracy 0.64\n",
      "Loss 206.99187 20 25\n",
      "Training Accuracy 0.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 209.06523 21 25\n",
      "Training Accuracy 0.635\n",
      "Loss 208.88022 22 25\n",
      "Training Accuracy 0.66\n",
      "Loss 226.60374 23 25\n",
      "Training Accuracy 0.605\n",
      "Loss 229.65129 24 25\n",
      "Training Accuracy 0.605\n",
      "Loss 201.97212 25 25\n",
      "Training Accuracy 0.655\n",
      "Loss 217.21182 26 25\n",
      "Training Accuracy 0.605\n",
      "Loss 206.00478 27 25\n",
      "Training Accuracy 0.62\n",
      "Loss 206.943 28 25\n",
      "Training Accuracy 0.66\n",
      "Loss 222.90344 29 25\n",
      "Training Accuracy 0.58\n",
      "Loss 224.82979 30 25\n",
      "Training Accuracy 0.64\n",
      "Loss 213.01248 31 25\n",
      "Training Accuracy 0.645\n",
      "Loss 211.74704 32 25\n",
      "Training Accuracy 0.635\n",
      "Loss 218.07567 33 25\n",
      "Training Accuracy 0.645\n",
      "Loss 194.41919 34 25\n",
      "Training Accuracy 0.655\n",
      "Loss 196.29034 35 25\n",
      "Training Accuracy 0.64\n",
      "Loss 223.68192 36 25\n",
      "Training Accuracy 0.58\n",
      "Loss 212.32976 37 25\n",
      "Training Accuracy 0.62\n",
      "Loss 222.06004 38 25\n",
      "Training Accuracy 0.625\n",
      "Loss 185.38177 39 25\n",
      "Training Accuracy 0.68\n",
      "Loss 205.89543 40 25\n",
      "Training Accuracy 0.66\n",
      "Loss 212.13673 41 25\n",
      "Training Accuracy 0.6\n",
      "Loss 258.9976 42 25\n",
      "Training Accuracy 0.585\n",
      "Loss 205.30417 43 25\n",
      "Training Accuracy 0.615\n",
      "Loss 209.45264 44 25\n",
      "Training Accuracy 0.635\n",
      "Loss 224.80815 45 25\n",
      "Training Accuracy 0.64\n",
      "Loss 248.43275 46 25\n",
      "Training Accuracy 0.57\n",
      "Loss 194.28111 47 25\n",
      "Training Accuracy 0.665\n",
      "Loss 188.80452 48 25\n",
      "Training Accuracy 0.645\n",
      "Loss 203.29697 49 25\n",
      "Training Accuracy 0.65\n",
      "Loss 238.15858 50 25\n",
      "Training Accuracy 0.595\n",
      "Loss 199.43538 51 25\n",
      "Training Accuracy 0.67\n",
      "Loss 189.69904 52 25\n",
      "Training Accuracy 0.695\n",
      "Loss 183.48332 53 25\n",
      "Training Accuracy 0.655\n",
      "Loss 235.22647 54 25\n",
      "Training Accuracy 0.62\n",
      "Loss 224.27434 55 25\n",
      "Training Accuracy 0.605\n",
      "Loss 212.72943 56 25\n",
      "Training Accuracy 0.64\n",
      "Loss 208.79475 57 25\n",
      "Training Accuracy 0.635\n",
      "Loss 202.09384 58 25\n",
      "Training Accuracy 0.635\n",
      "Loss 214.9224 59 25\n",
      "Training Accuracy 0.635\n",
      "Loss 208.81093 60 25\n",
      "Training Accuracy 0.7\n",
      "Loss 210.54256 61 25\n",
      "Training Accuracy 0.63\n",
      "Loss 202.58257 62 25\n",
      "Training Accuracy 0.635\n",
      "Loss 211.00847 63 25\n",
      "Training Accuracy 0.63\n",
      "Loss 210.05042 64 25\n",
      "Training Accuracy 0.665\n",
      "Loss 221.9235 65 25\n",
      "Training Accuracy 0.61\n",
      "Loss 208.62305 66 25\n",
      "Training Accuracy 0.58\n",
      "Loss 217.7103 67 25\n",
      "Training Accuracy 0.62\n",
      "Loss 202.18384 68 25\n",
      "Training Accuracy 0.665\n",
      "Loss 211.57346 69 25\n",
      "Training Accuracy 0.645\n",
      "Loss 216.4234 70 25\n",
      "Training Accuracy 0.655\n",
      "Loss 214.7777 71 25\n",
      "Training Accuracy 0.665\n",
      "Loss 216.99251 72 25\n",
      "Training Accuracy 0.61\n",
      "Loss 223.18982 73 25\n",
      "Training Accuracy 0.6\n",
      "Loss 234.06264 74 25\n",
      "Training Accuracy 0.615\n",
      "Loss 219.95422 75 25\n",
      "Training Accuracy 0.61\n",
      "Loss 200.65984 76 25\n",
      "Training Accuracy 0.62\n",
      "Loss 233.82086 77 25\n",
      "Training Accuracy 0.625\n",
      "Loss 208.98235 78 25\n",
      "Training Accuracy 0.67\n",
      "Loss 214.87389 79 25\n",
      "Training Accuracy 0.605\n",
      "Loss 228.76256 80 25\n",
      "Training Accuracy 0.61\n",
      "Loss 196.04407 81 25\n",
      "Training Accuracy 0.695\n",
      "Loss 211.49551 82 25\n",
      "Training Accuracy 0.64\n",
      "Loss 207.34935 83 25\n",
      "Training Accuracy 0.675\n",
      "Loss 242.31479 84 25\n",
      "Training Accuracy 0.585\n",
      "Loss 212.5973 85 25\n",
      "Training Accuracy 0.595\n",
      "Loss 216.20847 86 25\n",
      "Training Accuracy 0.655\n",
      "Loss 247.3767 87 25\n",
      "Training Accuracy 0.62\n",
      "Loss 247.30032 88 25\n",
      "Training Accuracy 0.6\n",
      "Loss 224.21658 89 25\n",
      "Training Accuracy 0.64\n",
      "Loss 224.1905 90 25\n",
      "Training Accuracy 0.605\n",
      "Loss 226.22806 91 25\n",
      "Training Accuracy 0.62\n",
      "Loss 225.28612 92 25\n",
      "Training Accuracy 0.64\n",
      "Loss 215.49118 93 25\n",
      "Training Accuracy 0.655\n",
      "Loss 220.92465 94 25\n",
      "Training Accuracy 0.63\n",
      "Loss 207.87465 95 25\n",
      "Training Accuracy 0.605\n",
      "Loss 219.13344 96 25\n",
      "Training Accuracy 0.615\n",
      "Loss 224.69049 97 25\n",
      "Training Accuracy 0.605\n",
      "Loss 211.73018 98 25\n",
      "Training Accuracy 0.655\n",
      "Loss 209.27702 99 25\n",
      "Training Accuracy 0.625\n",
      "Loss 216.17947 100 25\n",
      "Training Accuracy 0.67\n",
      "Loss 232.25676 101 25\n",
      "Training Accuracy 0.625\n",
      "Loss 201.37625 102 25\n",
      "Training Accuracy 0.635\n",
      "Loss 223.83769 103 25\n",
      "Training Accuracy 0.61\n",
      "Loss 212.54555 104 25\n",
      "Training Accuracy 0.645\n",
      "Loss 222.17601 105 25\n",
      "Training Accuracy 0.65\n",
      "Loss 216.0123 106 25\n",
      "Training Accuracy 0.645\n",
      "Loss 209.93419 107 25\n",
      "Training Accuracy 0.605\n",
      "Loss 221.61534 108 25\n",
      "Training Accuracy 0.595\n",
      "Loss 217.15428 109 25\n",
      "Training Accuracy 0.62\n",
      "Loss 218.57603 110 25\n",
      "Training Accuracy 0.625\n",
      "Loss 216.11412 111 25\n",
      "Training Accuracy 0.645\n",
      "Loss 230.32504 112 25\n",
      "Training Accuracy 0.625\n",
      "Loss 249.52968 113 25\n",
      "Training Accuracy 0.615\n",
      "Loss 212.3537 114 25\n",
      "Training Accuracy 0.635\n",
      "Loss 240.2229 115 25\n",
      "Training Accuracy 0.575\n",
      "Loss 237.65663 116 25\n",
      "Training Accuracy 0.61\n",
      "Loss 183.62148 117 25\n",
      "Training Accuracy 0.735\n",
      "Loss 211.99472 118 25\n",
      "Training Accuracy 0.65\n",
      "Loss 244.93208 119 25\n",
      "Training Accuracy 0.565\n",
      "Loss 241.99399 120 25\n",
      "Training Accuracy 0.585\n",
      "Loss 226.95676 121 25\n",
      "Training Accuracy 0.625\n",
      "Loss 206.3526 122 25\n",
      "Training Accuracy 0.65\n",
      "Loss 220.04218 123 25\n",
      "Training Accuracy 0.595\n",
      "Loss 203.67374 124 25\n",
      "Training Accuracy 0.66\n",
      "Loss 198.26155 125 25\n",
      "Training Accuracy 0.665\n",
      "Loss 237.3448 126 25\n",
      "Training Accuracy 0.6\n",
      "Loss 218.00533 127 25\n",
      "Training Accuracy 0.625\n",
      "Loss 211.69243 128 25\n",
      "Training Accuracy 0.635\n",
      "Loss 203.97083 129 25\n",
      "Training Accuracy 0.67\n",
      "Loss 199.8138 130 25\n",
      "Training Accuracy 0.645\n",
      "Loss 192.44447 131 25\n",
      "Training Accuracy 0.67\n",
      "Loss 194.08679 132 25\n",
      "Training Accuracy 0.705\n",
      "Loss 206.51866 133 25\n",
      "Training Accuracy 0.675\n",
      "Loss 197.53069 134 25\n",
      "Training Accuracy 0.675\n",
      "Loss 212.45273 135 25\n",
      "Training Accuracy 0.635\n",
      "Loss 225.2724 136 25\n",
      "Training Accuracy 0.615\n",
      "Loss 234.69077 137 25\n",
      "Training Accuracy 0.6\n",
      "Loss 213.25833 138 25\n",
      "Training Accuracy 0.66\n",
      "Loss 232.95226 139 25\n",
      "Training Accuracy 0.635\n",
      "Loss 195.83832 140 25\n",
      "Training Accuracy 0.65\n",
      "Loss 212.34912 141 25\n",
      "Training Accuracy 0.64\n",
      "Loss 219.61957 142 25\n",
      "Training Accuracy 0.6\n",
      "Loss 188.2783 143 25\n",
      "Training Accuracy 0.675\n",
      "Loss 233.56082 144 25\n",
      "Training Accuracy 0.57\n",
      "Loss 212.85925 145 25\n",
      "Training Accuracy 0.62\n",
      "Loss 223.699 146 25\n",
      "Training Accuracy 0.6\n",
      "Loss 229.9848 147 25\n",
      "Training Accuracy 0.61\n",
      "Loss 224.21869 148 25\n",
      "Training Accuracy 0.615\n",
      "Loss 218.61604 149 25\n",
      "Training Accuracy 0.615\n",
      "Loss 198.53366 150 25\n",
      "Training Accuracy 0.68\n",
      "Loss 231.64111 151 25\n",
      "Training Accuracy 0.61\n",
      "Loss 235.44907 152 25\n",
      "Training Accuracy 0.62\n",
      "Loss 213.98643 153 25\n",
      "Training Accuracy 0.665\n",
      "Loss 208.84715 154 25\n",
      "Training Accuracy 0.66\n",
      "Loss 199.32338 155 25\n",
      "Training Accuracy 0.69\n",
      "Loss 231.90738 156 25\n",
      "Training Accuracy 0.56\n",
      "Loss 185.60852 157 25\n",
      "Training Accuracy 0.66\n",
      "Loss 196.88712 158 25\n",
      "Training Accuracy 0.655\n",
      "Loss 237.04321 159 25\n",
      "Training Accuracy 0.65\n",
      "Loss 217.05576 160 25\n",
      "Training Accuracy 0.64\n",
      "Loss 229.52289 161 25\n",
      "Training Accuracy 0.61\n",
      "Loss 215.58154 162 25\n",
      "Training Accuracy 0.615\n",
      "Loss 242.84282 163 25\n",
      "Training Accuracy 0.615\n",
      "Loss 199.03212 164 25\n",
      "Training Accuracy 0.615\n",
      "Loss 224.05652 165 25\n",
      "Training Accuracy 0.62\n",
      "Loss 207.0405 166 25\n",
      "Training Accuracy 0.675\n",
      "Loss 194.58879 167 25\n",
      "Training Accuracy 0.665\n",
      "Loss 238.76862 168 25\n",
      "Training Accuracy 0.62\n",
      "Loss 209.30539 169 25\n",
      "Training Accuracy 0.64\n",
      "Loss 210.30241 170 25\n",
      "Training Accuracy 0.625\n",
      "Loss 234.05736 171 25\n",
      "Training Accuracy 0.6\n",
      "Loss 207.6718 172 25\n",
      "Training Accuracy 0.64\n",
      "Loss 239.18251 173 25\n",
      "Training Accuracy 0.645\n",
      "Loss 179.57922 174 25\n",
      "Training Accuracy 0.685\n",
      "Loss 189.50708 175 25\n",
      "Training Accuracy 0.695\n",
      "Loss 174.34807 176 25\n",
      "Training Accuracy 0.695\n",
      "Loss 240.30908 177 25\n",
      "Training Accuracy 0.605\n",
      "Loss 197.70802 178 25\n",
      "Training Accuracy 0.68\n",
      "Loss 236.6727 179 25\n",
      "Training Accuracy 0.625\n",
      "Loss 219.91068 180 25\n",
      "Training Accuracy 0.645\n",
      "Loss 194.10432 181 25\n",
      "Training Accuracy 0.685\n",
      "Loss 231.25227 182 25\n",
      "Training Accuracy 0.6\n",
      "Loss 226.71916 183 25\n",
      "Training Accuracy 0.58\n",
      "Loss 189.27863 184 25\n",
      "Training Accuracy 0.685\n",
      "Loss 213.69554 185 25\n",
      "Training Accuracy 0.68\n",
      "Loss 207.80396 186 25\n",
      "Training Accuracy 0.63\n",
      "Loss 252.62679 187 25\n",
      "Training Accuracy 0.55\n",
      "Loss 236.02737 188 25\n",
      "Training Accuracy 0.615\n",
      "Loss 209.06078 189 25\n",
      "Training Accuracy 0.68\n",
      "Loss 210.87944 190 25\n",
      "Training Accuracy 0.625\n",
      "Loss 203.8188 191 25\n",
      "Training Accuracy 0.655\n",
      "Loss 227.62918 192 25\n",
      "Training Accuracy 0.64\n",
      "Loss 195.58052 193 25\n",
      "Training Accuracy 0.685\n",
      "Loss 205.32468 194 25\n",
      "Training Accuracy 0.665\n",
      "Loss 198.54472 195 25\n",
      "Training Accuracy 0.7\n",
      "Loss 198.21712 196 25\n",
      "Training Accuracy 0.675\n",
      "Loss 213.44337 197 25\n",
      "Training Accuracy 0.62\n",
      "Loss 197.41107 198 25\n",
      "Training Accuracy 0.635\n",
      "Loss 166.86687 199 25\n",
      "Training Accuracy 0.725\n",
      "Loss 200.76404 200 25\n",
      "Training Accuracy 0.67\n",
      "Loss 205.76134 201 25\n",
      "Training Accuracy 0.62\n",
      "Loss 202.3438 202 25\n",
      "Training Accuracy 0.625\n",
      "Loss 220.84811 203 25\n",
      "Training Accuracy 0.65\n",
      "Loss 211.47923 204 25\n",
      "Training Accuracy 0.6\n",
      "Loss 225.331 205 25\n",
      "Training Accuracy 0.65\n",
      "Loss 206.97345 206 25\n",
      "Training Accuracy 0.65\n",
      "Loss 207.83157 207 25\n",
      "Training Accuracy 0.665\n",
      "Loss 235.73973 208 25\n",
      "Training Accuracy 0.645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 233.60515 209 25\n",
      "Training Accuracy 0.64\n",
      "Loss 211.47826 210 25\n",
      "Training Accuracy 0.635\n",
      "Loss 197.7975 211 25\n",
      "Training Accuracy 0.685\n",
      "Loss 190.73407 212 25\n",
      "Training Accuracy 0.695\n",
      "Loss 255.55495 213 25\n",
      "Training Accuracy 0.57\n",
      "Loss 209.75027 214 25\n",
      "Training Accuracy 0.655\n",
      "Loss 240.678 215 25\n",
      "Training Accuracy 0.595\n",
      "Loss 232.83554 216 25\n",
      "Training Accuracy 0.6\n",
      "Loss 215.7655 217 25\n",
      "Training Accuracy 0.59\n",
      "Loss 222.21832 218 25\n",
      "Training Accuracy 0.63\n",
      "Loss 212.36557 219 25\n",
      "Training Accuracy 0.635\n",
      "Loss 206.76349 220 25\n",
      "Training Accuracy 0.66\n",
      "Loss 208.38403 221 25\n",
      "Training Accuracy 0.64\n",
      "Loss 215.19264 222 25\n",
      "Training Accuracy 0.615\n",
      "Loss 228.98991 223 25\n",
      "Training Accuracy 0.625\n",
      "Loss 236.46016 224 25\n",
      "Training Accuracy 0.58\n",
      "Loss 231.90941 225 25\n",
      "Training Accuracy 0.63\n",
      "Loss 188.801 226 25\n",
      "Training Accuracy 0.675\n",
      "Loss 238.59865 227 25\n",
      "Training Accuracy 0.635\n",
      "Loss 247.07715 228 25\n",
      "Training Accuracy 0.6\n",
      "Loss 209.74306 229 25\n",
      "Training Accuracy 0.655\n",
      "Loss 222.3422 230 25\n",
      "Training Accuracy 0.635\n",
      "Loss 189.30939 231 25\n",
      "Training Accuracy 0.705\n",
      "Loss 218.6591 232 25\n",
      "Training Accuracy 0.61\n",
      "Loss 234.09279 233 25\n",
      "Training Accuracy 0.545\n",
      "Loss 225.73465 234 25\n",
      "Training Accuracy 0.605\n",
      "Loss 216.89261 235 25\n",
      "Training Accuracy 0.62\n",
      "Loss 190.22826 236 25\n",
      "Training Accuracy 0.65\n",
      "Loss 213.9801 237 25\n",
      "Training Accuracy 0.655\n",
      "Loss 203.4097 238 25\n",
      "Training Accuracy 0.62\n",
      "Loss 226.55292 239 25\n",
      "Training Accuracy 0.595\n",
      "Loss 212.26509 240 25\n",
      "Training Accuracy 0.59\n",
      "Loss 237.53812 241 25\n",
      "Training Accuracy 0.565\n",
      "Loss 203.64667 242 25\n",
      "Training Accuracy 0.665\n",
      "Loss 194.06248 243 25\n",
      "Training Accuracy 0.645\n",
      "Loss 221.69913 244 25\n",
      "Training Accuracy 0.59\n",
      "Loss 211.1122 245 25\n",
      "Training Accuracy 0.62\n",
      "Loss 231.30899 246 25\n",
      "Training Accuracy 0.62\n",
      "Loss 187.10243 247 25\n",
      "Training Accuracy 0.605\n",
      "Loss 201.58232 248 25\n",
      "Training Accuracy 0.655\n",
      "Loss 230.39906 249 25\n",
      "Training Accuracy 0.54\n",
      "Loss 230.92412 250 25\n",
      "Training Accuracy 0.585\n",
      "Loss 236.54416 251 25\n",
      "Training Accuracy 0.55\n",
      "Loss 197.66454 252 25\n",
      "Training Accuracy 0.67\n",
      "Loss 194.85336 253 25\n",
      "Training Accuracy 0.635\n",
      "Loss 220.92474 254 25\n",
      "Training Accuracy 0.62\n",
      "Loss 204.44514 255 25\n",
      "Training Accuracy 0.66\n",
      "Loss 232.45045 256 25\n",
      "Training Accuracy 0.62\n",
      "Loss 199.51721 257 25\n",
      "Training Accuracy 0.675\n",
      "Loss 213.17972 258 25\n",
      "Training Accuracy 0.625\n",
      "Loss 218.93942 259 25\n",
      "Training Accuracy 0.61\n",
      "Loss 175.2436 260 25\n",
      "Training Accuracy 0.685\n",
      "Loss 225.98204 261 25\n",
      "Training Accuracy 0.605\n",
      "Loss 209.22772 262 25\n",
      "Training Accuracy 0.605\n",
      "Loss 259.06992 263 25\n",
      "Training Accuracy 0.575\n",
      "Loss 228.36151 264 25\n",
      "Training Accuracy 0.605\n",
      "Loss 193.89644 265 25\n",
      "Training Accuracy 0.635\n",
      "Loss 199.56387 266 25\n",
      "Training Accuracy 0.69\n",
      "Loss 221.15123 267 25\n",
      "Training Accuracy 0.625\n",
      "Loss 229.39815 268 25\n",
      "Training Accuracy 0.575\n",
      "Loss 198.27682 269 25\n",
      "Training Accuracy 0.63\n",
      "Loss 185.36995 270 25\n",
      "Training Accuracy 0.7\n",
      "Loss 236.49063 271 25\n",
      "Training Accuracy 0.555\n",
      "Loss 209.09622 272 25\n",
      "Training Accuracy 0.65\n",
      "Loss 237.9207 273 25\n",
      "Training Accuracy 0.595\n",
      "Loss 204.78252 274 25\n",
      "Training Accuracy 0.655\n",
      "Loss 206.92308 275 25\n",
      "Training Accuracy 0.62\n",
      "Loss 198.53831 276 25\n",
      "Training Accuracy 0.655\n",
      "Loss 234.3761 277 25\n",
      "Training Accuracy 0.595\n",
      "Loss 212.41846 278 25\n",
      "Training Accuracy 0.63\n",
      "Loss 222.60237 279 25\n",
      "Training Accuracy 0.63\n",
      "Loss 189.39813 280 25\n",
      "Training Accuracy 0.65\n",
      "Loss 204.65811 281 25\n",
      "Training Accuracy 0.68\n",
      "Loss 212.58405 282 25\n",
      "Training Accuracy 0.62\n",
      "Loss 206.88225 283 25\n",
      "Training Accuracy 0.65\n",
      "Loss 178.42334 284 25\n",
      "Training Accuracy 0.71\n",
      "Loss 233.1831 285 25\n",
      "Training Accuracy 0.635\n",
      "Loss 211.51692 286 25\n",
      "Training Accuracy 0.66\n",
      "Loss 194.24826 287 25\n",
      "Training Accuracy 0.685\n",
      "Loss 217.23033 288 25\n",
      "Training Accuracy 0.61\n",
      "Loss 207.22418 289 25\n",
      "Training Accuracy 0.69\n",
      "Loss 213.98 290 25\n",
      "Training Accuracy 0.665\n",
      "Loss 229.0493 291 25\n",
      "Training Accuracy 0.635\n",
      "Loss 138.56964 292 25\n",
      "Training Accuracy 0.6212121\n",
      "Loss 182.95615 1 26\n",
      "Training Accuracy 0.675\n",
      "Loss 214.0938 2 26\n",
      "Training Accuracy 0.59\n",
      "Loss 196.81563 3 26\n",
      "Training Accuracy 0.69\n",
      "Loss 220.52591 4 26\n",
      "Training Accuracy 0.66\n",
      "Loss 182.53903 5 26\n",
      "Training Accuracy 0.685\n",
      "Loss 232.6213 6 26\n",
      "Training Accuracy 0.58\n",
      "Loss 222.9911 7 26\n",
      "Training Accuracy 0.66\n",
      "Loss 233.80148 8 26\n",
      "Training Accuracy 0.65\n",
      "Loss 208.54027 9 26\n",
      "Training Accuracy 0.65\n",
      "Loss 220.76494 10 26\n",
      "Training Accuracy 0.635\n",
      "Loss 236.5218 11 26\n",
      "Training Accuracy 0.635\n",
      "Loss 203.74333 12 26\n",
      "Training Accuracy 0.615\n",
      "Loss 207.38007 13 26\n",
      "Training Accuracy 0.63\n",
      "Loss 224.3321 14 26\n",
      "Training Accuracy 0.63\n",
      "Loss 197.59981 15 26\n",
      "Training Accuracy 0.695\n",
      "Loss 258.1011 16 26\n",
      "Training Accuracy 0.59\n",
      "Loss 195.48293 17 26\n",
      "Training Accuracy 0.67\n",
      "Loss 198.82166 18 26\n",
      "Training Accuracy 0.665\n",
      "Loss 204.61633 19 26\n",
      "Training Accuracy 0.62\n",
      "Loss 212.604 20 26\n",
      "Training Accuracy 0.63\n",
      "Loss 210.59615 21 26\n",
      "Training Accuracy 0.65\n",
      "Loss 213.0628 22 26\n",
      "Training Accuracy 0.655\n",
      "Loss 217.49019 23 26\n",
      "Training Accuracy 0.63\n",
      "Loss 232.60965 24 26\n",
      "Training Accuracy 0.59\n",
      "Loss 207.00192 25 26\n",
      "Training Accuracy 0.65\n",
      "Loss 224.0426 26 26\n",
      "Training Accuracy 0.62\n",
      "Loss 200.85802 27 26\n",
      "Training Accuracy 0.66\n",
      "Loss 208.21474 28 26\n",
      "Training Accuracy 0.6\n",
      "Loss 218.68817 29 26\n",
      "Training Accuracy 0.575\n",
      "Loss 219.0735 30 26\n",
      "Training Accuracy 0.64\n",
      "Loss 216.09789 31 26\n",
      "Training Accuracy 0.62\n",
      "Loss 206.72827 32 26\n",
      "Training Accuracy 0.64\n",
      "Loss 223.55696 33 26\n",
      "Training Accuracy 0.64\n",
      "Loss 193.25745 34 26\n",
      "Training Accuracy 0.675\n",
      "Loss 198.74402 35 26\n",
      "Training Accuracy 0.63\n",
      "Loss 211.11414 36 26\n",
      "Training Accuracy 0.63\n",
      "Loss 214.47716 37 26\n",
      "Training Accuracy 0.62\n",
      "Loss 219.85555 38 26\n",
      "Training Accuracy 0.645\n",
      "Loss 175.38126 39 26\n",
      "Training Accuracy 0.665\n",
      "Loss 198.51068 40 26\n",
      "Training Accuracy 0.685\n",
      "Loss 216.11601 41 26\n",
      "Training Accuracy 0.635\n",
      "Loss 264.38464 42 26\n",
      "Training Accuracy 0.56\n",
      "Loss 200.92574 43 26\n",
      "Training Accuracy 0.645\n",
      "Loss 196.0286 44 26\n",
      "Training Accuracy 0.665\n",
      "Loss 213.01178 45 26\n",
      "Training Accuracy 0.655\n",
      "Loss 239.53308 46 26\n",
      "Training Accuracy 0.625\n",
      "Loss 197.66905 47 26\n",
      "Training Accuracy 0.67\n",
      "Loss 182.54987 48 26\n",
      "Training Accuracy 0.685\n",
      "Loss 205.5053 49 26\n",
      "Training Accuracy 0.655\n",
      "Loss 239.93689 50 26\n",
      "Training Accuracy 0.6\n",
      "Loss 194.15297 51 26\n",
      "Training Accuracy 0.655\n",
      "Loss 198.13565 52 26\n",
      "Training Accuracy 0.665\n",
      "Loss 189.48586 53 26\n",
      "Training Accuracy 0.655\n",
      "Loss 230.25122 54 26\n",
      "Training Accuracy 0.625\n",
      "Loss 221.3955 55 26\n",
      "Training Accuracy 0.63\n",
      "Loss 215.80263 56 26\n",
      "Training Accuracy 0.58\n",
      "Loss 207.0499 57 26\n",
      "Training Accuracy 0.63\n",
      "Loss 204.58374 58 26\n",
      "Training Accuracy 0.635\n",
      "Loss 214.73396 59 26\n",
      "Training Accuracy 0.61\n",
      "Loss 206.38777 60 26\n",
      "Training Accuracy 0.67\n",
      "Loss 220.88652 61 26\n",
      "Training Accuracy 0.6\n",
      "Loss 192.9186 62 26\n",
      "Training Accuracy 0.67\n",
      "Loss 205.05127 63 26\n",
      "Training Accuracy 0.685\n",
      "Loss 207.72505 64 26\n",
      "Training Accuracy 0.68\n",
      "Loss 214.88037 65 26\n",
      "Training Accuracy 0.605\n",
      "Loss 200.60228 66 26\n",
      "Training Accuracy 0.675\n",
      "Loss 216.15508 67 26\n",
      "Training Accuracy 0.6\n",
      "Loss 206.11414 68 26\n",
      "Training Accuracy 0.625\n",
      "Loss 213.91365 69 26\n",
      "Training Accuracy 0.635\n",
      "Loss 214.58896 70 26\n",
      "Training Accuracy 0.655\n",
      "Loss 200.14061 71 26\n",
      "Training Accuracy 0.705\n",
      "Loss 212.68814 72 26\n",
      "Training Accuracy 0.65\n",
      "Loss 213.35085 73 26\n",
      "Training Accuracy 0.675\n",
      "Loss 219.32257 74 26\n",
      "Training Accuracy 0.625\n",
      "Loss 203.73581 75 26\n",
      "Training Accuracy 0.66\n",
      "Loss 194.85928 76 26\n",
      "Training Accuracy 0.685\n",
      "Loss 221.09367 77 26\n",
      "Training Accuracy 0.615\n",
      "Loss 206.46559 78 26\n",
      "Training Accuracy 0.68\n",
      "Loss 211.04929 79 26\n",
      "Training Accuracy 0.605\n",
      "Loss 225.60841 80 26\n",
      "Training Accuracy 0.635\n",
      "Loss 201.59933 81 26\n",
      "Training Accuracy 0.635\n",
      "Loss 207.5483 82 26\n",
      "Training Accuracy 0.655\n",
      "Loss 201.98248 83 26\n",
      "Training Accuracy 0.685\n",
      "Loss 241.97035 84 26\n",
      "Training Accuracy 0.59\n",
      "Loss 215.04083 85 26\n",
      "Training Accuracy 0.635\n",
      "Loss 220.84874 86 26\n",
      "Training Accuracy 0.65\n",
      "Loss 256.29712 87 26\n",
      "Training Accuracy 0.59\n",
      "Loss 246.61412 88 26\n",
      "Training Accuracy 0.6\n",
      "Loss 211.39233 89 26\n",
      "Training Accuracy 0.64\n",
      "Loss 220.24391 90 26\n",
      "Training Accuracy 0.62\n",
      "Loss 211.94882 91 26\n",
      "Training Accuracy 0.64\n",
      "Loss 219.99232 92 26\n",
      "Training Accuracy 0.67\n",
      "Loss 220.1269 93 26\n",
      "Training Accuracy 0.64\n",
      "Loss 213.08054 94 26\n",
      "Training Accuracy 0.635\n",
      "Loss 200.31245 95 26\n",
      "Training Accuracy 0.645\n",
      "Loss 210.02806 96 26\n",
      "Training Accuracy 0.62\n",
      "Loss 219.78645 97 26\n",
      "Training Accuracy 0.625\n",
      "Loss 204.22467 98 26\n",
      "Training Accuracy 0.65\n",
      "Loss 201.25708 99 26\n",
      "Training Accuracy 0.665\n",
      "Loss 212.46063 100 26\n",
      "Training Accuracy 0.705\n",
      "Loss 230.32187 101 26\n",
      "Training Accuracy 0.61\n",
      "Loss 202.11246 102 26\n",
      "Training Accuracy 0.58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 222.29225 103 26\n",
      "Training Accuracy 0.605\n",
      "Loss 211.67682 104 26\n",
      "Training Accuracy 0.64\n",
      "Loss 219.41585 105 26\n",
      "Training Accuracy 0.625\n",
      "Loss 205.9913 106 26\n",
      "Training Accuracy 0.67\n",
      "Loss 214.13919 107 26\n",
      "Training Accuracy 0.62\n",
      "Loss 212.61894 108 26\n",
      "Training Accuracy 0.59\n",
      "Loss 216.87965 109 26\n",
      "Training Accuracy 0.59\n",
      "Loss 221.4389 110 26\n",
      "Training Accuracy 0.625\n",
      "Loss 215.73949 111 26\n",
      "Training Accuracy 0.65\n",
      "Loss 230.47327 112 26\n",
      "Training Accuracy 0.63\n",
      "Loss 239.32294 113 26\n",
      "Training Accuracy 0.65\n",
      "Loss 213.38235 114 26\n",
      "Training Accuracy 0.63\n",
      "Loss 232.8351 115 26\n",
      "Training Accuracy 0.64\n",
      "Loss 231.2013 116 26\n",
      "Training Accuracy 0.62\n",
      "Loss 169.7896 117 26\n",
      "Training Accuracy 0.745\n",
      "Loss 213.42686 118 26\n",
      "Training Accuracy 0.66\n",
      "Loss 242.27638 119 26\n",
      "Training Accuracy 0.58\n",
      "Loss 230.36543 120 26\n",
      "Training Accuracy 0.625\n",
      "Loss 231.18423 121 26\n",
      "Training Accuracy 0.6\n",
      "Loss 209.23625 122 26\n",
      "Training Accuracy 0.64\n",
      "Loss 216.81535 123 26\n",
      "Training Accuracy 0.63\n",
      "Loss 202.77768 124 26\n",
      "Training Accuracy 0.65\n",
      "Loss 191.45695 125 26\n",
      "Training Accuracy 0.66\n",
      "Loss 230.7675 126 26\n",
      "Training Accuracy 0.605\n",
      "Loss 219.57048 127 26\n",
      "Training Accuracy 0.57\n",
      "Loss 201.21759 128 26\n",
      "Training Accuracy 0.65\n",
      "Loss 194.7199 129 26\n",
      "Training Accuracy 0.66\n",
      "Loss 193.1324 130 26\n",
      "Training Accuracy 0.66\n",
      "Loss 190.07445 131 26\n",
      "Training Accuracy 0.69\n",
      "Loss 193.66908 132 26\n",
      "Training Accuracy 0.7\n",
      "Loss 201.53386 133 26\n",
      "Training Accuracy 0.67\n",
      "Loss 203.42946 134 26\n",
      "Training Accuracy 0.63\n",
      "Loss 198.52243 135 26\n",
      "Training Accuracy 0.69\n",
      "Loss 218.21959 136 26\n",
      "Training Accuracy 0.645\n",
      "Loss 235.31612 137 26\n",
      "Training Accuracy 0.595\n",
      "Loss 202.45172 138 26\n",
      "Training Accuracy 0.65\n",
      "Loss 225.5122 139 26\n",
      "Training Accuracy 0.645\n",
      "Loss 182.34923 140 26\n",
      "Training Accuracy 0.68\n",
      "Loss 214.4957 141 26\n",
      "Training Accuracy 0.65\n",
      "Loss 212.57085 142 26\n",
      "Training Accuracy 0.61\n",
      "Loss 192.97989 143 26\n",
      "Training Accuracy 0.69\n",
      "Loss 224.20769 144 26\n",
      "Training Accuracy 0.58\n",
      "Loss 205.59302 145 26\n",
      "Training Accuracy 0.635\n",
      "Loss 231.94963 146 26\n",
      "Training Accuracy 0.59\n",
      "Loss 215.23466 147 26\n",
      "Training Accuracy 0.625\n",
      "Loss 217.13376 148 26\n",
      "Training Accuracy 0.6\n",
      "Loss 214.3262 149 26\n",
      "Training Accuracy 0.665\n",
      "Loss 207.57645 150 26\n",
      "Training Accuracy 0.645\n",
      "Loss 225.80685 151 26\n",
      "Training Accuracy 0.625\n",
      "Loss 222.17026 152 26\n",
      "Training Accuracy 0.605\n",
      "Loss 193.59212 153 26\n",
      "Training Accuracy 0.665\n",
      "Loss 202.63728 154 26\n",
      "Training Accuracy 0.65\n",
      "Loss 203.61029 155 26\n",
      "Training Accuracy 0.665\n",
      "Loss 220.33554 156 26\n",
      "Training Accuracy 0.615\n",
      "Loss 191.75058 157 26\n",
      "Training Accuracy 0.66\n",
      "Loss 208.12376 158 26\n",
      "Training Accuracy 0.645\n",
      "Loss 237.75198 159 26\n",
      "Training Accuracy 0.64\n",
      "Loss 214.5547 160 26\n",
      "Training Accuracy 0.66\n",
      "Loss 239.76059 161 26\n",
      "Training Accuracy 0.595\n",
      "Loss 197.92433 162 26\n",
      "Training Accuracy 0.66\n",
      "Loss 235.3662 163 26\n",
      "Training Accuracy 0.645\n",
      "Loss 189.56712 164 26\n",
      "Training Accuracy 0.635\n",
      "Loss 208.9588 165 26\n",
      "Training Accuracy 0.655\n",
      "Loss 203.15616 166 26\n",
      "Training Accuracy 0.715\n",
      "Loss 198.53867 167 26\n",
      "Training Accuracy 0.635\n",
      "Loss 233.50206 168 26\n",
      "Training Accuracy 0.62\n",
      "Loss 206.4643 169 26\n",
      "Training Accuracy 0.665\n",
      "Loss 210.67903 170 26\n",
      "Training Accuracy 0.665\n",
      "Loss 216.31462 171 26\n",
      "Training Accuracy 0.63\n",
      "Loss 199.39253 172 26\n",
      "Training Accuracy 0.645\n",
      "Loss 228.73506 173 26\n",
      "Training Accuracy 0.65\n",
      "Loss 183.2384 174 26\n",
      "Training Accuracy 0.67\n",
      "Loss 181.40253 175 26\n",
      "Training Accuracy 0.72\n",
      "Loss 170.97144 176 26\n",
      "Training Accuracy 0.715\n",
      "Loss 242.2632 177 26\n",
      "Training Accuracy 0.615\n",
      "Loss 200.05814 178 26\n",
      "Training Accuracy 0.685\n",
      "Loss 236.95038 179 26\n",
      "Training Accuracy 0.625\n",
      "Loss 219.01938 180 26\n",
      "Training Accuracy 0.61\n",
      "Loss 186.07677 181 26\n",
      "Training Accuracy 0.7\n",
      "Loss 217.7884 182 26\n",
      "Training Accuracy 0.625\n",
      "Loss 218.98267 183 26\n",
      "Training Accuracy 0.61\n",
      "Loss 192.11383 184 26\n",
      "Training Accuracy 0.7\n",
      "Loss 203.40604 185 26\n",
      "Training Accuracy 0.67\n",
      "Loss 203.32283 186 26\n",
      "Training Accuracy 0.65\n",
      "Loss 246.0478 187 26\n",
      "Training Accuracy 0.58\n",
      "Loss 220.62624 188 26\n",
      "Training Accuracy 0.655\n",
      "Loss 202.75253 189 26\n",
      "Training Accuracy 0.66\n",
      "Loss 193.70323 190 26\n",
      "Training Accuracy 0.675\n",
      "Loss 200.67236 191 26\n",
      "Training Accuracy 0.64\n",
      "Loss 232.42697 192 26\n",
      "Training Accuracy 0.6\n",
      "Loss 194.33934 193 26\n",
      "Training Accuracy 0.67\n",
      "Loss 199.78712 194 26\n",
      "Training Accuracy 0.665\n",
      "Loss 186.46194 195 26\n",
      "Training Accuracy 0.69\n",
      "Loss 194.06622 196 26\n",
      "Training Accuracy 0.685\n",
      "Loss 208.68279 197 26\n",
      "Training Accuracy 0.625\n",
      "Loss 192.10034 198 26\n",
      "Training Accuracy 0.64\n",
      "Loss 177.9068 199 26\n",
      "Training Accuracy 0.685\n",
      "Loss 209.4096 200 26\n",
      "Training Accuracy 0.635\n",
      "Loss 186.1306 201 26\n",
      "Training Accuracy 0.68\n",
      "Loss 199.02649 202 26\n",
      "Training Accuracy 0.635\n",
      "Loss 209.77309 203 26\n",
      "Training Accuracy 0.64\n",
      "Loss 211.98546 204 26\n",
      "Training Accuracy 0.625\n",
      "Loss 227.13472 205 26\n",
      "Training Accuracy 0.63\n",
      "Loss 218.17233 206 26\n",
      "Training Accuracy 0.595\n",
      "Loss 217.55643 207 26\n",
      "Training Accuracy 0.625\n",
      "Loss 217.61563 208 26\n",
      "Training Accuracy 0.59\n",
      "Loss 225.77652 209 26\n",
      "Training Accuracy 0.64\n",
      "Loss 193.78456 210 26\n",
      "Training Accuracy 0.66\n",
      "Loss 203.64151 211 26\n",
      "Training Accuracy 0.675\n",
      "Loss 202.95168 212 26\n",
      "Training Accuracy 0.66\n",
      "Loss 237.2293 213 26\n",
      "Training Accuracy 0.6\n",
      "Loss 207.26923 214 26\n",
      "Training Accuracy 0.61\n",
      "Loss 237.97923 215 26\n",
      "Training Accuracy 0.57\n",
      "Loss 220.83804 216 26\n",
      "Training Accuracy 0.66\n",
      "Loss 219.78459 217 26\n",
      "Training Accuracy 0.58\n",
      "Loss 217.35983 218 26\n",
      "Training Accuracy 0.655\n",
      "Loss 212.31786 219 26\n",
      "Training Accuracy 0.625\n",
      "Loss 196.91571 220 26\n",
      "Training Accuracy 0.63\n",
      "Loss 211.4497 221 26\n",
      "Training Accuracy 0.645\n",
      "Loss 214.00706 222 26\n",
      "Training Accuracy 0.61\n",
      "Loss 239.0393 223 26\n",
      "Training Accuracy 0.59\n",
      "Loss 234.6149 224 26\n",
      "Training Accuracy 0.62\n",
      "Loss 238.82904 225 26\n",
      "Training Accuracy 0.615\n",
      "Loss 180.8896 226 26\n",
      "Training Accuracy 0.695\n",
      "Loss 232.06654 227 26\n",
      "Training Accuracy 0.63\n",
      "Loss 260.23083 228 26\n",
      "Training Accuracy 0.565\n",
      "Loss 203.97293 229 26\n",
      "Training Accuracy 0.67\n",
      "Loss 217.57643 230 26\n",
      "Training Accuracy 0.66\n",
      "Loss 198.07843 231 26\n",
      "Training Accuracy 0.62\n",
      "Loss 222.52051 232 26\n",
      "Training Accuracy 0.645\n",
      "Loss 228.90215 233 26\n",
      "Training Accuracy 0.59\n",
      "Loss 217.7019 234 26\n",
      "Training Accuracy 0.63\n",
      "Loss 220.57458 235 26\n",
      "Training Accuracy 0.635\n",
      "Loss 188.78255 236 26\n",
      "Training Accuracy 0.655\n",
      "Loss 217.11064 237 26\n",
      "Training Accuracy 0.67\n",
      "Loss 191.2483 238 26\n",
      "Training Accuracy 0.645\n",
      "Loss 219.01491 239 26\n",
      "Training Accuracy 0.635\n",
      "Loss 212.77507 240 26\n",
      "Training Accuracy 0.575\n",
      "Loss 224.73143 241 26\n",
      "Training Accuracy 0.62\n",
      "Loss 202.33354 242 26\n",
      "Training Accuracy 0.695\n",
      "Loss 175.37788 243 26\n",
      "Training Accuracy 0.71\n",
      "Loss 215.49658 244 26\n",
      "Training Accuracy 0.615\n",
      "Loss 207.03795 245 26\n",
      "Training Accuracy 0.63\n",
      "Loss 225.50389 246 26\n",
      "Training Accuracy 0.63\n",
      "Loss 181.5218 247 26\n",
      "Training Accuracy 0.68\n",
      "Loss 199.37257 248 26\n",
      "Training Accuracy 0.67\n",
      "Loss 218.85606 249 26\n",
      "Training Accuracy 0.615\n",
      "Loss 226.1673 250 26\n",
      "Training Accuracy 0.61\n",
      "Loss 223.9242 251 26\n",
      "Training Accuracy 0.595\n",
      "Loss 185.2068 252 26\n",
      "Training Accuracy 0.69\n",
      "Loss 190.74135 253 26\n",
      "Training Accuracy 0.7\n",
      "Loss 214.28787 254 26\n",
      "Training Accuracy 0.65\n",
      "Loss 186.55324 255 26\n",
      "Training Accuracy 0.7\n",
      "Loss 233.63794 256 26\n",
      "Training Accuracy 0.56\n",
      "Loss 198.81363 257 26\n",
      "Training Accuracy 0.67\n",
      "Loss 215.013 258 26\n",
      "Training Accuracy 0.675\n",
      "Loss 215.79077 259 26\n",
      "Training Accuracy 0.57\n",
      "Loss 180.32013 260 26\n",
      "Training Accuracy 0.685\n",
      "Loss 217.9703 261 26\n",
      "Training Accuracy 0.645\n",
      "Loss 215.43692 262 26\n",
      "Training Accuracy 0.565\n",
      "Loss 249.5373 263 26\n",
      "Training Accuracy 0.605\n",
      "Loss 219.4177 264 26\n",
      "Training Accuracy 0.66\n",
      "Loss 193.88614 265 26\n",
      "Training Accuracy 0.66\n",
      "Loss 195.28769 266 26\n",
      "Training Accuracy 0.65\n",
      "Loss 223.30318 267 26\n",
      "Training Accuracy 0.61\n",
      "Loss 231.98541 268 26\n",
      "Training Accuracy 0.615\n",
      "Loss 201.6399 269 26\n",
      "Training Accuracy 0.605\n",
      "Loss 175.70976 270 26\n",
      "Training Accuracy 0.695\n",
      "Loss 230.7162 271 26\n",
      "Training Accuracy 0.625\n",
      "Loss 204.4231 272 26\n",
      "Training Accuracy 0.67\n",
      "Loss 220.56853 273 26\n",
      "Training Accuracy 0.63\n",
      "Loss 210.13889 274 26\n",
      "Training Accuracy 0.66\n",
      "Loss 212.41528 275 26\n",
      "Training Accuracy 0.61\n",
      "Loss 202.72873 276 26\n",
      "Training Accuracy 0.675\n",
      "Loss 219.72763 277 26\n",
      "Training Accuracy 0.645\n",
      "Loss 191.30183 278 26\n",
      "Training Accuracy 0.625\n",
      "Loss 210.2973 279 26\n",
      "Training Accuracy 0.675\n",
      "Loss 202.82991 280 26\n",
      "Training Accuracy 0.64\n",
      "Loss 200.62871 281 26\n",
      "Training Accuracy 0.66\n",
      "Loss 208.6936 282 26\n",
      "Training Accuracy 0.65\n",
      "Loss 206.9768 283 26\n",
      "Training Accuracy 0.7\n",
      "Loss 182.45409 284 26\n",
      "Training Accuracy 0.715\n",
      "Loss 226.9144 285 26\n",
      "Training Accuracy 0.625\n",
      "Loss 200.19199 286 26\n",
      "Training Accuracy 0.7\n",
      "Loss 198.02966 287 26\n",
      "Training Accuracy 0.7\n",
      "Loss 213.00766 288 26\n",
      "Training Accuracy 0.645\n",
      "Loss 190.86008 289 26\n",
      "Training Accuracy 0.685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 213.4135 290 26\n",
      "Training Accuracy 0.635\n",
      "Loss 225.49045 291 26\n",
      "Training Accuracy 0.64\n",
      "Loss 131.92442 292 26\n",
      "Training Accuracy 0.67424244\n",
      "Loss 178.75357 1 27\n",
      "Training Accuracy 0.71\n",
      "Loss 198.12132 2 27\n",
      "Training Accuracy 0.67\n",
      "Loss 195.23744 3 27\n",
      "Training Accuracy 0.655\n",
      "Loss 219.3374 4 27\n",
      "Training Accuracy 0.625\n",
      "Loss 186.62466 5 27\n",
      "Training Accuracy 0.705\n",
      "Loss 219.53435 6 27\n",
      "Training Accuracy 0.585\n",
      "Loss 222.65956 7 27\n",
      "Training Accuracy 0.65\n",
      "Loss 220.50697 8 27\n",
      "Training Accuracy 0.645\n",
      "Loss 195.78886 9 27\n",
      "Training Accuracy 0.655\n",
      "Loss 226.44394 10 27\n",
      "Training Accuracy 0.62\n",
      "Loss 232.72978 11 27\n",
      "Training Accuracy 0.62\n",
      "Loss 195.21974 12 27\n",
      "Training Accuracy 0.635\n",
      "Loss 194.56001 13 27\n",
      "Training Accuracy 0.645\n",
      "Loss 213.59303 14 27\n",
      "Training Accuracy 0.635\n",
      "Loss 198.05014 15 27\n",
      "Training Accuracy 0.69\n",
      "Loss 256.29208 16 27\n",
      "Training Accuracy 0.585\n",
      "Loss 188.93694 17 27\n",
      "Training Accuracy 0.685\n",
      "Loss 185.66628 18 27\n",
      "Training Accuracy 0.645\n",
      "Loss 195.80756 19 27\n",
      "Training Accuracy 0.635\n",
      "Loss 202.85503 20 27\n",
      "Training Accuracy 0.67\n",
      "Loss 206.62334 21 27\n",
      "Training Accuracy 0.665\n",
      "Loss 211.88913 22 27\n",
      "Training Accuracy 0.63\n",
      "Loss 208.57231 23 27\n",
      "Training Accuracy 0.665\n",
      "Loss 220.02031 24 27\n",
      "Training Accuracy 0.64\n",
      "Loss 206.94058 25 27\n",
      "Training Accuracy 0.655\n",
      "Loss 205.36307 26 27\n",
      "Training Accuracy 0.645\n",
      "Loss 202.18045 27 27\n",
      "Training Accuracy 0.64\n",
      "Loss 191.41718 28 27\n",
      "Training Accuracy 0.67\n",
      "Loss 210.50388 29 27\n",
      "Training Accuracy 0.63\n",
      "Loss 222.3689 30 27\n",
      "Training Accuracy 0.665\n",
      "Loss 217.7367 31 27\n",
      "Training Accuracy 0.655\n",
      "Loss 200.83684 32 27\n",
      "Training Accuracy 0.625\n",
      "Loss 225.38649 33 27\n",
      "Training Accuracy 0.635\n",
      "Loss 180.24051 34 27\n",
      "Training Accuracy 0.715\n",
      "Loss 203.96703 35 27\n",
      "Training Accuracy 0.605\n",
      "Loss 209.55348 36 27\n",
      "Training Accuracy 0.655\n",
      "Loss 210.33044 37 27\n",
      "Training Accuracy 0.65\n",
      "Loss 212.05832 38 27\n",
      "Training Accuracy 0.67\n",
      "Loss 188.72804 39 27\n",
      "Training Accuracy 0.695\n",
      "Loss 212.81464 40 27\n",
      "Training Accuracy 0.63\n",
      "Loss 210.09605 41 27\n",
      "Training Accuracy 0.615\n",
      "Loss 238.37958 42 27\n",
      "Training Accuracy 0.615\n",
      "Loss 204.24986 43 27\n",
      "Training Accuracy 0.615\n",
      "Loss 200.28795 44 27\n",
      "Training Accuracy 0.655\n",
      "Loss 211.17809 45 27\n",
      "Training Accuracy 0.605\n",
      "Loss 235.84718 46 27\n",
      "Training Accuracy 0.6\n",
      "Loss 193.02263 47 27\n",
      "Training Accuracy 0.685\n",
      "Loss 183.90503 48 27\n",
      "Training Accuracy 0.65\n",
      "Loss 206.58398 49 27\n",
      "Training Accuracy 0.63\n",
      "Loss 229.08316 50 27\n",
      "Training Accuracy 0.61\n",
      "Loss 191.6507 51 27\n",
      "Training Accuracy 0.685\n",
      "Loss 187.7208 52 27\n",
      "Training Accuracy 0.705\n",
      "Loss 177.2854 53 27\n",
      "Training Accuracy 0.68\n",
      "Loss 235.10481 54 27\n",
      "Training Accuracy 0.595\n",
      "Loss 220.12036 55 27\n",
      "Training Accuracy 0.625\n",
      "Loss 211.6494 56 27\n",
      "Training Accuracy 0.595\n",
      "Loss 209.6967 57 27\n",
      "Training Accuracy 0.615\n",
      "Loss 198.60207 58 27\n",
      "Training Accuracy 0.655\n",
      "Loss 223.24777 59 27\n",
      "Training Accuracy 0.63\n",
      "Loss 208.60495 60 27\n",
      "Training Accuracy 0.65\n",
      "Loss 199.43353 61 27\n",
      "Training Accuracy 0.655\n",
      "Loss 199.19254 62 27\n",
      "Training Accuracy 0.65\n",
      "Loss 209.05058 63 27\n",
      "Training Accuracy 0.635\n",
      "Loss 202.87569 64 27\n",
      "Training Accuracy 0.665\n",
      "Loss 214.83478 65 27\n",
      "Training Accuracy 0.62\n",
      "Loss 197.13861 66 27\n",
      "Training Accuracy 0.655\n",
      "Loss 211.83379 67 27\n",
      "Training Accuracy 0.64\n",
      "Loss 206.76378 68 27\n",
      "Training Accuracy 0.605\n",
      "Loss 197.48642 69 27\n",
      "Training Accuracy 0.675\n",
      "Loss 209.09438 70 27\n",
      "Training Accuracy 0.655\n",
      "Loss 199.47397 71 27\n",
      "Training Accuracy 0.71\n",
      "Loss 217.06738 72 27\n",
      "Training Accuracy 0.66\n",
      "Loss 217.74275 73 27\n",
      "Training Accuracy 0.63\n",
      "Loss 217.42282 74 27\n",
      "Training Accuracy 0.65\n",
      "Loss 207.95451 75 27\n",
      "Training Accuracy 0.65\n",
      "Loss 180.91649 76 27\n",
      "Training Accuracy 0.705\n",
      "Loss 217.47385 77 27\n",
      "Training Accuracy 0.65\n",
      "Loss 205.03516 78 27\n",
      "Training Accuracy 0.655\n",
      "Loss 208.25632 79 27\n",
      "Training Accuracy 0.595\n",
      "Loss 216.71635 80 27\n",
      "Training Accuracy 0.655\n",
      "Loss 196.10098 81 27\n",
      "Training Accuracy 0.655\n",
      "Loss 190.39008 82 27\n",
      "Training Accuracy 0.675\n",
      "Loss 213.04718 83 27\n",
      "Training Accuracy 0.625\n",
      "Loss 226.80385 84 27\n",
      "Training Accuracy 0.605\n",
      "Loss 199.44745 85 27\n",
      "Training Accuracy 0.645\n",
      "Loss 222.32135 86 27\n",
      "Training Accuracy 0.65\n",
      "Loss 251.58922 87 27\n",
      "Training Accuracy 0.61\n",
      "Loss 237.7626 88 27\n",
      "Training Accuracy 0.61\n",
      "Loss 210.4447 89 27\n",
      "Training Accuracy 0.655\n",
      "Loss 217.59329 90 27\n",
      "Training Accuracy 0.635\n",
      "Loss 210.92735 91 27\n",
      "Training Accuracy 0.64\n",
      "Loss 206.0254 92 27\n",
      "Training Accuracy 0.67\n",
      "Loss 214.43857 93 27\n",
      "Training Accuracy 0.645\n",
      "Loss 216.18385 94 27\n",
      "Training Accuracy 0.63\n",
      "Loss 197.5219 95 27\n",
      "Training Accuracy 0.63\n",
      "Loss 209.59456 96 27\n",
      "Training Accuracy 0.635\n",
      "Loss 220.66441 97 27\n",
      "Training Accuracy 0.62\n",
      "Loss 194.9051 98 27\n",
      "Training Accuracy 0.65\n",
      "Loss 194.59119 99 27\n",
      "Training Accuracy 0.665\n",
      "Loss 207.5173 100 27\n",
      "Training Accuracy 0.715\n",
      "Loss 223.58975 101 27\n",
      "Training Accuracy 0.595\n",
      "Loss 201.31909 102 27\n",
      "Training Accuracy 0.59\n",
      "Loss 204.35667 103 27\n",
      "Training Accuracy 0.635\n",
      "Loss 211.67169 104 27\n",
      "Training Accuracy 0.62\n",
      "Loss 208.04176 105 27\n",
      "Training Accuracy 0.67\n",
      "Loss 195.3887 106 27\n",
      "Training Accuracy 0.675\n",
      "Loss 198.87856 107 27\n",
      "Training Accuracy 0.65\n",
      "Loss 217.29639 108 27\n",
      "Training Accuracy 0.61\n",
      "Loss 209.22139 109 27\n",
      "Training Accuracy 0.655\n",
      "Loss 216.4366 110 27\n",
      "Training Accuracy 0.66\n",
      "Loss 217.50185 111 27\n",
      "Training Accuracy 0.64\n",
      "Loss 226.08925 112 27\n",
      "Training Accuracy 0.63\n",
      "Loss 233.67944 113 27\n",
      "Training Accuracy 0.625\n",
      "Loss 220.80655 114 27\n",
      "Training Accuracy 0.6\n",
      "Loss 231.30305 115 27\n",
      "Training Accuracy 0.62\n",
      "Loss 238.72409 116 27\n",
      "Training Accuracy 0.615\n",
      "Loss 166.09871 117 27\n",
      "Training Accuracy 0.745\n",
      "Loss 212.95328 118 27\n",
      "Training Accuracy 0.63\n",
      "Loss 240.8929 119 27\n",
      "Training Accuracy 0.575\n",
      "Loss 222.41763 120 27\n",
      "Training Accuracy 0.63\n",
      "Loss 223.26813 121 27\n",
      "Training Accuracy 0.635\n",
      "Loss 192.87154 122 27\n",
      "Training Accuracy 0.67\n",
      "Loss 212.9874 123 27\n",
      "Training Accuracy 0.62\n",
      "Loss 198.9275 124 27\n",
      "Training Accuracy 0.675\n",
      "Loss 177.51909 125 27\n",
      "Training Accuracy 0.69\n",
      "Loss 229.86328 126 27\n",
      "Training Accuracy 0.595\n",
      "Loss 214.66609 127 27\n",
      "Training Accuracy 0.625\n",
      "Loss 200.7519 128 27\n",
      "Training Accuracy 0.67\n",
      "Loss 196.1885 129 27\n",
      "Training Accuracy 0.69\n",
      "Loss 194.78456 130 27\n",
      "Training Accuracy 0.645\n",
      "Loss 187.87943 131 27\n",
      "Training Accuracy 0.685\n",
      "Loss 199.89244 132 27\n",
      "Training Accuracy 0.645\n",
      "Loss 203.37881 133 27\n",
      "Training Accuracy 0.64\n",
      "Loss 196.74156 134 27\n",
      "Training Accuracy 0.66\n",
      "Loss 205.42796 135 27\n",
      "Training Accuracy 0.65\n",
      "Loss 224.52885 136 27\n",
      "Training Accuracy 0.66\n",
      "Loss 222.26053 137 27\n",
      "Training Accuracy 0.655\n",
      "Loss 202.17822 138 27\n",
      "Training Accuracy 0.675\n",
      "Loss 221.35109 139 27\n",
      "Training Accuracy 0.67\n",
      "Loss 180.89377 140 27\n",
      "Training Accuracy 0.66\n",
      "Loss 209.47847 141 27\n",
      "Training Accuracy 0.645\n",
      "Loss 204.12877 142 27\n",
      "Training Accuracy 0.64\n",
      "Loss 185.36128 143 27\n",
      "Training Accuracy 0.7\n",
      "Loss 226.41545 144 27\n",
      "Training Accuracy 0.635\n",
      "Loss 202.3149 145 27\n",
      "Training Accuracy 0.66\n",
      "Loss 219.75871 146 27\n",
      "Training Accuracy 0.6\n",
      "Loss 216.647 147 27\n",
      "Training Accuracy 0.625\n",
      "Loss 215.53464 148 27\n",
      "Training Accuracy 0.615\n",
      "Loss 205.49084 149 27\n",
      "Training Accuracy 0.675\n",
      "Loss 196.63963 150 27\n",
      "Training Accuracy 0.655\n",
      "Loss 226.97238 151 27\n",
      "Training Accuracy 0.645\n",
      "Loss 235.47551 152 27\n",
      "Training Accuracy 0.61\n",
      "Loss 190.34532 153 27\n",
      "Training Accuracy 0.655\n",
      "Loss 201.2666 154 27\n",
      "Training Accuracy 0.67\n",
      "Loss 199.00966 155 27\n",
      "Training Accuracy 0.66\n",
      "Loss 210.53241 156 27\n",
      "Training Accuracy 0.635\n",
      "Loss 178.1262 157 27\n",
      "Training Accuracy 0.685\n",
      "Loss 201.34302 158 27\n",
      "Training Accuracy 0.675\n",
      "Loss 231.68703 159 27\n",
      "Training Accuracy 0.66\n",
      "Loss 216.47336 160 27\n",
      "Training Accuracy 0.635\n",
      "Loss 225.16193 161 27\n",
      "Training Accuracy 0.605\n",
      "Loss 205.84236 162 27\n",
      "Training Accuracy 0.645\n",
      "Loss 231.71716 163 27\n",
      "Training Accuracy 0.64\n",
      "Loss 185.89035 164 27\n",
      "Training Accuracy 0.645\n",
      "Loss 197.10088 165 27\n",
      "Training Accuracy 0.675\n",
      "Loss 207.36517 166 27\n",
      "Training Accuracy 0.7\n",
      "Loss 176.34242 167 27\n",
      "Training Accuracy 0.675\n",
      "Loss 221.70663 168 27\n",
      "Training Accuracy 0.615\n",
      "Loss 203.71062 169 27\n",
      "Training Accuracy 0.63\n",
      "Loss 198.83743 170 27\n",
      "Training Accuracy 0.67\n",
      "Loss 226.4256 171 27\n",
      "Training Accuracy 0.625\n",
      "Loss 187.09299 172 27\n",
      "Training Accuracy 0.655\n",
      "Loss 230.3972 173 27\n",
      "Training Accuracy 0.615\n",
      "Loss 172.70592 174 27\n",
      "Training Accuracy 0.665\n",
      "Loss 179.85487 175 27\n",
      "Training Accuracy 0.7\n",
      "Loss 169.42937 176 27\n",
      "Training Accuracy 0.68\n",
      "Loss 243.64056 177 27\n",
      "Training Accuracy 0.615\n",
      "Loss 190.59363 178 27\n",
      "Training Accuracy 0.67\n",
      "Loss 213.17973 179 27\n",
      "Training Accuracy 0.645\n",
      "Loss 211.30792 180 27\n",
      "Training Accuracy 0.61\n",
      "Loss 180.63356 181 27\n",
      "Training Accuracy 0.705\n",
      "Loss 227.10927 182 27\n",
      "Training Accuracy 0.605\n",
      "Loss 219.57524 183 27\n",
      "Training Accuracy 0.62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 184.47867 184 27\n",
      "Training Accuracy 0.705\n",
      "Loss 201.54254 185 27\n",
      "Training Accuracy 0.66\n",
      "Loss 196.65045 186 27\n",
      "Training Accuracy 0.67\n",
      "Loss 241.64122 187 27\n",
      "Training Accuracy 0.585\n",
      "Loss 214.04544 188 27\n",
      "Training Accuracy 0.65\n",
      "Loss 206.04568 189 27\n",
      "Training Accuracy 0.665\n",
      "Loss 195.57355 190 27\n",
      "Training Accuracy 0.66\n",
      "Loss 199.16827 191 27\n",
      "Training Accuracy 0.63\n",
      "Loss 225.29797 192 27\n",
      "Training Accuracy 0.615\n",
      "Loss 188.18773 193 27\n",
      "Training Accuracy 0.715\n",
      "Loss 202.54482 194 27\n",
      "Training Accuracy 0.675\n",
      "Loss 181.88838 195 27\n",
      "Training Accuracy 0.7\n",
      "Loss 192.88113 196 27\n",
      "Training Accuracy 0.66\n",
      "Loss 206.79724 197 27\n",
      "Training Accuracy 0.645\n",
      "Loss 194.95256 198 27\n",
      "Training Accuracy 0.665\n",
      "Loss 171.28362 199 27\n",
      "Training Accuracy 0.715\n",
      "Loss 203.16245 200 27\n",
      "Training Accuracy 0.625\n",
      "Loss 186.23843 201 27\n",
      "Training Accuracy 0.665\n",
      "Loss 201.75381 202 27\n",
      "Training Accuracy 0.625\n",
      "Loss 214.70218 203 27\n",
      "Training Accuracy 0.62\n",
      "Loss 189.5343 204 27\n",
      "Training Accuracy 0.63\n",
      "Loss 229.00414 205 27\n",
      "Training Accuracy 0.615\n",
      "Loss 210.75633 206 27\n",
      "Training Accuracy 0.64\n",
      "Loss 208.17203 207 27\n",
      "Training Accuracy 0.67\n",
      "Loss 214.39246 208 27\n",
      "Training Accuracy 0.645\n",
      "Loss 225.07751 209 27\n",
      "Training Accuracy 0.61\n",
      "Loss 193.49565 210 27\n",
      "Training Accuracy 0.635\n",
      "Loss 184.02533 211 27\n",
      "Training Accuracy 0.7\n",
      "Loss 195.00294 212 27\n",
      "Training Accuracy 0.645\n",
      "Loss 240.15225 213 27\n",
      "Training Accuracy 0.61\n",
      "Loss 203.68602 214 27\n",
      "Training Accuracy 0.625\n",
      "Loss 236.89973 215 27\n",
      "Training Accuracy 0.555\n",
      "Loss 214.28934 216 27\n",
      "Training Accuracy 0.605\n",
      "Loss 217.86719 217 27\n",
      "Training Accuracy 0.615\n",
      "Loss 213.86145 218 27\n",
      "Training Accuracy 0.615\n",
      "Loss 207.90465 219 27\n",
      "Training Accuracy 0.65\n",
      "Loss 193.99612 220 27\n",
      "Training Accuracy 0.685\n",
      "Loss 201.79143 221 27\n",
      "Training Accuracy 0.645\n",
      "Loss 206.7149 222 27\n",
      "Training Accuracy 0.615\n",
      "Loss 221.36365 223 27\n",
      "Training Accuracy 0.605\n",
      "Loss 234.48746 224 27\n",
      "Training Accuracy 0.6\n",
      "Loss 222.04211 225 27\n",
      "Training Accuracy 0.63\n",
      "Loss 181.92668 226 27\n",
      "Training Accuracy 0.66\n",
      "Loss 229.37053 227 27\n",
      "Training Accuracy 0.65\n",
      "Loss 242.1126 228 27\n",
      "Training Accuracy 0.6\n",
      "Loss 206.75732 229 27\n",
      "Training Accuracy 0.64\n",
      "Loss 214.24219 230 27\n",
      "Training Accuracy 0.645\n",
      "Loss 190.27686 231 27\n",
      "Training Accuracy 0.7\n",
      "Loss 203.3426 232 27\n",
      "Training Accuracy 0.655\n",
      "Loss 230.29836 233 27\n",
      "Training Accuracy 0.57\n",
      "Loss 197.46243 234 27\n",
      "Training Accuracy 0.585\n",
      "Loss 213.69997 235 27\n",
      "Training Accuracy 0.65\n",
      "Loss 182.9053 236 27\n",
      "Training Accuracy 0.7\n",
      "Loss 212.65472 237 27\n",
      "Training Accuracy 0.64\n",
      "Loss 193.65067 238 27\n",
      "Training Accuracy 0.645\n",
      "Loss 223.86407 239 27\n",
      "Training Accuracy 0.62\n",
      "Loss 211.42352 240 27\n",
      "Training Accuracy 0.625\n",
      "Loss 229.30956 241 27\n",
      "Training Accuracy 0.595\n",
      "Loss 201.3554 242 27\n",
      "Training Accuracy 0.655\n",
      "Loss 185.32147 243 27\n",
      "Training Accuracy 0.69\n",
      "Loss 206.87505 244 27\n",
      "Training Accuracy 0.665\n",
      "Loss 207.6129 245 27\n",
      "Training Accuracy 0.66\n",
      "Loss 221.61382 246 27\n",
      "Training Accuracy 0.605\n",
      "Loss 178.9271 247 27\n",
      "Training Accuracy 0.66\n",
      "Loss 183.58421 248 27\n",
      "Training Accuracy 0.7\n",
      "Loss 223.98643 249 27\n",
      "Training Accuracy 0.62\n",
      "Loss 211.40247 250 27\n",
      "Training Accuracy 0.62\n",
      "Loss 209.99706 251 27\n",
      "Training Accuracy 0.635\n",
      "Loss 189.44382 252 27\n",
      "Training Accuracy 0.65\n",
      "Loss 177.72055 253 27\n",
      "Training Accuracy 0.735\n",
      "Loss 205.80653 254 27\n",
      "Training Accuracy 0.655\n",
      "Loss 188.91939 255 27\n",
      "Training Accuracy 0.67\n",
      "Loss 221.7587 256 27\n",
      "Training Accuracy 0.64\n",
      "Loss 201.09698 257 27\n",
      "Training Accuracy 0.66\n",
      "Loss 204.89578 258 27\n",
      "Training Accuracy 0.645\n",
      "Loss 215.16333 259 27\n",
      "Training Accuracy 0.635\n",
      "Loss 166.96086 260 27\n",
      "Training Accuracy 0.7\n",
      "Loss 215.12573 261 27\n",
      "Training Accuracy 0.685\n",
      "Loss 200.80194 262 27\n",
      "Training Accuracy 0.625\n",
      "Loss 247.51909 263 27\n",
      "Training Accuracy 0.59\n",
      "Loss 209.09778 264 27\n",
      "Training Accuracy 0.68\n",
      "Loss 180.82495 265 27\n",
      "Training Accuracy 0.72\n",
      "Loss 202.7679 266 27\n",
      "Training Accuracy 0.635\n",
      "Loss 215.46298 267 27\n",
      "Training Accuracy 0.605\n",
      "Loss 219.77092 268 27\n",
      "Training Accuracy 0.64\n",
      "Loss 199.83246 269 27\n",
      "Training Accuracy 0.645\n",
      "Loss 171.6362 270 27\n",
      "Training Accuracy 0.7\n",
      "Loss 218.55139 271 27\n",
      "Training Accuracy 0.64\n",
      "Loss 219.4942 272 27\n",
      "Training Accuracy 0.64\n",
      "Loss 223.77515 273 27\n",
      "Training Accuracy 0.63\n",
      "Loss 199.48221 274 27\n",
      "Training Accuracy 0.655\n",
      "Loss 202.82149 275 27\n",
      "Training Accuracy 0.645\n",
      "Loss 199.64056 276 27\n",
      "Training Accuracy 0.63\n",
      "Loss 229.82796 277 27\n",
      "Training Accuracy 0.62\n",
      "Loss 197.2599 278 27\n",
      "Training Accuracy 0.63\n",
      "Loss 208.49294 279 27\n",
      "Training Accuracy 0.67\n",
      "Loss 190.92557 280 27\n",
      "Training Accuracy 0.665\n",
      "Loss 186.0709 281 27\n",
      "Training Accuracy 0.675\n",
      "Loss 201.5474 282 27\n",
      "Training Accuracy 0.66\n",
      "Loss 194.65228 283 27\n",
      "Training Accuracy 0.715\n",
      "Loss 180.34349 284 27\n",
      "Training Accuracy 0.695\n",
      "Loss 239.58969 285 27\n",
      "Training Accuracy 0.625\n",
      "Loss 199.66237 286 27\n",
      "Training Accuracy 0.69\n",
      "Loss 187.16719 287 27\n",
      "Training Accuracy 0.725\n",
      "Loss 214.06592 288 27\n",
      "Training Accuracy 0.67\n",
      "Loss 201.6928 289 27\n",
      "Training Accuracy 0.685\n",
      "Loss 205.3678 290 27\n",
      "Training Accuracy 0.65\n",
      "Loss 220.42671 291 27\n",
      "Training Accuracy 0.655\n",
      "Loss 128.30373 292 27\n",
      "Training Accuracy 0.6363636\n",
      "Loss 163.65257 1 28\n",
      "Training Accuracy 0.72\n",
      "Loss 196.73817 2 28\n",
      "Training Accuracy 0.69\n",
      "Loss 189.91513 3 28\n",
      "Training Accuracy 0.665\n",
      "Loss 215.3152 4 28\n",
      "Training Accuracy 0.65\n",
      "Loss 176.2983 5 28\n",
      "Training Accuracy 0.74\n",
      "Loss 217.40839 6 28\n",
      "Training Accuracy 0.63\n",
      "Loss 204.797 7 28\n",
      "Training Accuracy 0.68\n",
      "Loss 218.87279 8 28\n",
      "Training Accuracy 0.645\n",
      "Loss 197.2489 9 28\n",
      "Training Accuracy 0.65\n",
      "Loss 215.86981 10 28\n",
      "Training Accuracy 0.64\n",
      "Loss 240.89218 11 28\n",
      "Training Accuracy 0.64\n",
      "Loss 187.96974 12 28\n",
      "Training Accuracy 0.665\n",
      "Loss 211.89717 13 28\n",
      "Training Accuracy 0.61\n",
      "Loss 222.20503 14 28\n",
      "Training Accuracy 0.635\n",
      "Loss 178.75327 15 28\n",
      "Training Accuracy 0.695\n",
      "Loss 242.80014 16 28\n",
      "Training Accuracy 0.62\n",
      "Loss 181.45013 17 28\n",
      "Training Accuracy 0.71\n",
      "Loss 192.55954 18 28\n",
      "Training Accuracy 0.685\n",
      "Loss 186.0495 19 28\n",
      "Training Accuracy 0.67\n",
      "Loss 196.1164 20 28\n",
      "Training Accuracy 0.67\n",
      "Loss 198.25188 21 28\n",
      "Training Accuracy 0.645\n",
      "Loss 210.51166 22 28\n",
      "Training Accuracy 0.645\n",
      "Loss 214.01035 23 28\n",
      "Training Accuracy 0.62\n",
      "Loss 227.84038 24 28\n",
      "Training Accuracy 0.61\n",
      "Loss 181.85635 25 28\n",
      "Training Accuracy 0.7\n",
      "Loss 208.31795 26 28\n",
      "Training Accuracy 0.635\n",
      "Loss 191.51347 27 28\n",
      "Training Accuracy 0.665\n",
      "Loss 196.46962 28 28\n",
      "Training Accuracy 0.665\n",
      "Loss 196.3372 29 28\n",
      "Training Accuracy 0.64\n",
      "Loss 213.80716 30 28\n",
      "Training Accuracy 0.65\n",
      "Loss 210.63243 31 28\n",
      "Training Accuracy 0.675\n",
      "Loss 205.9256 32 28\n",
      "Training Accuracy 0.645\n",
      "Loss 201.4538 33 28\n",
      "Training Accuracy 0.66\n",
      "Loss 176.03152 34 28\n",
      "Training Accuracy 0.7\n",
      "Loss 192.09534 35 28\n",
      "Training Accuracy 0.66\n",
      "Loss 203.53198 36 28\n",
      "Training Accuracy 0.66\n",
      "Loss 199.19617 37 28\n",
      "Training Accuracy 0.67\n",
      "Loss 226.73578 38 28\n",
      "Training Accuracy 0.625\n",
      "Loss 171.76309 39 28\n",
      "Training Accuracy 0.71\n",
      "Loss 203.59271 40 28\n",
      "Training Accuracy 0.64\n",
      "Loss 207.03168 41 28\n",
      "Training Accuracy 0.635\n",
      "Loss 245.89241 42 28\n",
      "Training Accuracy 0.575\n",
      "Loss 201.36345 43 28\n",
      "Training Accuracy 0.64\n",
      "Loss 206.33553 44 28\n",
      "Training Accuracy 0.64\n",
      "Loss 206.13268 45 28\n",
      "Training Accuracy 0.69\n",
      "Loss 228.387 46 28\n",
      "Training Accuracy 0.615\n",
      "Loss 194.3919 47 28\n",
      "Training Accuracy 0.685\n",
      "Loss 170.30183 48 28\n",
      "Training Accuracy 0.705\n",
      "Loss 205.79694 49 28\n",
      "Training Accuracy 0.645\n",
      "Loss 223.33275 50 28\n",
      "Training Accuracy 0.63\n",
      "Loss 185.00784 51 28\n",
      "Training Accuracy 0.71\n",
      "Loss 188.51164 52 28\n",
      "Training Accuracy 0.67\n",
      "Loss 167.3926 53 28\n",
      "Training Accuracy 0.71\n",
      "Loss 229.24069 54 28\n",
      "Training Accuracy 0.64\n",
      "Loss 213.8547 55 28\n",
      "Training Accuracy 0.6\n",
      "Loss 207.66644 56 28\n",
      "Training Accuracy 0.625\n",
      "Loss 196.82562 57 28\n",
      "Training Accuracy 0.67\n",
      "Loss 194.28198 58 28\n",
      "Training Accuracy 0.645\n",
      "Loss 216.65778 59 28\n",
      "Training Accuracy 0.615\n",
      "Loss 190.89682 60 28\n",
      "Training Accuracy 0.68\n",
      "Loss 215.84041 61 28\n",
      "Training Accuracy 0.605\n",
      "Loss 194.74818 62 28\n",
      "Training Accuracy 0.65\n",
      "Loss 198.50938 63 28\n",
      "Training Accuracy 0.675\n",
      "Loss 210.81212 64 28\n",
      "Training Accuracy 0.64\n",
      "Loss 208.01665 65 28\n",
      "Training Accuracy 0.635\n",
      "Loss 192.56726 66 28\n",
      "Training Accuracy 0.695\n",
      "Loss 200.45833 67 28\n",
      "Training Accuracy 0.665\n",
      "Loss 199.53763 68 28\n",
      "Training Accuracy 0.65\n",
      "Loss 203.27087 69 28\n",
      "Training Accuracy 0.635\n",
      "Loss 206.22557 70 28\n",
      "Training Accuracy 0.67\n",
      "Loss 202.30505 71 28\n",
      "Training Accuracy 0.715\n",
      "Loss 201.25978 72 28\n",
      "Training Accuracy 0.685\n",
      "Loss 218.49675 73 28\n",
      "Training Accuracy 0.59\n",
      "Loss 217.93765 74 28\n",
      "Training Accuracy 0.62\n",
      "Loss 206.01863 75 28\n",
      "Training Accuracy 0.63\n",
      "Loss 178.39906 76 28\n",
      "Training Accuracy 0.675\n",
      "Loss 210.28613 77 28\n",
      "Training Accuracy 0.655\n",
      "Loss 200.77774 78 28\n",
      "Training Accuracy 0.655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 208.60594 79 28\n",
      "Training Accuracy 0.62\n",
      "Loss 213.24544 80 28\n",
      "Training Accuracy 0.655\n",
      "Loss 185.58946 81 28\n",
      "Training Accuracy 0.69\n",
      "Loss 194.37122 82 28\n",
      "Training Accuracy 0.66\n",
      "Loss 195.41591 83 28\n",
      "Training Accuracy 0.695\n",
      "Loss 226.52318 84 28\n",
      "Training Accuracy 0.61\n",
      "Loss 203.52312 85 28\n",
      "Training Accuracy 0.655\n",
      "Loss 214.80095 86 28\n",
      "Training Accuracy 0.67\n",
      "Loss 241.02412 87 28\n",
      "Training Accuracy 0.605\n",
      "Loss 230.15002 88 28\n",
      "Training Accuracy 0.615\n",
      "Loss 205.72075 89 28\n",
      "Training Accuracy 0.655\n",
      "Loss 204.93407 90 28\n",
      "Training Accuracy 0.63\n",
      "Loss 204.92923 91 28\n",
      "Training Accuracy 0.65\n",
      "Loss 210.43436 92 28\n",
      "Training Accuracy 0.67\n",
      "Loss 217.0342 93 28\n",
      "Training Accuracy 0.66\n",
      "Loss 212.3502 94 28\n",
      "Training Accuracy 0.655\n",
      "Loss 199.10236 95 28\n",
      "Training Accuracy 0.66\n",
      "Loss 204.09163 96 28\n",
      "Training Accuracy 0.64\n",
      "Loss 211.77704 97 28\n",
      "Training Accuracy 0.63\n",
      "Loss 183.74211 98 28\n",
      "Training Accuracy 0.68\n",
      "Loss 190.99802 99 28\n",
      "Training Accuracy 0.69\n",
      "Loss 196.64294 100 28\n",
      "Training Accuracy 0.71\n",
      "Loss 230.21857 101 28\n",
      "Training Accuracy 0.6\n",
      "Loss 194.70068 102 28\n",
      "Training Accuracy 0.67\n",
      "Loss 207.81659 103 28\n",
      "Training Accuracy 0.64\n",
      "Loss 202.89854 104 28\n",
      "Training Accuracy 0.63\n",
      "Loss 200.24356 105 28\n",
      "Training Accuracy 0.665\n",
      "Loss 196.65535 106 28\n",
      "Training Accuracy 0.68\n",
      "Loss 198.2798 107 28\n",
      "Training Accuracy 0.665\n",
      "Loss 206.8339 108 28\n",
      "Training Accuracy 0.62\n",
      "Loss 197.39037 109 28\n",
      "Training Accuracy 0.645\n",
      "Loss 212.05063 110 28\n",
      "Training Accuracy 0.655\n",
      "Loss 214.58333 111 28\n",
      "Training Accuracy 0.61\n",
      "Loss 216.66394 112 28\n",
      "Training Accuracy 0.63\n",
      "Loss 223.00935 113 28\n",
      "Training Accuracy 0.655\n",
      "Loss 205.9309 114 28\n",
      "Training Accuracy 0.62\n",
      "Loss 226.74202 115 28\n",
      "Training Accuracy 0.635\n",
      "Loss 241.83171 116 28\n",
      "Training Accuracy 0.62\n",
      "Loss 166.8213 117 28\n",
      "Training Accuracy 0.72\n",
      "Loss 208.2345 118 28\n",
      "Training Accuracy 0.63\n",
      "Loss 240.1712 119 28\n",
      "Training Accuracy 0.58\n",
      "Loss 219.93497 120 28\n",
      "Training Accuracy 0.65\n",
      "Loss 212.93181 121 28\n",
      "Training Accuracy 0.605\n",
      "Loss 188.16629 122 28\n",
      "Training Accuracy 0.68\n",
      "Loss 208.96318 123 28\n",
      "Training Accuracy 0.64\n",
      "Loss 198.27055 124 28\n",
      "Training Accuracy 0.66\n",
      "Loss 183.47047 125 28\n",
      "Training Accuracy 0.69\n",
      "Loss 227.31581 126 28\n",
      "Training Accuracy 0.635\n",
      "Loss 206.88364 127 28\n",
      "Training Accuracy 0.625\n",
      "Loss 198.24377 128 28\n",
      "Training Accuracy 0.645\n",
      "Loss 187.02159 129 28\n",
      "Training Accuracy 0.71\n",
      "Loss 195.4154 130 28\n",
      "Training Accuracy 0.635\n",
      "Loss 192.47588 131 28\n",
      "Training Accuracy 0.685\n",
      "Loss 193.42696 132 28\n",
      "Training Accuracy 0.685\n",
      "Loss 193.66902 133 28\n",
      "Training Accuracy 0.665\n",
      "Loss 196.78511 134 28\n",
      "Training Accuracy 0.645\n",
      "Loss 200.57872 135 28\n",
      "Training Accuracy 0.645\n",
      "Loss 204.8466 136 28\n",
      "Training Accuracy 0.69\n",
      "Loss 232.97885 137 28\n",
      "Training Accuracy 0.615\n",
      "Loss 201.31331 138 28\n",
      "Training Accuracy 0.64\n",
      "Loss 222.80112 139 28\n",
      "Training Accuracy 0.67\n",
      "Loss 180.07527 140 28\n",
      "Training Accuracy 0.7\n",
      "Loss 203.96095 141 28\n",
      "Training Accuracy 0.655\n",
      "Loss 200.01054 142 28\n",
      "Training Accuracy 0.63\n",
      "Loss 184.12692 143 28\n",
      "Training Accuracy 0.695\n",
      "Loss 213.29887 144 28\n",
      "Training Accuracy 0.64\n",
      "Loss 200.05843 145 28\n",
      "Training Accuracy 0.645\n",
      "Loss 229.31439 146 28\n",
      "Training Accuracy 0.6\n",
      "Loss 210.70769 147 28\n",
      "Training Accuracy 0.645\n",
      "Loss 194.18019 148 28\n",
      "Training Accuracy 0.655\n",
      "Loss 190.97295 149 28\n",
      "Training Accuracy 0.7\n",
      "Loss 192.31406 150 28\n",
      "Training Accuracy 0.69\n",
      "Loss 218.92165 151 28\n",
      "Training Accuracy 0.625\n",
      "Loss 220.07516 152 28\n",
      "Training Accuracy 0.615\n",
      "Loss 194.87518 153 28\n",
      "Training Accuracy 0.675\n",
      "Loss 195.61613 154 28\n",
      "Training Accuracy 0.655\n",
      "Loss 184.64745 155 28\n",
      "Training Accuracy 0.69\n",
      "Loss 211.9264 156 28\n",
      "Training Accuracy 0.625\n",
      "Loss 184.23772 157 28\n",
      "Training Accuracy 0.655\n",
      "Loss 196.68639 158 28\n",
      "Training Accuracy 0.68\n",
      "Loss 225.41125 159 28\n",
      "Training Accuracy 0.625\n",
      "Loss 211.08241 160 28\n",
      "Training Accuracy 0.655\n",
      "Loss 211.23453 161 28\n",
      "Training Accuracy 0.615\n",
      "Loss 207.33139 162 28\n",
      "Training Accuracy 0.65\n",
      "Loss 222.47229 163 28\n",
      "Training Accuracy 0.625\n",
      "Loss 191.07784 164 28\n",
      "Training Accuracy 0.64\n",
      "Loss 197.57977 165 28\n",
      "Training Accuracy 0.67\n",
      "Loss 198.97217 166 28\n",
      "Training Accuracy 0.705\n",
      "Loss 177.16568 167 28\n",
      "Training Accuracy 0.67\n",
      "Loss 232.5797 168 28\n",
      "Training Accuracy 0.605\n",
      "Loss 195.71007 169 28\n",
      "Training Accuracy 0.66\n",
      "Loss 213.94234 170 28\n",
      "Training Accuracy 0.625\n",
      "Loss 203.82751 171 28\n",
      "Training Accuracy 0.68\n",
      "Loss 195.43625 172 28\n",
      "Training Accuracy 0.675\n",
      "Loss 207.02126 173 28\n",
      "Training Accuracy 0.65\n",
      "Loss 189.42882 174 28\n",
      "Training Accuracy 0.66\n",
      "Loss 173.06532 175 28\n",
      "Training Accuracy 0.74\n",
      "Loss 158.52928 176 28\n",
      "Training Accuracy 0.76\n",
      "Loss 228.19551 177 28\n",
      "Training Accuracy 0.62\n",
      "Loss 188.86024 178 28\n",
      "Training Accuracy 0.68\n",
      "Loss 215.09093 179 28\n",
      "Training Accuracy 0.615\n",
      "Loss 201.44604 180 28\n",
      "Training Accuracy 0.665\n",
      "Loss 180.91429 181 28\n",
      "Training Accuracy 0.705\n",
      "Loss 209.66946 182 28\n",
      "Training Accuracy 0.655\n",
      "Loss 214.36209 183 28\n",
      "Training Accuracy 0.625\n",
      "Loss 167.29115 184 28\n",
      "Training Accuracy 0.745\n",
      "Loss 194.41403 185 28\n",
      "Training Accuracy 0.71\n",
      "Loss 195.73221 186 28\n",
      "Training Accuracy 0.655\n",
      "Loss 227.38489 187 28\n",
      "Training Accuracy 0.59\n",
      "Loss 226.158 188 28\n",
      "Training Accuracy 0.6\n",
      "Loss 202.42526 189 28\n",
      "Training Accuracy 0.65\n",
      "Loss 190.91188 190 28\n",
      "Training Accuracy 0.675\n",
      "Loss 198.03148 191 28\n",
      "Training Accuracy 0.66\n",
      "Loss 217.42169 192 28\n",
      "Training Accuracy 0.58\n",
      "Loss 187.29846 193 28\n",
      "Training Accuracy 0.695\n",
      "Loss 199.19052 194 28\n",
      "Training Accuracy 0.65\n",
      "Loss 192.46786 195 28\n",
      "Training Accuracy 0.63\n",
      "Loss 195.2521 196 28\n",
      "Training Accuracy 0.635\n",
      "Loss 204.05531 197 28\n",
      "Training Accuracy 0.63\n",
      "Loss 189.96062 198 28\n",
      "Training Accuracy 0.625\n",
      "Loss 173.93784 199 28\n",
      "Training Accuracy 0.715\n",
      "Loss 195.18942 200 28\n",
      "Training Accuracy 0.685\n",
      "Loss 194.4219 201 28\n",
      "Training Accuracy 0.705\n",
      "Loss 201.0126 202 28\n",
      "Training Accuracy 0.63\n",
      "Loss 203.64987 203 28\n",
      "Training Accuracy 0.66\n",
      "Loss 195.28261 204 28\n",
      "Training Accuracy 0.645\n",
      "Loss 219.74858 205 28\n",
      "Training Accuracy 0.655\n",
      "Loss 206.34569 206 28\n",
      "Training Accuracy 0.63\n",
      "Loss 211.4276 207 28\n",
      "Training Accuracy 0.63\n",
      "Loss 206.34077 208 28\n",
      "Training Accuracy 0.68\n",
      "Loss 211.00757 209 28\n",
      "Training Accuracy 0.67\n",
      "Loss 183.06293 210 28\n",
      "Training Accuracy 0.69\n",
      "Loss 200.38118 211 28\n",
      "Training Accuracy 0.64\n",
      "Loss 194.46234 212 28\n",
      "Training Accuracy 0.66\n",
      "Loss 249.1817 213 28\n",
      "Training Accuracy 0.565\n",
      "Loss 203.15964 214 28\n",
      "Training Accuracy 0.645\n",
      "Loss 221.56804 215 28\n",
      "Training Accuracy 0.595\n",
      "Loss 225.23273 216 28\n",
      "Training Accuracy 0.63\n",
      "Loss 210.60748 217 28\n",
      "Training Accuracy 0.645\n",
      "Loss 208.41386 218 28\n",
      "Training Accuracy 0.635\n",
      "Loss 208.54437 219 28\n",
      "Training Accuracy 0.645\n",
      "Loss 192.97856 220 28\n",
      "Training Accuracy 0.66\n",
      "Loss 206.04614 221 28\n",
      "Training Accuracy 0.62\n",
      "Loss 201.41544 222 28\n",
      "Training Accuracy 0.645\n",
      "Loss 219.24326 223 28\n",
      "Training Accuracy 0.655\n",
      "Loss 227.44904 224 28\n",
      "Training Accuracy 0.6\n",
      "Loss 222.10852 225 28\n",
      "Training Accuracy 0.66\n",
      "Loss 172.25407 226 28\n",
      "Training Accuracy 0.69\n",
      "Loss 227.39713 227 28\n",
      "Training Accuracy 0.605\n",
      "Loss 225.10109 228 28\n",
      "Training Accuracy 0.63\n",
      "Loss 201.91327 229 28\n",
      "Training Accuracy 0.66\n",
      "Loss 199.86945 230 28\n",
      "Training Accuracy 0.675\n",
      "Loss 184.5527 231 28\n",
      "Training Accuracy 0.695\n",
      "Loss 216.73137 232 28\n",
      "Training Accuracy 0.64\n",
      "Loss 231.33928 233 28\n",
      "Training Accuracy 0.57\n",
      "Loss 208.08185 234 28\n",
      "Training Accuracy 0.585\n",
      "Loss 208.58023 235 28\n",
      "Training Accuracy 0.62\n",
      "Loss 187.82849 236 28\n",
      "Training Accuracy 0.675\n",
      "Loss 212.70345 237 28\n",
      "Training Accuracy 0.585\n",
      "Loss 195.43996 238 28\n",
      "Training Accuracy 0.635\n",
      "Loss 217.11275 239 28\n",
      "Training Accuracy 0.655\n",
      "Loss 206.7281 240 28\n",
      "Training Accuracy 0.61\n",
      "Loss 234.08385 241 28\n",
      "Training Accuracy 0.58\n",
      "Loss 205.54742 242 28\n",
      "Training Accuracy 0.64\n",
      "Loss 172.09647 243 28\n",
      "Training Accuracy 0.69\n",
      "Loss 196.93576 244 28\n",
      "Training Accuracy 0.64\n",
      "Loss 198.65979 245 28\n",
      "Training Accuracy 0.635\n",
      "Loss 212.50432 246 28\n",
      "Training Accuracy 0.615\n",
      "Loss 178.8665 247 28\n",
      "Training Accuracy 0.655\n",
      "Loss 186.9344 248 28\n",
      "Training Accuracy 0.72\n",
      "Loss 213.26408 249 28\n",
      "Training Accuracy 0.57\n",
      "Loss 217.6163 250 28\n",
      "Training Accuracy 0.615\n",
      "Loss 213.92165 251 28\n",
      "Training Accuracy 0.605\n",
      "Loss 167.1193 252 28\n",
      "Training Accuracy 0.7\n",
      "Loss 171.49478 253 28\n",
      "Training Accuracy 0.725\n",
      "Loss 208.45921 254 28\n",
      "Training Accuracy 0.65\n",
      "Loss 179.9046 255 28\n",
      "Training Accuracy 0.715\n",
      "Loss 221.14401 256 28\n",
      "Training Accuracy 0.655\n",
      "Loss 191.34895 257 28\n",
      "Training Accuracy 0.71\n",
      "Loss 209.1596 258 28\n",
      "Training Accuracy 0.615\n",
      "Loss 208.15787 259 28\n",
      "Training Accuracy 0.62\n",
      "Loss 170.82645 260 28\n",
      "Training Accuracy 0.705\n",
      "Loss 209.41805 261 28\n",
      "Training Accuracy 0.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 206.5535 262 28\n",
      "Training Accuracy 0.61\n",
      "Loss 246.82022 263 28\n",
      "Training Accuracy 0.61\n",
      "Loss 202.05185 264 28\n",
      "Training Accuracy 0.67\n",
      "Loss 191.8518 265 28\n",
      "Training Accuracy 0.66\n",
      "Loss 202.58223 266 28\n",
      "Training Accuracy 0.635\n",
      "Loss 205.96072 267 28\n",
      "Training Accuracy 0.63\n",
      "Loss 205.10307 268 28\n",
      "Training Accuracy 0.665\n",
      "Loss 195.41786 269 28\n",
      "Training Accuracy 0.61\n",
      "Loss 172.48146 270 28\n",
      "Training Accuracy 0.655\n",
      "Loss 226.74818 271 28\n",
      "Training Accuracy 0.605\n",
      "Loss 206.20245 272 28\n",
      "Training Accuracy 0.65\n",
      "Loss 219.70045 273 28\n",
      "Training Accuracy 0.62\n",
      "Loss 191.47493 274 28\n",
      "Training Accuracy 0.705\n",
      "Loss 201.3315 275 28\n",
      "Training Accuracy 0.605\n",
      "Loss 189.85269 276 28\n",
      "Training Accuracy 0.685\n",
      "Loss 219.50325 277 28\n",
      "Training Accuracy 0.65\n",
      "Loss 190.08739 278 28\n",
      "Training Accuracy 0.625\n",
      "Loss 197.62505 279 28\n",
      "Training Accuracy 0.675\n",
      "Loss 194.66571 280 28\n",
      "Training Accuracy 0.655\n",
      "Loss 187.37306 281 28\n",
      "Training Accuracy 0.69\n",
      "Loss 199.68268 282 28\n",
      "Training Accuracy 0.68\n",
      "Loss 190.9992 283 28\n",
      "Training Accuracy 0.72\n",
      "Loss 170.13327 284 28\n",
      "Training Accuracy 0.755\n",
      "Loss 233.55983 285 28\n",
      "Training Accuracy 0.61\n",
      "Loss 194.65347 286 28\n",
      "Training Accuracy 0.69\n",
      "Loss 183.76422 287 28\n",
      "Training Accuracy 0.705\n",
      "Loss 205.38681 288 28\n",
      "Training Accuracy 0.675\n",
      "Loss 188.12025 289 28\n",
      "Training Accuracy 0.67\n",
      "Loss 198.60388 290 28\n",
      "Training Accuracy 0.64\n",
      "Loss 211.8028 291 28\n",
      "Training Accuracy 0.675\n",
      "Loss 128.2573 292 28\n",
      "Training Accuracy 0.6439394\n",
      "Loss 160.439 1 29\n",
      "Training Accuracy 0.735\n",
      "Loss 203.95235 2 29\n",
      "Training Accuracy 0.655\n",
      "Loss 183.24606 3 29\n",
      "Training Accuracy 0.68\n",
      "Loss 203.87947 4 29\n",
      "Training Accuracy 0.655\n",
      "Loss 183.8381 5 29\n",
      "Training Accuracy 0.71\n",
      "Loss 208.38217 6 29\n",
      "Training Accuracy 0.615\n",
      "Loss 209.19489 7 29\n",
      "Training Accuracy 0.65\n",
      "Loss 210.93675 8 29\n",
      "Training Accuracy 0.65\n",
      "Loss 188.42809 9 29\n",
      "Training Accuracy 0.69\n",
      "Loss 212.29146 10 29\n",
      "Training Accuracy 0.675\n",
      "Loss 226.84595 11 29\n",
      "Training Accuracy 0.655\n",
      "Loss 186.34628 12 29\n",
      "Training Accuracy 0.655\n",
      "Loss 201.64445 13 29\n",
      "Training Accuracy 0.635\n",
      "Loss 205.40652 14 29\n",
      "Training Accuracy 0.655\n",
      "Loss 189.4372 15 29\n",
      "Training Accuracy 0.7\n",
      "Loss 246.29396 16 29\n",
      "Training Accuracy 0.635\n",
      "Loss 177.97586 17 29\n",
      "Training Accuracy 0.715\n",
      "Loss 187.61032 18 29\n",
      "Training Accuracy 0.675\n",
      "Loss 192.12068 19 29\n",
      "Training Accuracy 0.68\n",
      "Loss 186.79941 20 29\n",
      "Training Accuracy 0.69\n",
      "Loss 200.12839 21 29\n",
      "Training Accuracy 0.655\n",
      "Loss 201.1782 22 29\n",
      "Training Accuracy 0.71\n",
      "Loss 195.69092 23 29\n",
      "Training Accuracy 0.71\n",
      "Loss 217.88965 24 29\n",
      "Training Accuracy 0.64\n",
      "Loss 186.50783 25 29\n",
      "Training Accuracy 0.665\n",
      "Loss 208.53337 26 29\n",
      "Training Accuracy 0.685\n",
      "Loss 187.60757 27 29\n",
      "Training Accuracy 0.69\n",
      "Loss 187.99707 28 29\n",
      "Training Accuracy 0.64\n",
      "Loss 209.90933 29 29\n",
      "Training Accuracy 0.625\n",
      "Loss 217.53003 30 29\n",
      "Training Accuracy 0.655\n",
      "Loss 201.81293 31 29\n",
      "Training Accuracy 0.68\n",
      "Loss 190.85222 32 29\n",
      "Training Accuracy 0.64\n",
      "Loss 210.28093 33 29\n",
      "Training Accuracy 0.655\n",
      "Loss 178.31046 34 29\n",
      "Training Accuracy 0.655\n",
      "Loss 187.51776 35 29\n",
      "Training Accuracy 0.635\n",
      "Loss 210.0697 36 29\n",
      "Training Accuracy 0.64\n",
      "Loss 203.92403 37 29\n",
      "Training Accuracy 0.62\n",
      "Loss 206.51442 38 29\n",
      "Training Accuracy 0.675\n",
      "Loss 177.5941 39 29\n",
      "Training Accuracy 0.71\n",
      "Loss 193.61522 40 29\n",
      "Training Accuracy 0.675\n",
      "Loss 201.2194 41 29\n",
      "Training Accuracy 0.65\n",
      "Loss 233.2251 42 29\n",
      "Training Accuracy 0.61\n",
      "Loss 193.29475 43 29\n",
      "Training Accuracy 0.67\n",
      "Loss 189.33723 44 29\n",
      "Training Accuracy 0.645\n",
      "Loss 204.84584 45 29\n",
      "Training Accuracy 0.67\n",
      "Loss 232.38838 46 29\n",
      "Training Accuracy 0.615\n",
      "Loss 190.39708 47 29\n",
      "Training Accuracy 0.68\n",
      "Loss 171.91707 48 29\n",
      "Training Accuracy 0.695\n",
      "Loss 198.21376 49 29\n",
      "Training Accuracy 0.65\n",
      "Loss 210.34543 50 29\n",
      "Training Accuracy 0.68\n",
      "Loss 185.43776 51 29\n",
      "Training Accuracy 0.66\n",
      "Loss 179.1449 52 29\n",
      "Training Accuracy 0.735\n",
      "Loss 165.65562 53 29\n",
      "Training Accuracy 0.695\n",
      "Loss 223.3747 54 29\n",
      "Training Accuracy 0.645\n",
      "Loss 204.99217 55 29\n",
      "Training Accuracy 0.65\n",
      "Loss 207.04797 56 29\n",
      "Training Accuracy 0.635\n",
      "Loss 176.61317 57 29\n",
      "Training Accuracy 0.715\n",
      "Loss 185.89064 58 29\n",
      "Training Accuracy 0.675\n",
      "Loss 210.31061 59 29\n",
      "Training Accuracy 0.65\n",
      "Loss 202.7108 60 29\n",
      "Training Accuracy 0.685\n",
      "Loss 194.98792 61 29\n",
      "Training Accuracy 0.645\n",
      "Loss 185.9324 62 29\n",
      "Training Accuracy 0.73\n",
      "Loss 205.2514 63 29\n",
      "Training Accuracy 0.62\n",
      "Loss 203.30293 64 29\n",
      "Training Accuracy 0.695\n",
      "Loss 218.85626 65 29\n",
      "Training Accuracy 0.59\n",
      "Loss 198.26607 66 29\n",
      "Training Accuracy 0.63\n",
      "Loss 196.6302 67 29\n",
      "Training Accuracy 0.685\n",
      "Loss 205.93484 68 29\n",
      "Training Accuracy 0.645\n",
      "Loss 197.99347 69 29\n",
      "Training Accuracy 0.69\n",
      "Loss 191.90263 70 29\n",
      "Training Accuracy 0.68\n",
      "Loss 203.00848 71 29\n",
      "Training Accuracy 0.7\n",
      "Loss 198.72327 72 29\n",
      "Training Accuracy 0.66\n",
      "Loss 210.34084 73 29\n",
      "Training Accuracy 0.64\n",
      "Loss 220.04451 74 29\n",
      "Training Accuracy 0.66\n",
      "Loss 205.27373 75 29\n",
      "Training Accuracy 0.67\n",
      "Loss 180.81798 76 29\n",
      "Training Accuracy 0.695\n",
      "Loss 215.09328 77 29\n",
      "Training Accuracy 0.625\n",
      "Loss 191.62828 78 29\n",
      "Training Accuracy 0.695\n",
      "Loss 200.71661 79 29\n",
      "Training Accuracy 0.645\n",
      "Loss 214.58705 80 29\n",
      "Training Accuracy 0.625\n",
      "Loss 191.07501 81 29\n",
      "Training Accuracy 0.64\n",
      "Loss 190.3133 82 29\n",
      "Training Accuracy 0.685\n",
      "Loss 195.92862 83 29\n",
      "Training Accuracy 0.665\n",
      "Loss 217.02553 84 29\n",
      "Training Accuracy 0.635\n",
      "Loss 194.90634 85 29\n",
      "Training Accuracy 0.655\n",
      "Loss 201.09448 86 29\n",
      "Training Accuracy 0.695\n",
      "Loss 249.68475 87 29\n",
      "Training Accuracy 0.59\n",
      "Loss 229.71704 88 29\n",
      "Training Accuracy 0.63\n",
      "Loss 199.13208 89 29\n",
      "Training Accuracy 0.685\n",
      "Loss 218.44756 90 29\n",
      "Training Accuracy 0.61\n",
      "Loss 193.7453 91 29\n",
      "Training Accuracy 0.67\n",
      "Loss 208.20795 92 29\n",
      "Training Accuracy 0.7\n",
      "Loss 199.41945 93 29\n",
      "Training Accuracy 0.655\n",
      "Loss 203.91603 94 29\n",
      "Training Accuracy 0.64\n",
      "Loss 186.41296 95 29\n",
      "Training Accuracy 0.655\n",
      "Loss 217.99289 96 29\n",
      "Training Accuracy 0.61\n",
      "Loss 205.01797 97 29\n",
      "Training Accuracy 0.625\n",
      "Loss 187.09357 98 29\n",
      "Training Accuracy 0.67\n",
      "Loss 194.8711 99 29\n",
      "Training Accuracy 0.68\n",
      "Loss 202.22107 100 29\n",
      "Training Accuracy 0.685\n",
      "Loss 227.2201 101 29\n",
      "Training Accuracy 0.62\n",
      "Loss 173.23305 102 29\n",
      "Training Accuracy 0.67\n",
      "Loss 198.40613 103 29\n",
      "Training Accuracy 0.66\n",
      "Loss 194.12646 104 29\n",
      "Training Accuracy 0.67\n",
      "Loss 206.88773 105 29\n",
      "Training Accuracy 0.63\n",
      "Loss 185.98297 106 29\n",
      "Training Accuracy 0.69\n",
      "Loss 189.7207 107 29\n",
      "Training Accuracy 0.67\n",
      "Loss 199.35724 108 29\n",
      "Training Accuracy 0.63\n",
      "Loss 208.11348 109 29\n",
      "Training Accuracy 0.61\n",
      "Loss 197.49026 110 29\n",
      "Training Accuracy 0.68\n",
      "Loss 204.21857 111 29\n",
      "Training Accuracy 0.665\n",
      "Loss 209.54543 112 29\n",
      "Training Accuracy 0.635\n",
      "Loss 226.44711 113 29\n",
      "Training Accuracy 0.625\n",
      "Loss 206.28003 114 29\n",
      "Training Accuracy 0.635\n",
      "Loss 225.35214 115 29\n",
      "Training Accuracy 0.615\n",
      "Loss 230.55635 116 29\n",
      "Training Accuracy 0.615\n",
      "Loss 166.53491 117 29\n",
      "Training Accuracy 0.75\n",
      "Loss 191.83823 118 29\n",
      "Training Accuracy 0.645\n",
      "Loss 224.81815 119 29\n",
      "Training Accuracy 0.635\n",
      "Loss 213.54156 120 29\n",
      "Training Accuracy 0.645\n",
      "Loss 212.56529 121 29\n",
      "Training Accuracy 0.635\n",
      "Loss 200.36325 122 29\n",
      "Training Accuracy 0.675\n",
      "Loss 198.72598 123 29\n",
      "Training Accuracy 0.66\n",
      "Loss 182.98492 124 29\n",
      "Training Accuracy 0.685\n",
      "Loss 187.38547 125 29\n",
      "Training Accuracy 0.68\n",
      "Loss 219.0248 126 29\n",
      "Training Accuracy 0.63\n",
      "Loss 205.07127 127 29\n",
      "Training Accuracy 0.62\n",
      "Loss 194.79453 128 29\n",
      "Training Accuracy 0.665\n",
      "Loss 180.34723 129 29\n",
      "Training Accuracy 0.715\n",
      "Loss 194.2611 130 29\n",
      "Training Accuracy 0.67\n",
      "Loss 185.22835 131 29\n",
      "Training Accuracy 0.7\n",
      "Loss 192.55344 132 29\n",
      "Training Accuracy 0.67\n",
      "Loss 193.86603 133 29\n",
      "Training Accuracy 0.685\n",
      "Loss 195.22084 134 29\n",
      "Training Accuracy 0.68\n",
      "Loss 199.71335 135 29\n",
      "Training Accuracy 0.63\n",
      "Loss 207.13922 136 29\n",
      "Training Accuracy 0.665\n",
      "Loss 216.26784 137 29\n",
      "Training Accuracy 0.66\n",
      "Loss 202.25766 138 29\n",
      "Training Accuracy 0.69\n",
      "Loss 226.65071 139 29\n",
      "Training Accuracy 0.635\n",
      "Loss 180.07474 140 29\n",
      "Training Accuracy 0.68\n",
      "Loss 202.72847 141 29\n",
      "Training Accuracy 0.66\n",
      "Loss 209.92638 142 29\n",
      "Training Accuracy 0.595\n",
      "Loss 176.1474 143 29\n",
      "Training Accuracy 0.715\n",
      "Loss 223.00839 144 29\n",
      "Training Accuracy 0.625\n",
      "Loss 191.03589 145 29\n",
      "Training Accuracy 0.645\n",
      "Loss 214.71959 146 29\n",
      "Training Accuracy 0.59\n",
      "Loss 199.6112 147 29\n",
      "Training Accuracy 0.66\n",
      "Loss 207.03343 148 29\n",
      "Training Accuracy 0.64\n",
      "Loss 190.28821 149 29\n",
      "Training Accuracy 0.67\n",
      "Loss 203.9626 150 29\n",
      "Training Accuracy 0.665\n",
      "Loss 211.665 151 29\n",
      "Training Accuracy 0.645\n",
      "Loss 219.30762 152 29\n",
      "Training Accuracy 0.615\n",
      "Loss 183.41083 153 29\n",
      "Training Accuracy 0.69\n",
      "Loss 196.23453 154 29\n",
      "Training Accuracy 0.67\n",
      "Loss 189.94337 155 29\n",
      "Training Accuracy 0.66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 198.7856 156 29\n",
      "Training Accuracy 0.625\n",
      "Loss 172.456 157 29\n",
      "Training Accuracy 0.67\n",
      "Loss 197.002 158 29\n",
      "Training Accuracy 0.67\n",
      "Loss 230.68065 159 29\n",
      "Training Accuracy 0.63\n",
      "Loss 196.4752 160 29\n",
      "Training Accuracy 0.635\n",
      "Loss 216.45088 161 29\n",
      "Training Accuracy 0.64\n",
      "Loss 194.73926 162 29\n",
      "Training Accuracy 0.66\n",
      "Loss 216.8301 163 29\n",
      "Training Accuracy 0.67\n",
      "Loss 188.13338 164 29\n",
      "Training Accuracy 0.615\n",
      "Loss 190.3445 165 29\n",
      "Training Accuracy 0.685\n",
      "Loss 205.71262 166 29\n",
      "Training Accuracy 0.665\n",
      "Loss 177.01283 167 29\n",
      "Training Accuracy 0.695\n",
      "Loss 214.61154 168 29\n",
      "Training Accuracy 0.665\n",
      "Loss 200.97795 169 29\n",
      "Training Accuracy 0.645\n",
      "Loss 213.54077 170 29\n",
      "Training Accuracy 0.635\n",
      "Loss 214.42671 171 29\n",
      "Training Accuracy 0.65\n",
      "Loss 196.75392 172 29\n",
      "Training Accuracy 0.685\n",
      "Loss 217.94334 173 29\n",
      "Training Accuracy 0.66\n",
      "Loss 172.47263 174 29\n",
      "Training Accuracy 0.64\n",
      "Loss 170.40256 175 29\n",
      "Training Accuracy 0.745\n",
      "Loss 154.41049 176 29\n",
      "Training Accuracy 0.735\n",
      "Loss 220.67474 177 29\n",
      "Training Accuracy 0.63\n",
      "Loss 185.5481 178 29\n",
      "Training Accuracy 0.69\n",
      "Loss 211.91403 179 29\n",
      "Training Accuracy 0.665\n",
      "Loss 206.29454 180 29\n",
      "Training Accuracy 0.625\n",
      "Loss 184.91428 181 29\n",
      "Training Accuracy 0.665\n",
      "Loss 207.30214 182 29\n",
      "Training Accuracy 0.625\n",
      "Loss 212.86978 183 29\n",
      "Training Accuracy 0.65\n",
      "Loss 174.88417 184 29\n",
      "Training Accuracy 0.745\n",
      "Loss 192.22694 185 29\n",
      "Training Accuracy 0.67\n",
      "Loss 194.29439 186 29\n",
      "Training Accuracy 0.675\n",
      "Loss 229.93141 187 29\n",
      "Training Accuracy 0.585\n",
      "Loss 207.57346 188 29\n",
      "Training Accuracy 0.66\n",
      "Loss 198.18968 189 29\n",
      "Training Accuracy 0.68\n",
      "Loss 195.25952 190 29\n",
      "Training Accuracy 0.675\n",
      "Loss 182.61961 191 29\n",
      "Training Accuracy 0.675\n",
      "Loss 216.83504 192 29\n",
      "Training Accuracy 0.625\n",
      "Loss 187.38393 193 29\n",
      "Training Accuracy 0.69\n",
      "Loss 202.43008 194 29\n",
      "Training Accuracy 0.67\n",
      "Loss 178.54121 195 29\n",
      "Training Accuracy 0.715\n",
      "Loss 191.61087 196 29\n",
      "Training Accuracy 0.655\n",
      "Loss 199.60011 197 29\n",
      "Training Accuracy 0.665\n",
      "Loss 193.51018 198 29\n",
      "Training Accuracy 0.625\n",
      "Loss 156.75253 199 29\n",
      "Training Accuracy 0.73\n",
      "Loss 184.16673 200 29\n",
      "Training Accuracy 0.665\n",
      "Loss 182.30812 201 29\n",
      "Training Accuracy 0.655\n",
      "Loss 190.1136 202 29\n",
      "Training Accuracy 0.655\n",
      "Loss 193.69153 203 29\n",
      "Training Accuracy 0.695\n",
      "Loss 189.6504 204 29\n",
      "Training Accuracy 0.67\n",
      "Loss 208.94617 205 29\n",
      "Training Accuracy 0.66\n",
      "Loss 199.77985 206 29\n",
      "Training Accuracy 0.665\n",
      "Loss 199.85735 207 29\n",
      "Training Accuracy 0.68\n",
      "Loss 208.11707 208 29\n",
      "Training Accuracy 0.625\n",
      "Loss 224.2667 209 29\n",
      "Training Accuracy 0.66\n",
      "Loss 186.73004 210 29\n",
      "Training Accuracy 0.665\n",
      "Loss 190.59471 211 29\n",
      "Training Accuracy 0.68\n",
      "Loss 177.75633 212 29\n",
      "Training Accuracy 0.71\n",
      "Loss 229.54703 213 29\n",
      "Training Accuracy 0.64\n",
      "Loss 200.02643 214 29\n",
      "Training Accuracy 0.64\n",
      "Loss 230.26878 215 29\n",
      "Training Accuracy 0.58\n",
      "Loss 201.33421 216 29\n",
      "Training Accuracy 0.625\n",
      "Loss 214.3569 217 29\n",
      "Training Accuracy 0.605\n",
      "Loss 213.51138 218 29\n",
      "Training Accuracy 0.65\n",
      "Loss 204.06026 219 29\n",
      "Training Accuracy 0.665\n",
      "Loss 186.99673 220 29\n",
      "Training Accuracy 0.71\n",
      "Loss 199.98901 221 29\n",
      "Training Accuracy 0.635\n",
      "Loss 194.99161 222 29\n",
      "Training Accuracy 0.665\n",
      "Loss 216.99243 223 29\n",
      "Training Accuracy 0.61\n",
      "Loss 212.77348 224 29\n",
      "Training Accuracy 0.64\n",
      "Loss 230.85452 225 29\n",
      "Training Accuracy 0.635\n",
      "Loss 167.28194 226 29\n",
      "Training Accuracy 0.71\n",
      "Loss 214.92978 227 29\n",
      "Training Accuracy 0.645\n",
      "Loss 231.7768 228 29\n",
      "Training Accuracy 0.625\n",
      "Loss 186.8856 229 29\n",
      "Training Accuracy 0.705\n",
      "Loss 218.33733 230 29\n",
      "Training Accuracy 0.655\n",
      "Loss 190.81621 231 29\n",
      "Training Accuracy 0.65\n",
      "Loss 213.61409 232 29\n",
      "Training Accuracy 0.62\n",
      "Loss 222.4701 233 29\n",
      "Training Accuracy 0.59\n",
      "Loss 205.79031 234 29\n",
      "Training Accuracy 0.605\n",
      "Loss 210.37952 235 29\n",
      "Training Accuracy 0.655\n",
      "Loss 168.05544 236 29\n",
      "Training Accuracy 0.745\n",
      "Loss 200.012 237 29\n",
      "Training Accuracy 0.65\n",
      "Loss 186.7746 238 29\n",
      "Training Accuracy 0.655\n",
      "Loss 215.64975 239 29\n",
      "Training Accuracy 0.615\n",
      "Loss 202.64157 240 29\n",
      "Training Accuracy 0.635\n",
      "Loss 226.46512 241 29\n",
      "Training Accuracy 0.595\n",
      "Loss 187.25331 242 29\n",
      "Training Accuracy 0.67\n",
      "Loss 182.61548 243 29\n",
      "Training Accuracy 0.66\n",
      "Loss 202.15623 244 29\n",
      "Training Accuracy 0.6\n",
      "Loss 199.0808 245 29\n",
      "Training Accuracy 0.625\n",
      "Loss 211.90489 246 29\n",
      "Training Accuracy 0.65\n",
      "Loss 178.95494 247 29\n",
      "Training Accuracy 0.67\n",
      "Loss 186.07394 248 29\n",
      "Training Accuracy 0.675\n",
      "Loss 220.20706 249 29\n",
      "Training Accuracy 0.54\n",
      "Loss 214.94229 250 29\n",
      "Training Accuracy 0.635\n",
      "Loss 211.67416 251 29\n",
      "Training Accuracy 0.63\n",
      "Loss 176.10683 252 29\n",
      "Training Accuracy 0.665\n",
      "Loss 187.88158 253 29\n",
      "Training Accuracy 0.67\n",
      "Loss 209.28781 254 29\n",
      "Training Accuracy 0.66\n",
      "Loss 183.25381 255 29\n",
      "Training Accuracy 0.67\n",
      "Loss 215.81175 256 29\n",
      "Training Accuracy 0.65\n",
      "Loss 191.37296 257 29\n",
      "Training Accuracy 0.695\n",
      "Loss 198.6456 258 29\n",
      "Training Accuracy 0.645\n",
      "Loss 198.2927 259 29\n",
      "Training Accuracy 0.645\n",
      "Loss 163.05716 260 29\n",
      "Training Accuracy 0.685\n",
      "Loss 210.89458 261 29\n",
      "Training Accuracy 0.635\n",
      "Loss 197.1263 262 29\n",
      "Training Accuracy 0.645\n",
      "Loss 232.51416 263 29\n",
      "Training Accuracy 0.635\n",
      "Loss 207.52307 264 29\n",
      "Training Accuracy 0.67\n",
      "Loss 183.08606 265 29\n",
      "Training Accuracy 0.68\n",
      "Loss 198.47461 266 29\n",
      "Training Accuracy 0.645\n",
      "Loss 211.5574 267 29\n",
      "Training Accuracy 0.63\n",
      "Loss 206.98619 268 29\n",
      "Training Accuracy 0.66\n",
      "Loss 190.81628 269 29\n",
      "Training Accuracy 0.665\n",
      "Loss 177.98485 270 29\n",
      "Training Accuracy 0.665\n",
      "Loss 228.58923 271 29\n",
      "Training Accuracy 0.63\n",
      "Loss 194.28244 272 29\n",
      "Training Accuracy 0.67\n",
      "Loss 225.20251 273 29\n",
      "Training Accuracy 0.61\n",
      "Loss 197.51053 274 29\n",
      "Training Accuracy 0.635\n",
      "Loss 194.20224 275 29\n",
      "Training Accuracy 0.61\n",
      "Loss 182.09207 276 29\n",
      "Training Accuracy 0.66\n",
      "Loss 219.86685 277 29\n",
      "Training Accuracy 0.645\n",
      "Loss 194.45442 278 29\n",
      "Training Accuracy 0.635\n",
      "Loss 205.51552 279 29\n",
      "Training Accuracy 0.66\n",
      "Loss 195.73795 280 29\n",
      "Training Accuracy 0.64\n",
      "Loss 185.54472 281 29\n",
      "Training Accuracy 0.665\n",
      "Loss 200.90611 282 29\n",
      "Training Accuracy 0.625\n",
      "Loss 188.57283 283 29\n",
      "Training Accuracy 0.705\n",
      "Loss 169.67628 284 29\n",
      "Training Accuracy 0.69\n",
      "Loss 235.04659 285 29\n",
      "Training Accuracy 0.625\n",
      "Loss 200.61551 286 29\n",
      "Training Accuracy 0.66\n",
      "Loss 179.36649 287 29\n",
      "Training Accuracy 0.725\n",
      "Loss 206.41154 288 29\n",
      "Training Accuracy 0.7\n",
      "Loss 188.40173 289 29\n",
      "Training Accuracy 0.68\n",
      "Loss 195.97002 290 29\n",
      "Training Accuracy 0.67\n",
      "Loss 213.95395 291 29\n",
      "Training Accuracy 0.585\n",
      "Loss 130.4284 292 29\n",
      "Training Accuracy 0.70454544\n",
      "Loss 166.36977 1 30\n",
      "Training Accuracy 0.725\n",
      "Loss 195.20056 2 30\n",
      "Training Accuracy 0.675\n",
      "Loss 189.25 3 30\n",
      "Training Accuracy 0.71\n",
      "Loss 200.72134 4 30\n",
      "Training Accuracy 0.655\n",
      "Loss 175.24115 5 30\n",
      "Training Accuracy 0.73\n",
      "Loss 205.7543 6 30\n",
      "Training Accuracy 0.675\n",
      "Loss 203.63004 7 30\n",
      "Training Accuracy 0.66\n",
      "Loss 218.82542 8 30\n",
      "Training Accuracy 0.635\n",
      "Loss 179.35829 9 30\n",
      "Training Accuracy 0.705\n",
      "Loss 219.37027 10 30\n",
      "Training Accuracy 0.625\n",
      "Loss 224.4727 11 30\n",
      "Training Accuracy 0.66\n",
      "Loss 180.93256 12 30\n",
      "Training Accuracy 0.69\n",
      "Loss 180.31544 13 30\n",
      "Training Accuracy 0.69\n",
      "Loss 204.55705 14 30\n",
      "Training Accuracy 0.645\n",
      "Loss 183.91272 15 30\n",
      "Training Accuracy 0.695\n",
      "Loss 240.82083 16 30\n",
      "Training Accuracy 0.63\n",
      "Loss 174.91843 17 30\n",
      "Training Accuracy 0.685\n",
      "Loss 170.50755 18 30\n",
      "Training Accuracy 0.7\n",
      "Loss 190.74551 19 30\n",
      "Training Accuracy 0.62\n",
      "Loss 189.60918 20 30\n",
      "Training Accuracy 0.66\n",
      "Loss 196.78448 21 30\n",
      "Training Accuracy 0.65\n",
      "Loss 195.50911 22 30\n",
      "Training Accuracy 0.665\n",
      "Loss 206.38583 23 30\n",
      "Training Accuracy 0.68\n",
      "Loss 218.812 24 30\n",
      "Training Accuracy 0.615\n",
      "Loss 190.8849 25 30\n",
      "Training Accuracy 0.705\n",
      "Loss 201.27965 26 30\n",
      "Training Accuracy 0.68\n",
      "Loss 188.624 27 30\n",
      "Training Accuracy 0.665\n",
      "Loss 188.75323 28 30\n",
      "Training Accuracy 0.675\n",
      "Loss 192.24806 29 30\n",
      "Training Accuracy 0.645\n",
      "Loss 198.8791 30 30\n",
      "Training Accuracy 0.69\n",
      "Loss 207.56607 31 30\n",
      "Training Accuracy 0.655\n",
      "Loss 195.41277 32 30\n",
      "Training Accuracy 0.62\n",
      "Loss 196.56291 33 30\n",
      "Training Accuracy 0.675\n",
      "Loss 184.00328 34 30\n",
      "Training Accuracy 0.69\n",
      "Loss 179.5396 35 30\n",
      "Training Accuracy 0.64\n",
      "Loss 200.72568 36 30\n",
      "Training Accuracy 0.65\n",
      "Loss 189.28351 37 30\n",
      "Training Accuracy 0.65\n",
      "Loss 203.51224 38 30\n",
      "Training Accuracy 0.675\n",
      "Loss 171.58821 39 30\n",
      "Training Accuracy 0.73\n",
      "Loss 189.66353 40 30\n",
      "Training Accuracy 0.67\n",
      "Loss 198.26378 41 30\n",
      "Training Accuracy 0.635\n",
      "Loss 224.70204 42 30\n",
      "Training Accuracy 0.6\n",
      "Loss 193.87285 43 30\n",
      "Training Accuracy 0.665\n",
      "Loss 198.64468 44 30\n",
      "Training Accuracy 0.66\n",
      "Loss 189.67026 45 30\n",
      "Training Accuracy 0.71\n",
      "Loss 226.58115 46 30\n",
      "Training Accuracy 0.655\n",
      "Loss 180.61671 47 30\n",
      "Training Accuracy 0.695\n",
      "Loss 174.85269 48 30\n",
      "Training Accuracy 0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 194.59966 49 30\n",
      "Training Accuracy 0.675\n",
      "Loss 234.32767 50 30\n",
      "Training Accuracy 0.605\n",
      "Loss 177.76825 51 30\n",
      "Training Accuracy 0.7\n",
      "Loss 185.645 52 30\n",
      "Training Accuracy 0.675\n",
      "Loss 159.26793 53 30\n",
      "Training Accuracy 0.755\n",
      "Loss 216.40457 54 30\n",
      "Training Accuracy 0.61\n",
      "Loss 200.8736 55 30\n",
      "Training Accuracy 0.625\n",
      "Loss 195.20297 56 30\n",
      "Training Accuracy 0.66\n",
      "Loss 190.55432 57 30\n",
      "Training Accuracy 0.67\n",
      "Loss 187.2403 58 30\n",
      "Training Accuracy 0.66\n",
      "Loss 205.74367 59 30\n",
      "Training Accuracy 0.685\n",
      "Loss 198.23994 60 30\n",
      "Training Accuracy 0.69\n",
      "Loss 207.87213 61 30\n",
      "Training Accuracy 0.61\n",
      "Loss 177.61603 62 30\n",
      "Training Accuracy 0.685\n",
      "Loss 190.88074 63 30\n",
      "Training Accuracy 0.695\n",
      "Loss 205.04753 64 30\n",
      "Training Accuracy 0.7\n",
      "Loss 197.56311 65 30\n",
      "Training Accuracy 0.675\n",
      "Loss 175.30263 66 30\n",
      "Training Accuracy 0.68\n",
      "Loss 206.94354 67 30\n",
      "Training Accuracy 0.655\n",
      "Loss 203.388 68 30\n",
      "Training Accuracy 0.66\n",
      "Loss 189.43365 69 30\n",
      "Training Accuracy 0.705\n",
      "Loss 204.29926 70 30\n",
      "Training Accuracy 0.67\n",
      "Loss 201.52675 71 30\n",
      "Training Accuracy 0.675\n",
      "Loss 188.07379 72 30\n",
      "Training Accuracy 0.705\n",
      "Loss 204.95456 73 30\n",
      "Training Accuracy 0.61\n",
      "Loss 211.20667 74 30\n",
      "Training Accuracy 0.645\n",
      "Loss 205.97961 75 30\n",
      "Training Accuracy 0.655\n",
      "Loss 181.38098 76 30\n",
      "Training Accuracy 0.695\n",
      "Loss 209.63094 77 30\n",
      "Training Accuracy 0.665\n",
      "Loss 195.77545 78 30\n",
      "Training Accuracy 0.66\n",
      "Loss 193.52678 79 30\n",
      "Training Accuracy 0.67\n",
      "Loss 199.87128 80 30\n",
      "Training Accuracy 0.69\n",
      "Loss 193.79243 81 30\n",
      "Training Accuracy 0.665\n",
      "Loss 180.85934 82 30\n",
      "Training Accuracy 0.69\n",
      "Loss 190.54227 83 30\n",
      "Training Accuracy 0.705\n",
      "Loss 216.12971 84 30\n",
      "Training Accuracy 0.645\n",
      "Loss 195.24854 85 30\n",
      "Training Accuracy 0.665\n",
      "Loss 188.54674 86 30\n",
      "Training Accuracy 0.715\n",
      "Loss 239.42575 87 30\n",
      "Training Accuracy 0.595\n",
      "Loss 232.54697 88 30\n",
      "Training Accuracy 0.63\n",
      "Loss 190.9054 89 30\n",
      "Training Accuracy 0.675\n",
      "Loss 199.49207 90 30\n",
      "Training Accuracy 0.635\n",
      "Loss 199.4777 91 30\n",
      "Training Accuracy 0.66\n",
      "Loss 200.20784 92 30\n",
      "Training Accuracy 0.68\n",
      "Loss 200.34933 93 30\n",
      "Training Accuracy 0.66\n",
      "Loss 203.33977 94 30\n",
      "Training Accuracy 0.62\n",
      "Loss 190.84656 95 30\n",
      "Training Accuracy 0.655\n",
      "Loss 201.40526 96 30\n",
      "Training Accuracy 0.635\n",
      "Loss 204.91612 97 30\n",
      "Training Accuracy 0.625\n",
      "Loss 179.6915 98 30\n",
      "Training Accuracy 0.695\n",
      "Loss 181.20998 99 30\n",
      "Training Accuracy 0.685\n",
      "Loss 193.94797 100 30\n",
      "Training Accuracy 0.68\n",
      "Loss 228.40579 101 30\n",
      "Training Accuracy 0.59\n",
      "Loss 195.27542 102 30\n",
      "Training Accuracy 0.655\n",
      "Loss 204.99283 103 30\n",
      "Training Accuracy 0.66\n",
      "Loss 193.9429 104 30\n",
      "Training Accuracy 0.665\n",
      "Loss 199.19452 105 30\n",
      "Training Accuracy 0.655\n",
      "Loss 187.2447 106 30\n",
      "Training Accuracy 0.715\n",
      "Loss 201.44017 107 30\n",
      "Training Accuracy 0.635\n",
      "Loss 189.0095 108 30\n",
      "Training Accuracy 0.645\n",
      "Loss 191.7433 109 30\n",
      "Training Accuracy 0.63\n",
      "Loss 210.7013 110 30\n",
      "Training Accuracy 0.645\n",
      "Loss 198.15828 111 30\n",
      "Training Accuracy 0.66\n",
      "Loss 218.56349 112 30\n",
      "Training Accuracy 0.635\n",
      "Loss 217.56479 113 30\n",
      "Training Accuracy 0.655\n",
      "Loss 208.047 114 30\n",
      "Training Accuracy 0.61\n",
      "Loss 217.2647 115 30\n",
      "Training Accuracy 0.64\n",
      "Loss 229.88754 116 30\n",
      "Training Accuracy 0.655\n",
      "Loss 162.87141 117 30\n",
      "Training Accuracy 0.74\n",
      "Loss 198.54546 118 30\n",
      "Training Accuracy 0.705\n",
      "Loss 221.56409 119 30\n",
      "Training Accuracy 0.605\n",
      "Loss 219.03888 120 30\n",
      "Training Accuracy 0.625\n",
      "Loss 208.7431 121 30\n",
      "Training Accuracy 0.645\n",
      "Loss 190.59474 122 30\n",
      "Training Accuracy 0.69\n",
      "Loss 191.92342 123 30\n",
      "Training Accuracy 0.65\n",
      "Loss 186.81303 124 30\n",
      "Training Accuracy 0.675\n",
      "Loss 178.71951 125 30\n",
      "Training Accuracy 0.695\n",
      "Loss 218.56311 126 30\n",
      "Training Accuracy 0.635\n",
      "Loss 198.86469 127 30\n",
      "Training Accuracy 0.625\n",
      "Loss 184.8257 128 30\n",
      "Training Accuracy 0.645\n",
      "Loss 192.13486 129 30\n",
      "Training Accuracy 0.67\n",
      "Loss 189.34586 130 30\n",
      "Training Accuracy 0.66\n",
      "Loss 171.76254 131 30\n",
      "Training Accuracy 0.72\n",
      "Loss 195.06946 132 30\n",
      "Training Accuracy 0.665\n",
      "Loss 196.07916 133 30\n",
      "Training Accuracy 0.62\n",
      "Loss 191.1509 134 30\n",
      "Training Accuracy 0.655\n",
      "Loss 197.54883 135 30\n",
      "Training Accuracy 0.695\n",
      "Loss 204.63069 136 30\n",
      "Training Accuracy 0.695\n",
      "Loss 212.11354 137 30\n",
      "Training Accuracy 0.65\n",
      "Loss 191.01387 138 30\n",
      "Training Accuracy 0.65\n",
      "Loss 203.37112 139 30\n",
      "Training Accuracy 0.695\n",
      "Loss 177.51071 140 30\n",
      "Training Accuracy 0.685\n",
      "Loss 192.31306 141 30\n",
      "Training Accuracy 0.68\n",
      "Loss 203.08328 142 30\n",
      "Training Accuracy 0.615\n",
      "Loss 177.6622 143 30\n",
      "Training Accuracy 0.685\n",
      "Loss 215.29808 144 30\n",
      "Training Accuracy 0.575\n",
      "Loss 187.48853 145 30\n",
      "Training Accuracy 0.675\n",
      "Loss 218.21664 146 30\n",
      "Training Accuracy 0.595\n",
      "Loss 201.46175 147 30\n",
      "Training Accuracy 0.625\n",
      "Loss 194.50398 148 30\n",
      "Training Accuracy 0.655\n",
      "Loss 191.04613 149 30\n",
      "Training Accuracy 0.655\n",
      "Loss 184.66335 150 30\n",
      "Training Accuracy 0.69\n",
      "Loss 221.18666 151 30\n",
      "Training Accuracy 0.625\n",
      "Loss 214.74896 152 30\n",
      "Training Accuracy 0.605\n",
      "Loss 188.4236 153 30\n",
      "Training Accuracy 0.66\n",
      "Loss 201.67105 154 30\n",
      "Training Accuracy 0.66\n",
      "Loss 183.9958 155 30\n",
      "Training Accuracy 0.685\n",
      "Loss 199.98909 156 30\n",
      "Training Accuracy 0.66\n",
      "Loss 185.01611 157 30\n",
      "Training Accuracy 0.665\n",
      "Loss 187.576 158 30\n",
      "Training Accuracy 0.7\n",
      "Loss 217.7405 159 30\n",
      "Training Accuracy 0.6\n",
      "Loss 208.1852 160 30\n",
      "Training Accuracy 0.655\n",
      "Loss 226.18628 161 30\n",
      "Training Accuracy 0.61\n",
      "Loss 192.12097 162 30\n",
      "Training Accuracy 0.68\n",
      "Loss 218.54053 163 30\n",
      "Training Accuracy 0.655\n",
      "Loss 176.04982 164 30\n",
      "Training Accuracy 0.66\n",
      "Loss 200.06473 165 30\n",
      "Training Accuracy 0.675\n",
      "Loss 204.78714 166 30\n",
      "Training Accuracy 0.68\n",
      "Loss 186.95465 167 30\n",
      "Training Accuracy 0.675\n",
      "Loss 208.5036 168 30\n",
      "Training Accuracy 0.64\n",
      "Loss 199.76604 169 30\n",
      "Training Accuracy 0.625\n",
      "Loss 201.01942 170 30\n",
      "Training Accuracy 0.655\n",
      "Loss 211.51465 171 30\n",
      "Training Accuracy 0.625\n",
      "Loss 178.38411 172 30\n",
      "Training Accuracy 0.705\n",
      "Loss 214.44328 173 30\n",
      "Training Accuracy 0.645\n",
      "Loss 177.29254 174 30\n",
      "Training Accuracy 0.7\n",
      "Loss 171.622 175 30\n",
      "Training Accuracy 0.725\n",
      "Loss 152.28526 176 30\n",
      "Training Accuracy 0.74\n",
      "Loss 229.33417 177 30\n",
      "Training Accuracy 0.6\n",
      "Loss 182.3509 178 30\n",
      "Training Accuracy 0.71\n",
      "Loss 210.61787 179 30\n",
      "Training Accuracy 0.65\n",
      "Loss 210.3012 180 30\n",
      "Training Accuracy 0.625\n",
      "Loss 176.04059 181 30\n",
      "Training Accuracy 0.685\n",
      "Loss 203.98386 182 30\n",
      "Training Accuracy 0.64\n",
      "Loss 198.49054 183 30\n",
      "Training Accuracy 0.65\n",
      "Loss 166.28873 184 30\n",
      "Training Accuracy 0.72\n",
      "Loss 191.27005 185 30\n",
      "Training Accuracy 0.685\n",
      "Loss 185.77678 186 30\n",
      "Training Accuracy 0.685\n",
      "Loss 225.17691 187 30\n",
      "Training Accuracy 0.64\n",
      "Loss 211.10532 188 30\n",
      "Training Accuracy 0.645\n",
      "Loss 206.999 189 30\n",
      "Training Accuracy 0.63\n",
      "Loss 186.52142 190 30\n",
      "Training Accuracy 0.65\n",
      "Loss 172.41316 191 30\n",
      "Training Accuracy 0.685\n",
      "Loss 222.67714 192 30\n",
      "Training Accuracy 0.595\n",
      "Loss 187.19963 193 30\n",
      "Training Accuracy 0.735\n",
      "Loss 184.24863 194 30\n",
      "Training Accuracy 0.695\n",
      "Loss 183.03972 195 30\n",
      "Training Accuracy 0.71\n",
      "Loss 178.81497 196 30\n",
      "Training Accuracy 0.705\n",
      "Loss 196.80634 197 30\n",
      "Training Accuracy 0.625\n",
      "Loss 186.84468 198 30\n",
      "Training Accuracy 0.67\n",
      "Loss 164.4444 199 30\n",
      "Training Accuracy 0.71\n",
      "Loss 187.01805 200 30\n",
      "Training Accuracy 0.675\n",
      "Loss 184.51125 201 30\n",
      "Training Accuracy 0.67\n",
      "Loss 189.5675 202 30\n",
      "Training Accuracy 0.685\n",
      "Loss 195.5347 203 30\n",
      "Training Accuracy 0.685\n",
      "Loss 181.44006 204 30\n",
      "Training Accuracy 0.69\n",
      "Loss 216.79466 205 30\n",
      "Training Accuracy 0.65\n",
      "Loss 203.3626 206 30\n",
      "Training Accuracy 0.655\n",
      "Loss 202.75365 207 30\n",
      "Training Accuracy 0.655\n",
      "Loss 208.13977 208 30\n",
      "Training Accuracy 0.655\n",
      "Loss 209.23001 209 30\n",
      "Training Accuracy 0.675\n",
      "Loss 175.45068 210 30\n",
      "Training Accuracy 0.68\n",
      "Loss 176.36829 211 30\n",
      "Training Accuracy 0.74\n",
      "Loss 184.36043 212 30\n",
      "Training Accuracy 0.7\n",
      "Loss 231.33025 213 30\n",
      "Training Accuracy 0.615\n",
      "Loss 199.24118 214 30\n",
      "Training Accuracy 0.655\n",
      "Loss 213.2368 215 30\n",
      "Training Accuracy 0.64\n",
      "Loss 212.17912 216 30\n",
      "Training Accuracy 0.63\n",
      "Loss 203.50562 217 30\n",
      "Training Accuracy 0.65\n",
      "Loss 202.15999 218 30\n",
      "Training Accuracy 0.68\n",
      "Loss 198.05505 219 30\n",
      "Training Accuracy 0.645\n",
      "Loss 194.70038 220 30\n",
      "Training Accuracy 0.645\n",
      "Loss 196.96616 221 30\n",
      "Training Accuracy 0.635\n",
      "Loss 183.7529 222 30\n",
      "Training Accuracy 0.675\n",
      "Loss 212.51724 223 30\n",
      "Training Accuracy 0.64\n",
      "Loss 215.73396 224 30\n",
      "Training Accuracy 0.63\n",
      "Loss 219.53029 225 30\n",
      "Training Accuracy 0.65\n",
      "Loss 169.05371 226 30\n",
      "Training Accuracy 0.7\n",
      "Loss 221.15115 227 30\n",
      "Training Accuracy 0.61\n",
      "Loss 231.5791 228 30\n",
      "Training Accuracy 0.585\n",
      "Loss 188.348 229 30\n",
      "Training Accuracy 0.695\n",
      "Loss 205.08496 230 30\n",
      "Training Accuracy 0.65\n",
      "Loss 178.25511 231 30\n",
      "Training Accuracy 0.705\n",
      "Loss 204.23857 232 30\n",
      "Training Accuracy 0.65\n",
      "Loss 216.98929 233 30\n",
      "Training Accuracy 0.595\n",
      "Loss 204.54059 234 30\n",
      "Training Accuracy 0.59\n",
      "Loss 196.62134 235 30\n",
      "Training Accuracy 0.665\n",
      "Loss 176.58485 236 30\n",
      "Training Accuracy 0.675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 202.57553 237 30\n",
      "Training Accuracy 0.64\n",
      "Loss 189.44562 238 30\n",
      "Training Accuracy 0.605\n",
      "Loss 202.45964 239 30\n",
      "Training Accuracy 0.665\n",
      "Loss 199.16426 240 30\n",
      "Training Accuracy 0.625\n",
      "Loss 224.87238 241 30\n",
      "Training Accuracy 0.635\n",
      "Loss 190.26147 242 30\n",
      "Training Accuracy 0.665\n",
      "Loss 179.47482 243 30\n",
      "Training Accuracy 0.7\n",
      "Loss 203.57256 244 30\n",
      "Training Accuracy 0.62\n",
      "Loss 190.14793 245 30\n",
      "Training Accuracy 0.68\n",
      "Loss 216.96956 246 30\n",
      "Training Accuracy 0.635\n",
      "Loss 187.10556 247 30\n",
      "Training Accuracy 0.66\n",
      "Loss 182.79997 248 30\n",
      "Training Accuracy 0.695\n",
      "Loss 205.57538 249 30\n",
      "Training Accuracy 0.6\n",
      "Loss 207.97034 250 30\n",
      "Training Accuracy 0.63\n",
      "Loss 203.02351 251 30\n",
      "Training Accuracy 0.635\n",
      "Loss 170.14948 252 30\n",
      "Training Accuracy 0.69\n",
      "Loss 162.80106 253 30\n",
      "Training Accuracy 0.72\n",
      "Loss 195.6972 254 30\n",
      "Training Accuracy 0.665\n",
      "Loss 168.81511 255 30\n",
      "Training Accuracy 0.715\n",
      "Loss 222.14629 256 30\n",
      "Training Accuracy 0.635\n",
      "Loss 198.95834 257 30\n",
      "Training Accuracy 0.655\n",
      "Loss 204.56209 258 30\n",
      "Training Accuracy 0.665\n",
      "Loss 204.97049 259 30\n",
      "Training Accuracy 0.69\n",
      "Loss 164.42941 260 30\n",
      "Training Accuracy 0.69\n",
      "Loss 195.00371 261 30\n",
      "Training Accuracy 0.66\n",
      "Loss 199.59909 262 30\n",
      "Training Accuracy 0.6\n",
      "Loss 223.86006 263 30\n",
      "Training Accuracy 0.65\n",
      "Loss 207.1006 264 30\n",
      "Training Accuracy 0.67\n",
      "Loss 175.03806 265 30\n",
      "Training Accuracy 0.705\n",
      "Loss 197.54266 266 30\n",
      "Training Accuracy 0.655\n",
      "Loss 205.41881 267 30\n",
      "Training Accuracy 0.625\n",
      "Loss 224.77463 268 30\n",
      "Training Accuracy 0.6\n",
      "Loss 181.74014 269 30\n",
      "Training Accuracy 0.67\n",
      "Loss 169.18083 270 30\n",
      "Training Accuracy 0.72\n",
      "Loss 220.52934 271 30\n",
      "Training Accuracy 0.66\n",
      "Loss 197.70097 272 30\n",
      "Training Accuracy 0.655\n",
      "Loss 215.45119 273 30\n",
      "Training Accuracy 0.63\n",
      "Loss 178.78862 274 30\n",
      "Training Accuracy 0.71\n",
      "Loss 190.95718 275 30\n",
      "Training Accuracy 0.665\n",
      "Loss 177.02422 276 30\n",
      "Training Accuracy 0.67\n",
      "Loss 208.39792 277 30\n",
      "Training Accuracy 0.65\n",
      "Loss 182.95097 278 30\n",
      "Training Accuracy 0.68\n",
      "Loss 199.75989 279 30\n",
      "Training Accuracy 0.695\n",
      "Loss 189.83002 280 30\n",
      "Training Accuracy 0.655\n",
      "Loss 187.42001 281 30\n",
      "Training Accuracy 0.665\n",
      "Loss 190.17188 282 30\n",
      "Training Accuracy 0.675\n",
      "Loss 187.78763 283 30\n",
      "Training Accuracy 0.695\n",
      "Loss 157.03822 284 30\n",
      "Training Accuracy 0.74\n",
      "Loss 224.38342 285 30\n",
      "Training Accuracy 0.615\n",
      "Loss 191.08972 286 30\n",
      "Training Accuracy 0.675\n",
      "Loss 186.00934 287 30\n",
      "Training Accuracy 0.73\n",
      "Loss 198.82794 288 30\n",
      "Training Accuracy 0.71\n",
      "Loss 186.77705 289 30\n",
      "Training Accuracy 0.695\n",
      "Loss 197.28456 290 30\n",
      "Training Accuracy 0.67\n",
      "Loss 210.81406 291 30\n",
      "Training Accuracy 0.655\n",
      "Loss 127.91892 292 30\n",
      "Training Accuracy 0.6439394\n",
      "Loss 163.99745 1 31\n",
      "Training Accuracy 0.755\n",
      "Loss 188.81548 2 31\n",
      "Training Accuracy 0.685\n",
      "Loss 176.65517 3 31\n",
      "Training Accuracy 0.695\n",
      "Loss 210.87747 4 31\n",
      "Training Accuracy 0.645\n",
      "Loss 170.4074 5 31\n",
      "Training Accuracy 0.71\n",
      "Loss 212.2344 6 31\n",
      "Training Accuracy 0.625\n",
      "Loss 204.13213 7 31\n",
      "Training Accuracy 0.695\n",
      "Loss 203.50609 8 31\n",
      "Training Accuracy 0.66\n",
      "Loss 175.85428 9 31\n",
      "Training Accuracy 0.725\n",
      "Loss 217.54689 10 31\n",
      "Training Accuracy 0.615\n",
      "Loss 218.68185 11 31\n",
      "Training Accuracy 0.665\n",
      "Loss 171.68204 12 31\n",
      "Training Accuracy 0.725\n",
      "Loss 180.26813 13 31\n",
      "Training Accuracy 0.68\n",
      "Loss 202.84396 14 31\n",
      "Training Accuracy 0.645\n",
      "Loss 179.44789 15 31\n",
      "Training Accuracy 0.695\n",
      "Loss 242.37137 16 31\n",
      "Training Accuracy 0.595\n",
      "Loss 173.06271 17 31\n",
      "Training Accuracy 0.715\n",
      "Loss 181.11397 18 31\n",
      "Training Accuracy 0.665\n",
      "Loss 191.57405 19 31\n",
      "Training Accuracy 0.665\n",
      "Loss 183.79932 20 31\n",
      "Training Accuracy 0.675\n",
      "Loss 190.00125 21 31\n",
      "Training Accuracy 0.685\n",
      "Loss 187.3015 22 31\n",
      "Training Accuracy 0.675\n",
      "Loss 202.18741 23 31\n",
      "Training Accuracy 0.67\n",
      "Loss 208.88304 24 31\n",
      "Training Accuracy 0.64\n",
      "Loss 177.65163 25 31\n",
      "Training Accuracy 0.72\n",
      "Loss 197.64075 26 31\n",
      "Training Accuracy 0.66\n",
      "Loss 185.66052 27 31\n",
      "Training Accuracy 0.715\n",
      "Loss 178.27115 28 31\n",
      "Training Accuracy 0.67\n",
      "Loss 198.08698 29 31\n",
      "Training Accuracy 0.65\n",
      "Loss 206.88329 30 31\n",
      "Training Accuracy 0.64\n",
      "Loss 202.56383 31 31\n",
      "Training Accuracy 0.69\n",
      "Loss 185.95374 32 31\n",
      "Training Accuracy 0.64\n",
      "Loss 198.99467 33 31\n",
      "Training Accuracy 0.67\n",
      "Loss 170.67686 34 31\n",
      "Training Accuracy 0.705\n",
      "Loss 179.47005 35 31\n",
      "Training Accuracy 0.665\n",
      "Loss 203.34769 36 31\n",
      "Training Accuracy 0.63\n",
      "Loss 188.23839 37 31\n",
      "Training Accuracy 0.695\n",
      "Loss 205.797 38 31\n",
      "Training Accuracy 0.64\n",
      "Loss 178.1071 39 31\n",
      "Training Accuracy 0.675\n",
      "Loss 181.64221 40 31\n",
      "Training Accuracy 0.69\n",
      "Loss 197.82541 41 31\n",
      "Training Accuracy 0.665\n",
      "Loss 227.47365 42 31\n",
      "Training Accuracy 0.64\n",
      "Loss 199.37361 43 31\n",
      "Training Accuracy 0.655\n",
      "Loss 190.19987 44 31\n",
      "Training Accuracy 0.67\n",
      "Loss 209.69467 45 31\n",
      "Training Accuracy 0.655\n",
      "Loss 226.91035 46 31\n",
      "Training Accuracy 0.635\n",
      "Loss 184.52248 47 31\n",
      "Training Accuracy 0.695\n",
      "Loss 155.02495 48 31\n",
      "Training Accuracy 0.715\n",
      "Loss 198.67195 49 31\n",
      "Training Accuracy 0.655\n",
      "Loss 215.18288 50 31\n",
      "Training Accuracy 0.645\n",
      "Loss 171.17136 51 31\n",
      "Training Accuracy 0.69\n",
      "Loss 176.88783 52 31\n",
      "Training Accuracy 0.705\n",
      "Loss 160.49982 53 31\n",
      "Training Accuracy 0.7\n",
      "Loss 216.81937 54 31\n",
      "Training Accuracy 0.65\n",
      "Loss 199.11916 55 31\n",
      "Training Accuracy 0.65\n",
      "Loss 210.89433 56 31\n",
      "Training Accuracy 0.585\n",
      "Loss 197.34433 57 31\n",
      "Training Accuracy 0.685\n",
      "Loss 181.96764 58 31\n",
      "Training Accuracy 0.67\n",
      "Loss 210.1235 59 31\n",
      "Training Accuracy 0.665\n",
      "Loss 193.9701 60 31\n",
      "Training Accuracy 0.69\n",
      "Loss 194.32027 61 31\n",
      "Training Accuracy 0.655\n",
      "Loss 179.46883 62 31\n",
      "Training Accuracy 0.72\n",
      "Loss 184.43063 63 31\n",
      "Training Accuracy 0.69\n",
      "Loss 198.89343 64 31\n",
      "Training Accuracy 0.665\n",
      "Loss 202.93256 65 31\n",
      "Training Accuracy 0.63\n",
      "Loss 180.18863 66 31\n",
      "Training Accuracy 0.68\n",
      "Loss 196.84694 67 31\n",
      "Training Accuracy 0.65\n",
      "Loss 196.33907 68 31\n",
      "Training Accuracy 0.655\n",
      "Loss 190.39728 69 31\n",
      "Training Accuracy 0.705\n",
      "Loss 191.88094 70 31\n",
      "Training Accuracy 0.695\n",
      "Loss 192.05592 71 31\n",
      "Training Accuracy 0.7\n",
      "Loss 201.26277 72 31\n",
      "Training Accuracy 0.665\n",
      "Loss 210.20401 73 31\n",
      "Training Accuracy 0.59\n",
      "Loss 204.95209 74 31\n",
      "Training Accuracy 0.66\n",
      "Loss 206.27962 75 31\n",
      "Training Accuracy 0.65\n",
      "Loss 178.68523 76 31\n",
      "Training Accuracy 0.69\n",
      "Loss 215.14476 77 31\n",
      "Training Accuracy 0.645\n",
      "Loss 195.91988 78 31\n",
      "Training Accuracy 0.685\n",
      "Loss 198.20401 79 31\n",
      "Training Accuracy 0.6\n",
      "Loss 200.25644 80 31\n",
      "Training Accuracy 0.655\n",
      "Loss 178.89801 81 31\n",
      "Training Accuracy 0.69\n",
      "Loss 196.11552 82 31\n",
      "Training Accuracy 0.685\n",
      "Loss 185.2779 83 31\n",
      "Training Accuracy 0.695\n",
      "Loss 206.59233 84 31\n",
      "Training Accuracy 0.66\n",
      "Loss 192.19019 85 31\n",
      "Training Accuracy 0.65\n",
      "Loss 203.12268 86 31\n",
      "Training Accuracy 0.665\n",
      "Loss 227.85158 87 31\n",
      "Training Accuracy 0.59\n",
      "Loss 221.57964 88 31\n",
      "Training Accuracy 0.68\n",
      "Loss 198.22403 89 31\n",
      "Training Accuracy 0.685\n",
      "Loss 213.57196 90 31\n",
      "Training Accuracy 0.635\n",
      "Loss 183.8927 91 31\n",
      "Training Accuracy 0.675\n",
      "Loss 205.10168 92 31\n",
      "Training Accuracy 0.655\n",
      "Loss 197.16513 93 31\n",
      "Training Accuracy 0.655\n",
      "Loss 196.51968 94 31\n",
      "Training Accuracy 0.66\n",
      "Loss 194.15282 95 31\n",
      "Training Accuracy 0.635\n",
      "Loss 196.8162 96 31\n",
      "Training Accuracy 0.67\n",
      "Loss 198.0582 97 31\n",
      "Training Accuracy 0.64\n",
      "Loss 178.74716 98 31\n",
      "Training Accuracy 0.68\n",
      "Loss 190.42467 99 31\n",
      "Training Accuracy 0.7\n",
      "Loss 197.50224 100 31\n",
      "Training Accuracy 0.695\n",
      "Loss 216.89288 101 31\n",
      "Training Accuracy 0.645\n",
      "Loss 185.35338 102 31\n",
      "Training Accuracy 0.68\n",
      "Loss 199.18195 103 31\n",
      "Training Accuracy 0.615\n",
      "Loss 197.96051 104 31\n",
      "Training Accuracy 0.68\n",
      "Loss 196.48555 105 31\n",
      "Training Accuracy 0.67\n",
      "Loss 187.23085 106 31\n",
      "Training Accuracy 0.7\n",
      "Loss 191.725 107 31\n",
      "Training Accuracy 0.67\n",
      "Loss 203.42738 108 31\n",
      "Training Accuracy 0.63\n",
      "Loss 185.22601 109 31\n",
      "Training Accuracy 0.675\n",
      "Loss 195.95293 110 31\n",
      "Training Accuracy 0.675\n",
      "Loss 198.98003 111 31\n",
      "Training Accuracy 0.68\n",
      "Loss 206.63307 112 31\n",
      "Training Accuracy 0.68\n",
      "Loss 224.0468 113 31\n",
      "Training Accuracy 0.675\n",
      "Loss 194.51071 114 31\n",
      "Training Accuracy 0.64\n",
      "Loss 219.57852 115 31\n",
      "Training Accuracy 0.64\n",
      "Loss 209.54706 116 31\n",
      "Training Accuracy 0.665\n",
      "Loss 162.85558 117 31\n",
      "Training Accuracy 0.755\n",
      "Loss 200.6685 118 31\n",
      "Training Accuracy 0.635\n",
      "Loss 221.64174 119 31\n",
      "Training Accuracy 0.585\n",
      "Loss 203.21733 120 31\n",
      "Training Accuracy 0.66\n",
      "Loss 206.51685 121 31\n",
      "Training Accuracy 0.645\n",
      "Loss 194.6661 122 31\n",
      "Training Accuracy 0.675\n",
      "Loss 195.93402 123 31\n",
      "Training Accuracy 0.65\n",
      "Loss 186.66579 124 31\n",
      "Training Accuracy 0.67\n",
      "Loss 180.11697 125 31\n",
      "Training Accuracy 0.705\n",
      "Loss 207.5216 126 31\n",
      "Training Accuracy 0.64\n",
      "Loss 202.56982 127 31\n",
      "Training Accuracy 0.615\n",
      "Loss 193.77576 128 31\n",
      "Training Accuracy 0.675\n",
      "Loss 181.11172 129 31\n",
      "Training Accuracy 0.71\n",
      "Loss 181.31662 130 31\n",
      "Training Accuracy 0.665\n",
      "Loss 171.7942 131 31\n",
      "Training Accuracy 0.74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 179.57408 132 31\n",
      "Training Accuracy 0.72\n",
      "Loss 178.3102 133 31\n",
      "Training Accuracy 0.71\n",
      "Loss 189.27261 134 31\n",
      "Training Accuracy 0.64\n",
      "Loss 195.19406 135 31\n",
      "Training Accuracy 0.665\n",
      "Loss 206.7055 136 31\n",
      "Training Accuracy 0.67\n",
      "Loss 219.77791 137 31\n",
      "Training Accuracy 0.615\n",
      "Loss 195.50166 138 31\n",
      "Training Accuracy 0.68\n",
      "Loss 227.14966 139 31\n",
      "Training Accuracy 0.635\n",
      "Loss 171.67688 140 31\n",
      "Training Accuracy 0.7\n",
      "Loss 189.62062 141 31\n",
      "Training Accuracy 0.715\n",
      "Loss 209.85526 142 31\n",
      "Training Accuracy 0.59\n",
      "Loss 170.88455 143 31\n",
      "Training Accuracy 0.7\n",
      "Loss 206.45146 144 31\n",
      "Training Accuracy 0.67\n",
      "Loss 194.92624 145 31\n",
      "Training Accuracy 0.665\n",
      "Loss 204.86829 146 31\n",
      "Training Accuracy 0.645\n",
      "Loss 194.67769 147 31\n",
      "Training Accuracy 0.675\n",
      "Loss 207.87334 148 31\n",
      "Training Accuracy 0.64\n",
      "Loss 193.34357 149 31\n",
      "Training Accuracy 0.665\n",
      "Loss 187.93216 150 31\n",
      "Training Accuracy 0.695\n",
      "Loss 207.10365 151 31\n",
      "Training Accuracy 0.69\n",
      "Loss 215.81259 152 31\n",
      "Training Accuracy 0.615\n",
      "Loss 186.6535 153 31\n",
      "Training Accuracy 0.675\n",
      "Loss 187.34575 154 31\n",
      "Training Accuracy 0.695\n",
      "Loss 186.61241 155 31\n",
      "Training Accuracy 0.66\n",
      "Loss 201.83731 156 31\n",
      "Training Accuracy 0.625\n",
      "Loss 171.73012 157 31\n",
      "Training Accuracy 0.655\n",
      "Loss 186.61351 158 31\n",
      "Training Accuracy 0.71\n",
      "Loss 228.38548 159 31\n",
      "Training Accuracy 0.61\n",
      "Loss 196.08583 160 31\n",
      "Training Accuracy 0.68\n",
      "Loss 219.73224 161 31\n",
      "Training Accuracy 0.62\n",
      "Loss 189.45834 162 31\n",
      "Training Accuracy 0.665\n",
      "Loss 205.92804 163 31\n",
      "Training Accuracy 0.69\n",
      "Loss 181.83403 164 31\n",
      "Training Accuracy 0.64\n",
      "Loss 185.10513 165 31\n",
      "Training Accuracy 0.705\n",
      "Loss 197.61061 166 31\n",
      "Training Accuracy 0.71\n",
      "Loss 176.76965 167 31\n",
      "Training Accuracy 0.675\n",
      "Loss 217.22119 168 31\n",
      "Training Accuracy 0.65\n",
      "Loss 196.81664 169 31\n",
      "Training Accuracy 0.65\n",
      "Loss 201.65749 170 31\n",
      "Training Accuracy 0.655\n",
      "Loss 197.43979 171 31\n",
      "Training Accuracy 0.68\n",
      "Loss 181.07382 172 31\n",
      "Training Accuracy 0.71\n",
      "Loss 212.43428 173 31\n",
      "Training Accuracy 0.68\n",
      "Loss 168.15855 174 31\n",
      "Training Accuracy 0.705\n",
      "Loss 168.03316 175 31\n",
      "Training Accuracy 0.71\n",
      "Loss 154.51907 176 31\n",
      "Training Accuracy 0.755\n",
      "Loss 218.05133 177 31\n",
      "Training Accuracy 0.625\n",
      "Loss 185.68935 178 31\n",
      "Training Accuracy 0.66\n",
      "Loss 207.02611 179 31\n",
      "Training Accuracy 0.655\n",
      "Loss 205.04414 180 31\n",
      "Training Accuracy 0.635\n",
      "Loss 172.05453 181 31\n",
      "Training Accuracy 0.73\n",
      "Loss 207.98135 182 31\n",
      "Training Accuracy 0.635\n",
      "Loss 194.75313 183 31\n",
      "Training Accuracy 0.63\n",
      "Loss 173.44164 184 31\n",
      "Training Accuracy 0.715\n",
      "Loss 192.2927 185 31\n",
      "Training Accuracy 0.65\n",
      "Loss 188.0676 186 31\n",
      "Training Accuracy 0.67\n",
      "Loss 225.66313 187 31\n",
      "Training Accuracy 0.58\n",
      "Loss 200.11333 188 31\n",
      "Training Accuracy 0.7\n",
      "Loss 187.34085 189 31\n",
      "Training Accuracy 0.73\n",
      "Loss 185.55199 190 31\n",
      "Training Accuracy 0.695\n",
      "Loss 177.84526 191 31\n",
      "Training Accuracy 0.71\n",
      "Loss 211.10684 192 31\n",
      "Training Accuracy 0.63\n",
      "Loss 186.36458 193 31\n",
      "Training Accuracy 0.71\n",
      "Loss 186.79308 194 31\n",
      "Training Accuracy 0.7\n",
      "Loss 171.46965 195 31\n",
      "Training Accuracy 0.7\n",
      "Loss 185.978 196 31\n",
      "Training Accuracy 0.645\n",
      "Loss 193.81888 197 31\n",
      "Training Accuracy 0.655\n",
      "Loss 183.47475 198 31\n",
      "Training Accuracy 0.66\n",
      "Loss 166.78394 199 31\n",
      "Training Accuracy 0.685\n",
      "Loss 183.57892 200 31\n",
      "Training Accuracy 0.705\n",
      "Loss 185.03238 201 31\n",
      "Training Accuracy 0.675\n",
      "Loss 179.92892 202 31\n",
      "Training Accuracy 0.665\n",
      "Loss 190.08014 203 31\n",
      "Training Accuracy 0.7\n",
      "Loss 190.42728 204 31\n",
      "Training Accuracy 0.66\n",
      "Loss 211.65602 205 31\n",
      "Training Accuracy 0.635\n",
      "Loss 179.92804 206 31\n",
      "Training Accuracy 0.74\n",
      "Loss 197.96465 207 31\n",
      "Training Accuracy 0.65\n",
      "Loss 200.45638 208 31\n",
      "Training Accuracy 0.675\n",
      "Loss 205.69145 209 31\n",
      "Training Accuracy 0.635\n",
      "Loss 178.40631 210 31\n",
      "Training Accuracy 0.675\n",
      "Loss 175.28966 211 31\n",
      "Training Accuracy 0.71\n",
      "Loss 185.29555 212 31\n",
      "Training Accuracy 0.655\n",
      "Loss 224.17181 213 31\n",
      "Training Accuracy 0.64\n",
      "Loss 198.99644 214 31\n",
      "Training Accuracy 0.655\n",
      "Loss 206.61783 215 31\n",
      "Training Accuracy 0.65\n",
      "Loss 196.04327 216 31\n",
      "Training Accuracy 0.69\n",
      "Loss 192.39299 217 31\n",
      "Training Accuracy 0.68\n",
      "Loss 203.25786 218 31\n",
      "Training Accuracy 0.68\n",
      "Loss 194.4858 219 31\n",
      "Training Accuracy 0.7\n",
      "Loss 188.81139 220 31\n",
      "Training Accuracy 0.665\n",
      "Loss 197.04301 221 31\n",
      "Training Accuracy 0.63\n",
      "Loss 191.17798 222 31\n",
      "Training Accuracy 0.66\n",
      "Loss 204.58911 223 31\n",
      "Training Accuracy 0.655\n",
      "Loss 213.74083 224 31\n",
      "Training Accuracy 0.62\n",
      "Loss 208.35443 225 31\n",
      "Training Accuracy 0.67\n",
      "Loss 159.2782 226 31\n",
      "Training Accuracy 0.73\n",
      "Loss 225.03044 227 31\n",
      "Training Accuracy 0.615\n",
      "Loss 224.93475 228 31\n",
      "Training Accuracy 0.665\n",
      "Loss 193.14552 229 31\n",
      "Training Accuracy 0.685\n",
      "Loss 194.84175 230 31\n",
      "Training Accuracy 0.695\n",
      "Loss 176.52124 231 31\n",
      "Training Accuracy 0.69\n",
      "Loss 216.5722 232 31\n",
      "Training Accuracy 0.605\n",
      "Loss 229.22897 233 31\n",
      "Training Accuracy 0.57\n",
      "Loss 197.55135 234 31\n",
      "Training Accuracy 0.615\n",
      "Loss 199.6972 235 31\n",
      "Training Accuracy 0.66\n",
      "Loss 171.04697 236 31\n",
      "Training Accuracy 0.695\n",
      "Loss 203.01376 237 31\n",
      "Training Accuracy 0.63\n",
      "Loss 189.11014 238 31\n",
      "Training Accuracy 0.685\n",
      "Loss 203.04611 239 31\n",
      "Training Accuracy 0.635\n",
      "Loss 198.79626 240 31\n",
      "Training Accuracy 0.635\n",
      "Loss 226.891 241 31\n",
      "Training Accuracy 0.585\n",
      "Loss 188.57303 242 31\n",
      "Training Accuracy 0.64\n",
      "Loss 173.6819 243 31\n",
      "Training Accuracy 0.7\n",
      "Loss 206.06639 244 31\n",
      "Training Accuracy 0.61\n",
      "Loss 198.81313 245 31\n",
      "Training Accuracy 0.685\n",
      "Loss 205.19203 246 31\n",
      "Training Accuracy 0.63\n",
      "Loss 172.37817 247 31\n",
      "Training Accuracy 0.66\n",
      "Loss 180.93723 248 31\n",
      "Training Accuracy 0.66\n",
      "Loss 212.255 249 31\n",
      "Training Accuracy 0.61\n",
      "Loss 202.15327 250 31\n",
      "Training Accuracy 0.635\n",
      "Loss 204.94911 251 31\n",
      "Training Accuracy 0.64\n",
      "Loss 169.4672 252 31\n",
      "Training Accuracy 0.7\n",
      "Loss 168.15475 253 31\n",
      "Training Accuracy 0.7\n",
      "Loss 198.75522 254 31\n",
      "Training Accuracy 0.67\n",
      "Loss 168.69777 255 31\n",
      "Training Accuracy 0.7\n",
      "Loss 204.01173 256 31\n",
      "Training Accuracy 0.675\n",
      "Loss 184.78372 257 31\n",
      "Training Accuracy 0.7\n",
      "Loss 196.3242 258 31\n",
      "Training Accuracy 0.67\n",
      "Loss 183.11626 259 31\n",
      "Training Accuracy 0.665\n",
      "Loss 161.26556 260 31\n",
      "Training Accuracy 0.715\n",
      "Loss 190.23758 261 31\n",
      "Training Accuracy 0.685\n",
      "Loss 187.30597 262 31\n",
      "Training Accuracy 0.65\n",
      "Loss 225.15817 263 31\n",
      "Training Accuracy 0.635\n",
      "Loss 198.96613 264 31\n",
      "Training Accuracy 0.69\n",
      "Loss 183.51346 265 31\n",
      "Training Accuracy 0.68\n",
      "Loss 179.91998 266 31\n",
      "Training Accuracy 0.675\n",
      "Loss 192.21864 267 31\n",
      "Training Accuracy 0.665\n",
      "Loss 196.43257 268 31\n",
      "Training Accuracy 0.69\n",
      "Loss 183.32031 269 31\n",
      "Training Accuracy 0.675\n",
      "Loss 178.53304 270 31\n",
      "Training Accuracy 0.685\n",
      "Loss 216.73195 271 31\n",
      "Training Accuracy 0.615\n",
      "Loss 196.17986 272 31\n",
      "Training Accuracy 0.675\n",
      "Loss 203.49529 273 31\n",
      "Training Accuracy 0.645\n",
      "Loss 189.65013 274 31\n",
      "Training Accuracy 0.705\n",
      "Loss 185.30908 275 31\n",
      "Training Accuracy 0.675\n",
      "Loss 190.54965 276 31\n",
      "Training Accuracy 0.655\n",
      "Loss 201.2102 277 31\n",
      "Training Accuracy 0.675\n",
      "Loss 185.53098 278 31\n",
      "Training Accuracy 0.67\n",
      "Loss 194.03091 279 31\n",
      "Training Accuracy 0.71\n",
      "Loss 175.86768 280 31\n",
      "Training Accuracy 0.695\n",
      "Loss 176.1856 281 31\n",
      "Training Accuracy 0.695\n",
      "Loss 199.2222 282 31\n",
      "Training Accuracy 0.65\n",
      "Loss 177.37535 283 31\n",
      "Training Accuracy 0.715\n",
      "Loss 165.41228 284 31\n",
      "Training Accuracy 0.735\n",
      "Loss 217.51129 285 31\n",
      "Training Accuracy 0.595\n",
      "Loss 193.97786 286 31\n",
      "Training Accuracy 0.705\n",
      "Loss 182.73454 287 31\n",
      "Training Accuracy 0.675\n",
      "Loss 192.63876 288 31\n",
      "Training Accuracy 0.7\n",
      "Loss 182.40384 289 31\n",
      "Training Accuracy 0.7\n",
      "Loss 184.70435 290 31\n",
      "Training Accuracy 0.685\n",
      "Loss 206.0417 291 31\n",
      "Training Accuracy 0.645\n",
      "Loss 121.76433 292 31\n",
      "Training Accuracy 0.6666667\n",
      "Loss 152.42296 1 32\n",
      "Training Accuracy 0.74\n",
      "Loss 189.50607 2 32\n",
      "Training Accuracy 0.685\n",
      "Loss 176.1861 3 32\n",
      "Training Accuracy 0.705\n",
      "Loss 199.49797 4 32\n",
      "Training Accuracy 0.66\n",
      "Loss 161.0038 5 32\n",
      "Training Accuracy 0.705\n",
      "Loss 203.39374 6 32\n",
      "Training Accuracy 0.625\n",
      "Loss 200.91249 7 32\n",
      "Training Accuracy 0.66\n",
      "Loss 208.4559 8 32\n",
      "Training Accuracy 0.66\n",
      "Loss 173.79884 9 32\n",
      "Training Accuracy 0.72\n",
      "Loss 204.73424 10 32\n",
      "Training Accuracy 0.61\n",
      "Loss 219.505 11 32\n",
      "Training Accuracy 0.705\n",
      "Loss 186.60706 12 32\n",
      "Training Accuracy 0.655\n",
      "Loss 183.25786 13 32\n",
      "Training Accuracy 0.68\n",
      "Loss 197.00467 14 32\n",
      "Training Accuracy 0.68\n",
      "Loss 176.6884 15 32\n",
      "Training Accuracy 0.7\n",
      "Loss 230.22086 16 32\n",
      "Training Accuracy 0.61\n",
      "Loss 171.59073 17 32\n",
      "Training Accuracy 0.695\n",
      "Loss 172.23692 18 32\n",
      "Training Accuracy 0.725\n",
      "Loss 169.73083 19 32\n",
      "Training Accuracy 0.685\n",
      "Loss 178.88521 20 32\n",
      "Training Accuracy 0.725\n",
      "Loss 198.63483 21 32\n",
      "Training Accuracy 0.655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 184.85078 22 32\n",
      "Training Accuracy 0.74\n",
      "Loss 199.28311 23 32\n",
      "Training Accuracy 0.665\n",
      "Loss 207.88037 24 32\n",
      "Training Accuracy 0.65\n",
      "Loss 179.05865 25 32\n",
      "Training Accuracy 0.72\n",
      "Loss 192.70883 26 32\n",
      "Training Accuracy 0.685\n",
      "Loss 190.91335 27 32\n",
      "Training Accuracy 0.655\n",
      "Loss 180.55742 28 32\n",
      "Training Accuracy 0.615\n",
      "Loss 206.60205 29 32\n",
      "Training Accuracy 0.61\n",
      "Loss 202.42383 30 32\n",
      "Training Accuracy 0.665\n",
      "Loss 196.42632 31 32\n",
      "Training Accuracy 0.675\n",
      "Loss 183.48991 32 32\n",
      "Training Accuracy 0.645\n",
      "Loss 192.15042 33 32\n",
      "Training Accuracy 0.665\n",
      "Loss 181.52515 34 32\n",
      "Training Accuracy 0.685\n",
      "Loss 173.11705 35 32\n",
      "Training Accuracy 0.67\n",
      "Loss 190.20181 36 32\n",
      "Training Accuracy 0.635\n",
      "Loss 180.03496 37 32\n",
      "Training Accuracy 0.625\n",
      "Loss 196.39641 38 32\n",
      "Training Accuracy 0.665\n",
      "Loss 158.60274 39 32\n",
      "Training Accuracy 0.73\n",
      "Loss 195.9781 40 32\n",
      "Training Accuracy 0.69\n",
      "Loss 195.27687 41 32\n",
      "Training Accuracy 0.65\n",
      "Loss 220.71085 42 32\n",
      "Training Accuracy 0.61\n",
      "Loss 178.0705 43 32\n",
      "Training Accuracy 0.67\n",
      "Loss 186.02638 44 32\n",
      "Training Accuracy 0.69\n",
      "Loss 188.26369 45 32\n",
      "Training Accuracy 0.69\n",
      "Loss 208.19618 46 32\n",
      "Training Accuracy 0.645\n",
      "Loss 186.04335 47 32\n",
      "Training Accuracy 0.725\n",
      "Loss 166.75002 48 32\n",
      "Training Accuracy 0.7\n",
      "Loss 191.22308 49 32\n",
      "Training Accuracy 0.69\n",
      "Loss 227.95764 50 32\n",
      "Training Accuracy 0.6\n",
      "Loss 167.53859 51 32\n",
      "Training Accuracy 0.705\n",
      "Loss 174.27911 52 32\n",
      "Training Accuracy 0.71\n",
      "Loss 153.21533 53 32\n",
      "Training Accuracy 0.73\n",
      "Loss 208.2977 54 32\n",
      "Training Accuracy 0.665\n",
      "Loss 194.70415 55 32\n",
      "Training Accuracy 0.675\n",
      "Loss 196.0869 56 32\n",
      "Training Accuracy 0.63\n",
      "Loss 191.57932 57 32\n",
      "Training Accuracy 0.685\n",
      "Loss 192.65977 58 32\n",
      "Training Accuracy 0.635\n",
      "Loss 205.3402 59 32\n",
      "Training Accuracy 0.695\n",
      "Loss 192.85461 60 32\n",
      "Training Accuracy 0.685\n",
      "Loss 201.51695 61 32\n",
      "Training Accuracy 0.615\n",
      "Loss 173.51591 62 32\n",
      "Training Accuracy 0.72\n",
      "Loss 188.8985 63 32\n",
      "Training Accuracy 0.655\n",
      "Loss 198.18332 64 32\n",
      "Training Accuracy 0.685\n",
      "Loss 199.31854 65 32\n",
      "Training Accuracy 0.615\n",
      "Loss 178.06847 66 32\n",
      "Training Accuracy 0.67\n",
      "Loss 187.41945 67 32\n",
      "Training Accuracy 0.64\n",
      "Loss 197.02013 68 32\n",
      "Training Accuracy 0.65\n",
      "Loss 185.94876 69 32\n",
      "Training Accuracy 0.705\n",
      "Loss 206.85435 70 32\n",
      "Training Accuracy 0.665\n",
      "Loss 197.89865 71 32\n",
      "Training Accuracy 0.715\n",
      "Loss 198.60156 72 32\n",
      "Training Accuracy 0.64\n",
      "Loss 199.94437 73 32\n",
      "Training Accuracy 0.655\n",
      "Loss 196.58116 74 32\n",
      "Training Accuracy 0.69\n",
      "Loss 185.8312 75 32\n",
      "Training Accuracy 0.71\n",
      "Loss 171.13022 76 32\n",
      "Training Accuracy 0.745\n",
      "Loss 192.66841 77 32\n",
      "Training Accuracy 0.695\n",
      "Loss 181.48724 78 32\n",
      "Training Accuracy 0.705\n",
      "Loss 183.40025 79 32\n",
      "Training Accuracy 0.635\n",
      "Loss 196.88458 80 32\n",
      "Training Accuracy 0.69\n",
      "Loss 182.06352 81 32\n",
      "Training Accuracy 0.665\n",
      "Loss 180.97487 82 32\n",
      "Training Accuracy 0.695\n",
      "Loss 193.33197 83 32\n",
      "Training Accuracy 0.69\n",
      "Loss 202.07884 84 32\n",
      "Training Accuracy 0.695\n",
      "Loss 180.55093 85 32\n",
      "Training Accuracy 0.685\n",
      "Loss 196.70818 86 32\n",
      "Training Accuracy 0.715\n",
      "Loss 229.75758 87 32\n",
      "Training Accuracy 0.63\n",
      "Loss 219.04562 88 32\n",
      "Training Accuracy 0.645\n",
      "Loss 194.13957 89 32\n",
      "Training Accuracy 0.64\n",
      "Loss 206.37787 90 32\n",
      "Training Accuracy 0.655\n",
      "Loss 198.50449 91 32\n",
      "Training Accuracy 0.64\n",
      "Loss 204.72429 92 32\n",
      "Training Accuracy 0.69\n",
      "Loss 201.63512 93 32\n",
      "Training Accuracy 0.635\n",
      "Loss 199.97964 94 32\n",
      "Training Accuracy 0.65\n",
      "Loss 182.39453 95 32\n",
      "Training Accuracy 0.64\n",
      "Loss 196.21925 96 32\n",
      "Training Accuracy 0.62\n",
      "Loss 203.91106 97 32\n",
      "Training Accuracy 0.635\n",
      "Loss 171.39453 98 32\n",
      "Training Accuracy 0.72\n",
      "Loss 173.55438 99 32\n",
      "Training Accuracy 0.72\n",
      "Loss 187.87856 100 32\n",
      "Training Accuracy 0.72\n",
      "Loss 205.19392 101 32\n",
      "Training Accuracy 0.63\n",
      "Loss 188.47163 102 32\n",
      "Training Accuracy 0.675\n",
      "Loss 194.50027 103 32\n",
      "Training Accuracy 0.68\n",
      "Loss 203.72308 104 32\n",
      "Training Accuracy 0.67\n",
      "Loss 192.04628 105 32\n",
      "Training Accuracy 0.675\n",
      "Loss 180.05426 106 32\n",
      "Training Accuracy 0.725\n",
      "Loss 196.59584 107 32\n",
      "Training Accuracy 0.65\n",
      "Loss 199.9161 108 32\n",
      "Training Accuracy 0.615\n",
      "Loss 193.73244 109 32\n",
      "Training Accuracy 0.675\n",
      "Loss 201.21619 110 32\n",
      "Training Accuracy 0.665\n",
      "Loss 199.68866 111 32\n",
      "Training Accuracy 0.62\n",
      "Loss 201.36403 112 32\n",
      "Training Accuracy 0.695\n",
      "Loss 212.36035 113 32\n",
      "Training Accuracy 0.67\n",
      "Loss 198.1059 114 32\n",
      "Training Accuracy 0.655\n",
      "Loss 212.84647 115 32\n",
      "Training Accuracy 0.665\n",
      "Loss 214.87341 116 32\n",
      "Training Accuracy 0.635\n",
      "Loss 149.93785 117 32\n",
      "Training Accuracy 0.73\n",
      "Loss 192.58492 118 32\n",
      "Training Accuracy 0.69\n",
      "Loss 210.42195 119 32\n",
      "Training Accuracy 0.635\n",
      "Loss 200.77432 120 32\n",
      "Training Accuracy 0.665\n",
      "Loss 194.99483 121 32\n",
      "Training Accuracy 0.66\n",
      "Loss 193.77255 122 32\n",
      "Training Accuracy 0.64\n",
      "Loss 195.67793 123 32\n",
      "Training Accuracy 0.64\n",
      "Loss 189.94237 124 32\n",
      "Training Accuracy 0.66\n",
      "Loss 175.72083 125 32\n",
      "Training Accuracy 0.695\n",
      "Loss 211.3044 126 32\n",
      "Training Accuracy 0.635\n",
      "Loss 194.67519 127 32\n",
      "Training Accuracy 0.655\n",
      "Loss 184.93741 128 32\n",
      "Training Accuracy 0.705\n",
      "Loss 188.40947 129 32\n",
      "Training Accuracy 0.7\n",
      "Loss 171.18336 130 32\n",
      "Training Accuracy 0.675\n",
      "Loss 191.82338 131 32\n",
      "Training Accuracy 0.665\n",
      "Loss 181.37518 132 32\n",
      "Training Accuracy 0.665\n",
      "Loss 193.01007 133 32\n",
      "Training Accuracy 0.69\n",
      "Loss 178.54677 134 32\n",
      "Training Accuracy 0.685\n",
      "Loss 191.39667 135 32\n",
      "Training Accuracy 0.68\n",
      "Loss 192.67421 136 32\n",
      "Training Accuracy 0.69\n",
      "Loss 225.24506 137 32\n",
      "Training Accuracy 0.65\n",
      "Loss 175.66252 138 32\n",
      "Training Accuracy 0.68\n",
      "Loss 206.99934 139 32\n",
      "Training Accuracy 0.655\n",
      "Loss 182.4821 140 32\n",
      "Training Accuracy 0.71\n",
      "Loss 190.29141 141 32\n",
      "Training Accuracy 0.68\n",
      "Loss 198.26447 142 32\n",
      "Training Accuracy 0.64\n",
      "Loss 163.87299 143 32\n",
      "Training Accuracy 0.705\n",
      "Loss 199.5147 144 32\n",
      "Training Accuracy 0.665\n",
      "Loss 170.88953 145 32\n",
      "Training Accuracy 0.71\n",
      "Loss 203.61223 146 32\n",
      "Training Accuracy 0.66\n",
      "Loss 187.78384 147 32\n",
      "Training Accuracy 0.69\n",
      "Loss 190.28128 148 32\n",
      "Training Accuracy 0.675\n",
      "Loss 191.36278 149 32\n",
      "Training Accuracy 0.685\n",
      "Loss 183.72833 150 32\n",
      "Training Accuracy 0.715\n",
      "Loss 214.46393 151 32\n",
      "Training Accuracy 0.64\n",
      "Loss 204.53242 152 32\n",
      "Training Accuracy 0.66\n",
      "Loss 182.12892 153 32\n",
      "Training Accuracy 0.7\n",
      "Loss 202.4236 154 32\n",
      "Training Accuracy 0.6\n",
      "Loss 178.02437 155 32\n",
      "Training Accuracy 0.695\n",
      "Loss 196.91512 156 32\n",
      "Training Accuracy 0.67\n",
      "Loss 171.23495 157 32\n",
      "Training Accuracy 0.705\n",
      "Loss 174.3986 158 32\n",
      "Training Accuracy 0.71\n",
      "Loss 212.35226 159 32\n",
      "Training Accuracy 0.645\n",
      "Loss 192.71542 160 32\n",
      "Training Accuracy 0.66\n",
      "Loss 209.71408 161 32\n",
      "Training Accuracy 0.635\n",
      "Loss 180.34067 162 32\n",
      "Training Accuracy 0.67\n",
      "Loss 216.7967 163 32\n",
      "Training Accuracy 0.635\n",
      "Loss 179.06027 164 32\n",
      "Training Accuracy 0.665\n",
      "Loss 179.13507 165 32\n",
      "Training Accuracy 0.675\n",
      "Loss 196.7411 166 32\n",
      "Training Accuracy 0.69\n",
      "Loss 183.21365 167 32\n",
      "Training Accuracy 0.655\n",
      "Loss 207.78986 168 32\n",
      "Training Accuracy 0.625\n",
      "Loss 179.89113 169 32\n",
      "Training Accuracy 0.685\n",
      "Loss 197.55075 170 32\n",
      "Training Accuracy 0.645\n",
      "Loss 201.64224 171 32\n",
      "Training Accuracy 0.68\n",
      "Loss 176.02458 172 32\n",
      "Training Accuracy 0.685\n",
      "Loss 211.7232 173 32\n",
      "Training Accuracy 0.635\n",
      "Loss 162.25568 174 32\n",
      "Training Accuracy 0.695\n",
      "Loss 165.61266 175 32\n",
      "Training Accuracy 0.73\n",
      "Loss 151.86728 176 32\n",
      "Training Accuracy 0.73\n",
      "Loss 207.89227 177 32\n",
      "Training Accuracy 0.655\n",
      "Loss 178.53851 178 32\n",
      "Training Accuracy 0.715\n",
      "Loss 200.1348 179 32\n",
      "Training Accuracy 0.64\n",
      "Loss 208.97319 180 32\n",
      "Training Accuracy 0.64\n",
      "Loss 170.26834 181 32\n",
      "Training Accuracy 0.72\n",
      "Loss 195.65828 182 32\n",
      "Training Accuracy 0.675\n",
      "Loss 204.8296 183 32\n",
      "Training Accuracy 0.625\n",
      "Loss 167.53513 184 32\n",
      "Training Accuracy 0.74\n",
      "Loss 173.99847 185 32\n",
      "Training Accuracy 0.705\n",
      "Loss 173.3003 186 32\n",
      "Training Accuracy 0.72\n",
      "Loss 226.8584 187 32\n",
      "Training Accuracy 0.585\n",
      "Loss 199.60606 188 32\n",
      "Training Accuracy 0.65\n",
      "Loss 187.7204 189 32\n",
      "Training Accuracy 0.665\n",
      "Loss 176.72404 190 32\n",
      "Training Accuracy 0.695\n",
      "Loss 168.28455 191 32\n",
      "Training Accuracy 0.72\n",
      "Loss 203.36565 192 32\n",
      "Training Accuracy 0.635\n",
      "Loss 181.88542 193 32\n",
      "Training Accuracy 0.705\n",
      "Loss 172.9795 194 32\n",
      "Training Accuracy 0.71\n",
      "Loss 172.4482 195 32\n",
      "Training Accuracy 0.735\n",
      "Loss 179.53983 196 32\n",
      "Training Accuracy 0.69\n",
      "Loss 187.70285 197 32\n",
      "Training Accuracy 0.68\n",
      "Loss 175.78757 198 32\n",
      "Training Accuracy 0.665\n",
      "Loss 163.14264 199 32\n",
      "Training Accuracy 0.705\n",
      "Loss 179.46886 200 32\n",
      "Training Accuracy 0.68\n",
      "Loss 182.50421 201 32\n",
      "Training Accuracy 0.68\n",
      "Loss 180.18364 202 32\n",
      "Training Accuracy 0.68\n",
      "Loss 186.06853 203 32\n",
      "Training Accuracy 0.715\n",
      "Loss 175.45325 204 32\n",
      "Training Accuracy 0.7\n",
      "Loss 211.90543 205 32\n",
      "Training Accuracy 0.65\n",
      "Loss 189.59033 206 32\n",
      "Training Accuracy 0.675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 200.98227 207 32\n",
      "Training Accuracy 0.66\n",
      "Loss 198.81412 208 32\n",
      "Training Accuracy 0.635\n",
      "Loss 201.42502 209 32\n",
      "Training Accuracy 0.655\n",
      "Loss 176.88486 210 32\n",
      "Training Accuracy 0.675\n",
      "Loss 176.63074 211 32\n",
      "Training Accuracy 0.72\n",
      "Loss 179.92383 212 32\n",
      "Training Accuracy 0.695\n",
      "Loss 223.4987 213 32\n",
      "Training Accuracy 0.625\n",
      "Loss 191.13391 214 32\n",
      "Training Accuracy 0.67\n",
      "Loss 209.2048 215 32\n",
      "Training Accuracy 0.64\n",
      "Loss 196.81538 216 32\n",
      "Training Accuracy 0.66\n",
      "Loss 197.47122 217 32\n",
      "Training Accuracy 0.66\n",
      "Loss 207.55359 218 32\n",
      "Training Accuracy 0.675\n",
      "Loss 174.44829 219 32\n",
      "Training Accuracy 0.74\n",
      "Loss 192.12297 220 32\n",
      "Training Accuracy 0.655\n",
      "Loss 183.28456 221 32\n",
      "Training Accuracy 0.695\n",
      "Loss 180.11984 222 32\n",
      "Training Accuracy 0.665\n",
      "Loss 195.67299 223 32\n",
      "Training Accuracy 0.66\n",
      "Loss 214.35963 224 32\n",
      "Training Accuracy 0.645\n",
      "Loss 210.97174 225 32\n",
      "Training Accuracy 0.645\n",
      "Loss 161.00795 226 32\n",
      "Training Accuracy 0.715\n",
      "Loss 209.87823 227 32\n",
      "Training Accuracy 0.655\n",
      "Loss 216.1684 228 32\n",
      "Training Accuracy 0.64\n",
      "Loss 183.99208 229 32\n",
      "Training Accuracy 0.695\n",
      "Loss 203.25816 230 32\n",
      "Training Accuracy 0.67\n",
      "Loss 168.37125 231 32\n",
      "Training Accuracy 0.74\n",
      "Loss 189.85938 232 32\n",
      "Training Accuracy 0.65\n",
      "Loss 215.15782 233 32\n",
      "Training Accuracy 0.605\n",
      "Loss 195.52655 234 32\n",
      "Training Accuracy 0.61\n",
      "Loss 182.11394 235 32\n",
      "Training Accuracy 0.695\n",
      "Loss 172.40364 236 32\n",
      "Training Accuracy 0.72\n",
      "Loss 213.06203 237 32\n",
      "Training Accuracy 0.665\n",
      "Loss 180.47595 238 32\n",
      "Training Accuracy 0.675\n",
      "Loss 200.49501 239 32\n",
      "Training Accuracy 0.645\n",
      "Loss 192.0959 240 32\n",
      "Training Accuracy 0.645\n",
      "Loss 215.82637 241 32\n",
      "Training Accuracy 0.645\n",
      "Loss 185.68282 242 32\n",
      "Training Accuracy 0.66\n",
      "Loss 164.91661 243 32\n",
      "Training Accuracy 0.705\n",
      "Loss 184.72078 244 32\n",
      "Training Accuracy 0.685\n",
      "Loss 198.04552 245 32\n",
      "Training Accuracy 0.685\n",
      "Loss 210.1513 246 32\n",
      "Training Accuracy 0.645\n",
      "Loss 175.91893 247 32\n",
      "Training Accuracy 0.66\n",
      "Loss 171.0673 248 32\n",
      "Training Accuracy 0.76\n",
      "Loss 198.5635 249 32\n",
      "Training Accuracy 0.605\n",
      "Loss 208.1463 250 32\n",
      "Training Accuracy 0.63\n",
      "Loss 198.1455 251 32\n",
      "Training Accuracy 0.645\n",
      "Loss 168.46263 252 32\n",
      "Training Accuracy 0.73\n",
      "Loss 156.8917 253 32\n",
      "Training Accuracy 0.75\n",
      "Loss 184.8269 254 32\n",
      "Training Accuracy 0.69\n",
      "Loss 174.82816 255 32\n",
      "Training Accuracy 0.69\n",
      "Loss 208.1165 256 32\n",
      "Training Accuracy 0.645\n",
      "Loss 187.37347 257 32\n",
      "Training Accuracy 0.665\n",
      "Loss 200.7835 258 32\n",
      "Training Accuracy 0.65\n",
      "Loss 191.3046 259 32\n",
      "Training Accuracy 0.66\n",
      "Loss 164.49365 260 32\n",
      "Training Accuracy 0.725\n",
      "Loss 191.30838 261 32\n",
      "Training Accuracy 0.675\n",
      "Loss 193.77917 262 32\n",
      "Training Accuracy 0.67\n",
      "Loss 223.63379 263 32\n",
      "Training Accuracy 0.66\n",
      "Loss 203.22449 264 32\n",
      "Training Accuracy 0.67\n",
      "Loss 168.71222 265 32\n",
      "Training Accuracy 0.69\n",
      "Loss 185.24797 266 32\n",
      "Training Accuracy 0.655\n",
      "Loss 198.94058 267 32\n",
      "Training Accuracy 0.645\n",
      "Loss 204.35591 268 32\n",
      "Training Accuracy 0.695\n",
      "Loss 187.22383 269 32\n",
      "Training Accuracy 0.635\n",
      "Loss 171.28004 270 32\n",
      "Training Accuracy 0.655\n",
      "Loss 214.06708 271 32\n",
      "Training Accuracy 0.645\n",
      "Loss 184.3405 272 32\n",
      "Training Accuracy 0.67\n",
      "Loss 209.09918 273 32\n",
      "Training Accuracy 0.69\n",
      "Loss 191.01236 274 32\n",
      "Training Accuracy 0.69\n",
      "Loss 178.33727 275 32\n",
      "Training Accuracy 0.695\n",
      "Loss 178.28615 276 32\n",
      "Training Accuracy 0.685\n",
      "Loss 185.29805 277 32\n",
      "Training Accuracy 0.705\n",
      "Loss 171.47621 278 32\n",
      "Training Accuracy 0.675\n",
      "Loss 184.7114 279 32\n",
      "Training Accuracy 0.705\n",
      "Loss 172.30083 280 32\n",
      "Training Accuracy 0.69\n",
      "Loss 174.82117 281 32\n",
      "Training Accuracy 0.675\n",
      "Loss 183.67007 282 32\n",
      "Training Accuracy 0.71\n",
      "Loss 182.41211 283 32\n",
      "Training Accuracy 0.72\n",
      "Loss 152.84134 284 32\n",
      "Training Accuracy 0.77\n",
      "Loss 207.16377 285 32\n",
      "Training Accuracy 0.62\n",
      "Loss 188.92082 286 32\n",
      "Training Accuracy 0.71\n",
      "Loss 187.57823 287 32\n",
      "Training Accuracy 0.7\n",
      "Loss 198.35559 288 32\n",
      "Training Accuracy 0.675\n",
      "Loss 168.31285 289 32\n",
      "Training Accuracy 0.76\n",
      "Loss 201.305 290 32\n",
      "Training Accuracy 0.635\n",
      "Loss 205.81503 291 32\n",
      "Training Accuracy 0.675\n",
      "Loss 121.79315 292 32\n",
      "Training Accuracy 0.7121212\n",
      "Loss 146.24944 1 33\n",
      "Training Accuracy 0.765\n",
      "Loss 189.6718 2 33\n",
      "Training Accuracy 0.72\n",
      "Loss 169.9337 3 33\n",
      "Training Accuracy 0.73\n",
      "Loss 193.01727 4 33\n",
      "Training Accuracy 0.675\n",
      "Loss 162.24388 5 33\n",
      "Training Accuracy 0.73\n",
      "Loss 194.04944 6 33\n",
      "Training Accuracy 0.68\n",
      "Loss 189.77614 7 33\n",
      "Training Accuracy 0.68\n",
      "Loss 205.51929 8 33\n",
      "Training Accuracy 0.65\n",
      "Loss 181.0833 9 33\n",
      "Training Accuracy 0.695\n",
      "Loss 205.18425 10 33\n",
      "Training Accuracy 0.62\n",
      "Loss 211.6971 11 33\n",
      "Training Accuracy 0.66\n",
      "Loss 164.84433 12 33\n",
      "Training Accuracy 0.72\n",
      "Loss 174.5861 13 33\n",
      "Training Accuracy 0.73\n",
      "Loss 186.25468 14 33\n",
      "Training Accuracy 0.65\n",
      "Loss 179.62079 15 33\n",
      "Training Accuracy 0.67\n",
      "Loss 232.55592 16 33\n",
      "Training Accuracy 0.615\n",
      "Loss 173.40654 17 33\n",
      "Training Accuracy 0.705\n",
      "Loss 163.6315 18 33\n",
      "Training Accuracy 0.72\n",
      "Loss 173.81866 19 33\n",
      "Training Accuracy 0.685\n",
      "Loss 183.62189 20 33\n",
      "Training Accuracy 0.68\n",
      "Loss 193.41335 21 33\n",
      "Training Accuracy 0.65\n",
      "Loss 191.77505 22 33\n",
      "Training Accuracy 0.695\n",
      "Loss 192.6249 23 33\n",
      "Training Accuracy 0.675\n",
      "Loss 214.51863 24 33\n",
      "Training Accuracy 0.625\n",
      "Loss 181.07584 25 33\n",
      "Training Accuracy 0.7\n",
      "Loss 189.11201 26 33\n",
      "Training Accuracy 0.665\n",
      "Loss 168.52061 27 33\n",
      "Training Accuracy 0.72\n",
      "Loss 177.7605 28 33\n",
      "Training Accuracy 0.675\n",
      "Loss 193.27696 29 33\n",
      "Training Accuracy 0.635\n",
      "Loss 193.86668 30 33\n",
      "Training Accuracy 0.655\n",
      "Loss 195.51453 31 33\n",
      "Training Accuracy 0.675\n",
      "Loss 191.10063 32 33\n",
      "Training Accuracy 0.695\n",
      "Loss 192.85748 33 33\n",
      "Training Accuracy 0.69\n",
      "Loss 168.50429 34 33\n",
      "Training Accuracy 0.71\n",
      "Loss 176.65671 35 33\n",
      "Training Accuracy 0.685\n",
      "Loss 199.05609 36 33\n",
      "Training Accuracy 0.645\n",
      "Loss 174.39084 37 33\n",
      "Training Accuracy 0.68\n",
      "Loss 192.27963 38 33\n",
      "Training Accuracy 0.65\n",
      "Loss 153.84091 39 33\n",
      "Training Accuracy 0.755\n",
      "Loss 184.36777 40 33\n",
      "Training Accuracy 0.68\n",
      "Loss 198.35954 41 33\n",
      "Training Accuracy 0.655\n",
      "Loss 212.54083 42 33\n",
      "Training Accuracy 0.63\n",
      "Loss 180.2399 43 33\n",
      "Training Accuracy 0.67\n",
      "Loss 188.73862 44 33\n",
      "Training Accuracy 0.66\n",
      "Loss 184.02109 45 33\n",
      "Training Accuracy 0.695\n",
      "Loss 222.38268 46 33\n",
      "Training Accuracy 0.61\n",
      "Loss 180.66212 47 33\n",
      "Training Accuracy 0.66\n",
      "Loss 162.40314 48 33\n",
      "Training Accuracy 0.705\n",
      "Loss 195.85 49 33\n",
      "Training Accuracy 0.68\n",
      "Loss 209.55336 50 33\n",
      "Training Accuracy 0.67\n",
      "Loss 164.80397 51 33\n",
      "Training Accuracy 0.74\n",
      "Loss 168.71841 52 33\n",
      "Training Accuracy 0.7\n",
      "Loss 153.8385 53 33\n",
      "Training Accuracy 0.7\n",
      "Loss 212.04474 54 33\n",
      "Training Accuracy 0.665\n",
      "Loss 202.46164 55 33\n",
      "Training Accuracy 0.65\n",
      "Loss 190.22598 56 33\n",
      "Training Accuracy 0.66\n",
      "Loss 182.56062 57 33\n",
      "Training Accuracy 0.695\n",
      "Loss 182.26367 58 33\n",
      "Training Accuracy 0.65\n",
      "Loss 192.2128 59 33\n",
      "Training Accuracy 0.665\n",
      "Loss 183.78073 60 33\n",
      "Training Accuracy 0.725\n",
      "Loss 190.49261 61 33\n",
      "Training Accuracy 0.67\n",
      "Loss 176.35435 62 33\n",
      "Training Accuracy 0.685\n",
      "Loss 180.16588 63 33\n",
      "Training Accuracy 0.695\n",
      "Loss 195.44614 64 33\n",
      "Training Accuracy 0.68\n",
      "Loss 193.8375 65 33\n",
      "Training Accuracy 0.625\n",
      "Loss 175.72176 66 33\n",
      "Training Accuracy 0.705\n",
      "Loss 186.38579 67 33\n",
      "Training Accuracy 0.68\n",
      "Loss 184.39613 68 33\n",
      "Training Accuracy 0.63\n",
      "Loss 182.76309 69 33\n",
      "Training Accuracy 0.73\n",
      "Loss 184.31197 70 33\n",
      "Training Accuracy 0.725\n",
      "Loss 180.25224 71 33\n",
      "Training Accuracy 0.705\n",
      "Loss 192.84145 72 33\n",
      "Training Accuracy 0.69\n",
      "Loss 197.10529 73 33\n",
      "Training Accuracy 0.635\n",
      "Loss 196.2845 74 33\n",
      "Training Accuracy 0.665\n",
      "Loss 191.92493 75 33\n",
      "Training Accuracy 0.62\n",
      "Loss 161.14642 76 33\n",
      "Training Accuracy 0.735\n",
      "Loss 203.82541 77 33\n",
      "Training Accuracy 0.665\n",
      "Loss 193.46486 78 33\n",
      "Training Accuracy 0.71\n",
      "Loss 189.03644 79 33\n",
      "Training Accuracy 0.665\n",
      "Loss 196.10806 80 33\n",
      "Training Accuracy 0.695\n",
      "Loss 183.94884 81 33\n",
      "Training Accuracy 0.655\n",
      "Loss 179.02515 82 33\n",
      "Training Accuracy 0.68\n",
      "Loss 180.93663 83 33\n",
      "Training Accuracy 0.74\n",
      "Loss 209.38431 84 33\n",
      "Training Accuracy 0.675\n",
      "Loss 187.9307 85 33\n",
      "Training Accuracy 0.695\n",
      "Loss 187.71178 86 33\n",
      "Training Accuracy 0.705\n",
      "Loss 233.70187 87 33\n",
      "Training Accuracy 0.61\n",
      "Loss 227.45058 88 33\n",
      "Training Accuracy 0.655\n",
      "Loss 190.32295 89 33\n",
      "Training Accuracy 0.675\n",
      "Loss 198.89307 90 33\n",
      "Training Accuracy 0.68\n",
      "Loss 188.8135 91 33\n",
      "Training Accuracy 0.67\n",
      "Loss 198.14928 92 33\n",
      "Training Accuracy 0.66\n",
      "Loss 189.6649 93 33\n",
      "Training Accuracy 0.685\n",
      "Loss 192.18065 94 33\n",
      "Training Accuracy 0.68\n",
      "Loss 187.95975 95 33\n",
      "Training Accuracy 0.635\n",
      "Loss 196.68974 96 33\n",
      "Training Accuracy 0.66\n",
      "Loss 189.97748 97 33\n",
      "Training Accuracy 0.645\n",
      "Loss 171.36777 98 33\n",
      "Training Accuracy 0.725\n",
      "Loss 175.6068 99 33\n",
      "Training Accuracy 0.71\n",
      "Loss 174.1014 100 33\n",
      "Training Accuracy 0.71\n",
      "Loss 201.70596 101 33\n",
      "Training Accuracy 0.65\n",
      "Loss 183.09274 102 33\n",
      "Training Accuracy 0.655\n",
      "Loss 193.16187 103 33\n",
      "Training Accuracy 0.685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 183.09447 104 33\n",
      "Training Accuracy 0.695\n",
      "Loss 181.84856 105 33\n",
      "Training Accuracy 0.69\n",
      "Loss 186.49826 106 33\n",
      "Training Accuracy 0.665\n",
      "Loss 177.1048 107 33\n",
      "Training Accuracy 0.67\n",
      "Loss 192.5851 108 33\n",
      "Training Accuracy 0.66\n",
      "Loss 193.27272 109 33\n",
      "Training Accuracy 0.65\n",
      "Loss 185.34534 110 33\n",
      "Training Accuracy 0.69\n",
      "Loss 199.17245 111 33\n",
      "Training Accuracy 0.66\n",
      "Loss 203.43344 112 33\n",
      "Training Accuracy 0.665\n",
      "Loss 228.4129 113 33\n",
      "Training Accuracy 0.63\n",
      "Loss 190.61879 114 33\n",
      "Training Accuracy 0.645\n",
      "Loss 208.60657 115 33\n",
      "Training Accuracy 0.67\n",
      "Loss 219.18652 116 33\n",
      "Training Accuracy 0.685\n",
      "Loss 152.47876 117 33\n",
      "Training Accuracy 0.77\n",
      "Loss 188.9607 118 33\n",
      "Training Accuracy 0.675\n",
      "Loss 212.46439 119 33\n",
      "Training Accuracy 0.625\n",
      "Loss 204.85896 120 33\n",
      "Training Accuracy 0.645\n",
      "Loss 203.18336 121 33\n",
      "Training Accuracy 0.645\n",
      "Loss 184.5696 122 33\n",
      "Training Accuracy 0.71\n",
      "Loss 186.39929 123 33\n",
      "Training Accuracy 0.665\n",
      "Loss 189.26894 124 33\n",
      "Training Accuracy 0.68\n",
      "Loss 164.80247 125 33\n",
      "Training Accuracy 0.695\n",
      "Loss 214.65903 126 33\n",
      "Training Accuracy 0.635\n",
      "Loss 197.2369 127 33\n",
      "Training Accuracy 0.65\n",
      "Loss 185.76404 128 33\n",
      "Training Accuracy 0.68\n",
      "Loss 176.60345 129 33\n",
      "Training Accuracy 0.745\n",
      "Loss 181.4586 130 33\n",
      "Training Accuracy 0.655\n",
      "Loss 169.78345 131 33\n",
      "Training Accuracy 0.715\n",
      "Loss 184.15596 132 33\n",
      "Training Accuracy 0.69\n",
      "Loss 172.99261 133 33\n",
      "Training Accuracy 0.735\n",
      "Loss 176.31755 134 33\n",
      "Training Accuracy 0.695\n",
      "Loss 181.54349 135 33\n",
      "Training Accuracy 0.665\n",
      "Loss 183.396 136 33\n",
      "Training Accuracy 0.72\n",
      "Loss 204.00346 137 33\n",
      "Training Accuracy 0.675\n",
      "Loss 188.50821 138 33\n",
      "Training Accuracy 0.7\n",
      "Loss 196.50865 139 33\n",
      "Training Accuracy 0.675\n",
      "Loss 165.07863 140 33\n",
      "Training Accuracy 0.705\n",
      "Loss 187.40343 141 33\n",
      "Training Accuracy 0.7\n",
      "Loss 190.90323 142 33\n",
      "Training Accuracy 0.645\n",
      "Loss 171.35059 143 33\n",
      "Training Accuracy 0.685\n",
      "Loss 203.03574 144 33\n",
      "Training Accuracy 0.685\n",
      "Loss 182.40338 145 33\n",
      "Training Accuracy 0.685\n",
      "Loss 214.02374 146 33\n",
      "Training Accuracy 0.65\n",
      "Loss 184.38109 147 33\n",
      "Training Accuracy 0.695\n",
      "Loss 192.20828 148 33\n",
      "Training Accuracy 0.64\n",
      "Loss 186.79465 149 33\n",
      "Training Accuracy 0.705\n",
      "Loss 174.37488 150 33\n",
      "Training Accuracy 0.7\n",
      "Loss 198.40826 151 33\n",
      "Training Accuracy 0.67\n",
      "Loss 206.88829 152 33\n",
      "Training Accuracy 0.645\n",
      "Loss 171.14584 153 33\n",
      "Training Accuracy 0.715\n",
      "Loss 182.69048 154 33\n",
      "Training Accuracy 0.705\n",
      "Loss 166.37059 155 33\n",
      "Training Accuracy 0.69\n",
      "Loss 186.47867 156 33\n",
      "Training Accuracy 0.67\n",
      "Loss 165.58614 157 33\n",
      "Training Accuracy 0.685\n",
      "Loss 182.0566 158 33\n",
      "Training Accuracy 0.705\n",
      "Loss 209.30168 159 33\n",
      "Training Accuracy 0.66\n",
      "Loss 186.15056 160 33\n",
      "Training Accuracy 0.65\n",
      "Loss 202.28506 161 33\n",
      "Training Accuracy 0.63\n",
      "Loss 194.47594 162 33\n",
      "Training Accuracy 0.645\n",
      "Loss 221.37976 163 33\n",
      "Training Accuracy 0.62\n",
      "Loss 174.69714 164 33\n",
      "Training Accuracy 0.67\n",
      "Loss 187.50215 165 33\n",
      "Training Accuracy 0.685\n",
      "Loss 183.1104 166 33\n",
      "Training Accuracy 0.715\n",
      "Loss 173.5464 167 33\n",
      "Training Accuracy 0.705\n",
      "Loss 204.48877 168 33\n",
      "Training Accuracy 0.67\n",
      "Loss 163.26378 169 33\n",
      "Training Accuracy 0.755\n",
      "Loss 193.90541 170 33\n",
      "Training Accuracy 0.63\n",
      "Loss 193.00972 171 33\n",
      "Training Accuracy 0.7\n",
      "Loss 162.87439 172 33\n",
      "Training Accuracy 0.735\n",
      "Loss 200.70557 173 33\n",
      "Training Accuracy 0.69\n",
      "Loss 160.50743 174 33\n",
      "Training Accuracy 0.74\n",
      "Loss 161.11705 175 33\n",
      "Training Accuracy 0.73\n",
      "Loss 151.59088 176 33\n",
      "Training Accuracy 0.725\n",
      "Loss 202.04631 177 33\n",
      "Training Accuracy 0.67\n",
      "Loss 180.38007 178 33\n",
      "Training Accuracy 0.7\n",
      "Loss 203.40172 179 33\n",
      "Training Accuracy 0.64\n",
      "Loss 201.0966 180 33\n",
      "Training Accuracy 0.645\n",
      "Loss 172.4383 181 33\n",
      "Training Accuracy 0.72\n",
      "Loss 197.70047 182 33\n",
      "Training Accuracy 0.62\n",
      "Loss 207.4195 183 33\n",
      "Training Accuracy 0.655\n",
      "Loss 167.93839 184 33\n",
      "Training Accuracy 0.74\n",
      "Loss 182.15485 185 33\n",
      "Training Accuracy 0.735\n",
      "Loss 170.27634 186 33\n",
      "Training Accuracy 0.725\n",
      "Loss 220.57677 187 33\n",
      "Training Accuracy 0.61\n",
      "Loss 190.83405 188 33\n",
      "Training Accuracy 0.715\n",
      "Loss 183.15529 189 33\n",
      "Training Accuracy 0.695\n",
      "Loss 181.79578 190 33\n",
      "Training Accuracy 0.695\n",
      "Loss 170.36163 191 33\n",
      "Training Accuracy 0.71\n",
      "Loss 208.00786 192 33\n",
      "Training Accuracy 0.64\n",
      "Loss 170.30516 193 33\n",
      "Training Accuracy 0.715\n",
      "Loss 172.32523 194 33\n",
      "Training Accuracy 0.71\n",
      "Loss 166.1857 195 33\n",
      "Training Accuracy 0.715\n",
      "Loss 178.25636 196 33\n",
      "Training Accuracy 0.69\n",
      "Loss 187.84206 197 33\n",
      "Training Accuracy 0.65\n",
      "Loss 186.96663 198 33\n",
      "Training Accuracy 0.66\n",
      "Loss 153.73419 199 33\n",
      "Training Accuracy 0.77\n",
      "Loss 173.84076 200 33\n",
      "Training Accuracy 0.725\n",
      "Loss 178.55106 201 33\n",
      "Training Accuracy 0.685\n",
      "Loss 176.23691 202 33\n",
      "Training Accuracy 0.68\n",
      "Loss 193.06146 203 33\n",
      "Training Accuracy 0.685\n",
      "Loss 178.04326 204 33\n",
      "Training Accuracy 0.685\n",
      "Loss 208.44823 205 33\n",
      "Training Accuracy 0.65\n",
      "Loss 195.96446 206 33\n",
      "Training Accuracy 0.665\n",
      "Loss 199.9729 207 33\n",
      "Training Accuracy 0.63\n",
      "Loss 195.4226 208 33\n",
      "Training Accuracy 0.65\n",
      "Loss 206.19482 209 33\n",
      "Training Accuracy 0.67\n",
      "Loss 173.77322 210 33\n",
      "Training Accuracy 0.695\n",
      "Loss 165.04657 211 33\n",
      "Training Accuracy 0.74\n",
      "Loss 182.9922 212 33\n",
      "Training Accuracy 0.685\n",
      "Loss 219.98492 213 33\n",
      "Training Accuracy 0.635\n",
      "Loss 171.8707 214 33\n",
      "Training Accuracy 0.72\n",
      "Loss 203.6746 215 33\n",
      "Training Accuracy 0.67\n",
      "Loss 188.57768 216 33\n",
      "Training Accuracy 0.665\n",
      "Loss 206.14392 217 33\n",
      "Training Accuracy 0.645\n",
      "Loss 188.132 218 33\n",
      "Training Accuracy 0.685\n",
      "Loss 177.69197 219 33\n",
      "Training Accuracy 0.73\n",
      "Loss 193.81454 220 33\n",
      "Training Accuracy 0.68\n",
      "Loss 188.63719 221 33\n",
      "Training Accuracy 0.655\n",
      "Loss 180.70363 222 33\n",
      "Training Accuracy 0.65\n",
      "Loss 205.748 223 33\n",
      "Training Accuracy 0.68\n",
      "Loss 206.93948 224 33\n",
      "Training Accuracy 0.645\n",
      "Loss 190.38338 225 33\n",
      "Training Accuracy 0.7\n",
      "Loss 153.78299 226 33\n",
      "Training Accuracy 0.73\n",
      "Loss 209.22562 227 33\n",
      "Training Accuracy 0.645\n",
      "Loss 214.10716 228 33\n",
      "Training Accuracy 0.67\n",
      "Loss 185.59288 229 33\n",
      "Training Accuracy 0.665\n",
      "Loss 192.77489 230 33\n",
      "Training Accuracy 0.675\n",
      "Loss 176.90814 231 33\n",
      "Training Accuracy 0.715\n",
      "Loss 197.23592 232 33\n",
      "Training Accuracy 0.665\n",
      "Loss 227.26974 233 33\n",
      "Training Accuracy 0.565\n",
      "Loss 202.26677 234 33\n",
      "Training Accuracy 0.61\n",
      "Loss 198.29567 235 33\n",
      "Training Accuracy 0.66\n",
      "Loss 167.49786 236 33\n",
      "Training Accuracy 0.71\n",
      "Loss 188.21983 237 33\n",
      "Training Accuracy 0.67\n",
      "Loss 170.29686 238 33\n",
      "Training Accuracy 0.685\n",
      "Loss 203.05956 239 33\n",
      "Training Accuracy 0.665\n",
      "Loss 178.28302 240 33\n",
      "Training Accuracy 0.665\n",
      "Loss 209.43427 241 33\n",
      "Training Accuracy 0.63\n",
      "Loss 184.78049 242 33\n",
      "Training Accuracy 0.675\n",
      "Loss 166.28107 243 33\n",
      "Training Accuracy 0.725\n",
      "Loss 191.1912 244 33\n",
      "Training Accuracy 0.625\n",
      "Loss 188.31969 245 33\n",
      "Training Accuracy 0.685\n",
      "Loss 210.68544 246 33\n",
      "Training Accuracy 0.64\n",
      "Loss 179.88992 247 33\n",
      "Training Accuracy 0.65\n",
      "Loss 167.07338 248 33\n",
      "Training Accuracy 0.75\n",
      "Loss 197.37361 249 33\n",
      "Training Accuracy 0.605\n",
      "Loss 199.18774 250 33\n",
      "Training Accuracy 0.665\n",
      "Loss 194.7555 251 33\n",
      "Training Accuracy 0.62\n",
      "Loss 163.51782 252 33\n",
      "Training Accuracy 0.72\n",
      "Loss 159.80621 253 33\n",
      "Training Accuracy 0.71\n",
      "Loss 192.3172 254 33\n",
      "Training Accuracy 0.685\n",
      "Loss 169.61067 255 33\n",
      "Training Accuracy 0.705\n",
      "Loss 208.07265 256 33\n",
      "Training Accuracy 0.645\n",
      "Loss 171.4792 257 33\n",
      "Training Accuracy 0.695\n",
      "Loss 197.96648 258 33\n",
      "Training Accuracy 0.66\n",
      "Loss 182.01785 259 33\n",
      "Training Accuracy 0.67\n",
      "Loss 155.88689 260 33\n",
      "Training Accuracy 0.72\n",
      "Loss 195.69339 261 33\n",
      "Training Accuracy 0.675\n",
      "Loss 186.4864 262 33\n",
      "Training Accuracy 0.64\n",
      "Loss 226.9494 263 33\n",
      "Training Accuracy 0.635\n",
      "Loss 205.16632 264 33\n",
      "Training Accuracy 0.65\n",
      "Loss 163.16675 265 33\n",
      "Training Accuracy 0.7\n",
      "Loss 183.3627 266 33\n",
      "Training Accuracy 0.62\n",
      "Loss 193.68834 267 33\n",
      "Training Accuracy 0.645\n",
      "Loss 197.59558 268 33\n",
      "Training Accuracy 0.655\n",
      "Loss 189.0283 269 33\n",
      "Training Accuracy 0.67\n",
      "Loss 167.6492 270 33\n",
      "Training Accuracy 0.7\n",
      "Loss 203.03122 271 33\n",
      "Training Accuracy 0.645\n",
      "Loss 188.48062 272 33\n",
      "Training Accuracy 0.715\n",
      "Loss 202.5252 273 33\n",
      "Training Accuracy 0.665\n",
      "Loss 175.11 274 33\n",
      "Training Accuracy 0.68\n",
      "Loss 188.91635 275 33\n",
      "Training Accuracy 0.665\n",
      "Loss 184.7948 276 33\n",
      "Training Accuracy 0.66\n",
      "Loss 193.97577 277 33\n",
      "Training Accuracy 0.695\n",
      "Loss 179.3852 278 33\n",
      "Training Accuracy 0.65\n",
      "Loss 185.23314 279 33\n",
      "Training Accuracy 0.69\n",
      "Loss 186.29124 280 33\n",
      "Training Accuracy 0.675\n",
      "Loss 169.48935 281 33\n",
      "Training Accuracy 0.71\n",
      "Loss 176.70195 282 33\n",
      "Training Accuracy 0.68\n",
      "Loss 179.23145 283 33\n",
      "Training Accuracy 0.7\n",
      "Loss 163.29053 284 33\n",
      "Training Accuracy 0.72\n",
      "Loss 204.81308 285 33\n",
      "Training Accuracy 0.68\n",
      "Loss 177.70361 286 33\n",
      "Training Accuracy 0.735\n",
      "Loss 171.01901 287 33\n",
      "Training Accuracy 0.695\n",
      "Loss 200.70595 288 33\n",
      "Training Accuracy 0.68\n",
      "Loss 173.11287 289 33\n",
      "Training Accuracy 0.73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 190.28271 290 33\n",
      "Training Accuracy 0.66\n",
      "Loss 199.83266 291 33\n",
      "Training Accuracy 0.655\n",
      "Loss 126.93266 292 33\n",
      "Training Accuracy 0.68939394\n",
      "Loss 141.80199 1 34\n",
      "Training Accuracy 0.755\n",
      "Loss 190.17131 2 34\n",
      "Training Accuracy 0.645\n",
      "Loss 172.42628 3 34\n",
      "Training Accuracy 0.71\n",
      "Loss 196.23186 4 34\n",
      "Training Accuracy 0.675\n",
      "Loss 166.50607 5 34\n",
      "Training Accuracy 0.71\n",
      "Loss 203.49817 6 34\n",
      "Training Accuracy 0.665\n",
      "Loss 186.66286 7 34\n",
      "Training Accuracy 0.675\n",
      "Loss 193.28949 8 34\n",
      "Training Accuracy 0.685\n",
      "Loss 175.4236 9 34\n",
      "Training Accuracy 0.705\n",
      "Loss 205.8294 10 34\n",
      "Training Accuracy 0.625\n",
      "Loss 208.93109 11 34\n",
      "Training Accuracy 0.68\n",
      "Loss 156.45811 12 34\n",
      "Training Accuracy 0.715\n",
      "Loss 170.94601 13 34\n",
      "Training Accuracy 0.72\n",
      "Loss 192.57983 14 34\n",
      "Training Accuracy 0.665\n",
      "Loss 164.86417 15 34\n",
      "Training Accuracy 0.72\n",
      "Loss 216.64418 16 34\n",
      "Training Accuracy 0.665\n",
      "Loss 165.87395 17 34\n",
      "Training Accuracy 0.715\n",
      "Loss 169.15619 18 34\n",
      "Training Accuracy 0.715\n",
      "Loss 176.40887 19 34\n",
      "Training Accuracy 0.675\n",
      "Loss 169.4498 20 34\n",
      "Training Accuracy 0.705\n",
      "Loss 188.18054 21 34\n",
      "Training Accuracy 0.65\n",
      "Loss 188.60577 22 34\n",
      "Training Accuracy 0.67\n",
      "Loss 193.04962 23 34\n",
      "Training Accuracy 0.71\n",
      "Loss 207.02211 24 34\n",
      "Training Accuracy 0.645\n",
      "Loss 177.72923 25 34\n",
      "Training Accuracy 0.725\n",
      "Loss 199.13637 26 34\n",
      "Training Accuracy 0.635\n",
      "Loss 190.21135 27 34\n",
      "Training Accuracy 0.665\n",
      "Loss 170.30638 28 34\n",
      "Training Accuracy 0.695\n",
      "Loss 189.97415 29 34\n",
      "Training Accuracy 0.64\n",
      "Loss 200.22484 30 34\n",
      "Training Accuracy 0.69\n",
      "Loss 180.06625 31 34\n",
      "Training Accuracy 0.695\n",
      "Loss 189.22916 32 34\n",
      "Training Accuracy 0.67\n",
      "Loss 182.23526 33 34\n",
      "Training Accuracy 0.71\n",
      "Loss 173.42593 34 34\n",
      "Training Accuracy 0.665\n",
      "Loss 173.83206 35 34\n",
      "Training Accuracy 0.64\n",
      "Loss 196.86711 36 34\n",
      "Training Accuracy 0.655\n",
      "Loss 176.28966 37 34\n",
      "Training Accuracy 0.7\n",
      "Loss 181.8174 38 34\n",
      "Training Accuracy 0.7\n",
      "Loss 159.67442 39 34\n",
      "Training Accuracy 0.74\n",
      "Loss 167.2201 40 34\n",
      "Training Accuracy 0.7\n",
      "Loss 186.71834 41 34\n",
      "Training Accuracy 0.675\n",
      "Loss 216.2884 42 34\n",
      "Training Accuracy 0.62\n",
      "Loss 184.97383 43 34\n",
      "Training Accuracy 0.66\n",
      "Loss 193.96939 44 34\n",
      "Training Accuracy 0.665\n",
      "Loss 197.39876 45 34\n",
      "Training Accuracy 0.665\n",
      "Loss 217.37193 46 34\n",
      "Training Accuracy 0.605\n",
      "Loss 170.15009 47 34\n",
      "Training Accuracy 0.735\n",
      "Loss 154.51967 48 34\n",
      "Training Accuracy 0.725\n",
      "Loss 183.98735 49 34\n",
      "Training Accuracy 0.68\n",
      "Loss 207.40874 50 34\n",
      "Training Accuracy 0.695\n",
      "Loss 164.11858 51 34\n",
      "Training Accuracy 0.715\n",
      "Loss 183.26398 52 34\n",
      "Training Accuracy 0.725\n",
      "Loss 150.36203 53 34\n",
      "Training Accuracy 0.705\n",
      "Loss 207.96439 54 34\n",
      "Training Accuracy 0.675\n",
      "Loss 194.54114 55 34\n",
      "Training Accuracy 0.64\n",
      "Loss 180.81662 56 34\n",
      "Training Accuracy 0.715\n",
      "Loss 189.45535 57 34\n",
      "Training Accuracy 0.67\n",
      "Loss 177.9999 58 34\n",
      "Training Accuracy 0.68\n",
      "Loss 197.3686 59 34\n",
      "Training Accuracy 0.67\n",
      "Loss 181.96602 60 34\n",
      "Training Accuracy 0.71\n",
      "Loss 199.58203 61 34\n",
      "Training Accuracy 0.64\n",
      "Loss 164.6201 62 34\n",
      "Training Accuracy 0.715\n",
      "Loss 188.08435 63 34\n",
      "Training Accuracy 0.685\n",
      "Loss 192.0491 64 34\n",
      "Training Accuracy 0.655\n",
      "Loss 191.61601 65 34\n",
      "Training Accuracy 0.635\n",
      "Loss 173.99637 66 34\n",
      "Training Accuracy 0.715\n",
      "Loss 190.86203 67 34\n",
      "Training Accuracy 0.655\n",
      "Loss 189.33528 68 34\n",
      "Training Accuracy 0.655\n",
      "Loss 175.0941 69 34\n",
      "Training Accuracy 0.695\n",
      "Loss 175.56798 70 34\n",
      "Training Accuracy 0.735\n",
      "Loss 179.33542 71 34\n",
      "Training Accuracy 0.725\n",
      "Loss 183.32007 72 34\n",
      "Training Accuracy 0.69\n",
      "Loss 198.41179 73 34\n",
      "Training Accuracy 0.65\n",
      "Loss 187.4564 74 34\n",
      "Training Accuracy 0.695\n",
      "Loss 191.35555 75 34\n",
      "Training Accuracy 0.685\n",
      "Loss 166.52527 76 34\n",
      "Training Accuracy 0.72\n",
      "Loss 196.80276 77 34\n",
      "Training Accuracy 0.695\n",
      "Loss 174.62363 78 34\n",
      "Training Accuracy 0.735\n",
      "Loss 193.55463 79 34\n",
      "Training Accuracy 0.62\n",
      "Loss 201.41089 80 34\n",
      "Training Accuracy 0.665\n",
      "Loss 179.01201 81 34\n",
      "Training Accuracy 0.72\n",
      "Loss 171.56319 82 34\n",
      "Training Accuracy 0.715\n",
      "Loss 179.5382 83 34\n",
      "Training Accuracy 0.695\n",
      "Loss 201.80052 84 34\n",
      "Training Accuracy 0.645\n",
      "Loss 184.67477 85 34\n",
      "Training Accuracy 0.68\n",
      "Loss 189.41637 86 34\n",
      "Training Accuracy 0.665\n",
      "Loss 233.947 87 34\n",
      "Training Accuracy 0.63\n",
      "Loss 211.37416 88 34\n",
      "Training Accuracy 0.665\n",
      "Loss 190.95952 89 34\n",
      "Training Accuracy 0.655\n",
      "Loss 190.69452 90 34\n",
      "Training Accuracy 0.665\n",
      "Loss 188.35966 91 34\n",
      "Training Accuracy 0.66\n",
      "Loss 193.1317 92 34\n",
      "Training Accuracy 0.69\n",
      "Loss 196.06062 93 34\n",
      "Training Accuracy 0.655\n",
      "Loss 193.75732 94 34\n",
      "Training Accuracy 0.655\n",
      "Loss 170.89873 95 34\n",
      "Training Accuracy 0.705\n",
      "Loss 191.77145 96 34\n",
      "Training Accuracy 0.68\n",
      "Loss 191.44177 97 34\n",
      "Training Accuracy 0.64\n",
      "Loss 161.52274 98 34\n",
      "Training Accuracy 0.73\n",
      "Loss 187.3821 99 34\n",
      "Training Accuracy 0.68\n",
      "Loss 174.98196 100 34\n",
      "Training Accuracy 0.735\n",
      "Loss 199.53673 101 34\n",
      "Training Accuracy 0.65\n",
      "Loss 170.40175 102 34\n",
      "Training Accuracy 0.695\n",
      "Loss 176.55518 103 34\n",
      "Training Accuracy 0.705\n",
      "Loss 177.76784 104 34\n",
      "Training Accuracy 0.76\n",
      "Loss 190.93016 105 34\n",
      "Training Accuracy 0.675\n",
      "Loss 177.40578 106 34\n",
      "Training Accuracy 0.705\n",
      "Loss 181.54083 107 34\n",
      "Training Accuracy 0.695\n",
      "Loss 187.6237 108 34\n",
      "Training Accuracy 0.65\n",
      "Loss 187.8382 109 34\n",
      "Training Accuracy 0.67\n",
      "Loss 194.58066 110 34\n",
      "Training Accuracy 0.7\n",
      "Loss 181.79727 111 34\n",
      "Training Accuracy 0.68\n",
      "Loss 195.46587 112 34\n",
      "Training Accuracy 0.675\n",
      "Loss 216.10294 113 34\n",
      "Training Accuracy 0.665\n",
      "Loss 193.34067 114 34\n",
      "Training Accuracy 0.635\n",
      "Loss 213.49182 115 34\n",
      "Training Accuracy 0.65\n",
      "Loss 206.71277 116 34\n",
      "Training Accuracy 0.675\n",
      "Loss 153.3111 117 34\n",
      "Training Accuracy 0.76\n",
      "Loss 189.85626 118 34\n",
      "Training Accuracy 0.68\n",
      "Loss 215.07162 119 34\n",
      "Training Accuracy 0.64\n",
      "Loss 206.93863 120 34\n",
      "Training Accuracy 0.64\n",
      "Loss 187.17934 121 34\n",
      "Training Accuracy 0.69\n",
      "Loss 185.83707 122 34\n",
      "Training Accuracy 0.715\n",
      "Loss 192.84288 123 34\n",
      "Training Accuracy 0.68\n",
      "Loss 173.58876 124 34\n",
      "Training Accuracy 0.695\n",
      "Loss 162.40573 125 34\n",
      "Training Accuracy 0.725\n",
      "Loss 211.5357 126 34\n",
      "Training Accuracy 0.64\n",
      "Loss 189.66635 127 34\n",
      "Training Accuracy 0.65\n",
      "Loss 181.90497 128 34\n",
      "Training Accuracy 0.72\n",
      "Loss 176.53075 129 34\n",
      "Training Accuracy 0.705\n",
      "Loss 179.16173 130 34\n",
      "Training Accuracy 0.64\n",
      "Loss 175.19038 131 34\n",
      "Training Accuracy 0.72\n",
      "Loss 173.39459 132 34\n",
      "Training Accuracy 0.695\n",
      "Loss 184.00291 133 34\n",
      "Training Accuracy 0.67\n",
      "Loss 182.91977 134 34\n",
      "Training Accuracy 0.67\n",
      "Loss 184.76527 135 34\n",
      "Training Accuracy 0.695\n",
      "Loss 191.17938 136 34\n",
      "Training Accuracy 0.69\n",
      "Loss 197.57431 137 34\n",
      "Training Accuracy 0.69\n",
      "Loss 181.94281 138 34\n",
      "Training Accuracy 0.715\n",
      "Loss 201.49176 139 34\n",
      "Training Accuracy 0.67\n",
      "Loss 168.4983 140 34\n",
      "Training Accuracy 0.71\n",
      "Loss 189.17714 141 34\n",
      "Training Accuracy 0.71\n",
      "Loss 193.34344 142 34\n",
      "Training Accuracy 0.64\n",
      "Loss 161.01743 143 34\n",
      "Training Accuracy 0.725\n",
      "Loss 204.04713 144 34\n",
      "Training Accuracy 0.585\n",
      "Loss 169.45456 145 34\n",
      "Training Accuracy 0.715\n",
      "Loss 206.36496 146 34\n",
      "Training Accuracy 0.645\n",
      "Loss 189.11444 147 34\n",
      "Training Accuracy 0.67\n",
      "Loss 191.3371 148 34\n",
      "Training Accuracy 0.66\n",
      "Loss 178.17226 149 34\n",
      "Training Accuracy 0.715\n",
      "Loss 175.60597 150 34\n",
      "Training Accuracy 0.72\n",
      "Loss 201.15512 151 34\n",
      "Training Accuracy 0.645\n",
      "Loss 201.22578 152 34\n",
      "Training Accuracy 0.68\n",
      "Loss 176.03049 153 34\n",
      "Training Accuracy 0.72\n",
      "Loss 186.44464 154 34\n",
      "Training Accuracy 0.65\n",
      "Loss 168.09766 155 34\n",
      "Training Accuracy 0.715\n",
      "Loss 195.89732 156 34\n",
      "Training Accuracy 0.66\n",
      "Loss 167.44695 157 34\n",
      "Training Accuracy 0.695\n",
      "Loss 171.81699 158 34\n",
      "Training Accuracy 0.72\n",
      "Loss 203.50696 159 34\n",
      "Training Accuracy 0.67\n",
      "Loss 188.175 160 34\n",
      "Training Accuracy 0.675\n",
      "Loss 206.4867 161 34\n",
      "Training Accuracy 0.625\n",
      "Loss 177.96895 162 34\n",
      "Training Accuracy 0.685\n",
      "Loss 208.67755 163 34\n",
      "Training Accuracy 0.655\n",
      "Loss 168.86957 164 34\n",
      "Training Accuracy 0.68\n",
      "Loss 173.00298 165 34\n",
      "Training Accuracy 0.725\n",
      "Loss 187.14774 166 34\n",
      "Training Accuracy 0.7\n",
      "Loss 173.02327 167 34\n",
      "Training Accuracy 0.66\n",
      "Loss 198.21411 168 34\n",
      "Training Accuracy 0.655\n",
      "Loss 177.79285 169 34\n",
      "Training Accuracy 0.69\n",
      "Loss 197.46724 170 34\n",
      "Training Accuracy 0.67\n",
      "Loss 193.18079 171 34\n",
      "Training Accuracy 0.715\n",
      "Loss 172.04906 172 34\n",
      "Training Accuracy 0.69\n",
      "Loss 196.54184 173 34\n",
      "Training Accuracy 0.68\n",
      "Loss 168.47043 174 34\n",
      "Training Accuracy 0.675\n",
      "Loss 153.66191 175 34\n",
      "Training Accuracy 0.745\n",
      "Loss 147.33676 176 34\n",
      "Training Accuracy 0.765\n",
      "Loss 209.39369 177 34\n",
      "Training Accuracy 0.625\n",
      "Loss 174.91582 178 34\n",
      "Training Accuracy 0.685\n",
      "Loss 185.82953 179 34\n",
      "Training Accuracy 0.695\n",
      "Loss 190.2827 180 34\n",
      "Training Accuracy 0.685\n",
      "Loss 169.93759 181 34\n",
      "Training Accuracy 0.715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 198.81572 182 34\n",
      "Training Accuracy 0.605\n",
      "Loss 192.29298 183 34\n",
      "Training Accuracy 0.66\n",
      "Loss 160.7295 184 34\n",
      "Training Accuracy 0.745\n",
      "Loss 179.69037 185 34\n",
      "Training Accuracy 0.725\n",
      "Loss 176.41278 186 34\n",
      "Training Accuracy 0.7\n",
      "Loss 206.19937 187 34\n",
      "Training Accuracy 0.68\n",
      "Loss 188.89748 188 34\n",
      "Training Accuracy 0.72\n",
      "Loss 192.11896 189 34\n",
      "Training Accuracy 0.665\n",
      "Loss 178.15118 190 34\n",
      "Training Accuracy 0.7\n",
      "Loss 169.95093 191 34\n",
      "Training Accuracy 0.705\n",
      "Loss 187.99545 192 34\n",
      "Training Accuracy 0.665\n",
      "Loss 188.03304 193 34\n",
      "Training Accuracy 0.685\n",
      "Loss 181.65944 194 34\n",
      "Training Accuracy 0.7\n",
      "Loss 158.27032 195 34\n",
      "Training Accuracy 0.745\n",
      "Loss 174.11848 196 34\n",
      "Training Accuracy 0.67\n",
      "Loss 187.91284 197 34\n",
      "Training Accuracy 0.665\n",
      "Loss 189.24133 198 34\n",
      "Training Accuracy 0.67\n",
      "Loss 152.88411 199 34\n",
      "Training Accuracy 0.72\n",
      "Loss 174.40073 200 34\n",
      "Training Accuracy 0.695\n",
      "Loss 169.37265 201 34\n",
      "Training Accuracy 0.695\n",
      "Loss 174.11218 202 34\n",
      "Training Accuracy 0.685\n",
      "Loss 191.50688 203 34\n",
      "Training Accuracy 0.675\n",
      "Loss 172.78622 204 34\n",
      "Training Accuracy 0.69\n",
      "Loss 201.72989 205 34\n",
      "Training Accuracy 0.635\n",
      "Loss 201.33485 206 34\n",
      "Training Accuracy 0.63\n",
      "Loss 191.01068 207 34\n",
      "Training Accuracy 0.65\n",
      "Loss 188.62885 208 34\n",
      "Training Accuracy 0.675\n",
      "Loss 192.91815 209 34\n",
      "Training Accuracy 0.71\n",
      "Loss 180.61415 210 34\n",
      "Training Accuracy 0.7\n",
      "Loss 161.16942 211 34\n",
      "Training Accuracy 0.735\n",
      "Loss 172.46548 212 34\n",
      "Training Accuracy 0.7\n",
      "Loss 210.0267 213 34\n",
      "Training Accuracy 0.61\n",
      "Loss 185.84593 214 34\n",
      "Training Accuracy 0.665\n",
      "Loss 199.4765 215 34\n",
      "Training Accuracy 0.665\n",
      "Loss 193.24152 216 34\n",
      "Training Accuracy 0.655\n",
      "Loss 189.75566 217 34\n",
      "Training Accuracy 0.635\n",
      "Loss 185.16534 218 34\n",
      "Training Accuracy 0.645\n",
      "Loss 196.01796 219 34\n",
      "Training Accuracy 0.685\n",
      "Loss 181.16664 220 34\n",
      "Training Accuracy 0.695\n",
      "Loss 191.78435 221 34\n",
      "Training Accuracy 0.64\n",
      "Loss 172.93404 222 34\n",
      "Training Accuracy 0.67\n",
      "Loss 191.99312 223 34\n",
      "Training Accuracy 0.66\n",
      "Loss 200.71252 224 34\n",
      "Training Accuracy 0.655\n",
      "Loss 193.89465 225 34\n",
      "Training Accuracy 0.665\n",
      "Loss 150.49127 226 34\n",
      "Training Accuracy 0.77\n",
      "Loss 207.41934 227 34\n",
      "Training Accuracy 0.66\n",
      "Loss 215.37596 228 34\n",
      "Training Accuracy 0.64\n",
      "Loss 181.63411 229 34\n",
      "Training Accuracy 0.705\n",
      "Loss 191.34024 230 34\n",
      "Training Accuracy 0.69\n",
      "Loss 164.45241 231 34\n",
      "Training Accuracy 0.695\n",
      "Loss 202.33644 232 34\n",
      "Training Accuracy 0.665\n",
      "Loss 221.15874 233 34\n",
      "Training Accuracy 0.58\n",
      "Loss 182.66757 234 34\n",
      "Training Accuracy 0.66\n",
      "Loss 189.4275 235 34\n",
      "Training Accuracy 0.685\n",
      "Loss 166.06274 236 34\n",
      "Training Accuracy 0.73\n",
      "Loss 200.43121 237 34\n",
      "Training Accuracy 0.64\n",
      "Loss 171.82985 238 34\n",
      "Training Accuracy 0.68\n",
      "Loss 188.93143 239 34\n",
      "Training Accuracy 0.66\n",
      "Loss 193.19807 240 34\n",
      "Training Accuracy 0.635\n",
      "Loss 218.17934 241 34\n",
      "Training Accuracy 0.63\n",
      "Loss 182.55511 242 34\n",
      "Training Accuracy 0.685\n",
      "Loss 166.76549 243 34\n",
      "Training Accuracy 0.705\n",
      "Loss 179.61288 244 34\n",
      "Training Accuracy 0.67\n",
      "Loss 186.85345 245 34\n",
      "Training Accuracy 0.68\n",
      "Loss 199.61147 246 34\n",
      "Training Accuracy 0.66\n",
      "Loss 167.16545 247 34\n",
      "Training Accuracy 0.67\n",
      "Loss 168.3002 248 34\n",
      "Training Accuracy 0.73\n",
      "Loss 204.57498 249 34\n",
      "Training Accuracy 0.615\n",
      "Loss 194.3406 250 34\n",
      "Training Accuracy 0.66\n",
      "Loss 199.83734 251 34\n",
      "Training Accuracy 0.625\n",
      "Loss 165.7601 252 34\n",
      "Training Accuracy 0.695\n",
      "Loss 152.74884 253 34\n",
      "Training Accuracy 0.725\n",
      "Loss 179.50195 254 34\n",
      "Training Accuracy 0.665\n",
      "Loss 168.36285 255 34\n",
      "Training Accuracy 0.725\n",
      "Loss 198.80453 256 34\n",
      "Training Accuracy 0.665\n",
      "Loss 178.88516 257 34\n",
      "Training Accuracy 0.705\n",
      "Loss 188.06354 258 34\n",
      "Training Accuracy 0.705\n",
      "Loss 184.38943 259 34\n",
      "Training Accuracy 0.68\n",
      "Loss 146.07594 260 34\n",
      "Training Accuracy 0.72\n",
      "Loss 184.60593 261 34\n",
      "Training Accuracy 0.72\n",
      "Loss 175.47801 262 34\n",
      "Training Accuracy 0.7\n",
      "Loss 226.5066 263 34\n",
      "Training Accuracy 0.635\n",
      "Loss 190.54924 264 34\n",
      "Training Accuracy 0.705\n",
      "Loss 169.20053 265 34\n",
      "Training Accuracy 0.715\n",
      "Loss 180.50359 266 34\n",
      "Training Accuracy 0.66\n",
      "Loss 191.50638 267 34\n",
      "Training Accuracy 0.615\n",
      "Loss 188.63235 268 34\n",
      "Training Accuracy 0.68\n",
      "Loss 178.09245 269 34\n",
      "Training Accuracy 0.69\n",
      "Loss 158.17822 270 34\n",
      "Training Accuracy 0.74\n",
      "Loss 205.89934 271 34\n",
      "Training Accuracy 0.665\n",
      "Loss 180.19249 272 34\n",
      "Training Accuracy 0.685\n",
      "Loss 202.27101 273 34\n",
      "Training Accuracy 0.665\n",
      "Loss 182.19662 274 34\n",
      "Training Accuracy 0.705\n",
      "Loss 178.59042 275 34\n",
      "Training Accuracy 0.65\n",
      "Loss 167.1975 276 34\n",
      "Training Accuracy 0.7\n",
      "Loss 192.37163 277 34\n",
      "Training Accuracy 0.685\n",
      "Loss 180.78601 278 34\n",
      "Training Accuracy 0.66\n",
      "Loss 178.54796 279 34\n",
      "Training Accuracy 0.715\n",
      "Loss 174.14777 280 34\n",
      "Training Accuracy 0.715\n",
      "Loss 166.57076 281 34\n",
      "Training Accuracy 0.745\n",
      "Loss 185.33495 282 34\n",
      "Training Accuracy 0.685\n",
      "Loss 177.75021 283 34\n",
      "Training Accuracy 0.715\n",
      "Loss 159.17624 284 34\n",
      "Training Accuracy 0.74\n",
      "Loss 208.3656 285 34\n",
      "Training Accuracy 0.66\n",
      "Loss 173.91846 286 34\n",
      "Training Accuracy 0.745\n",
      "Loss 176.42725 287 34\n",
      "Training Accuracy 0.735\n",
      "Loss 192.27856 288 34\n",
      "Training Accuracy 0.695\n",
      "Loss 165.87924 289 34\n",
      "Training Accuracy 0.76\n",
      "Loss 180.68762 290 34\n",
      "Training Accuracy 0.69\n",
      "Loss 194.74448 291 34\n",
      "Training Accuracy 0.67\n",
      "Loss 124.15367 292 34\n",
      "Training Accuracy 0.6363636\n",
      "Loss 152.0729 1 35\n",
      "Training Accuracy 0.735\n",
      "Loss 180.00578 2 35\n",
      "Training Accuracy 0.71\n",
      "Loss 169.40897 3 35\n",
      "Training Accuracy 0.705\n",
      "Loss 183.74965 4 35\n",
      "Training Accuracy 0.69\n",
      "Loss 154.0087 5 35\n",
      "Training Accuracy 0.715\n",
      "Loss 191.43077 6 35\n",
      "Training Accuracy 0.675\n",
      "Loss 193.98982 7 35\n",
      "Training Accuracy 0.685\n",
      "Loss 194.46278 8 35\n",
      "Training Accuracy 0.72\n",
      "Loss 169.67542 9 35\n",
      "Training Accuracy 0.685\n",
      "Loss 200.10782 10 35\n",
      "Training Accuracy 0.64\n",
      "Loss 215.8548 11 35\n",
      "Training Accuracy 0.65\n",
      "Loss 168.695 12 35\n",
      "Training Accuracy 0.72\n",
      "Loss 177.41345 13 35\n",
      "Training Accuracy 0.715\n",
      "Loss 190.08585 14 35\n",
      "Training Accuracy 0.695\n",
      "Loss 176.13046 15 35\n",
      "Training Accuracy 0.68\n",
      "Loss 222.41997 16 35\n",
      "Training Accuracy 0.635\n",
      "Loss 155.8562 17 35\n",
      "Training Accuracy 0.755\n",
      "Loss 169.06223 18 35\n",
      "Training Accuracy 0.73\n",
      "Loss 178.43954 19 35\n",
      "Training Accuracy 0.685\n",
      "Loss 170.60054 20 35\n",
      "Training Accuracy 0.71\n",
      "Loss 171.69821 21 35\n",
      "Training Accuracy 0.745\n",
      "Loss 185.17546 22 35\n",
      "Training Accuracy 0.685\n",
      "Loss 184.56815 23 35\n",
      "Training Accuracy 0.69\n",
      "Loss 206.94362 24 35\n",
      "Training Accuracy 0.675\n",
      "Loss 176.2778 25 35\n",
      "Training Accuracy 0.705\n",
      "Loss 190.99135 26 35\n",
      "Training Accuracy 0.675\n",
      "Loss 172.47775 27 35\n",
      "Training Accuracy 0.68\n",
      "Loss 169.57195 28 35\n",
      "Training Accuracy 0.715\n",
      "Loss 179.8432 29 35\n",
      "Training Accuracy 0.685\n",
      "Loss 200.51201 30 35\n",
      "Training Accuracy 0.685\n",
      "Loss 182.27296 31 35\n",
      "Training Accuracy 0.67\n",
      "Loss 181.05627 32 35\n",
      "Training Accuracy 0.665\n",
      "Loss 180.83777 33 35\n",
      "Training Accuracy 0.665\n",
      "Loss 164.84886 34 35\n",
      "Training Accuracy 0.665\n",
      "Loss 172.49426 35 35\n",
      "Training Accuracy 0.71\n",
      "Loss 187.27856 36 35\n",
      "Training Accuracy 0.67\n",
      "Loss 179.07654 37 35\n",
      "Training Accuracy 0.69\n",
      "Loss 188.98105 38 35\n",
      "Training Accuracy 0.69\n",
      "Loss 150.1636 39 35\n",
      "Training Accuracy 0.76\n",
      "Loss 189.47586 40 35\n",
      "Training Accuracy 0.655\n",
      "Loss 183.64581 41 35\n",
      "Training Accuracy 0.665\n",
      "Loss 212.03432 42 35\n",
      "Training Accuracy 0.645\n",
      "Loss 184.83676 43 35\n",
      "Training Accuracy 0.645\n",
      "Loss 178.21596 44 35\n",
      "Training Accuracy 0.675\n",
      "Loss 186.74776 45 35\n",
      "Training Accuracy 0.675\n",
      "Loss 195.55078 46 35\n",
      "Training Accuracy 0.7\n",
      "Loss 179.15126 47 35\n",
      "Training Accuracy 0.72\n",
      "Loss 153.11005 48 35\n",
      "Training Accuracy 0.72\n",
      "Loss 180.4442 49 35\n",
      "Training Accuracy 0.685\n",
      "Loss 198.97737 50 35\n",
      "Training Accuracy 0.68\n",
      "Loss 158.81453 51 35\n",
      "Training Accuracy 0.73\n",
      "Loss 158.9941 52 35\n",
      "Training Accuracy 0.74\n",
      "Loss 151.99712 53 35\n",
      "Training Accuracy 0.73\n",
      "Loss 203.04875 54 35\n",
      "Training Accuracy 0.64\n",
      "Loss 185.66406 55 35\n",
      "Training Accuracy 0.685\n",
      "Loss 180.71109 56 35\n",
      "Training Accuracy 0.675\n",
      "Loss 171.99608 57 35\n",
      "Training Accuracy 0.71\n",
      "Loss 172.37193 58 35\n",
      "Training Accuracy 0.67\n",
      "Loss 198.06433 59 35\n",
      "Training Accuracy 0.69\n",
      "Loss 176.01767 60 35\n",
      "Training Accuracy 0.72\n",
      "Loss 185.3002 61 35\n",
      "Training Accuracy 0.67\n",
      "Loss 172.68872 62 35\n",
      "Training Accuracy 0.7\n",
      "Loss 191.68748 63 35\n",
      "Training Accuracy 0.67\n",
      "Loss 190.93668 64 35\n",
      "Training Accuracy 0.695\n",
      "Loss 192.41031 65 35\n",
      "Training Accuracy 0.635\n",
      "Loss 176.83047 66 35\n",
      "Training Accuracy 0.695\n",
      "Loss 179.91669 67 35\n",
      "Training Accuracy 0.675\n",
      "Loss 176.86311 68 35\n",
      "Training Accuracy 0.695\n",
      "Loss 186.69858 69 35\n",
      "Training Accuracy 0.685\n",
      "Loss 165.92584 70 35\n",
      "Training Accuracy 0.74\n",
      "Loss 183.99022 71 35\n",
      "Training Accuracy 0.715\n",
      "Loss 186.8782 72 35\n",
      "Training Accuracy 0.665\n",
      "Loss 190.40578 73 35\n",
      "Training Accuracy 0.68\n",
      "Loss 181.0668 74 35\n",
      "Training Accuracy 0.68\n",
      "Loss 180.73021 75 35\n",
      "Training Accuracy 0.715\n",
      "Loss 172.27 76 35\n",
      "Training Accuracy 0.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 195.22122 77 35\n",
      "Training Accuracy 0.68\n",
      "Loss 179.21361 78 35\n",
      "Training Accuracy 0.695\n",
      "Loss 193.99007 79 35\n",
      "Training Accuracy 0.61\n",
      "Loss 194.28207 80 35\n",
      "Training Accuracy 0.675\n",
      "Loss 163.78603 81 35\n",
      "Training Accuracy 0.685\n",
      "Loss 173.09064 82 35\n",
      "Training Accuracy 0.74\n",
      "Loss 182.39241 83 35\n",
      "Training Accuracy 0.715\n",
      "Loss 198.83308 84 35\n",
      "Training Accuracy 0.675\n",
      "Loss 178.21042 85 35\n",
      "Training Accuracy 0.675\n",
      "Loss 183.22675 86 35\n",
      "Training Accuracy 0.705\n",
      "Loss 227.90047 87 35\n",
      "Training Accuracy 0.615\n",
      "Loss 222.26192 88 35\n",
      "Training Accuracy 0.625\n",
      "Loss 177.72978 89 35\n",
      "Training Accuracy 0.67\n",
      "Loss 194.08408 90 35\n",
      "Training Accuracy 0.65\n",
      "Loss 186.90411 91 35\n",
      "Training Accuracy 0.675\n",
      "Loss 193.28517 92 35\n",
      "Training Accuracy 0.695\n",
      "Loss 194.31808 93 35\n",
      "Training Accuracy 0.67\n",
      "Loss 185.80322 94 35\n",
      "Training Accuracy 0.68\n",
      "Loss 171.04305 95 35\n",
      "Training Accuracy 0.685\n",
      "Loss 176.38202 96 35\n",
      "Training Accuracy 0.695\n",
      "Loss 188.98602 97 35\n",
      "Training Accuracy 0.64\n",
      "Loss 167.70732 98 35\n",
      "Training Accuracy 0.715\n",
      "Loss 175.22208 99 35\n",
      "Training Accuracy 0.66\n",
      "Loss 186.52092 100 35\n",
      "Training Accuracy 0.71\n",
      "Loss 204.06506 101 35\n",
      "Training Accuracy 0.67\n",
      "Loss 163.7254 102 35\n",
      "Training Accuracy 0.715\n",
      "Loss 185.99556 103 35\n",
      "Training Accuracy 0.72\n",
      "Loss 194.7656 104 35\n",
      "Training Accuracy 0.67\n",
      "Loss 186.42795 105 35\n",
      "Training Accuracy 0.695\n",
      "Loss 172.92403 106 35\n",
      "Training Accuracy 0.725\n",
      "Loss 169.40744 107 35\n",
      "Training Accuracy 0.695\n",
      "Loss 185.97997 108 35\n",
      "Training Accuracy 0.675\n",
      "Loss 172.52777 109 35\n",
      "Training Accuracy 0.7\n",
      "Loss 192.34074 110 35\n",
      "Training Accuracy 0.695\n",
      "Loss 191.01158 111 35\n",
      "Training Accuracy 0.67\n",
      "Loss 206.77461 112 35\n",
      "Training Accuracy 0.66\n",
      "Loss 218.21544 113 35\n",
      "Training Accuracy 0.675\n",
      "Loss 184.02524 114 35\n",
      "Training Accuracy 0.685\n",
      "Loss 199.45499 115 35\n",
      "Training Accuracy 0.68\n",
      "Loss 203.84274 116 35\n",
      "Training Accuracy 0.69\n",
      "Loss 154.27203 117 35\n",
      "Training Accuracy 0.765\n",
      "Loss 161.51262 118 35\n",
      "Training Accuracy 0.71\n",
      "Loss 198.81229 119 35\n",
      "Training Accuracy 0.665\n",
      "Loss 201.46701 120 35\n",
      "Training Accuracy 0.635\n",
      "Loss 192.63278 121 35\n",
      "Training Accuracy 0.675\n",
      "Loss 175.88634 122 35\n",
      "Training Accuracy 0.72\n",
      "Loss 193.2533 123 35\n",
      "Training Accuracy 0.645\n",
      "Loss 176.47153 124 35\n",
      "Training Accuracy 0.695\n",
      "Loss 156.22095 125 35\n",
      "Training Accuracy 0.715\n",
      "Loss 193.52687 126 35\n",
      "Training Accuracy 0.685\n",
      "Loss 194.82434 127 35\n",
      "Training Accuracy 0.64\n",
      "Loss 191.33917 128 35\n",
      "Training Accuracy 0.65\n",
      "Loss 170.40955 129 35\n",
      "Training Accuracy 0.72\n",
      "Loss 164.88101 130 35\n",
      "Training Accuracy 0.655\n",
      "Loss 170.7218 131 35\n",
      "Training Accuracy 0.745\n",
      "Loss 171.29135 132 35\n",
      "Training Accuracy 0.68\n",
      "Loss 178.40814 133 35\n",
      "Training Accuracy 0.7\n",
      "Loss 174.07706 134 35\n",
      "Training Accuracy 0.705\n",
      "Loss 190.9007 135 35\n",
      "Training Accuracy 0.655\n",
      "Loss 188.81192 136 35\n",
      "Training Accuracy 0.685\n",
      "Loss 177.11894 137 35\n",
      "Training Accuracy 0.7\n",
      "Loss 179.47424 138 35\n",
      "Training Accuracy 0.7\n",
      "Loss 190.36794 139 35\n",
      "Training Accuracy 0.695\n",
      "Loss 174.76324 140 35\n",
      "Training Accuracy 0.705\n",
      "Loss 191.38852 141 35\n",
      "Training Accuracy 0.655\n",
      "Loss 192.56754 142 35\n",
      "Training Accuracy 0.635\n",
      "Loss 158.81155 143 35\n",
      "Training Accuracy 0.745\n",
      "Loss 200.30292 144 35\n",
      "Training Accuracy 0.655\n",
      "Loss 180.98389 145 35\n",
      "Training Accuracy 0.685\n",
      "Loss 212.81743 146 35\n",
      "Training Accuracy 0.63\n",
      "Loss 197.79105 147 35\n",
      "Training Accuracy 0.64\n",
      "Loss 188.19118 148 35\n",
      "Training Accuracy 0.665\n",
      "Loss 174.87039 149 35\n",
      "Training Accuracy 0.68\n",
      "Loss 179.40677 150 35\n",
      "Training Accuracy 0.705\n",
      "Loss 195.75423 151 35\n",
      "Training Accuracy 0.65\n",
      "Loss 194.92903 152 35\n",
      "Training Accuracy 0.69\n",
      "Loss 176.87064 153 35\n",
      "Training Accuracy 0.72\n",
      "Loss 191.97528 154 35\n",
      "Training Accuracy 0.65\n",
      "Loss 175.0672 155 35\n",
      "Training Accuracy 0.675\n",
      "Loss 187.18651 156 35\n",
      "Training Accuracy 0.655\n",
      "Loss 163.76279 157 35\n",
      "Training Accuracy 0.695\n",
      "Loss 170.43861 158 35\n",
      "Training Accuracy 0.735\n",
      "Loss 207.76532 159 35\n",
      "Training Accuracy 0.68\n",
      "Loss 192.13818 160 35\n",
      "Training Accuracy 0.71\n",
      "Loss 202.32426 161 35\n",
      "Training Accuracy 0.635\n",
      "Loss 182.16295 162 35\n",
      "Training Accuracy 0.695\n",
      "Loss 208.55457 163 35\n",
      "Training Accuracy 0.62\n",
      "Loss 174.0482 164 35\n",
      "Training Accuracy 0.68\n",
      "Loss 178.10449 165 35\n",
      "Training Accuracy 0.715\n",
      "Loss 180.71005 166 35\n",
      "Training Accuracy 0.695\n",
      "Loss 173.26952 167 35\n",
      "Training Accuracy 0.69\n",
      "Loss 198.78874 168 35\n",
      "Training Accuracy 0.65\n",
      "Loss 177.44589 169 35\n",
      "Training Accuracy 0.71\n",
      "Loss 192.04234 170 35\n",
      "Training Accuracy 0.685\n",
      "Loss 190.63759 171 35\n",
      "Training Accuracy 0.7\n",
      "Loss 170.05501 172 35\n",
      "Training Accuracy 0.72\n",
      "Loss 194.44025 173 35\n",
      "Training Accuracy 0.68\n",
      "Loss 159.2376 174 35\n",
      "Training Accuracy 0.695\n",
      "Loss 157.68082 175 35\n",
      "Training Accuracy 0.725\n",
      "Loss 138.91216 176 35\n",
      "Training Accuracy 0.785\n",
      "Loss 190.91989 177 35\n",
      "Training Accuracy 0.69\n",
      "Loss 164.38272 178 35\n",
      "Training Accuracy 0.73\n",
      "Loss 193.57678 179 35\n",
      "Training Accuracy 0.66\n",
      "Loss 202.96942 180 35\n",
      "Training Accuracy 0.665\n",
      "Loss 164.80264 181 35\n",
      "Training Accuracy 0.75\n",
      "Loss 204.0246 182 35\n",
      "Training Accuracy 0.635\n",
      "Loss 190.7988 183 35\n",
      "Training Accuracy 0.66\n",
      "Loss 155.76093 184 35\n",
      "Training Accuracy 0.755\n",
      "Loss 171.09315 185 35\n",
      "Training Accuracy 0.755\n",
      "Loss 169.13696 186 35\n",
      "Training Accuracy 0.715\n",
      "Loss 211.78885 187 35\n",
      "Training Accuracy 0.61\n",
      "Loss 195.97867 188 35\n",
      "Training Accuracy 0.67\n",
      "Loss 172.72513 189 35\n",
      "Training Accuracy 0.695\n",
      "Loss 164.4098 190 35\n",
      "Training Accuracy 0.725\n",
      "Loss 164.61163 191 35\n",
      "Training Accuracy 0.73\n",
      "Loss 185.9793 192 35\n",
      "Training Accuracy 0.69\n",
      "Loss 169.7438 193 35\n",
      "Training Accuracy 0.75\n",
      "Loss 177.47784 194 35\n",
      "Training Accuracy 0.71\n",
      "Loss 155.18616 195 35\n",
      "Training Accuracy 0.785\n",
      "Loss 175.99774 196 35\n",
      "Training Accuracy 0.65\n",
      "Loss 182.30797 197 35\n",
      "Training Accuracy 0.69\n",
      "Loss 173.34521 198 35\n",
      "Training Accuracy 0.685\n",
      "Loss 164.98364 199 35\n",
      "Training Accuracy 0.725\n",
      "Loss 164.08229 200 35\n",
      "Training Accuracy 0.7\n",
      "Loss 165.98723 201 35\n",
      "Training Accuracy 0.715\n",
      "Loss 162.54073 202 35\n",
      "Training Accuracy 0.71\n",
      "Loss 178.80823 203 35\n",
      "Training Accuracy 0.715\n",
      "Loss 161.64786 204 35\n",
      "Training Accuracy 0.715\n",
      "Loss 198.66571 205 35\n",
      "Training Accuracy 0.685\n",
      "Loss 184.79858 206 35\n",
      "Training Accuracy 0.695\n",
      "Loss 190.73283 207 35\n",
      "Training Accuracy 0.69\n",
      "Loss 181.48438 208 35\n",
      "Training Accuracy 0.7\n",
      "Loss 190.39468 209 35\n",
      "Training Accuracy 0.695\n",
      "Loss 160.55746 210 35\n",
      "Training Accuracy 0.755\n",
      "Loss 153.06223 211 35\n",
      "Training Accuracy 0.75\n",
      "Loss 180.67105 212 35\n",
      "Training Accuracy 0.715\n",
      "Loss 211.33623 213 35\n",
      "Training Accuracy 0.63\n",
      "Loss 174.94885 214 35\n",
      "Training Accuracy 0.67\n",
      "Loss 208.0089 215 35\n",
      "Training Accuracy 0.62\n",
      "Loss 189.27232 216 35\n",
      "Training Accuracy 0.67\n",
      "Loss 191.30754 217 35\n",
      "Training Accuracy 0.635\n",
      "Loss 188.96014 218 35\n",
      "Training Accuracy 0.655\n",
      "Loss 186.36047 219 35\n",
      "Training Accuracy 0.685\n",
      "Loss 184.41496 220 35\n",
      "Training Accuracy 0.66\n",
      "Loss 177.75299 221 35\n",
      "Training Accuracy 0.705\n",
      "Loss 177.1044 222 35\n",
      "Training Accuracy 0.675\n",
      "Loss 194.15031 223 35\n",
      "Training Accuracy 0.64\n",
      "Loss 204.38121 224 35\n",
      "Training Accuracy 0.65\n",
      "Loss 202.5491 225 35\n",
      "Training Accuracy 0.635\n",
      "Loss 156.56273 226 35\n",
      "Training Accuracy 0.71\n",
      "Loss 200.29512 227 35\n",
      "Training Accuracy 0.645\n",
      "Loss 221.61539 228 35\n",
      "Training Accuracy 0.615\n",
      "Loss 169.43169 229 35\n",
      "Training Accuracy 0.715\n",
      "Loss 186.50401 230 35\n",
      "Training Accuracy 0.705\n",
      "Loss 167.98259 231 35\n",
      "Training Accuracy 0.72\n",
      "Loss 188.63498 232 35\n",
      "Training Accuracy 0.655\n",
      "Loss 216.85971 233 35\n",
      "Training Accuracy 0.595\n",
      "Loss 193.27333 234 35\n",
      "Training Accuracy 0.615\n",
      "Loss 189.91727 235 35\n",
      "Training Accuracy 0.68\n",
      "Loss 164.42181 236 35\n",
      "Training Accuracy 0.7\n",
      "Loss 182.66525 237 35\n",
      "Training Accuracy 0.69\n",
      "Loss 174.18562 238 35\n",
      "Training Accuracy 0.665\n",
      "Loss 197.96658 239 35\n",
      "Training Accuracy 0.635\n",
      "Loss 176.72725 240 35\n",
      "Training Accuracy 0.67\n",
      "Loss 203.14766 241 35\n",
      "Training Accuracy 0.645\n",
      "Loss 178.31535 242 35\n",
      "Training Accuracy 0.685\n",
      "Loss 155.50233 243 35\n",
      "Training Accuracy 0.725\n",
      "Loss 181.40758 244 35\n",
      "Training Accuracy 0.675\n",
      "Loss 179.82202 245 35\n",
      "Training Accuracy 0.7\n",
      "Loss 197.55112 246 35\n",
      "Training Accuracy 0.66\n",
      "Loss 168.48338 247 35\n",
      "Training Accuracy 0.68\n",
      "Loss 163.35286 248 35\n",
      "Training Accuracy 0.705\n",
      "Loss 191.8349 249 35\n",
      "Training Accuracy 0.62\n",
      "Loss 199.50941 250 35\n",
      "Training Accuracy 0.605\n",
      "Loss 192.83992 251 35\n",
      "Training Accuracy 0.68\n",
      "Loss 157.0224 252 35\n",
      "Training Accuracy 0.72\n",
      "Loss 154.26604 253 35\n",
      "Training Accuracy 0.725\n",
      "Loss 201.25671 254 35\n",
      "Training Accuracy 0.685\n",
      "Loss 159.30077 255 35\n",
      "Training Accuracy 0.72\n",
      "Loss 207.905 256 35\n",
      "Training Accuracy 0.645\n",
      "Loss 174.44849 257 35\n",
      "Training Accuracy 0.715\n",
      "Loss 194.87027 258 35\n",
      "Training Accuracy 0.66\n",
      "Loss 174.75087 259 35\n",
      "Training Accuracy 0.685\n",
      "Loss 152.13892 260 35\n",
      "Training Accuracy 0.735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 186.35251 261 35\n",
      "Training Accuracy 0.685\n",
      "Loss 183.70808 262 35\n",
      "Training Accuracy 0.67\n",
      "Loss 220.63748 263 35\n",
      "Training Accuracy 0.615\n",
      "Loss 190.7973 264 35\n",
      "Training Accuracy 0.71\n",
      "Loss 167.99991 265 35\n",
      "Training Accuracy 0.705\n",
      "Loss 187.90622 266 35\n",
      "Training Accuracy 0.61\n",
      "Loss 179.60591 267 35\n",
      "Training Accuracy 0.66\n",
      "Loss 195.85135 268 35\n",
      "Training Accuracy 0.655\n",
      "Loss 176.87823 269 35\n",
      "Training Accuracy 0.695\n",
      "Loss 164.79604 270 35\n",
      "Training Accuracy 0.69\n",
      "Loss 195.6937 271 35\n",
      "Training Accuracy 0.66\n",
      "Loss 173.85727 272 35\n",
      "Training Accuracy 0.7\n",
      "Loss 194.08472 273 35\n",
      "Training Accuracy 0.665\n",
      "Loss 168.6059 274 35\n",
      "Training Accuracy 0.725\n",
      "Loss 169.9941 275 35\n",
      "Training Accuracy 0.7\n",
      "Loss 174.46379 276 35\n",
      "Training Accuracy 0.695\n",
      "Loss 185.68579 277 35\n",
      "Training Accuracy 0.735\n",
      "Loss 174.16821 278 35\n",
      "Training Accuracy 0.665\n",
      "Loss 183.83655 279 35\n",
      "Training Accuracy 0.69\n",
      "Loss 178.3025 280 35\n",
      "Training Accuracy 0.67\n",
      "Loss 157.94278 281 35\n",
      "Training Accuracy 0.72\n",
      "Loss 168.30775 282 35\n",
      "Training Accuracy 0.74\n",
      "Loss 177.6731 283 35\n",
      "Training Accuracy 0.735\n",
      "Loss 148.18921 284 35\n",
      "Training Accuracy 0.775\n",
      "Loss 199.31882 285 35\n",
      "Training Accuracy 0.685\n",
      "Loss 183.61371 286 35\n",
      "Training Accuracy 0.7\n",
      "Loss 174.58698 287 35\n",
      "Training Accuracy 0.69\n",
      "Loss 185.09355 288 35\n",
      "Training Accuracy 0.715\n",
      "Loss 175.76736 289 35\n",
      "Training Accuracy 0.71\n",
      "Loss 183.51216 290 35\n",
      "Training Accuracy 0.69\n",
      "Loss 209.55305 291 35\n",
      "Training Accuracy 0.63\n",
      "Loss 128.65479 292 35\n",
      "Training Accuracy 0.6439394\n",
      "Loss 154.9031 1 36\n",
      "Training Accuracy 0.725\n",
      "Loss 177.93806 2 36\n",
      "Training Accuracy 0.7\n",
      "Loss 152.49478 3 36\n",
      "Training Accuracy 0.765\n",
      "Loss 189.19028 4 36\n",
      "Training Accuracy 0.675\n",
      "Loss 163.47461 5 36\n",
      "Training Accuracy 0.72\n",
      "Loss 192.0175 6 36\n",
      "Training Accuracy 0.65\n",
      "Loss 182.35649 7 36\n",
      "Training Accuracy 0.715\n",
      "Loss 186.37566 8 36\n",
      "Training Accuracy 0.715\n",
      "Loss 173.30812 9 36\n",
      "Training Accuracy 0.7\n",
      "Loss 198.32161 10 36\n",
      "Training Accuracy 0.655\n",
      "Loss 203.51135 11 36\n",
      "Training Accuracy 0.68\n",
      "Loss 163.01514 12 36\n",
      "Training Accuracy 0.715\n",
      "Loss 168.22029 13 36\n",
      "Training Accuracy 0.705\n",
      "Loss 179.92358 14 36\n",
      "Training Accuracy 0.74\n",
      "Loss 176.98825 15 36\n",
      "Training Accuracy 0.695\n",
      "Loss 223.1033 16 36\n",
      "Training Accuracy 0.635\n",
      "Loss 154.57259 17 36\n",
      "Training Accuracy 0.745\n",
      "Loss 155.95143 18 36\n",
      "Training Accuracy 0.725\n",
      "Loss 162.91518 19 36\n",
      "Training Accuracy 0.705\n",
      "Loss 172.33394 20 36\n",
      "Training Accuracy 0.735\n",
      "Loss 177.6356 21 36\n",
      "Training Accuracy 0.72\n",
      "Loss 177.2357 22 36\n",
      "Training Accuracy 0.66\n",
      "Loss 180.32368 23 36\n",
      "Training Accuracy 0.705\n",
      "Loss 187.64165 24 36\n",
      "Training Accuracy 0.675\n",
      "Loss 166.69627 25 36\n",
      "Training Accuracy 0.735\n",
      "Loss 188.86748 26 36\n",
      "Training Accuracy 0.675\n",
      "Loss 177.0374 27 36\n",
      "Training Accuracy 0.68\n",
      "Loss 170.84006 28 36\n",
      "Training Accuracy 0.685\n",
      "Loss 174.05931 29 36\n",
      "Training Accuracy 0.68\n",
      "Loss 190.11499 30 36\n",
      "Training Accuracy 0.7\n",
      "Loss 180.98073 31 36\n",
      "Training Accuracy 0.7\n",
      "Loss 182.99963 32 36\n",
      "Training Accuracy 0.67\n",
      "Loss 179.20044 33 36\n",
      "Training Accuracy 0.715\n",
      "Loss 157.9958 34 36\n",
      "Training Accuracy 0.72\n",
      "Loss 163.739 35 36\n",
      "Training Accuracy 0.705\n",
      "Loss 197.66255 36 36\n",
      "Training Accuracy 0.665\n",
      "Loss 167.41197 37 36\n",
      "Training Accuracy 0.73\n",
      "Loss 191.86444 38 36\n",
      "Training Accuracy 0.685\n",
      "Loss 159.0572 39 36\n",
      "Training Accuracy 0.755\n",
      "Loss 164.54462 40 36\n",
      "Training Accuracy 0.725\n",
      "Loss 185.99666 41 36\n",
      "Training Accuracy 0.665\n",
      "Loss 194.01488 42 36\n",
      "Training Accuracy 0.65\n",
      "Loss 177.87057 43 36\n",
      "Training Accuracy 0.69\n",
      "Loss 177.61884 44 36\n",
      "Training Accuracy 0.69\n",
      "Loss 168.81848 45 36\n",
      "Training Accuracy 0.72\n",
      "Loss 198.18834 46 36\n",
      "Training Accuracy 0.655\n",
      "Loss 167.47008 47 36\n",
      "Training Accuracy 0.74\n",
      "Loss 158.16122 48 36\n",
      "Training Accuracy 0.69\n",
      "Loss 178.07112 49 36\n",
      "Training Accuracy 0.69\n",
      "Loss 198.24937 50 36\n",
      "Training Accuracy 0.685\n",
      "Loss 157.95242 51 36\n",
      "Training Accuracy 0.715\n",
      "Loss 166.89688 52 36\n",
      "Training Accuracy 0.74\n",
      "Loss 155.11807 53 36\n",
      "Training Accuracy 0.7\n",
      "Loss 206.00197 54 36\n",
      "Training Accuracy 0.615\n",
      "Loss 192.4535 55 36\n",
      "Training Accuracy 0.675\n",
      "Loss 184.17424 56 36\n",
      "Training Accuracy 0.675\n",
      "Loss 166.82925 57 36\n",
      "Training Accuracy 0.72\n",
      "Loss 167.90392 58 36\n",
      "Training Accuracy 0.69\n",
      "Loss 183.95433 59 36\n",
      "Training Accuracy 0.715\n",
      "Loss 166.78679 60 36\n",
      "Training Accuracy 0.73\n",
      "Loss 190.38617 61 36\n",
      "Training Accuracy 0.67\n",
      "Loss 164.94807 62 36\n",
      "Training Accuracy 0.695\n",
      "Loss 174.95233 63 36\n",
      "Training Accuracy 0.71\n",
      "Loss 179.41263 64 36\n",
      "Training Accuracy 0.7\n",
      "Loss 175.93059 65 36\n",
      "Training Accuracy 0.66\n",
      "Loss 173.34937 66 36\n",
      "Training Accuracy 0.71\n",
      "Loss 184.15993 67 36\n",
      "Training Accuracy 0.665\n",
      "Loss 170.23582 68 36\n",
      "Training Accuracy 0.72\n",
      "Loss 168.50446 69 36\n",
      "Training Accuracy 0.715\n",
      "Loss 182.34819 70 36\n",
      "Training Accuracy 0.71\n",
      "Loss 188.77336 71 36\n",
      "Training Accuracy 0.69\n",
      "Loss 168.60712 72 36\n",
      "Training Accuracy 0.725\n",
      "Loss 193.49147 73 36\n",
      "Training Accuracy 0.625\n",
      "Loss 176.59065 74 36\n",
      "Training Accuracy 0.7\n",
      "Loss 181.87175 75 36\n",
      "Training Accuracy 0.715\n",
      "Loss 165.05061 76 36\n",
      "Training Accuracy 0.685\n",
      "Loss 198.03958 77 36\n",
      "Training Accuracy 0.665\n",
      "Loss 182.804 78 36\n",
      "Training Accuracy 0.71\n",
      "Loss 177.9188 79 36\n",
      "Training Accuracy 0.675\n",
      "Loss 191.59862 80 36\n",
      "Training Accuracy 0.635\n",
      "Loss 163.5042 81 36\n",
      "Training Accuracy 0.705\n",
      "Loss 164.26785 82 36\n",
      "Training Accuracy 0.7\n",
      "Loss 170.89058 83 36\n",
      "Training Accuracy 0.73\n",
      "Loss 189.28181 84 36\n",
      "Training Accuracy 0.7\n",
      "Loss 162.75623 85 36\n",
      "Training Accuracy 0.725\n",
      "Loss 179.23094 86 36\n",
      "Training Accuracy 0.72\n",
      "Loss 214.33104 87 36\n",
      "Training Accuracy 0.64\n",
      "Loss 209.25687 88 36\n",
      "Training Accuracy 0.685\n",
      "Loss 177.99454 89 36\n",
      "Training Accuracy 0.67\n",
      "Loss 191.4167 90 36\n",
      "Training Accuracy 0.655\n",
      "Loss 180.84021 91 36\n",
      "Training Accuracy 0.68\n",
      "Loss 184.46535 92 36\n",
      "Training Accuracy 0.7\n",
      "Loss 191.9578 93 36\n",
      "Training Accuracy 0.675\n",
      "Loss 184.69186 94 36\n",
      "Training Accuracy 0.675\n",
      "Loss 174.24368 95 36\n",
      "Training Accuracy 0.675\n",
      "Loss 177.08096 96 36\n",
      "Training Accuracy 0.7\n",
      "Loss 193.29112 97 36\n",
      "Training Accuracy 0.66\n",
      "Loss 163.51907 98 36\n",
      "Training Accuracy 0.725\n",
      "Loss 165.69228 99 36\n",
      "Training Accuracy 0.715\n",
      "Loss 165.97795 100 36\n",
      "Training Accuracy 0.74\n",
      "Loss 200.71277 101 36\n",
      "Training Accuracy 0.66\n",
      "Loss 177.40176 102 36\n",
      "Training Accuracy 0.685\n",
      "Loss 172.79019 103 36\n",
      "Training Accuracy 0.73\n",
      "Loss 186.23267 104 36\n",
      "Training Accuracy 0.68\n",
      "Loss 175.487 105 36\n",
      "Training Accuracy 0.675\n",
      "Loss 165.20119 106 36\n",
      "Training Accuracy 0.73\n",
      "Loss 170.59636 107 36\n",
      "Training Accuracy 0.7\n",
      "Loss 183.65933 108 36\n",
      "Training Accuracy 0.66\n",
      "Loss 182.95728 109 36\n",
      "Training Accuracy 0.65\n",
      "Loss 187.76065 110 36\n",
      "Training Accuracy 0.655\n",
      "Loss 184.62543 111 36\n",
      "Training Accuracy 0.655\n",
      "Loss 191.2927 112 36\n",
      "Training Accuracy 0.68\n",
      "Loss 201.3423 113 36\n",
      "Training Accuracy 0.68\n",
      "Loss 188.20114 114 36\n",
      "Training Accuracy 0.67\n",
      "Loss 191.30617 115 36\n",
      "Training Accuracy 0.675\n",
      "Loss 207.47649 116 36\n",
      "Training Accuracy 0.68\n",
      "Loss 140.25119 117 36\n",
      "Training Accuracy 0.755\n",
      "Loss 173.48047 118 36\n",
      "Training Accuracy 0.73\n",
      "Loss 201.92639 119 36\n",
      "Training Accuracy 0.635\n",
      "Loss 189.52098 120 36\n",
      "Training Accuracy 0.685\n",
      "Loss 182.13208 121 36\n",
      "Training Accuracy 0.715\n",
      "Loss 174.38275 122 36\n",
      "Training Accuracy 0.7\n",
      "Loss 183.05823 123 36\n",
      "Training Accuracy 0.65\n",
      "Loss 178.69264 124 36\n",
      "Training Accuracy 0.67\n",
      "Loss 163.28268 125 36\n",
      "Training Accuracy 0.71\n",
      "Loss 203.33644 126 36\n",
      "Training Accuracy 0.64\n",
      "Loss 183.98146 127 36\n",
      "Training Accuracy 0.65\n",
      "Loss 174.23648 128 36\n",
      "Training Accuracy 0.685\n",
      "Loss 167.84973 129 36\n",
      "Training Accuracy 0.75\n",
      "Loss 160.69722 130 36\n",
      "Training Accuracy 0.695\n",
      "Loss 164.45985 131 36\n",
      "Training Accuracy 0.725\n",
      "Loss 170.7563 132 36\n",
      "Training Accuracy 0.715\n",
      "Loss 173.86086 133 36\n",
      "Training Accuracy 0.68\n",
      "Loss 175.6153 134 36\n",
      "Training Accuracy 0.65\n",
      "Loss 187.02142 135 36\n",
      "Training Accuracy 0.66\n",
      "Loss 177.28143 136 36\n",
      "Training Accuracy 0.68\n",
      "Loss 198.68263 137 36\n",
      "Training Accuracy 0.66\n",
      "Loss 179.88431 138 36\n",
      "Training Accuracy 0.68\n",
      "Loss 186.14082 139 36\n",
      "Training Accuracy 0.685\n",
      "Loss 167.74606 140 36\n",
      "Training Accuracy 0.72\n",
      "Loss 190.40457 141 36\n",
      "Training Accuracy 0.69\n",
      "Loss 190.61397 142 36\n",
      "Training Accuracy 0.63\n",
      "Loss 153.65553 143 36\n",
      "Training Accuracy 0.745\n",
      "Loss 186.31459 144 36\n",
      "Training Accuracy 0.685\n",
      "Loss 174.94922 145 36\n",
      "Training Accuracy 0.685\n",
      "Loss 209.44289 146 36\n",
      "Training Accuracy 0.62\n",
      "Loss 186.95624 147 36\n",
      "Training Accuracy 0.68\n",
      "Loss 185.68695 148 36\n",
      "Training Accuracy 0.655\n",
      "Loss 182.82224 149 36\n",
      "Training Accuracy 0.715\n",
      "Loss 167.88916 150 36\n",
      "Training Accuracy 0.715\n",
      "Loss 201.39587 151 36\n",
      "Training Accuracy 0.655\n",
      "Loss 199.93056 152 36\n",
      "Training Accuracy 0.7\n",
      "Loss 165.966 153 36\n",
      "Training Accuracy 0.73\n",
      "Loss 178.59366 154 36\n",
      "Training Accuracy 0.695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 161.66272 155 36\n",
      "Training Accuracy 0.71\n",
      "Loss 187.69028 156 36\n",
      "Training Accuracy 0.665\n",
      "Loss 161.02217 157 36\n",
      "Training Accuracy 0.705\n",
      "Loss 176.78741 158 36\n",
      "Training Accuracy 0.71\n",
      "Loss 198.76962 159 36\n",
      "Training Accuracy 0.68\n",
      "Loss 178.121 160 36\n",
      "Training Accuracy 0.71\n",
      "Loss 203.88547 161 36\n",
      "Training Accuracy 0.635\n",
      "Loss 167.90575 162 36\n",
      "Training Accuracy 0.71\n",
      "Loss 189.77196 163 36\n",
      "Training Accuracy 0.695\n",
      "Loss 169.51025 164 36\n",
      "Training Accuracy 0.705\n",
      "Loss 184.29445 165 36\n",
      "Training Accuracy 0.685\n",
      "Loss 173.79298 166 36\n",
      "Training Accuracy 0.73\n",
      "Loss 166.76599 167 36\n",
      "Training Accuracy 0.705\n",
      "Loss 200.13394 168 36\n",
      "Training Accuracy 0.645\n",
      "Loss 161.52164 169 36\n",
      "Training Accuracy 0.75\n",
      "Loss 189.72568 170 36\n",
      "Training Accuracy 0.65\n",
      "Loss 183.57251 171 36\n",
      "Training Accuracy 0.735\n",
      "Loss 162.3606 172 36\n",
      "Training Accuracy 0.695\n",
      "Loss 187.16374 173 36\n",
      "Training Accuracy 0.695\n",
      "Loss 153.28915 174 36\n",
      "Training Accuracy 0.725\n",
      "Loss 161.45549 175 36\n",
      "Training Accuracy 0.73\n",
      "Loss 144.4003 176 36\n",
      "Training Accuracy 0.72\n",
      "Loss 207.13725 177 36\n",
      "Training Accuracy 0.645\n",
      "Loss 177.179 178 36\n",
      "Training Accuracy 0.705\n",
      "Loss 192.67319 179 36\n",
      "Training Accuracy 0.685\n",
      "Loss 182.40686 180 36\n",
      "Training Accuracy 0.68\n",
      "Loss 159.51141 181 36\n",
      "Training Accuracy 0.74\n",
      "Loss 198.64336 182 36\n",
      "Training Accuracy 0.68\n",
      "Loss 192.59363 183 36\n",
      "Training Accuracy 0.65\n",
      "Loss 159.52939 184 36\n",
      "Training Accuracy 0.73\n",
      "Loss 178.47093 185 36\n",
      "Training Accuracy 0.71\n",
      "Loss 167.85626 186 36\n",
      "Training Accuracy 0.69\n",
      "Loss 211.24799 187 36\n",
      "Training Accuracy 0.63\n",
      "Loss 179.70398 188 36\n",
      "Training Accuracy 0.71\n",
      "Loss 165.22319 189 36\n",
      "Training Accuracy 0.71\n",
      "Loss 167.22894 190 36\n",
      "Training Accuracy 0.715\n",
      "Loss 162.8312 191 36\n",
      "Training Accuracy 0.715\n",
      "Loss 189.79968 192 36\n",
      "Training Accuracy 0.685\n",
      "Loss 163.92021 193 36\n",
      "Training Accuracy 0.72\n",
      "Loss 162.6466 194 36\n",
      "Training Accuracy 0.74\n",
      "Loss 165.76126 195 36\n",
      "Training Accuracy 0.735\n",
      "Loss 159.67007 196 36\n",
      "Training Accuracy 0.75\n",
      "Loss 164.08658 197 36\n",
      "Training Accuracy 0.705\n",
      "Loss 173.5142 198 36\n",
      "Training Accuracy 0.68\n",
      "Loss 149.87471 199 36\n",
      "Training Accuracy 0.75\n",
      "Loss 154.9277 200 36\n",
      "Training Accuracy 0.74\n",
      "Loss 168.5669 201 36\n",
      "Training Accuracy 0.71\n",
      "Loss 165.43341 202 36\n",
      "Training Accuracy 0.695\n",
      "Loss 184.8756 203 36\n",
      "Training Accuracy 0.655\n",
      "Loss 170.48175 204 36\n",
      "Training Accuracy 0.685\n",
      "Loss 205.9699 205 36\n",
      "Training Accuracy 0.635\n",
      "Loss 175.1132 206 36\n",
      "Training Accuracy 0.715\n",
      "Loss 180.41661 207 36\n",
      "Training Accuracy 0.665\n",
      "Loss 190.4806 208 36\n",
      "Training Accuracy 0.69\n",
      "Loss 194.9555 209 36\n",
      "Training Accuracy 0.645\n",
      "Loss 166.78036 210 36\n",
      "Training Accuracy 0.72\n",
      "Loss 157.78175 211 36\n",
      "Training Accuracy 0.78\n",
      "Loss 178.06288 212 36\n",
      "Training Accuracy 0.665\n",
      "Loss 204.87758 213 36\n",
      "Training Accuracy 0.64\n",
      "Loss 170.08842 214 36\n",
      "Training Accuracy 0.68\n",
      "Loss 192.78561 215 36\n",
      "Training Accuracy 0.645\n",
      "Loss 187.26723 216 36\n",
      "Training Accuracy 0.68\n",
      "Loss 193.13869 217 36\n",
      "Training Accuracy 0.61\n",
      "Loss 196.0809 218 36\n",
      "Training Accuracy 0.66\n",
      "Loss 161.92189 219 36\n",
      "Training Accuracy 0.745\n",
      "Loss 178.85262 220 36\n",
      "Training Accuracy 0.675\n",
      "Loss 176.14902 221 36\n",
      "Training Accuracy 0.71\n",
      "Loss 179.40388 222 36\n",
      "Training Accuracy 0.69\n",
      "Loss 193.04834 223 36\n",
      "Training Accuracy 0.645\n",
      "Loss 193.48222 224 36\n",
      "Training Accuracy 0.665\n",
      "Loss 192.71098 225 36\n",
      "Training Accuracy 0.685\n",
      "Loss 149.57047 226 36\n",
      "Training Accuracy 0.765\n",
      "Loss 201.48312 227 36\n",
      "Training Accuracy 0.66\n",
      "Loss 214.08997 228 36\n",
      "Training Accuracy 0.655\n",
      "Loss 193.94283 229 36\n",
      "Training Accuracy 0.675\n",
      "Loss 189.76312 230 36\n",
      "Training Accuracy 0.69\n",
      "Loss 168.43742 231 36\n",
      "Training Accuracy 0.69\n",
      "Loss 192.36006 232 36\n",
      "Training Accuracy 0.685\n",
      "Loss 208.36084 233 36\n",
      "Training Accuracy 0.625\n",
      "Loss 177.82294 234 36\n",
      "Training Accuracy 0.685\n",
      "Loss 177.1762 235 36\n",
      "Training Accuracy 0.685\n",
      "Loss 160.37216 236 36\n",
      "Training Accuracy 0.72\n",
      "Loss 191.19821 237 36\n",
      "Training Accuracy 0.675\n",
      "Loss 165.68414 238 36\n",
      "Training Accuracy 0.69\n",
      "Loss 182.12097 239 36\n",
      "Training Accuracy 0.66\n",
      "Loss 186.57483 240 36\n",
      "Training Accuracy 0.66\n",
      "Loss 189.25008 241 36\n",
      "Training Accuracy 0.685\n",
      "Loss 179.84018 242 36\n",
      "Training Accuracy 0.68\n",
      "Loss 162.35858 243 36\n",
      "Training Accuracy 0.72\n",
      "Loss 183.21054 244 36\n",
      "Training Accuracy 0.695\n",
      "Loss 182.69641 245 36\n",
      "Training Accuracy 0.72\n",
      "Loss 199.39517 246 36\n",
      "Training Accuracy 0.65\n",
      "Loss 169.19487 247 36\n",
      "Training Accuracy 0.655\n",
      "Loss 158.39116 248 36\n",
      "Training Accuracy 0.705\n",
      "Loss 190.17976 249 36\n",
      "Training Accuracy 0.675\n",
      "Loss 183.20277 250 36\n",
      "Training Accuracy 0.69\n",
      "Loss 187.1035 251 36\n",
      "Training Accuracy 0.685\n",
      "Loss 152.91467 252 36\n",
      "Training Accuracy 0.735\n",
      "Loss 153.75604 253 36\n",
      "Training Accuracy 0.73\n",
      "Loss 176.89595 254 36\n",
      "Training Accuracy 0.71\n",
      "Loss 150.15965 255 36\n",
      "Training Accuracy 0.745\n",
      "Loss 193.62994 256 36\n",
      "Training Accuracy 0.665\n",
      "Loss 175.8665 257 36\n",
      "Training Accuracy 0.7\n",
      "Loss 193.87015 258 36\n",
      "Training Accuracy 0.675\n",
      "Loss 171.15335 259 36\n",
      "Training Accuracy 0.7\n",
      "Loss 149.8042 260 36\n",
      "Training Accuracy 0.72\n",
      "Loss 180.85037 261 36\n",
      "Training Accuracy 0.695\n",
      "Loss 179.84117 262 36\n",
      "Training Accuracy 0.71\n",
      "Loss 216.5476 263 36\n",
      "Training Accuracy 0.66\n",
      "Loss 190.44592 264 36\n",
      "Training Accuracy 0.69\n",
      "Loss 168.08388 265 36\n",
      "Training Accuracy 0.715\n",
      "Loss 169.23352 266 36\n",
      "Training Accuracy 0.685\n",
      "Loss 171.79066 267 36\n",
      "Training Accuracy 0.69\n",
      "Loss 191.87721 268 36\n",
      "Training Accuracy 0.655\n",
      "Loss 177.12897 269 36\n",
      "Training Accuracy 0.685\n",
      "Loss 159.80482 270 36\n",
      "Training Accuracy 0.71\n",
      "Loss 191.99919 271 36\n",
      "Training Accuracy 0.67\n",
      "Loss 172.40143 272 36\n",
      "Training Accuracy 0.725\n",
      "Loss 188.95326 273 36\n",
      "Training Accuracy 0.655\n",
      "Loss 173.60204 274 36\n",
      "Training Accuracy 0.73\n",
      "Loss 175.83188 275 36\n",
      "Training Accuracy 0.67\n",
      "Loss 169.6041 276 36\n",
      "Training Accuracy 0.69\n",
      "Loss 176.90439 277 36\n",
      "Training Accuracy 0.695\n",
      "Loss 162.57687 278 36\n",
      "Training Accuracy 0.695\n",
      "Loss 184.40039 279 36\n",
      "Training Accuracy 0.72\n",
      "Loss 184.66792 280 36\n",
      "Training Accuracy 0.64\n",
      "Loss 152.62299 281 36\n",
      "Training Accuracy 0.725\n",
      "Loss 167.59341 282 36\n",
      "Training Accuracy 0.745\n",
      "Loss 177.15868 283 36\n",
      "Training Accuracy 0.715\n",
      "Loss 147.9337 284 36\n",
      "Training Accuracy 0.755\n",
      "Loss 195.29381 285 36\n",
      "Training Accuracy 0.695\n",
      "Loss 183.59956 286 36\n",
      "Training Accuracy 0.7\n",
      "Loss 161.04442 287 36\n",
      "Training Accuracy 0.74\n",
      "Loss 187.0463 288 36\n",
      "Training Accuracy 0.665\n",
      "Loss 170.95529 289 36\n",
      "Training Accuracy 0.705\n",
      "Loss 169.39722 290 36\n",
      "Training Accuracy 0.695\n",
      "Loss 203.78123 291 36\n",
      "Training Accuracy 0.645\n",
      "Loss 116.37538 292 36\n",
      "Training Accuracy 0.65909094\n",
      "Loss 147.6938 1 37\n",
      "Training Accuracy 0.75\n",
      "Loss 174.41216 2 37\n",
      "Training Accuracy 0.71\n",
      "Loss 179.20114 3 37\n",
      "Training Accuracy 0.715\n",
      "Loss 178.30026 4 37\n",
      "Training Accuracy 0.7\n",
      "Loss 156.77136 5 37\n",
      "Training Accuracy 0.76\n",
      "Loss 178.79187 6 37\n",
      "Training Accuracy 0.69\n",
      "Loss 188.17426 7 37\n",
      "Training Accuracy 0.7\n",
      "Loss 184.73169 8 37\n",
      "Training Accuracy 0.695\n",
      "Loss 171.69888 9 37\n",
      "Training Accuracy 0.71\n",
      "Loss 181.44707 10 37\n",
      "Training Accuracy 0.675\n",
      "Loss 200.49326 11 37\n",
      "Training Accuracy 0.695\n",
      "Loss 160.80951 12 37\n",
      "Training Accuracy 0.705\n",
      "Loss 164.10141 13 37\n",
      "Training Accuracy 0.685\n",
      "Loss 194.08125 14 37\n",
      "Training Accuracy 0.68\n",
      "Loss 173.36197 15 37\n",
      "Training Accuracy 0.695\n",
      "Loss 216.42604 16 37\n",
      "Training Accuracy 0.69\n",
      "Loss 150.70958 17 37\n",
      "Training Accuracy 0.73\n",
      "Loss 158.70454 18 37\n",
      "Training Accuracy 0.73\n",
      "Loss 170.55504 19 37\n",
      "Training Accuracy 0.69\n",
      "Loss 174.3649 20 37\n",
      "Training Accuracy 0.66\n",
      "Loss 179.27345 21 37\n",
      "Training Accuracy 0.67\n",
      "Loss 175.04395 22 37\n",
      "Training Accuracy 0.685\n",
      "Loss 184.92775 23 37\n",
      "Training Accuracy 0.7\n",
      "Loss 194.87646 24 37\n",
      "Training Accuracy 0.685\n",
      "Loss 176.1429 25 37\n",
      "Training Accuracy 0.72\n",
      "Loss 182.1065 26 37\n",
      "Training Accuracy 0.685\n",
      "Loss 168.24529 27 37\n",
      "Training Accuracy 0.7\n",
      "Loss 166.56274 28 37\n",
      "Training Accuracy 0.715\n",
      "Loss 184.1575 29 37\n",
      "Training Accuracy 0.66\n",
      "Loss 182.22495 30 37\n",
      "Training Accuracy 0.715\n",
      "Loss 185.50616 31 37\n",
      "Training Accuracy 0.66\n",
      "Loss 169.92738 32 37\n",
      "Training Accuracy 0.68\n",
      "Loss 183.55753 33 37\n",
      "Training Accuracy 0.68\n",
      "Loss 163.85999 34 37\n",
      "Training Accuracy 0.705\n",
      "Loss 160.30759 35 37\n",
      "Training Accuracy 0.71\n",
      "Loss 185.02275 36 37\n",
      "Training Accuracy 0.7\n",
      "Loss 167.96019 37 37\n",
      "Training Accuracy 0.715\n",
      "Loss 187.37222 38 37\n",
      "Training Accuracy 0.685\n",
      "Loss 145.03584 39 37\n",
      "Training Accuracy 0.775\n",
      "Loss 178.13925 40 37\n",
      "Training Accuracy 0.685\n",
      "Loss 187.97737 41 37\n",
      "Training Accuracy 0.665\n",
      "Loss 218.3772 42 37\n",
      "Training Accuracy 0.605\n",
      "Loss 176.36032 43 37\n",
      "Training Accuracy 0.665\n",
      "Loss 165.98244 44 37\n",
      "Training Accuracy 0.695\n",
      "Loss 176.92433 45 37\n",
      "Training Accuracy 0.685\n",
      "Loss 184.95021 46 37\n",
      "Training Accuracy 0.745\n",
      "Loss 178.38911 47 37\n",
      "Training Accuracy 0.745\n",
      "Loss 156.14323 48 37\n",
      "Training Accuracy 0.74\n",
      "Loss 171.8914 49 37\n",
      "Training Accuracy 0.695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 193.83286 50 37\n",
      "Training Accuracy 0.68\n",
      "Loss 165.86919 51 37\n",
      "Training Accuracy 0.71\n",
      "Loss 157.3842 52 37\n",
      "Training Accuracy 0.75\n",
      "Loss 147.01039 53 37\n",
      "Training Accuracy 0.72\n",
      "Loss 191.66887 54 37\n",
      "Training Accuracy 0.68\n",
      "Loss 183.129 55 37\n",
      "Training Accuracy 0.685\n",
      "Loss 176.7524 56 37\n",
      "Training Accuracy 0.685\n",
      "Loss 179.09926 57 37\n",
      "Training Accuracy 0.705\n",
      "Loss 170.28307 58 37\n",
      "Training Accuracy 0.67\n",
      "Loss 189.16481 59 37\n",
      "Training Accuracy 0.645\n",
      "Loss 167.67969 60 37\n",
      "Training Accuracy 0.705\n",
      "Loss 180.01053 61 37\n",
      "Training Accuracy 0.685\n",
      "Loss 160.54825 62 37\n",
      "Training Accuracy 0.725\n",
      "Loss 168.19273 63 37\n",
      "Training Accuracy 0.72\n",
      "Loss 178.10901 64 37\n",
      "Training Accuracy 0.725\n",
      "Loss 184.25584 65 37\n",
      "Training Accuracy 0.66\n",
      "Loss 170.39136 66 37\n",
      "Training Accuracy 0.69\n",
      "Loss 168.17674 67 37\n",
      "Training Accuracy 0.695\n",
      "Loss 167.57712 68 37\n",
      "Training Accuracy 0.71\n",
      "Loss 180.64954 69 37\n",
      "Training Accuracy 0.69\n",
      "Loss 164.4499 70 37\n",
      "Training Accuracy 0.74\n",
      "Loss 173.13516 71 37\n",
      "Training Accuracy 0.745\n",
      "Loss 174.19017 72 37\n",
      "Training Accuracy 0.72\n",
      "Loss 183.54997 73 37\n",
      "Training Accuracy 0.68\n",
      "Loss 175.0633 74 37\n",
      "Training Accuracy 0.745\n",
      "Loss 185.97974 75 37\n",
      "Training Accuracy 0.67\n",
      "Loss 160.9501 76 37\n",
      "Training Accuracy 0.72\n",
      "Loss 198.86084 77 37\n",
      "Training Accuracy 0.645\n",
      "Loss 174.60672 78 37\n",
      "Training Accuracy 0.66\n",
      "Loss 180.93521 79 37\n",
      "Training Accuracy 0.64\n",
      "Loss 189.53722 80 37\n",
      "Training Accuracy 0.69\n",
      "Loss 160.81001 81 37\n",
      "Training Accuracy 0.755\n",
      "Loss 167.29504 82 37\n",
      "Training Accuracy 0.715\n",
      "Loss 173.21248 83 37\n",
      "Training Accuracy 0.695\n",
      "Loss 186.7339 84 37\n",
      "Training Accuracy 0.71\n",
      "Loss 184.29639 85 37\n",
      "Training Accuracy 0.685\n",
      "Loss 175.45291 86 37\n",
      "Training Accuracy 0.735\n",
      "Loss 198.70491 87 37\n",
      "Training Accuracy 0.68\n",
      "Loss 214.8182 88 37\n",
      "Training Accuracy 0.61\n",
      "Loss 173.25186 89 37\n",
      "Training Accuracy 0.7\n",
      "Loss 184.8064 90 37\n",
      "Training Accuracy 0.67\n",
      "Loss 179.5899 91 37\n",
      "Training Accuracy 0.69\n",
      "Loss 187.3933 92 37\n",
      "Training Accuracy 0.705\n",
      "Loss 175.52165 93 37\n",
      "Training Accuracy 0.715\n",
      "Loss 183.39404 94 37\n",
      "Training Accuracy 0.66\n",
      "Loss 163.87598 95 37\n",
      "Training Accuracy 0.695\n",
      "Loss 173.8484 96 37\n",
      "Training Accuracy 0.695\n",
      "Loss 188.68622 97 37\n",
      "Training Accuracy 0.675\n",
      "Loss 164.01857 98 37\n",
      "Training Accuracy 0.72\n",
      "Loss 163.87625 99 37\n",
      "Training Accuracy 0.705\n",
      "Loss 167.68156 100 37\n",
      "Training Accuracy 0.75\n",
      "Loss 202.98564 101 37\n",
      "Training Accuracy 0.64\n",
      "Loss 159.97592 102 37\n",
      "Training Accuracy 0.7\n",
      "Loss 177.11835 103 37\n",
      "Training Accuracy 0.715\n",
      "Loss 181.39175 104 37\n",
      "Training Accuracy 0.7\n",
      "Loss 176.15202 105 37\n",
      "Training Accuracy 0.68\n",
      "Loss 165.09805 106 37\n",
      "Training Accuracy 0.725\n",
      "Loss 171.05147 107 37\n",
      "Training Accuracy 0.705\n",
      "Loss 179.19426 108 37\n",
      "Training Accuracy 0.68\n",
      "Loss 170.72484 109 37\n",
      "Training Accuracy 0.69\n",
      "Loss 188.45872 110 37\n",
      "Training Accuracy 0.68\n",
      "Loss 186.9513 111 37\n",
      "Training Accuracy 0.67\n",
      "Loss 191.99303 112 37\n",
      "Training Accuracy 0.675\n",
      "Loss 207.71933 113 37\n",
      "Training Accuracy 0.65\n",
      "Loss 182.5055 114 37\n",
      "Training Accuracy 0.685\n",
      "Loss 197.07451 115 37\n",
      "Training Accuracy 0.68\n",
      "Loss 198.86177 116 37\n",
      "Training Accuracy 0.675\n",
      "Loss 137.24438 117 37\n",
      "Training Accuracy 0.765\n",
      "Loss 173.82628 118 37\n",
      "Training Accuracy 0.68\n",
      "Loss 205.79863 119 37\n",
      "Training Accuracy 0.63\n",
      "Loss 196.69965 120 37\n",
      "Training Accuracy 0.66\n",
      "Loss 181.15767 121 37\n",
      "Training Accuracy 0.685\n",
      "Loss 181.53696 122 37\n",
      "Training Accuracy 0.71\n",
      "Loss 173.63817 123 37\n",
      "Training Accuracy 0.68\n",
      "Loss 174.72246 124 37\n",
      "Training Accuracy 0.675\n",
      "Loss 170.56422 125 37\n",
      "Training Accuracy 0.695\n",
      "Loss 200.77742 126 37\n",
      "Training Accuracy 0.655\n",
      "Loss 178.82101 127 37\n",
      "Training Accuracy 0.685\n",
      "Loss 161.82011 128 37\n",
      "Training Accuracy 0.705\n",
      "Loss 168.50388 129 37\n",
      "Training Accuracy 0.73\n",
      "Loss 169.08212 130 37\n",
      "Training Accuracy 0.67\n",
      "Loss 168.15672 131 37\n",
      "Training Accuracy 0.72\n",
      "Loss 165.38982 132 37\n",
      "Training Accuracy 0.725\n",
      "Loss 165.54868 133 37\n",
      "Training Accuracy 0.72\n",
      "Loss 165.16798 134 37\n",
      "Training Accuracy 0.705\n",
      "Loss 180.4962 135 37\n",
      "Training Accuracy 0.7\n",
      "Loss 182.47122 136 37\n",
      "Training Accuracy 0.68\n",
      "Loss 191.40605 137 37\n",
      "Training Accuracy 0.71\n",
      "Loss 177.37784 138 37\n",
      "Training Accuracy 0.67\n",
      "Loss 185.28203 139 37\n",
      "Training Accuracy 0.67\n",
      "Loss 164.26006 140 37\n",
      "Training Accuracy 0.72\n",
      "Loss 169.84573 141 37\n",
      "Training Accuracy 0.71\n",
      "Loss 192.01733 142 37\n",
      "Training Accuracy 0.62\n",
      "Loss 166.04236 143 37\n",
      "Training Accuracy 0.695\n",
      "Loss 199.70926 144 37\n",
      "Training Accuracy 0.615\n",
      "Loss 174.98479 145 37\n",
      "Training Accuracy 0.67\n",
      "Loss 190.69304 146 37\n",
      "Training Accuracy 0.645\n",
      "Loss 192.74734 147 37\n",
      "Training Accuracy 0.665\n",
      "Loss 181.12592 148 37\n",
      "Training Accuracy 0.715\n",
      "Loss 178.33653 149 37\n",
      "Training Accuracy 0.7\n",
      "Loss 172.42021 150 37\n",
      "Training Accuracy 0.67\n",
      "Loss 182.89864 151 37\n",
      "Training Accuracy 0.72\n",
      "Loss 198.50383 152 37\n",
      "Training Accuracy 0.65\n",
      "Loss 169.40712 153 37\n",
      "Training Accuracy 0.72\n",
      "Loss 173.56073 154 37\n",
      "Training Accuracy 0.695\n",
      "Loss 166.46306 155 37\n",
      "Training Accuracy 0.695\n",
      "Loss 170.10828 156 37\n",
      "Training Accuracy 0.705\n",
      "Loss 161.68584 157 37\n",
      "Training Accuracy 0.705\n",
      "Loss 165.67934 158 37\n",
      "Training Accuracy 0.71\n",
      "Loss 207.054 159 37\n",
      "Training Accuracy 0.655\n",
      "Loss 182.79704 160 37\n",
      "Training Accuracy 0.67\n",
      "Loss 204.61443 161 37\n",
      "Training Accuracy 0.64\n",
      "Loss 169.48497 162 37\n",
      "Training Accuracy 0.72\n",
      "Loss 204.60158 163 37\n",
      "Training Accuracy 0.635\n",
      "Loss 156.66438 164 37\n",
      "Training Accuracy 0.715\n",
      "Loss 184.38635 165 37\n",
      "Training Accuracy 0.68\n",
      "Loss 168.41669 166 37\n",
      "Training Accuracy 0.77\n",
      "Loss 164.59322 167 37\n",
      "Training Accuracy 0.715\n",
      "Loss 184.8946 168 37\n",
      "Training Accuracy 0.69\n",
      "Loss 160.62239 169 37\n",
      "Training Accuracy 0.715\n",
      "Loss 190.46352 170 37\n",
      "Training Accuracy 0.665\n",
      "Loss 180.00726 171 37\n",
      "Training Accuracy 0.675\n",
      "Loss 158.29347 172 37\n",
      "Training Accuracy 0.73\n",
      "Loss 192.60968 173 37\n",
      "Training Accuracy 0.695\n",
      "Loss 159.21056 174 37\n",
      "Training Accuracy 0.715\n",
      "Loss 153.48703 175 37\n",
      "Training Accuracy 0.75\n",
      "Loss 143.83058 176 37\n",
      "Training Accuracy 0.785\n",
      "Loss 197.71738 177 37\n",
      "Training Accuracy 0.675\n",
      "Loss 167.2785 178 37\n",
      "Training Accuracy 0.73\n",
      "Loss 194.37561 179 37\n",
      "Training Accuracy 0.65\n",
      "Loss 192.79207 180 37\n",
      "Training Accuracy 0.68\n",
      "Loss 157.36086 181 37\n",
      "Training Accuracy 0.73\n",
      "Loss 188.0985 182 37\n",
      "Training Accuracy 0.665\n",
      "Loss 175.47134 183 37\n",
      "Training Accuracy 0.685\n",
      "Loss 144.27675 184 37\n",
      "Training Accuracy 0.78\n",
      "Loss 184.55856 185 37\n",
      "Training Accuracy 0.705\n",
      "Loss 182.03357 186 37\n",
      "Training Accuracy 0.675\n",
      "Loss 203.93939 187 37\n",
      "Training Accuracy 0.635\n",
      "Loss 187.92953 188 37\n",
      "Training Accuracy 0.64\n",
      "Loss 167.32787 189 37\n",
      "Training Accuracy 0.69\n",
      "Loss 171.6766 190 37\n",
      "Training Accuracy 0.68\n",
      "Loss 160.82639 191 37\n",
      "Training Accuracy 0.725\n",
      "Loss 194.31128 192 37\n",
      "Training Accuracy 0.675\n",
      "Loss 159.40504 193 37\n",
      "Training Accuracy 0.735\n",
      "Loss 167.77681 194 37\n",
      "Training Accuracy 0.725\n",
      "Loss 158.66916 195 37\n",
      "Training Accuracy 0.715\n",
      "Loss 168.07375 196 37\n",
      "Training Accuracy 0.665\n",
      "Loss 180.26538 197 37\n",
      "Training Accuracy 0.705\n",
      "Loss 171.27199 198 37\n",
      "Training Accuracy 0.66\n",
      "Loss 157.88702 199 37\n",
      "Training Accuracy 0.75\n",
      "Loss 173.38225 200 37\n",
      "Training Accuracy 0.67\n",
      "Loss 172.91107 201 37\n",
      "Training Accuracy 0.695\n",
      "Loss 165.8043 202 37\n",
      "Training Accuracy 0.675\n",
      "Loss 189.38562 203 37\n",
      "Training Accuracy 0.685\n",
      "Loss 170.36832 204 37\n",
      "Training Accuracy 0.7\n",
      "Loss 194.43695 205 37\n",
      "Training Accuracy 0.64\n",
      "Loss 174.24873 206 37\n",
      "Training Accuracy 0.73\n",
      "Loss 184.0639 207 37\n",
      "Training Accuracy 0.685\n",
      "Loss 175.78189 208 37\n",
      "Training Accuracy 0.705\n",
      "Loss 179.95117 209 37\n",
      "Training Accuracy 0.7\n",
      "Loss 166.87268 210 37\n",
      "Training Accuracy 0.73\n",
      "Loss 156.29158 211 37\n",
      "Training Accuracy 0.725\n",
      "Loss 175.32542 212 37\n",
      "Training Accuracy 0.65\n",
      "Loss 199.54239 213 37\n",
      "Training Accuracy 0.68\n",
      "Loss 170.88657 214 37\n",
      "Training Accuracy 0.705\n",
      "Loss 188.86249 215 37\n",
      "Training Accuracy 0.665\n",
      "Loss 171.49481 216 37\n",
      "Training Accuracy 0.71\n",
      "Loss 187.88728 217 37\n",
      "Training Accuracy 0.615\n",
      "Loss 192.1674 218 37\n",
      "Training Accuracy 0.65\n",
      "Loss 165.89355 219 37\n",
      "Training Accuracy 0.765\n",
      "Loss 167.33032 220 37\n",
      "Training Accuracy 0.735\n",
      "Loss 182.74615 221 37\n",
      "Training Accuracy 0.7\n",
      "Loss 169.26033 222 37\n",
      "Training Accuracy 0.69\n",
      "Loss 184.92773 223 37\n",
      "Training Accuracy 0.68\n",
      "Loss 195.44952 224 37\n",
      "Training Accuracy 0.66\n",
      "Loss 192.44136 225 37\n",
      "Training Accuracy 0.665\n",
      "Loss 139.80629 226 37\n",
      "Training Accuracy 0.75\n",
      "Loss 196.71494 227 37\n",
      "Training Accuracy 0.665\n",
      "Loss 209.96626 228 37\n",
      "Training Accuracy 0.67\n",
      "Loss 166.68124 229 37\n",
      "Training Accuracy 0.715\n",
      "Loss 187.1823 230 37\n",
      "Training Accuracy 0.665\n",
      "Loss 165.20883 231 37\n",
      "Training Accuracy 0.685\n",
      "Loss 188.44235 232 37\n",
      "Training Accuracy 0.685\n",
      "Loss 204.13083 233 37\n",
      "Training Accuracy 0.61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 184.78654 234 37\n",
      "Training Accuracy 0.615\n",
      "Loss 166.91837 235 37\n",
      "Training Accuracy 0.75\n",
      "Loss 158.28255 236 37\n",
      "Training Accuracy 0.72\n",
      "Loss 181.47493 237 37\n",
      "Training Accuracy 0.69\n",
      "Loss 161.104 238 37\n",
      "Training Accuracy 0.68\n",
      "Loss 177.63054 239 37\n",
      "Training Accuracy 0.675\n",
      "Loss 171.9392 240 37\n",
      "Training Accuracy 0.67\n",
      "Loss 195.7676 241 37\n",
      "Training Accuracy 0.66\n",
      "Loss 177.89006 242 37\n",
      "Training Accuracy 0.695\n",
      "Loss 150.3991 243 37\n",
      "Training Accuracy 0.75\n",
      "Loss 174.45673 244 37\n",
      "Training Accuracy 0.705\n",
      "Loss 172.11241 245 37\n",
      "Training Accuracy 0.715\n",
      "Loss 198.16866 246 37\n",
      "Training Accuracy 0.65\n",
      "Loss 154.6403 247 37\n",
      "Training Accuracy 0.7\n",
      "Loss 150.9463 248 37\n",
      "Training Accuracy 0.74\n",
      "Loss 190.4691 249 37\n",
      "Training Accuracy 0.65\n",
      "Loss 179.82889 250 37\n",
      "Training Accuracy 0.715\n",
      "Loss 183.80064 251 37\n",
      "Training Accuracy 0.66\n",
      "Loss 149.11673 252 37\n",
      "Training Accuracy 0.715\n",
      "Loss 148.56659 253 37\n",
      "Training Accuracy 0.755\n",
      "Loss 184.72125 254 37\n",
      "Training Accuracy 0.66\n",
      "Loss 167.9985 255 37\n",
      "Training Accuracy 0.695\n",
      "Loss 200.2296 256 37\n",
      "Training Accuracy 0.63\n",
      "Loss 177.36882 257 37\n",
      "Training Accuracy 0.705\n",
      "Loss 192.08005 258 37\n",
      "Training Accuracy 0.695\n",
      "Loss 170.22838 259 37\n",
      "Training Accuracy 0.7\n",
      "Loss 147.42036 260 37\n",
      "Training Accuracy 0.75\n",
      "Loss 190.07402 261 37\n",
      "Training Accuracy 0.695\n",
      "Loss 187.77173 262 37\n",
      "Training Accuracy 0.65\n",
      "Loss 207.6096 263 37\n",
      "Training Accuracy 0.645\n",
      "Loss 192.0428 264 37\n",
      "Training Accuracy 0.71\n",
      "Loss 169.32195 265 37\n",
      "Training Accuracy 0.71\n",
      "Loss 165.25067 266 37\n",
      "Training Accuracy 0.705\n",
      "Loss 174.81471 267 37\n",
      "Training Accuracy 0.7\n",
      "Loss 192.1717 268 37\n",
      "Training Accuracy 0.67\n",
      "Loss 167.54578 269 37\n",
      "Training Accuracy 0.68\n",
      "Loss 159.50851 270 37\n",
      "Training Accuracy 0.695\n",
      "Loss 190.48335 271 37\n",
      "Training Accuracy 0.685\n",
      "Loss 172.91968 272 37\n",
      "Training Accuracy 0.71\n",
      "Loss 189.7025 273 37\n",
      "Training Accuracy 0.675\n",
      "Loss 182.488 274 37\n",
      "Training Accuracy 0.715\n",
      "Loss 166.56989 275 37\n",
      "Training Accuracy 0.73\n",
      "Loss 159.7326 276 37\n",
      "Training Accuracy 0.73\n",
      "Loss 179.46071 277 37\n",
      "Training Accuracy 0.71\n",
      "Loss 163.37744 278 37\n",
      "Training Accuracy 0.715\n",
      "Loss 173.63063 279 37\n",
      "Training Accuracy 0.725\n",
      "Loss 174.3284 280 37\n",
      "Training Accuracy 0.72\n",
      "Loss 160.62366 281 37\n",
      "Training Accuracy 0.69\n",
      "Loss 167.77843 282 37\n",
      "Training Accuracy 0.715\n",
      "Loss 173.05469 283 37\n",
      "Training Accuracy 0.73\n",
      "Loss 146.75104 284 37\n",
      "Training Accuracy 0.74\n",
      "Loss 199.85826 285 37\n",
      "Training Accuracy 0.655\n",
      "Loss 167.10855 286 37\n",
      "Training Accuracy 0.73\n",
      "Loss 148.39986 287 37\n",
      "Training Accuracy 0.725\n",
      "Loss 182.36111 288 37\n",
      "Training Accuracy 0.68\n",
      "Loss 175.03624 289 37\n",
      "Training Accuracy 0.725\n",
      "Loss 170.88414 290 37\n",
      "Training Accuracy 0.715\n",
      "Loss 202.08841 291 37\n",
      "Training Accuracy 0.645\n",
      "Loss 116.43771 292 37\n",
      "Training Accuracy 0.6818182\n",
      "Loss 143.00002 1 38\n",
      "Training Accuracy 0.77\n",
      "Loss 170.07623 2 38\n",
      "Training Accuracy 0.72\n",
      "Loss 163.01843 3 38\n",
      "Training Accuracy 0.71\n",
      "Loss 187.21611 4 38\n",
      "Training Accuracy 0.7\n",
      "Loss 155.17319 5 38\n",
      "Training Accuracy 0.74\n",
      "Loss 177.61528 6 38\n",
      "Training Accuracy 0.695\n",
      "Loss 177.00221 7 38\n",
      "Training Accuracy 0.71\n",
      "Loss 182.22421 8 38\n",
      "Training Accuracy 0.71\n",
      "Loss 164.96867 9 38\n",
      "Training Accuracy 0.72\n",
      "Loss 190.46533 10 38\n",
      "Training Accuracy 0.675\n",
      "Loss 197.6201 11 38\n",
      "Training Accuracy 0.675\n",
      "Loss 158.1029 12 38\n",
      "Training Accuracy 0.725\n",
      "Loss 168.0082 13 38\n",
      "Training Accuracy 0.695\n",
      "Loss 179.99155 14 38\n",
      "Training Accuracy 0.72\n",
      "Loss 162.45706 15 38\n",
      "Training Accuracy 0.735\n",
      "Loss 218.6084 16 38\n",
      "Training Accuracy 0.675\n",
      "Loss 137.41339 17 38\n",
      "Training Accuracy 0.775\n",
      "Loss 159.22867 18 38\n",
      "Training Accuracy 0.7\n",
      "Loss 167.98366 19 38\n",
      "Training Accuracy 0.72\n",
      "Loss 159.27567 20 38\n",
      "Training Accuracy 0.72\n",
      "Loss 170.20113 21 38\n",
      "Training Accuracy 0.72\n",
      "Loss 169.5476 22 38\n",
      "Training Accuracy 0.725\n",
      "Loss 185.91605 23 38\n",
      "Training Accuracy 0.675\n",
      "Loss 192.74644 24 38\n",
      "Training Accuracy 0.655\n",
      "Loss 173.52542 25 38\n",
      "Training Accuracy 0.7\n",
      "Loss 177.36847 26 38\n",
      "Training Accuracy 0.67\n",
      "Loss 173.44336 27 38\n",
      "Training Accuracy 0.73\n",
      "Loss 163.33652 28 38\n",
      "Training Accuracy 0.705\n",
      "Loss 182.00375 29 38\n",
      "Training Accuracy 0.66\n",
      "Loss 187.77122 30 38\n",
      "Training Accuracy 0.705\n",
      "Loss 188.69637 31 38\n",
      "Training Accuracy 0.675\n",
      "Loss 177.28038 32 38\n",
      "Training Accuracy 0.685\n",
      "Loss 170.72539 33 38\n",
      "Training Accuracy 0.745\n",
      "Loss 162.57811 34 38\n",
      "Training Accuracy 0.73\n",
      "Loss 167.08932 35 38\n",
      "Training Accuracy 0.72\n",
      "Loss 175.19957 36 38\n",
      "Training Accuracy 0.72\n",
      "Loss 158.55757 37 38\n",
      "Training Accuracy 0.715\n",
      "Loss 183.63599 38 38\n",
      "Training Accuracy 0.67\n",
      "Loss 147.07893 39 38\n",
      "Training Accuracy 0.73\n",
      "Loss 177.65804 40 38\n",
      "Training Accuracy 0.68\n",
      "Loss 180.29778 41 38\n",
      "Training Accuracy 0.68\n",
      "Loss 202.9189 42 38\n",
      "Training Accuracy 0.67\n",
      "Loss 163.68793 43 38\n",
      "Training Accuracy 0.715\n",
      "Loss 174.5574 44 38\n",
      "Training Accuracy 0.68\n",
      "Loss 166.0242 45 38\n",
      "Training Accuracy 0.73\n",
      "Loss 203.21678 46 38\n",
      "Training Accuracy 0.635\n",
      "Loss 168.57968 47 38\n",
      "Training Accuracy 0.71\n",
      "Loss 152.08286 48 38\n",
      "Training Accuracy 0.695\n",
      "Loss 168.22884 49 38\n",
      "Training Accuracy 0.72\n",
      "Loss 197.99336 50 38\n",
      "Training Accuracy 0.67\n",
      "Loss 141.4677 51 38\n",
      "Training Accuracy 0.775\n",
      "Loss 150.3804 52 38\n",
      "Training Accuracy 0.77\n",
      "Loss 144.53952 53 38\n",
      "Training Accuracy 0.745\n",
      "Loss 188.52827 54 38\n",
      "Training Accuracy 0.68\n",
      "Loss 175.50623 55 38\n",
      "Training Accuracy 0.715\n",
      "Loss 176.75415 56 38\n",
      "Training Accuracy 0.7\n",
      "Loss 172.3966 57 38\n",
      "Training Accuracy 0.695\n",
      "Loss 167.07231 58 38\n",
      "Training Accuracy 0.72\n",
      "Loss 187.6574 59 38\n",
      "Training Accuracy 0.695\n",
      "Loss 175.09457 60 38\n",
      "Training Accuracy 0.74\n",
      "Loss 182.96973 61 38\n",
      "Training Accuracy 0.655\n",
      "Loss 167.6301 62 38\n",
      "Training Accuracy 0.695\n",
      "Loss 169.5533 63 38\n",
      "Training Accuracy 0.705\n",
      "Loss 170.99455 64 38\n",
      "Training Accuracy 0.725\n",
      "Loss 179.36559 65 38\n",
      "Training Accuracy 0.655\n",
      "Loss 160.36682 66 38\n",
      "Training Accuracy 0.7\n",
      "Loss 183.28258 67 38\n",
      "Training Accuracy 0.65\n",
      "Loss 168.95715 68 38\n",
      "Training Accuracy 0.695\n",
      "Loss 174.37022 69 38\n",
      "Training Accuracy 0.68\n",
      "Loss 175.81818 70 38\n",
      "Training Accuracy 0.7\n",
      "Loss 177.3373 71 38\n",
      "Training Accuracy 0.715\n",
      "Loss 180.08011 72 38\n",
      "Training Accuracy 0.72\n",
      "Loss 205.33028 73 38\n",
      "Training Accuracy 0.605\n",
      "Loss 176.88068 74 38\n",
      "Training Accuracy 0.655\n",
      "Loss 181.13696 75 38\n",
      "Training Accuracy 0.715\n",
      "Loss 162.7035 76 38\n",
      "Training Accuracy 0.715\n",
      "Loss 196.1092 77 38\n",
      "Training Accuracy 0.685\n",
      "Loss 180.59581 78 38\n",
      "Training Accuracy 0.7\n",
      "Loss 173.5029 79 38\n",
      "Training Accuracy 0.665\n",
      "Loss 188.83961 80 38\n",
      "Training Accuracy 0.71\n",
      "Loss 157.06773 81 38\n",
      "Training Accuracy 0.705\n",
      "Loss 160.31335 82 38\n",
      "Training Accuracy 0.73\n",
      "Loss 178.68045 83 38\n",
      "Training Accuracy 0.715\n",
      "Loss 184.91898 84 38\n",
      "Training Accuracy 0.695\n",
      "Loss 163.81834 85 38\n",
      "Training Accuracy 0.72\n",
      "Loss 178.16153 86 38\n",
      "Training Accuracy 0.695\n",
      "Loss 216.89053 87 38\n",
      "Training Accuracy 0.66\n",
      "Loss 196.74608 88 38\n",
      "Training Accuracy 0.68\n",
      "Loss 176.28735 89 38\n",
      "Training Accuracy 0.7\n",
      "Loss 179.52518 90 38\n",
      "Training Accuracy 0.69\n",
      "Loss 183.72234 91 38\n",
      "Training Accuracy 0.66\n",
      "Loss 170.4777 92 38\n",
      "Training Accuracy 0.71\n",
      "Loss 170.95323 93 38\n",
      "Training Accuracy 0.71\n",
      "Loss 179.1942 94 38\n",
      "Training Accuracy 0.675\n",
      "Loss 175.70247 95 38\n",
      "Training Accuracy 0.66\n",
      "Loss 175.41116 96 38\n",
      "Training Accuracy 0.695\n",
      "Loss 179.45732 97 38\n",
      "Training Accuracy 0.665\n",
      "Loss 156.53014 98 38\n",
      "Training Accuracy 0.75\n",
      "Loss 153.51456 99 38\n",
      "Training Accuracy 0.75\n",
      "Loss 167.55916 100 38\n",
      "Training Accuracy 0.73\n",
      "Loss 184.78972 101 38\n",
      "Training Accuracy 0.65\n",
      "Loss 168.91835 102 38\n",
      "Training Accuracy 0.7\n",
      "Loss 180.28935 103 38\n",
      "Training Accuracy 0.685\n",
      "Loss 179.54477 104 38\n",
      "Training Accuracy 0.7\n",
      "Loss 171.77258 105 38\n",
      "Training Accuracy 0.71\n",
      "Loss 163.47523 106 38\n",
      "Training Accuracy 0.74\n",
      "Loss 165.37389 107 38\n",
      "Training Accuracy 0.725\n",
      "Loss 173.3864 108 38\n",
      "Training Accuracy 0.695\n",
      "Loss 180.59846 109 38\n",
      "Training Accuracy 0.655\n",
      "Loss 175.0256 110 38\n",
      "Training Accuracy 0.705\n",
      "Loss 187.20137 111 38\n",
      "Training Accuracy 0.65\n",
      "Loss 180.31508 112 38\n",
      "Training Accuracy 0.73\n",
      "Loss 187.43762 113 38\n",
      "Training Accuracy 0.7\n",
      "Loss 178.41267 114 38\n",
      "Training Accuracy 0.675\n",
      "Loss 194.35835 115 38\n",
      "Training Accuracy 0.665\n",
      "Loss 198.84267 116 38\n",
      "Training Accuracy 0.65\n",
      "Loss 137.1286 117 38\n",
      "Training Accuracy 0.765\n",
      "Loss 164.63797 118 38\n",
      "Training Accuracy 0.73\n",
      "Loss 196.07004 119 38\n",
      "Training Accuracy 0.665\n",
      "Loss 185.20555 120 38\n",
      "Training Accuracy 0.7\n",
      "Loss 171.27414 121 38\n",
      "Training Accuracy 0.695\n",
      "Loss 173.04272 122 38\n",
      "Training Accuracy 0.73\n",
      "Loss 163.09644 123 38\n",
      "Training Accuracy 0.72\n",
      "Loss 169.41855 124 38\n",
      "Training Accuracy 0.69\n",
      "Loss 155.45282 125 38\n",
      "Training Accuracy 0.745\n",
      "Loss 195.59142 126 38\n",
      "Training Accuracy 0.655\n",
      "Loss 178.70827 127 38\n",
      "Training Accuracy 0.65\n",
      "Loss 166.18098 128 38\n",
      "Training Accuracy 0.74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 158.993 129 38\n",
      "Training Accuracy 0.76\n",
      "Loss 157.69626 130 38\n",
      "Training Accuracy 0.71\n",
      "Loss 152.39687 131 38\n",
      "Training Accuracy 0.75\n",
      "Loss 157.4179 132 38\n",
      "Training Accuracy 0.75\n",
      "Loss 162.45866 133 38\n",
      "Training Accuracy 0.74\n",
      "Loss 162.5124 134 38\n",
      "Training Accuracy 0.725\n",
      "Loss 173.38263 135 38\n",
      "Training Accuracy 0.7\n",
      "Loss 178.63393 136 38\n",
      "Training Accuracy 0.705\n",
      "Loss 202.57907 137 38\n",
      "Training Accuracy 0.67\n",
      "Loss 177.55203 138 38\n",
      "Training Accuracy 0.695\n",
      "Loss 190.90306 139 38\n",
      "Training Accuracy 0.69\n",
      "Loss 162.79982 140 38\n",
      "Training Accuracy 0.73\n",
      "Loss 173.69958 141 38\n",
      "Training Accuracy 0.695\n",
      "Loss 192.54442 142 38\n",
      "Training Accuracy 0.635\n",
      "Loss 163.7098 143 38\n",
      "Training Accuracy 0.725\n",
      "Loss 193.72723 144 38\n",
      "Training Accuracy 0.675\n",
      "Loss 163.10338 145 38\n",
      "Training Accuracy 0.69\n",
      "Loss 189.84393 146 38\n",
      "Training Accuracy 0.67\n",
      "Loss 184.77809 147 38\n",
      "Training Accuracy 0.665\n",
      "Loss 185.19249 148 38\n",
      "Training Accuracy 0.635\n",
      "Loss 168.68707 149 38\n",
      "Training Accuracy 0.725\n",
      "Loss 173.05876 150 38\n",
      "Training Accuracy 0.7\n",
      "Loss 180.28047 151 38\n",
      "Training Accuracy 0.715\n",
      "Loss 188.67825 152 38\n",
      "Training Accuracy 0.66\n",
      "Loss 171.76471 153 38\n",
      "Training Accuracy 0.675\n",
      "Loss 169.47171 154 38\n",
      "Training Accuracy 0.72\n",
      "Loss 169.6265 155 38\n",
      "Training Accuracy 0.705\n",
      "Loss 182.40097 156 38\n",
      "Training Accuracy 0.665\n",
      "Loss 155.88007 157 38\n",
      "Training Accuracy 0.745\n",
      "Loss 169.30685 158 38\n",
      "Training Accuracy 0.675\n",
      "Loss 198.38675 159 38\n",
      "Training Accuracy 0.64\n",
      "Loss 165.59581 160 38\n",
      "Training Accuracy 0.715\n",
      "Loss 194.87064 161 38\n",
      "Training Accuracy 0.665\n",
      "Loss 165.87181 162 38\n",
      "Training Accuracy 0.705\n",
      "Loss 199.68413 163 38\n",
      "Training Accuracy 0.665\n",
      "Loss 161.57788 164 38\n",
      "Training Accuracy 0.71\n",
      "Loss 170.80905 165 38\n",
      "Training Accuracy 0.745\n",
      "Loss 170.2965 166 38\n",
      "Training Accuracy 0.775\n",
      "Loss 158.28732 167 38\n",
      "Training Accuracy 0.725\n",
      "Loss 198.41235 168 38\n",
      "Training Accuracy 0.675\n",
      "Loss 160.0642 169 38\n",
      "Training Accuracy 0.715\n",
      "Loss 192.09518 170 38\n",
      "Training Accuracy 0.68\n",
      "Loss 178.21066 171 38\n",
      "Training Accuracy 0.72\n",
      "Loss 166.83798 172 38\n",
      "Training Accuracy 0.695\n",
      "Loss 192.61626 173 38\n",
      "Training Accuracy 0.665\n",
      "Loss 147.08919 174 38\n",
      "Training Accuracy 0.76\n",
      "Loss 148.75627 175 38\n",
      "Training Accuracy 0.785\n",
      "Loss 139.29591 176 38\n",
      "Training Accuracy 0.76\n",
      "Loss 183.40872 177 38\n",
      "Training Accuracy 0.665\n",
      "Loss 168.0676 178 38\n",
      "Training Accuracy 0.7\n",
      "Loss 184.7417 179 38\n",
      "Training Accuracy 0.68\n",
      "Loss 172.55353 180 38\n",
      "Training Accuracy 0.705\n",
      "Loss 161.96898 181 38\n",
      "Training Accuracy 0.745\n",
      "Loss 178.43492 182 38\n",
      "Training Accuracy 0.655\n",
      "Loss 185.75328 183 38\n",
      "Training Accuracy 0.665\n",
      "Loss 160.48782 184 38\n",
      "Training Accuracy 0.735\n",
      "Loss 164.88004 185 38\n",
      "Training Accuracy 0.73\n",
      "Loss 171.6449 186 38\n",
      "Training Accuracy 0.665\n",
      "Loss 208.34718 187 38\n",
      "Training Accuracy 0.655\n",
      "Loss 184.19473 188 38\n",
      "Training Accuracy 0.665\n",
      "Loss 170.7966 189 38\n",
      "Training Accuracy 0.69\n",
      "Loss 160.09163 190 38\n",
      "Training Accuracy 0.755\n",
      "Loss 158.89224 191 38\n",
      "Training Accuracy 0.74\n",
      "Loss 184.31792 192 38\n",
      "Training Accuracy 0.7\n",
      "Loss 160.7825 193 38\n",
      "Training Accuracy 0.705\n",
      "Loss 163.43964 194 38\n",
      "Training Accuracy 0.73\n",
      "Loss 155.82729 195 38\n",
      "Training Accuracy 0.75\n",
      "Loss 167.32806 196 38\n",
      "Training Accuracy 0.72\n",
      "Loss 167.23775 197 38\n",
      "Training Accuracy 0.72\n",
      "Loss 166.24733 198 38\n",
      "Training Accuracy 0.675\n",
      "Loss 144.18407 199 38\n",
      "Training Accuracy 0.72\n",
      "Loss 162.99055 200 38\n",
      "Training Accuracy 0.69\n",
      "Loss 170.60585 201 38\n",
      "Training Accuracy 0.71\n",
      "Loss 173.95804 202 38\n",
      "Training Accuracy 0.68\n",
      "Loss 179.65924 203 38\n",
      "Training Accuracy 0.68\n",
      "Loss 170.75128 204 38\n",
      "Training Accuracy 0.665\n",
      "Loss 184.82974 205 38\n",
      "Training Accuracy 0.71\n",
      "Loss 180.28719 206 38\n",
      "Training Accuracy 0.7\n",
      "Loss 177.22408 207 38\n",
      "Training Accuracy 0.695\n",
      "Loss 178.09058 208 38\n",
      "Training Accuracy 0.71\n",
      "Loss 184.17143 209 38\n",
      "Training Accuracy 0.68\n",
      "Loss 155.76219 210 38\n",
      "Training Accuracy 0.735\n",
      "Loss 158.35857 211 38\n",
      "Training Accuracy 0.74\n",
      "Loss 168.123 212 38\n",
      "Training Accuracy 0.695\n",
      "Loss 198.95067 213 38\n",
      "Training Accuracy 0.685\n",
      "Loss 174.7572 214 38\n",
      "Training Accuracy 0.725\n",
      "Loss 190.6868 215 38\n",
      "Training Accuracy 0.695\n",
      "Loss 186.17542 216 38\n",
      "Training Accuracy 0.705\n",
      "Loss 182.17964 217 38\n",
      "Training Accuracy 0.665\n",
      "Loss 171.99823 218 38\n",
      "Training Accuracy 0.725\n",
      "Loss 167.13585 219 38\n",
      "Training Accuracy 0.705\n",
      "Loss 164.1476 220 38\n",
      "Training Accuracy 0.73\n",
      "Loss 176.88943 221 38\n",
      "Training Accuracy 0.695\n",
      "Loss 166.71567 222 38\n",
      "Training Accuracy 0.685\n",
      "Loss 185.8298 223 38\n",
      "Training Accuracy 0.685\n",
      "Loss 191.43738 224 38\n",
      "Training Accuracy 0.66\n",
      "Loss 191.59076 225 38\n",
      "Training Accuracy 0.695\n",
      "Loss 140.85341 226 38\n",
      "Training Accuracy 0.755\n",
      "Loss 184.35207 227 38\n",
      "Training Accuracy 0.675\n",
      "Loss 211.87862 228 38\n",
      "Training Accuracy 0.65\n",
      "Loss 161.381 229 38\n",
      "Training Accuracy 0.71\n",
      "Loss 185.42326 230 38\n",
      "Training Accuracy 0.68\n",
      "Loss 160.2536 231 38\n",
      "Training Accuracy 0.745\n",
      "Loss 192.15057 232 38\n",
      "Training Accuracy 0.665\n",
      "Loss 196.46588 233 38\n",
      "Training Accuracy 0.59\n",
      "Loss 171.45009 234 38\n",
      "Training Accuracy 0.675\n",
      "Loss 167.90343 235 38\n",
      "Training Accuracy 0.77\n",
      "Loss 162.36938 236 38\n",
      "Training Accuracy 0.74\n",
      "Loss 170.4278 237 38\n",
      "Training Accuracy 0.705\n",
      "Loss 159.75403 238 38\n",
      "Training Accuracy 0.675\n",
      "Loss 191.22261 239 38\n",
      "Training Accuracy 0.68\n",
      "Loss 172.20279 240 38\n",
      "Training Accuracy 0.705\n",
      "Loss 190.8093 241 38\n",
      "Training Accuracy 0.705\n",
      "Loss 184.34627 242 38\n",
      "Training Accuracy 0.68\n",
      "Loss 150.21423 243 38\n",
      "Training Accuracy 0.745\n",
      "Loss 171.52942 244 38\n",
      "Training Accuracy 0.66\n",
      "Loss 168.63751 245 38\n",
      "Training Accuracy 0.73\n",
      "Loss 189.77466 246 38\n",
      "Training Accuracy 0.66\n",
      "Loss 158.17905 247 38\n",
      "Training Accuracy 0.705\n",
      "Loss 154.84961 248 38\n",
      "Training Accuracy 0.765\n",
      "Loss 188.88167 249 38\n",
      "Training Accuracy 0.63\n",
      "Loss 181.97878 250 38\n",
      "Training Accuracy 0.665\n",
      "Loss 189.67221 251 38\n",
      "Training Accuracy 0.65\n",
      "Loss 152.04381 252 38\n",
      "Training Accuracy 0.725\n",
      "Loss 146.48126 253 38\n",
      "Training Accuracy 0.765\n",
      "Loss 177.35487 254 38\n",
      "Training Accuracy 0.705\n",
      "Loss 154.60678 255 38\n",
      "Training Accuracy 0.715\n",
      "Loss 198.00368 256 38\n",
      "Training Accuracy 0.65\n",
      "Loss 164.11635 257 38\n",
      "Training Accuracy 0.74\n",
      "Loss 177.65376 258 38\n",
      "Training Accuracy 0.7\n",
      "Loss 171.54558 259 38\n",
      "Training Accuracy 0.7\n",
      "Loss 140.54005 260 38\n",
      "Training Accuracy 0.725\n",
      "Loss 184.98386 261 38\n",
      "Training Accuracy 0.7\n",
      "Loss 183.9001 262 38\n",
      "Training Accuracy 0.69\n",
      "Loss 197.56717 263 38\n",
      "Training Accuracy 0.695\n",
      "Loss 181.63971 264 38\n",
      "Training Accuracy 0.7\n",
      "Loss 155.75998 265 38\n",
      "Training Accuracy 0.72\n",
      "Loss 164.41252 266 38\n",
      "Training Accuracy 0.695\n",
      "Loss 178.24872 267 38\n",
      "Training Accuracy 0.685\n",
      "Loss 186.16754 268 38\n",
      "Training Accuracy 0.66\n",
      "Loss 175.17531 269 38\n",
      "Training Accuracy 0.67\n",
      "Loss 144.87488 270 38\n",
      "Training Accuracy 0.735\n",
      "Loss 191.9795 271 38\n",
      "Training Accuracy 0.685\n",
      "Loss 170.57574 272 38\n",
      "Training Accuracy 0.705\n",
      "Loss 192.3259 273 38\n",
      "Training Accuracy 0.675\n",
      "Loss 168.01193 274 38\n",
      "Training Accuracy 0.715\n",
      "Loss 172.43547 275 38\n",
      "Training Accuracy 0.675\n",
      "Loss 164.36263 276 38\n",
      "Training Accuracy 0.715\n",
      "Loss 167.834 277 38\n",
      "Training Accuracy 0.705\n",
      "Loss 165.37315 278 38\n",
      "Training Accuracy 0.72\n",
      "Loss 178.15309 279 38\n",
      "Training Accuracy 0.705\n",
      "Loss 166.72552 280 38\n",
      "Training Accuracy 0.685\n",
      "Loss 147.34865 281 38\n",
      "Training Accuracy 0.765\n",
      "Loss 166.1333 282 38\n",
      "Training Accuracy 0.7\n",
      "Loss 166.167 283 38\n",
      "Training Accuracy 0.765\n",
      "Loss 137.26508 284 38\n",
      "Training Accuracy 0.795\n",
      "Loss 199.08524 285 38\n",
      "Training Accuracy 0.66\n",
      "Loss 179.51067 286 38\n",
      "Training Accuracy 0.72\n",
      "Loss 147.92267 287 38\n",
      "Training Accuracy 0.745\n",
      "Loss 182.28969 288 38\n",
      "Training Accuracy 0.7\n",
      "Loss 166.96495 289 38\n",
      "Training Accuracy 0.72\n",
      "Loss 177.48651 290 38\n",
      "Training Accuracy 0.69\n",
      "Loss 194.8049 291 38\n",
      "Training Accuracy 0.705\n",
      "Loss 120.90698 292 38\n",
      "Training Accuracy 0.67424244\n",
      "Loss 131.7855 1 39\n",
      "Training Accuracy 0.765\n",
      "Loss 166.0168 2 39\n",
      "Training Accuracy 0.705\n",
      "Loss 160.27936 3 39\n",
      "Training Accuracy 0.74\n",
      "Loss 181.8804 4 39\n",
      "Training Accuracy 0.68\n",
      "Loss 154.98865 5 39\n",
      "Training Accuracy 0.73\n",
      "Loss 185.15422 6 39\n",
      "Training Accuracy 0.675\n",
      "Loss 181.97447 7 39\n",
      "Training Accuracy 0.68\n",
      "Loss 175.6011 8 39\n",
      "Training Accuracy 0.705\n",
      "Loss 173.20445 9 39\n",
      "Training Accuracy 0.725\n",
      "Loss 180.59964 10 39\n",
      "Training Accuracy 0.69\n",
      "Loss 184.35866 11 39\n",
      "Training Accuracy 0.73\n",
      "Loss 155.8042 12 39\n",
      "Training Accuracy 0.745\n",
      "Loss 172.16786 13 39\n",
      "Training Accuracy 0.705\n",
      "Loss 181.94524 14 39\n",
      "Training Accuracy 0.705\n",
      "Loss 156.23093 15 39\n",
      "Training Accuracy 0.76\n",
      "Loss 196.06357 16 39\n",
      "Training Accuracy 0.67\n",
      "Loss 154.33932 17 39\n",
      "Training Accuracy 0.725\n",
      "Loss 156.31024 18 39\n",
      "Training Accuracy 0.73\n",
      "Loss 164.82253 19 39\n",
      "Training Accuracy 0.705\n",
      "Loss 162.29947 20 39\n",
      "Training Accuracy 0.725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 171.19675 21 39\n",
      "Training Accuracy 0.7\n",
      "Loss 160.70233 22 39\n",
      "Training Accuracy 0.715\n",
      "Loss 173.44681 23 39\n",
      "Training Accuracy 0.7\n",
      "Loss 187.82703 24 39\n",
      "Training Accuracy 0.685\n",
      "Loss 156.88795 25 39\n",
      "Training Accuracy 0.75\n",
      "Loss 171.2553 26 39\n",
      "Training Accuracy 0.7\n",
      "Loss 156.35257 27 39\n",
      "Training Accuracy 0.7\n",
      "Loss 159.28258 28 39\n",
      "Training Accuracy 0.685\n",
      "Loss 173.05379 29 39\n",
      "Training Accuracy 0.69\n",
      "Loss 189.70493 30 39\n",
      "Training Accuracy 0.68\n",
      "Loss 168.64754 31 39\n",
      "Training Accuracy 0.72\n",
      "Loss 186.61263 32 39\n",
      "Training Accuracy 0.665\n",
      "Loss 174.05716 33 39\n",
      "Training Accuracy 0.725\n",
      "Loss 156.35063 34 39\n",
      "Training Accuracy 0.735\n",
      "Loss 159.46017 35 39\n",
      "Training Accuracy 0.7\n",
      "Loss 178.72937 36 39\n",
      "Training Accuracy 0.69\n",
      "Loss 159.53824 37 39\n",
      "Training Accuracy 0.74\n",
      "Loss 167.97937 38 39\n",
      "Training Accuracy 0.695\n",
      "Loss 145.11407 39 39\n",
      "Training Accuracy 0.75\n",
      "Loss 167.40746 40 39\n",
      "Training Accuracy 0.71\n",
      "Loss 178.64314 41 39\n",
      "Training Accuracy 0.685\n",
      "Loss 188.30188 42 39\n",
      "Training Accuracy 0.675\n",
      "Loss 174.10413 43 39\n",
      "Training Accuracy 0.67\n",
      "Loss 171.07433 44 39\n",
      "Training Accuracy 0.685\n",
      "Loss 170.7725 45 39\n",
      "Training Accuracy 0.725\n",
      "Loss 192.65889 46 39\n",
      "Training Accuracy 0.68\n",
      "Loss 156.96367 47 39\n",
      "Training Accuracy 0.76\n",
      "Loss 139.64009 48 39\n",
      "Training Accuracy 0.755\n",
      "Loss 175.07356 49 39\n",
      "Training Accuracy 0.68\n",
      "Loss 195.98232 50 39\n",
      "Training Accuracy 0.675\n",
      "Loss 141.3061 51 39\n",
      "Training Accuracy 0.745\n",
      "Loss 159.93 52 39\n",
      "Training Accuracy 0.745\n",
      "Loss 138.67287 53 39\n",
      "Training Accuracy 0.735\n",
      "Loss 188.32909 54 39\n",
      "Training Accuracy 0.69\n",
      "Loss 172.16063 55 39\n",
      "Training Accuracy 0.7\n",
      "Loss 184.08 56 39\n",
      "Training Accuracy 0.655\n",
      "Loss 168.59326 57 39\n",
      "Training Accuracy 0.7\n",
      "Loss 159.03189 58 39\n",
      "Training Accuracy 0.7\n",
      "Loss 175.71037 59 39\n",
      "Training Accuracy 0.71\n",
      "Loss 166.43936 60 39\n",
      "Training Accuracy 0.72\n",
      "Loss 162.01035 61 39\n",
      "Training Accuracy 0.715\n",
      "Loss 155.93279 62 39\n",
      "Training Accuracy 0.735\n",
      "Loss 169.53355 63 39\n",
      "Training Accuracy 0.745\n",
      "Loss 174.57649 64 39\n",
      "Training Accuracy 0.74\n",
      "Loss 174.70471 65 39\n",
      "Training Accuracy 0.695\n",
      "Loss 165.10707 66 39\n",
      "Training Accuracy 0.735\n",
      "Loss 173.69151 67 39\n",
      "Training Accuracy 0.69\n",
      "Loss 173.18709 68 39\n",
      "Training Accuracy 0.67\n",
      "Loss 180.56105 69 39\n",
      "Training Accuracy 0.66\n",
      "Loss 151.87144 70 39\n",
      "Training Accuracy 0.755\n",
      "Loss 176.7807 71 39\n",
      "Training Accuracy 0.68\n",
      "Loss 179.06808 72 39\n",
      "Training Accuracy 0.7\n",
      "Loss 176.40181 73 39\n",
      "Training Accuracy 0.675\n",
      "Loss 170.3788 74 39\n",
      "Training Accuracy 0.75\n",
      "Loss 173.99805 75 39\n",
      "Training Accuracy 0.715\n",
      "Loss 159.54008 76 39\n",
      "Training Accuracy 0.725\n",
      "Loss 196.55338 77 39\n",
      "Training Accuracy 0.685\n",
      "Loss 165.29152 78 39\n",
      "Training Accuracy 0.705\n",
      "Loss 178.72008 79 39\n",
      "Training Accuracy 0.665\n",
      "Loss 178.42017 80 39\n",
      "Training Accuracy 0.7\n",
      "Loss 156.48445 81 39\n",
      "Training Accuracy 0.705\n",
      "Loss 157.6637 82 39\n",
      "Training Accuracy 0.725\n",
      "Loss 165.77464 83 39\n",
      "Training Accuracy 0.725\n",
      "Loss 175.69482 84 39\n",
      "Training Accuracy 0.7\n",
      "Loss 168.8557 85 39\n",
      "Training Accuracy 0.71\n",
      "Loss 165.84639 86 39\n",
      "Training Accuracy 0.74\n",
      "Loss 209.86859 87 39\n",
      "Training Accuracy 0.66\n",
      "Loss 193.29263 88 39\n",
      "Training Accuracy 0.7\n",
      "Loss 177.46266 89 39\n",
      "Training Accuracy 0.66\n",
      "Loss 183.33812 90 39\n",
      "Training Accuracy 0.66\n",
      "Loss 158.38318 91 39\n",
      "Training Accuracy 0.75\n",
      "Loss 185.45065 92 39\n",
      "Training Accuracy 0.685\n",
      "Loss 176.53387 93 39\n",
      "Training Accuracy 0.725\n",
      "Loss 173.0996 94 39\n",
      "Training Accuracy 0.715\n",
      "Loss 162.93134 95 39\n",
      "Training Accuracy 0.68\n",
      "Loss 170.27774 96 39\n",
      "Training Accuracy 0.71\n",
      "Loss 185.09183 97 39\n",
      "Training Accuracy 0.69\n",
      "Loss 158.94398 98 39\n",
      "Training Accuracy 0.74\n",
      "Loss 160.22214 99 39\n",
      "Training Accuracy 0.725\n",
      "Loss 168.1141 100 39\n",
      "Training Accuracy 0.725\n",
      "Loss 189.24548 101 39\n",
      "Training Accuracy 0.69\n",
      "Loss 164.68906 102 39\n",
      "Training Accuracy 0.71\n",
      "Loss 177.00186 103 39\n",
      "Training Accuracy 0.71\n",
      "Loss 166.93222 104 39\n",
      "Training Accuracy 0.705\n",
      "Loss 167.32297 105 39\n",
      "Training Accuracy 0.715\n",
      "Loss 165.1005 106 39\n",
      "Training Accuracy 0.72\n",
      "Loss 158.73253 107 39\n",
      "Training Accuracy 0.735\n",
      "Loss 160.88087 108 39\n",
      "Training Accuracy 0.72\n",
      "Loss 171.34685 109 39\n",
      "Training Accuracy 0.66\n",
      "Loss 172.70998 110 39\n",
      "Training Accuracy 0.705\n",
      "Loss 173.61913 111 39\n",
      "Training Accuracy 0.725\n",
      "Loss 188.19075 112 39\n",
      "Training Accuracy 0.66\n",
      "Loss 188.34308 113 39\n",
      "Training Accuracy 0.71\n",
      "Loss 179.62039 114 39\n",
      "Training Accuracy 0.635\n",
      "Loss 185.4035 115 39\n",
      "Training Accuracy 0.655\n",
      "Loss 198.93968 116 39\n",
      "Training Accuracy 0.705\n",
      "Loss 141.28998 117 39\n",
      "Training Accuracy 0.77\n",
      "Loss 168.80917 118 39\n",
      "Training Accuracy 0.715\n",
      "Loss 192.27168 119 39\n",
      "Training Accuracy 0.635\n",
      "Loss 176.83392 120 39\n",
      "Training Accuracy 0.695\n",
      "Loss 175.2407 121 39\n",
      "Training Accuracy 0.705\n",
      "Loss 163.19292 122 39\n",
      "Training Accuracy 0.74\n",
      "Loss 164.35509 123 39\n",
      "Training Accuracy 0.695\n",
      "Loss 177.90839 124 39\n",
      "Training Accuracy 0.675\n",
      "Loss 149.45874 125 39\n",
      "Training Accuracy 0.735\n",
      "Loss 169.23682 126 39\n",
      "Training Accuracy 0.72\n",
      "Loss 179.19952 127 39\n",
      "Training Accuracy 0.68\n",
      "Loss 174.44812 128 39\n",
      "Training Accuracy 0.705\n",
      "Loss 166.32683 129 39\n",
      "Training Accuracy 0.75\n",
      "Loss 159.67418 130 39\n",
      "Training Accuracy 0.695\n",
      "Loss 151.68477 131 39\n",
      "Training Accuracy 0.735\n",
      "Loss 163.48776 132 39\n",
      "Training Accuracy 0.7\n",
      "Loss 156.33827 133 39\n",
      "Training Accuracy 0.74\n",
      "Loss 169.65654 134 39\n",
      "Training Accuracy 0.68\n",
      "Loss 165.66696 135 39\n",
      "Training Accuracy 0.735\n",
      "Loss 182.71895 136 39\n",
      "Training Accuracy 0.7\n",
      "Loss 176.77629 137 39\n",
      "Training Accuracy 0.705\n",
      "Loss 177.49562 138 39\n",
      "Training Accuracy 0.7\n",
      "Loss 187.671 139 39\n",
      "Training Accuracy 0.71\n",
      "Loss 162.0419 140 39\n",
      "Training Accuracy 0.735\n",
      "Loss 181.8226 141 39\n",
      "Training Accuracy 0.69\n",
      "Loss 181.04555 142 39\n",
      "Training Accuracy 0.645\n",
      "Loss 158.41028 143 39\n",
      "Training Accuracy 0.74\n",
      "Loss 193.60565 144 39\n",
      "Training Accuracy 0.645\n",
      "Loss 165.69695 145 39\n",
      "Training Accuracy 0.715\n",
      "Loss 199.3337 146 39\n",
      "Training Accuracy 0.64\n",
      "Loss 181.83414 147 39\n",
      "Training Accuracy 0.685\n",
      "Loss 170.27841 148 39\n",
      "Training Accuracy 0.705\n",
      "Loss 168.42041 149 39\n",
      "Training Accuracy 0.705\n",
      "Loss 164.0803 150 39\n",
      "Training Accuracy 0.71\n",
      "Loss 180.21228 151 39\n",
      "Training Accuracy 0.695\n",
      "Loss 185.44937 152 39\n",
      "Training Accuracy 0.7\n",
      "Loss 156.17389 153 39\n",
      "Training Accuracy 0.745\n",
      "Loss 171.05658 154 39\n",
      "Training Accuracy 0.68\n",
      "Loss 170.66963 155 39\n",
      "Training Accuracy 0.7\n",
      "Loss 173.73578 156 39\n",
      "Training Accuracy 0.69\n",
      "Loss 166.20154 157 39\n",
      "Training Accuracy 0.66\n",
      "Loss 161.88483 158 39\n",
      "Training Accuracy 0.74\n",
      "Loss 195.64609 159 39\n",
      "Training Accuracy 0.705\n",
      "Loss 173.63354 160 39\n",
      "Training Accuracy 0.69\n",
      "Loss 196.54097 161 39\n",
      "Training Accuracy 0.645\n",
      "Loss 159.22629 162 39\n",
      "Training Accuracy 0.715\n",
      "Loss 185.64891 163 39\n",
      "Training Accuracy 0.68\n",
      "Loss 162.13702 164 39\n",
      "Training Accuracy 0.74\n",
      "Loss 180.91093 165 39\n",
      "Training Accuracy 0.695\n",
      "Loss 177.99847 166 39\n",
      "Training Accuracy 0.69\n",
      "Loss 163.85896 167 39\n",
      "Training Accuracy 0.725\n",
      "Loss 189.43912 168 39\n",
      "Training Accuracy 0.705\n",
      "Loss 169.90433 169 39\n",
      "Training Accuracy 0.71\n",
      "Loss 185.19058 170 39\n",
      "Training Accuracy 0.67\n",
      "Loss 179.70216 171 39\n",
      "Training Accuracy 0.72\n",
      "Loss 156.25029 172 39\n",
      "Training Accuracy 0.745\n",
      "Loss 181.05417 173 39\n",
      "Training Accuracy 0.7\n",
      "Loss 145.59254 174 39\n",
      "Training Accuracy 0.77\n",
      "Loss 149.86542 175 39\n",
      "Training Accuracy 0.75\n",
      "Loss 135.38148 176 39\n",
      "Training Accuracy 0.77\n",
      "Loss 189.64795 177 39\n",
      "Training Accuracy 0.675\n",
      "Loss 168.60713 178 39\n",
      "Training Accuracy 0.695\n",
      "Loss 170.67963 179 39\n",
      "Training Accuracy 0.705\n",
      "Loss 180.76021 180 39\n",
      "Training Accuracy 0.665\n",
      "Loss 158.40607 181 39\n",
      "Training Accuracy 0.735\n",
      "Loss 187.44202 182 39\n",
      "Training Accuracy 0.675\n",
      "Loss 174.71625 183 39\n",
      "Training Accuracy 0.68\n",
      "Loss 136.80214 184 39\n",
      "Training Accuracy 0.8\n",
      "Loss 155.78593 185 39\n",
      "Training Accuracy 0.73\n",
      "Loss 172.9925 186 39\n",
      "Training Accuracy 0.705\n",
      "Loss 198.89246 187 39\n",
      "Training Accuracy 0.65\n",
      "Loss 173.74191 188 39\n",
      "Training Accuracy 0.72\n",
      "Loss 166.70726 189 39\n",
      "Training Accuracy 0.72\n",
      "Loss 166.23174 190 39\n",
      "Training Accuracy 0.715\n",
      "Loss 157.93013 191 39\n",
      "Training Accuracy 0.76\n",
      "Loss 172.92735 192 39\n",
      "Training Accuracy 0.695\n",
      "Loss 165.76549 193 39\n",
      "Training Accuracy 0.71\n",
      "Loss 162.88106 194 39\n",
      "Training Accuracy 0.705\n",
      "Loss 141.06667 195 39\n",
      "Training Accuracy 0.74\n",
      "Loss 160.50803 196 39\n",
      "Training Accuracy 0.725\n",
      "Loss 171.0275 197 39\n",
      "Training Accuracy 0.685\n",
      "Loss 168.57619 198 39\n",
      "Training Accuracy 0.685\n",
      "Loss 138.30157 199 39\n",
      "Training Accuracy 0.765\n",
      "Loss 161.30894 200 39\n",
      "Training Accuracy 0.72\n",
      "Loss 163.35371 201 39\n",
      "Training Accuracy 0.71\n",
      "Loss 148.55858 202 39\n",
      "Training Accuracy 0.725\n",
      "Loss 165.27664 203 39\n",
      "Training Accuracy 0.745\n",
      "Loss 166.76836 204 39\n",
      "Training Accuracy 0.695\n",
      "Loss 183.57602 205 39\n",
      "Training Accuracy 0.7\n",
      "Loss 183.5425 206 39\n",
      "Training Accuracy 0.695\n",
      "Loss 179.2479 207 39\n",
      "Training Accuracy 0.68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 182.3557 208 39\n",
      "Training Accuracy 0.69\n",
      "Loss 184.72108 209 39\n",
      "Training Accuracy 0.71\n",
      "Loss 155.28322 210 39\n",
      "Training Accuracy 0.705\n",
      "Loss 150.33893 211 39\n",
      "Training Accuracy 0.76\n",
      "Loss 166.83472 212 39\n",
      "Training Accuracy 0.69\n",
      "Loss 199.65424 213 39\n",
      "Training Accuracy 0.685\n",
      "Loss 172.67854 214 39\n",
      "Training Accuracy 0.67\n",
      "Loss 193.51129 215 39\n",
      "Training Accuracy 0.615\n",
      "Loss 180.2339 216 39\n",
      "Training Accuracy 0.685\n",
      "Loss 166.30788 217 39\n",
      "Training Accuracy 0.69\n",
      "Loss 181.33566 218 39\n",
      "Training Accuracy 0.69\n",
      "Loss 172.75385 219 39\n",
      "Training Accuracy 0.71\n",
      "Loss 167.15134 220 39\n",
      "Training Accuracy 0.73\n",
      "Loss 176.57428 221 39\n",
      "Training Accuracy 0.68\n",
      "Loss 167.51945 222 39\n",
      "Training Accuracy 0.7\n",
      "Loss 178.69371 223 39\n",
      "Training Accuracy 0.74\n",
      "Loss 184.10918 224 39\n",
      "Training Accuracy 0.68\n",
      "Loss 179.86282 225 39\n",
      "Training Accuracy 0.715\n",
      "Loss 140.83754 226 39\n",
      "Training Accuracy 0.78\n",
      "Loss 197.7014 227 39\n",
      "Training Accuracy 0.66\n",
      "Loss 204.91365 228 39\n",
      "Training Accuracy 0.675\n",
      "Loss 162.34952 229 39\n",
      "Training Accuracy 0.71\n",
      "Loss 181.4691 230 39\n",
      "Training Accuracy 0.66\n",
      "Loss 148.81474 231 39\n",
      "Training Accuracy 0.735\n",
      "Loss 187.58066 232 39\n",
      "Training Accuracy 0.7\n",
      "Loss 191.74774 233 39\n",
      "Training Accuracy 0.62\n",
      "Loss 166.32812 234 39\n",
      "Training Accuracy 0.67\n",
      "Loss 176.39832 235 39\n",
      "Training Accuracy 0.695\n",
      "Loss 150.02147 236 39\n",
      "Training Accuracy 0.76\n",
      "Loss 177.55681 237 39\n",
      "Training Accuracy 0.665\n",
      "Loss 162.0877 238 39\n",
      "Training Accuracy 0.695\n",
      "Loss 181.11948 239 39\n",
      "Training Accuracy 0.66\n",
      "Loss 171.74214 240 39\n",
      "Training Accuracy 0.7\n",
      "Loss 203.07988 241 39\n",
      "Training Accuracy 0.69\n",
      "Loss 165.68646 242 39\n",
      "Training Accuracy 0.72\n",
      "Loss 144.14919 243 39\n",
      "Training Accuracy 0.75\n",
      "Loss 168.18236 244 39\n",
      "Training Accuracy 0.705\n",
      "Loss 169.93074 245 39\n",
      "Training Accuracy 0.705\n",
      "Loss 198.65788 246 39\n",
      "Training Accuracy 0.645\n",
      "Loss 149.27055 247 39\n",
      "Training Accuracy 0.74\n",
      "Loss 161.06227 248 39\n",
      "Training Accuracy 0.69\n",
      "Loss 180.31444 249 39\n",
      "Training Accuracy 0.645\n",
      "Loss 180.26472 250 39\n",
      "Training Accuracy 0.675\n",
      "Loss 195.95084 251 39\n",
      "Training Accuracy 0.635\n",
      "Loss 137.52708 252 39\n",
      "Training Accuracy 0.755\n",
      "Loss 137.70575 253 39\n",
      "Training Accuracy 0.75\n",
      "Loss 178.69551 254 39\n",
      "Training Accuracy 0.685\n",
      "Loss 149.17726 255 39\n",
      "Training Accuracy 0.73\n",
      "Loss 198.93846 256 39\n",
      "Training Accuracy 0.67\n",
      "Loss 164.38527 257 39\n",
      "Training Accuracy 0.71\n",
      "Loss 180.29521 258 39\n",
      "Training Accuracy 0.685\n",
      "Loss 169.4841 259 39\n",
      "Training Accuracy 0.69\n",
      "Loss 135.27899 260 39\n",
      "Training Accuracy 0.735\n",
      "Loss 173.08075 261 39\n",
      "Training Accuracy 0.71\n",
      "Loss 168.2769 262 39\n",
      "Training Accuracy 0.705\n",
      "Loss 201.57878 263 39\n",
      "Training Accuracy 0.68\n",
      "Loss 176.04166 264 39\n",
      "Training Accuracy 0.73\n",
      "Loss 156.40909 265 39\n",
      "Training Accuracy 0.73\n",
      "Loss 158.08366 266 39\n",
      "Training Accuracy 0.745\n",
      "Loss 172.98846 267 39\n",
      "Training Accuracy 0.695\n",
      "Loss 171.23918 268 39\n",
      "Training Accuracy 0.705\n",
      "Loss 157.64392 269 39\n",
      "Training Accuracy 0.725\n",
      "Loss 144.38596 270 39\n",
      "Training Accuracy 0.73\n",
      "Loss 186.50842 271 39\n",
      "Training Accuracy 0.675\n",
      "Loss 176.4732 272 39\n",
      "Training Accuracy 0.71\n",
      "Loss 185.16045 273 39\n",
      "Training Accuracy 0.67\n",
      "Loss 174.67474 274 39\n",
      "Training Accuracy 0.67\n",
      "Loss 162.96783 275 39\n",
      "Training Accuracy 0.715\n",
      "Loss 163.1245 276 39\n",
      "Training Accuracy 0.735\n",
      "Loss 167.00885 277 39\n",
      "Training Accuracy 0.74\n",
      "Loss 170.08873 278 39\n",
      "Training Accuracy 0.68\n",
      "Loss 183.20833 279 39\n",
      "Training Accuracy 0.715\n",
      "Loss 168.81737 280 39\n",
      "Training Accuracy 0.69\n",
      "Loss 154.9437 281 39\n",
      "Training Accuracy 0.74\n",
      "Loss 153.60483 282 39\n",
      "Training Accuracy 0.725\n",
      "Loss 169.62083 283 39\n",
      "Training Accuracy 0.73\n",
      "Loss 134.7414 284 39\n",
      "Training Accuracy 0.77\n",
      "Loss 187.21019 285 39\n",
      "Training Accuracy 0.7\n",
      "Loss 165.32953 286 39\n",
      "Training Accuracy 0.75\n",
      "Loss 157.0406 287 39\n",
      "Training Accuracy 0.72\n",
      "Loss 178.78468 288 39\n",
      "Training Accuracy 0.695\n",
      "Loss 171.66118 289 39\n",
      "Training Accuracy 0.695\n",
      "Loss 178.40868 290 39\n",
      "Training Accuracy 0.7\n",
      "Loss 182.49367 291 39\n",
      "Training Accuracy 0.69\n",
      "Loss 122.131134 292 39\n",
      "Training Accuracy 0.6515151\n",
      "Loss 131.26865 1 40\n",
      "Training Accuracy 0.8\n",
      "Loss 164.98758 2 40\n",
      "Training Accuracy 0.75\n",
      "Loss 161.98668 3 40\n",
      "Training Accuracy 0.735\n",
      "Loss 169.45084 4 40\n",
      "Training Accuracy 0.685\n",
      "Loss 147.96213 5 40\n",
      "Training Accuracy 0.745\n",
      "Loss 183.25087 6 40\n",
      "Training Accuracy 0.695\n",
      "Loss 183.06802 7 40\n",
      "Training Accuracy 0.695\n",
      "Loss 168.3986 8 40\n",
      "Training Accuracy 0.72\n",
      "Loss 164.10083 9 40\n",
      "Training Accuracy 0.71\n",
      "Loss 172.34245 10 40\n",
      "Training Accuracy 0.71\n",
      "Loss 183.80869 11 40\n",
      "Training Accuracy 0.73\n",
      "Loss 161.0115 12 40\n",
      "Training Accuracy 0.7\n",
      "Loss 167.20653 13 40\n",
      "Training Accuracy 0.705\n",
      "Loss 174.41989 14 40\n",
      "Training Accuracy 0.7\n",
      "Loss 157.50613 15 40\n",
      "Training Accuracy 0.73\n",
      "Loss 202.80673 16 40\n",
      "Training Accuracy 0.68\n",
      "Loss 144.40503 17 40\n",
      "Training Accuracy 0.76\n",
      "Loss 153.63577 18 40\n",
      "Training Accuracy 0.74\n",
      "Loss 163.85777 19 40\n",
      "Training Accuracy 0.73\n",
      "Loss 163.12218 20 40\n",
      "Training Accuracy 0.73\n",
      "Loss 174.66245 21 40\n",
      "Training Accuracy 0.73\n",
      "Loss 164.60771 22 40\n",
      "Training Accuracy 0.715\n",
      "Loss 166.42108 23 40\n",
      "Training Accuracy 0.715\n",
      "Loss 184.85812 24 40\n",
      "Training Accuracy 0.665\n",
      "Loss 156.40346 25 40\n",
      "Training Accuracy 0.695\n",
      "Loss 171.94281 26 40\n",
      "Training Accuracy 0.67\n",
      "Loss 159.75671 27 40\n",
      "Training Accuracy 0.725\n",
      "Loss 148.23334 28 40\n",
      "Training Accuracy 0.755\n",
      "Loss 173.32736 29 40\n",
      "Training Accuracy 0.685\n",
      "Loss 191.14096 30 40\n",
      "Training Accuracy 0.7\n",
      "Loss 179.16104 31 40\n",
      "Training Accuracy 0.715\n",
      "Loss 162.53041 32 40\n",
      "Training Accuracy 0.69\n",
      "Loss 163.65149 33 40\n",
      "Training Accuracy 0.755\n",
      "Loss 162.18335 34 40\n",
      "Training Accuracy 0.695\n",
      "Loss 154.15706 35 40\n",
      "Training Accuracy 0.745\n",
      "Loss 173.9813 36 40\n",
      "Training Accuracy 0.705\n",
      "Loss 154.9907 37 40\n",
      "Training Accuracy 0.725\n",
      "Loss 172.65523 38 40\n",
      "Training Accuracy 0.72\n",
      "Loss 150.34315 39 40\n",
      "Training Accuracy 0.73\n",
      "Loss 164.0189 40 40\n",
      "Training Accuracy 0.72\n",
      "Loss 178.79839 41 40\n",
      "Training Accuracy 0.67\n",
      "Loss 187.22353 42 40\n",
      "Training Accuracy 0.67\n",
      "Loss 168.71838 43 40\n",
      "Training Accuracy 0.705\n",
      "Loss 168.2391 44 40\n",
      "Training Accuracy 0.72\n",
      "Loss 171.66121 45 40\n",
      "Training Accuracy 0.71\n",
      "Loss 181.05194 46 40\n",
      "Training Accuracy 0.695\n",
      "Loss 163.96474 47 40\n",
      "Training Accuracy 0.725\n",
      "Loss 138.81363 48 40\n",
      "Training Accuracy 0.735\n",
      "Loss 172.72253 49 40\n",
      "Training Accuracy 0.695\n",
      "Loss 192.72174 50 40\n",
      "Training Accuracy 0.665\n",
      "Loss 149.1391 51 40\n",
      "Training Accuracy 0.715\n",
      "Loss 151.23294 52 40\n",
      "Training Accuracy 0.765\n",
      "Loss 134.92928 53 40\n",
      "Training Accuracy 0.735\n",
      "Loss 179.06892 54 40\n",
      "Training Accuracy 0.69\n",
      "Loss 168.7302 55 40\n",
      "Training Accuracy 0.725\n",
      "Loss 165.53752 56 40\n",
      "Training Accuracy 0.715\n",
      "Loss 165.31065 57 40\n",
      "Training Accuracy 0.72\n",
      "Loss 160.94939 58 40\n",
      "Training Accuracy 0.74\n",
      "Loss 171.39859 59 40\n",
      "Training Accuracy 0.73\n",
      "Loss 164.6518 60 40\n",
      "Training Accuracy 0.755\n",
      "Loss 172.6242 61 40\n",
      "Training Accuracy 0.68\n",
      "Loss 146.18974 62 40\n",
      "Training Accuracy 0.73\n",
      "Loss 166.52682 63 40\n",
      "Training Accuracy 0.715\n",
      "Loss 169.81831 64 40\n",
      "Training Accuracy 0.705\n",
      "Loss 170.91803 65 40\n",
      "Training Accuracy 0.7\n",
      "Loss 159.1877 66 40\n",
      "Training Accuracy 0.705\n",
      "Loss 168.31436 67 40\n",
      "Training Accuracy 0.705\n",
      "Loss 171.7428 68 40\n",
      "Training Accuracy 0.685\n",
      "Loss 189.70079 69 40\n",
      "Training Accuracy 0.66\n",
      "Loss 165.323 70 40\n",
      "Training Accuracy 0.735\n",
      "Loss 157.52997 71 40\n",
      "Training Accuracy 0.745\n",
      "Loss 164.99629 72 40\n",
      "Training Accuracy 0.735\n",
      "Loss 184.18991 73 40\n",
      "Training Accuracy 0.685\n",
      "Loss 165.29118 74 40\n",
      "Training Accuracy 0.695\n",
      "Loss 169.17836 75 40\n",
      "Training Accuracy 0.695\n",
      "Loss 148.89742 76 40\n",
      "Training Accuracy 0.755\n",
      "Loss 179.69548 77 40\n",
      "Training Accuracy 0.725\n",
      "Loss 168.6123 78 40\n",
      "Training Accuracy 0.695\n",
      "Loss 174.74089 79 40\n",
      "Training Accuracy 0.65\n",
      "Loss 189.66599 80 40\n",
      "Training Accuracy 0.67\n",
      "Loss 160.39859 81 40\n",
      "Training Accuracy 0.72\n",
      "Loss 152.21606 82 40\n",
      "Training Accuracy 0.72\n",
      "Loss 167.32645 83 40\n",
      "Training Accuracy 0.7\n",
      "Loss 184.96162 84 40\n",
      "Training Accuracy 0.68\n",
      "Loss 162.87823 85 40\n",
      "Training Accuracy 0.715\n",
      "Loss 168.82039 86 40\n",
      "Training Accuracy 0.71\n",
      "Loss 211.20059 87 40\n",
      "Training Accuracy 0.62\n",
      "Loss 196.51598 88 40\n",
      "Training Accuracy 0.645\n",
      "Loss 174.06328 89 40\n",
      "Training Accuracy 0.675\n",
      "Loss 187.48645 90 40\n",
      "Training Accuracy 0.685\n",
      "Loss 161.64314 91 40\n",
      "Training Accuracy 0.725\n",
      "Loss 183.93715 92 40\n",
      "Training Accuracy 0.71\n",
      "Loss 167.23993 93 40\n",
      "Training Accuracy 0.725\n",
      "Loss 174.33112 94 40\n",
      "Training Accuracy 0.7\n",
      "Loss 168.14255 95 40\n",
      "Training Accuracy 0.685\n",
      "Loss 172.11043 96 40\n",
      "Training Accuracy 0.71\n",
      "Loss 171.74371 97 40\n",
      "Training Accuracy 0.675\n",
      "Loss 166.00093 98 40\n",
      "Training Accuracy 0.72\n",
      "Loss 168.44138 99 40\n",
      "Training Accuracy 0.7\n",
      "Loss 157.99599 100 40\n",
      "Training Accuracy 0.745\n",
      "Loss 193.79614 101 40\n",
      "Training Accuracy 0.655\n",
      "Loss 159.05858 102 40\n",
      "Training Accuracy 0.71\n",
      "Loss 165.55771 103 40\n",
      "Training Accuracy 0.725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 170.21924 104 40\n",
      "Training Accuracy 0.72\n",
      "Loss 170.19223 105 40\n",
      "Training Accuracy 0.705\n",
      "Loss 152.89348 106 40\n",
      "Training Accuracy 0.77\n",
      "Loss 160.96777 107 40\n",
      "Training Accuracy 0.715\n",
      "Loss 174.08885 108 40\n",
      "Training Accuracy 0.67\n",
      "Loss 154.24193 109 40\n",
      "Training Accuracy 0.73\n",
      "Loss 180.83826 110 40\n",
      "Training Accuracy 0.7\n",
      "Loss 198.2797 111 40\n",
      "Training Accuracy 0.655\n",
      "Loss 176.9203 112 40\n",
      "Training Accuracy 0.69\n",
      "Loss 191.18515 113 40\n",
      "Training Accuracy 0.68\n",
      "Loss 169.0099 114 40\n",
      "Training Accuracy 0.69\n",
      "Loss 197.57385 115 40\n",
      "Training Accuracy 0.64\n",
      "Loss 200.768 116 40\n",
      "Training Accuracy 0.685\n",
      "Loss 140.59138 117 40\n",
      "Training Accuracy 0.805\n",
      "Loss 161.51578 118 40\n",
      "Training Accuracy 0.695\n",
      "Loss 184.99284 119 40\n",
      "Training Accuracy 0.655\n",
      "Loss 170.88773 120 40\n",
      "Training Accuracy 0.72\n",
      "Loss 184.9335 121 40\n",
      "Training Accuracy 0.66\n",
      "Loss 162.73483 122 40\n",
      "Training Accuracy 0.72\n",
      "Loss 174.64517 123 40\n",
      "Training Accuracy 0.68\n",
      "Loss 163.20514 124 40\n",
      "Training Accuracy 0.705\n",
      "Loss 156.18355 125 40\n",
      "Training Accuracy 0.735\n",
      "Loss 195.86256 126 40\n",
      "Training Accuracy 0.65\n",
      "Loss 180.67072 127 40\n",
      "Training Accuracy 0.66\n",
      "Loss 156.75587 128 40\n",
      "Training Accuracy 0.74\n",
      "Loss 158.89694 129 40\n",
      "Training Accuracy 0.735\n",
      "Loss 159.37354 130 40\n",
      "Training Accuracy 0.695\n",
      "Loss 157.30911 131 40\n",
      "Training Accuracy 0.755\n",
      "Loss 159.30186 132 40\n",
      "Training Accuracy 0.715\n",
      "Loss 159.34946 133 40\n",
      "Training Accuracy 0.69\n",
      "Loss 155.92415 134 40\n",
      "Training Accuracy 0.75\n",
      "Loss 166.42154 135 40\n",
      "Training Accuracy 0.715\n",
      "Loss 168.64667 136 40\n",
      "Training Accuracy 0.715\n",
      "Loss 183.62723 137 40\n",
      "Training Accuracy 0.695\n",
      "Loss 175.35136 138 40\n",
      "Training Accuracy 0.705\n",
      "Loss 191.36823 139 40\n",
      "Training Accuracy 0.655\n",
      "Loss 156.09868 140 40\n",
      "Training Accuracy 0.7\n",
      "Loss 171.44662 141 40\n",
      "Training Accuracy 0.675\n",
      "Loss 169.48651 142 40\n",
      "Training Accuracy 0.69\n",
      "Loss 151.42444 143 40\n",
      "Training Accuracy 0.745\n",
      "Loss 170.12912 144 40\n",
      "Training Accuracy 0.72\n",
      "Loss 163.50078 145 40\n",
      "Training Accuracy 0.715\n",
      "Loss 192.90831 146 40\n",
      "Training Accuracy 0.63\n",
      "Loss 193.51474 147 40\n",
      "Training Accuracy 0.675\n",
      "Loss 182.53296 148 40\n",
      "Training Accuracy 0.65\n",
      "Loss 171.57666 149 40\n",
      "Training Accuracy 0.68\n",
      "Loss 170.60399 150 40\n",
      "Training Accuracy 0.68\n",
      "Loss 186.70932 151 40\n",
      "Training Accuracy 0.69\n",
      "Loss 183.65512 152 40\n",
      "Training Accuracy 0.69\n",
      "Loss 154.18678 153 40\n",
      "Training Accuracy 0.725\n",
      "Loss 178.79317 154 40\n",
      "Training Accuracy 0.66\n",
      "Loss 156.86879 155 40\n",
      "Training Accuracy 0.725\n",
      "Loss 161.09085 156 40\n",
      "Training Accuracy 0.74\n",
      "Loss 150.76457 157 40\n",
      "Training Accuracy 0.725\n",
      "Loss 154.18666 158 40\n",
      "Training Accuracy 0.745\n",
      "Loss 194.31154 159 40\n",
      "Training Accuracy 0.665\n",
      "Loss 166.5069 160 40\n",
      "Training Accuracy 0.73\n",
      "Loss 192.6926 161 40\n",
      "Training Accuracy 0.65\n",
      "Loss 167.30379 162 40\n",
      "Training Accuracy 0.695\n",
      "Loss 180.23245 163 40\n",
      "Training Accuracy 0.685\n",
      "Loss 150.21414 164 40\n",
      "Training Accuracy 0.75\n",
      "Loss 160.93011 165 40\n",
      "Training Accuracy 0.75\n",
      "Loss 172.19547 166 40\n",
      "Training Accuracy 0.725\n",
      "Loss 159.23227 167 40\n",
      "Training Accuracy 0.715\n",
      "Loss 174.24457 168 40\n",
      "Training Accuracy 0.7\n",
      "Loss 165.41557 169 40\n",
      "Training Accuracy 0.73\n",
      "Loss 173.26906 170 40\n",
      "Training Accuracy 0.695\n",
      "Loss 169.00159 171 40\n",
      "Training Accuracy 0.715\n",
      "Loss 150.16856 172 40\n",
      "Training Accuracy 0.745\n",
      "Loss 177.23155 173 40\n",
      "Training Accuracy 0.725\n",
      "Loss 145.66669 174 40\n",
      "Training Accuracy 0.74\n",
      "Loss 157.08493 175 40\n",
      "Training Accuracy 0.72\n",
      "Loss 137.19702 176 40\n",
      "Training Accuracy 0.765\n",
      "Loss 182.17715 177 40\n",
      "Training Accuracy 0.68\n",
      "Loss 168.71829 178 40\n",
      "Training Accuracy 0.715\n",
      "Loss 174.53946 179 40\n",
      "Training Accuracy 0.695\n",
      "Loss 174.44876 180 40\n",
      "Training Accuracy 0.7\n",
      "Loss 164.62495 181 40\n",
      "Training Accuracy 0.72\n",
      "Loss 188.29759 182 40\n",
      "Training Accuracy 0.665\n",
      "Loss 187.17896 183 40\n",
      "Training Accuracy 0.65\n",
      "Loss 151.5741 184 40\n",
      "Training Accuracy 0.765\n",
      "Loss 162.06741 185 40\n",
      "Training Accuracy 0.73\n",
      "Loss 164.25171 186 40\n",
      "Training Accuracy 0.715\n",
      "Loss 192.21017 187 40\n",
      "Training Accuracy 0.675\n",
      "Loss 161.41101 188 40\n",
      "Training Accuracy 0.725\n",
      "Loss 160.6606 189 40\n",
      "Training Accuracy 0.745\n",
      "Loss 168.46774 190 40\n",
      "Training Accuracy 0.71\n",
      "Loss 153.18599 191 40\n",
      "Training Accuracy 0.72\n",
      "Loss 177.37666 192 40\n",
      "Training Accuracy 0.685\n",
      "Loss 151.64355 193 40\n",
      "Training Accuracy 0.735\n",
      "Loss 168.6014 194 40\n",
      "Training Accuracy 0.735\n",
      "Loss 140.94165 195 40\n",
      "Training Accuracy 0.77\n",
      "Loss 143.61635 196 40\n",
      "Training Accuracy 0.745\n",
      "Loss 171.12299 197 40\n",
      "Training Accuracy 0.69\n",
      "Loss 166.53976 198 40\n",
      "Training Accuracy 0.685\n",
      "Loss 143.17882 199 40\n",
      "Training Accuracy 0.765\n",
      "Loss 157.14723 200 40\n",
      "Training Accuracy 0.73\n",
      "Loss 155.62688 201 40\n",
      "Training Accuracy 0.74\n",
      "Loss 156.65063 202 40\n",
      "Training Accuracy 0.695\n",
      "Loss 174.09454 203 40\n",
      "Training Accuracy 0.715\n",
      "Loss 174.6975 204 40\n",
      "Training Accuracy 0.655\n",
      "Loss 192.26761 205 40\n",
      "Training Accuracy 0.69\n",
      "Loss 169.42516 206 40\n",
      "Training Accuracy 0.71\n",
      "Loss 176.48491 207 40\n",
      "Training Accuracy 0.695\n",
      "Loss 182.61574 208 40\n",
      "Training Accuracy 0.675\n",
      "Loss 175.51851 209 40\n",
      "Training Accuracy 0.705\n",
      "Loss 158.61787 210 40\n",
      "Training Accuracy 0.73\n",
      "Loss 152.54024 211 40\n",
      "Training Accuracy 0.755\n",
      "Loss 158.26932 212 40\n",
      "Training Accuracy 0.69\n",
      "Loss 192.09679 213 40\n",
      "Training Accuracy 0.695\n",
      "Loss 161.04395 214 40\n",
      "Training Accuracy 0.705\n",
      "Loss 188.4667 215 40\n",
      "Training Accuracy 0.64\n",
      "Loss 179.10822 216 40\n",
      "Training Accuracy 0.67\n",
      "Loss 173.91397 217 40\n",
      "Training Accuracy 0.685\n",
      "Loss 179.48961 218 40\n",
      "Training Accuracy 0.69\n",
      "Loss 164.4427 219 40\n",
      "Training Accuracy 0.73\n",
      "Loss 163.9679 220 40\n",
      "Training Accuracy 0.72\n",
      "Loss 167.47388 221 40\n",
      "Training Accuracy 0.71\n",
      "Loss 157.73463 222 40\n",
      "Training Accuracy 0.685\n",
      "Loss 177.66039 223 40\n",
      "Training Accuracy 0.7\n",
      "Loss 188.29094 224 40\n",
      "Training Accuracy 0.7\n",
      "Loss 189.83405 225 40\n",
      "Training Accuracy 0.675\n",
      "Loss 139.33191 226 40\n",
      "Training Accuracy 0.745\n",
      "Loss 189.78154 227 40\n",
      "Training Accuracy 0.68\n",
      "Loss 207.82878 228 40\n",
      "Training Accuracy 0.665\n",
      "Loss 162.32759 229 40\n",
      "Training Accuracy 0.69\n",
      "Loss 177.5998 230 40\n",
      "Training Accuracy 0.675\n",
      "Loss 151.68033 231 40\n",
      "Training Accuracy 0.73\n",
      "Loss 186.42265 232 40\n",
      "Training Accuracy 0.69\n",
      "Loss 202.81567 233 40\n",
      "Training Accuracy 0.59\n",
      "Loss 172.96776 234 40\n",
      "Training Accuracy 0.65\n",
      "Loss 162.19144 235 40\n",
      "Training Accuracy 0.745\n",
      "Loss 147.86507 236 40\n",
      "Training Accuracy 0.765\n",
      "Loss 176.36717 237 40\n",
      "Training Accuracy 0.675\n",
      "Loss 155.40701 238 40\n",
      "Training Accuracy 0.71\n",
      "Loss 159.06958 239 40\n",
      "Training Accuracy 0.705\n",
      "Loss 171.63905 240 40\n",
      "Training Accuracy 0.71\n",
      "Loss 184.64789 241 40\n",
      "Training Accuracy 0.7\n",
      "Loss 180.03822 242 40\n",
      "Training Accuracy 0.635\n",
      "Loss 147.73038 243 40\n",
      "Training Accuracy 0.73\n",
      "Loss 175.96701 244 40\n",
      "Training Accuracy 0.67\n",
      "Loss 181.14182 245 40\n",
      "Training Accuracy 0.695\n",
      "Loss 180.90427 246 40\n",
      "Training Accuracy 0.695\n",
      "Loss 140.70312 247 40\n",
      "Training Accuracy 0.75\n",
      "Loss 148.13945 248 40\n",
      "Training Accuracy 0.79\n",
      "Loss 181.69797 249 40\n",
      "Training Accuracy 0.67\n",
      "Loss 181.70502 250 40\n",
      "Training Accuracy 0.68\n",
      "Loss 177.26375 251 40\n",
      "Training Accuracy 0.685\n",
      "Loss 140.32373 252 40\n",
      "Training Accuracy 0.755\n",
      "Loss 133.54938 253 40\n",
      "Training Accuracy 0.77\n",
      "Loss 178.34267 254 40\n",
      "Training Accuracy 0.71\n",
      "Loss 147.75648 255 40\n",
      "Training Accuracy 0.76\n",
      "Loss 185.1289 256 40\n",
      "Training Accuracy 0.69\n",
      "Loss 156.27412 257 40\n",
      "Training Accuracy 0.73\n",
      "Loss 181.14226 258 40\n",
      "Training Accuracy 0.685\n",
      "Loss 172.58308 259 40\n",
      "Training Accuracy 0.705\n",
      "Loss 138.48662 260 40\n",
      "Training Accuracy 0.77\n",
      "Loss 159.23457 261 40\n",
      "Training Accuracy 0.715\n",
      "Loss 169.99513 262 40\n",
      "Training Accuracy 0.685\n",
      "Loss 205.05695 263 40\n",
      "Training Accuracy 0.655\n",
      "Loss 175.69696 264 40\n",
      "Training Accuracy 0.74\n",
      "Loss 140.49623 265 40\n",
      "Training Accuracy 0.765\n",
      "Loss 162.60721 266 40\n",
      "Training Accuracy 0.7\n",
      "Loss 174.89003 267 40\n",
      "Training Accuracy 0.695\n",
      "Loss 175.25427 268 40\n",
      "Training Accuracy 0.68\n",
      "Loss 160.49005 269 40\n",
      "Training Accuracy 0.71\n",
      "Loss 147.41183 270 40\n",
      "Training Accuracy 0.74\n",
      "Loss 193.55942 271 40\n",
      "Training Accuracy 0.66\n",
      "Loss 164.20917 272 40\n",
      "Training Accuracy 0.735\n",
      "Loss 179.84888 273 40\n",
      "Training Accuracy 0.69\n",
      "Loss 165.22398 274 40\n",
      "Training Accuracy 0.705\n",
      "Loss 159.30164 275 40\n",
      "Training Accuracy 0.74\n",
      "Loss 167.36084 276 40\n",
      "Training Accuracy 0.705\n",
      "Loss 167.6669 277 40\n",
      "Training Accuracy 0.705\n",
      "Loss 157.50542 278 40\n",
      "Training Accuracy 0.73\n",
      "Loss 166.49 279 40\n",
      "Training Accuracy 0.74\n",
      "Loss 163.05283 280 40\n",
      "Training Accuracy 0.725\n",
      "Loss 148.09248 281 40\n",
      "Training Accuracy 0.72\n",
      "Loss 156.1318 282 40\n",
      "Training Accuracy 0.715\n",
      "Loss 170.1577 283 40\n",
      "Training Accuracy 0.73\n",
      "Loss 139.38182 284 40\n",
      "Training Accuracy 0.76\n",
      "Loss 193.53917 285 40\n",
      "Training Accuracy 0.685\n",
      "Loss 163.16914 286 40\n",
      "Training Accuracy 0.745\n",
      "Loss 150.83728 287 40\n",
      "Training Accuracy 0.72\n",
      "Loss 179.27512 288 40\n",
      "Training Accuracy 0.665\n",
      "Loss 166.8065 289 40\n",
      "Training Accuracy 0.715\n",
      "Loss 168.97229 290 40\n",
      "Training Accuracy 0.725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 188.02365 291 40\n",
      "Training Accuracy 0.71\n",
      "Loss 110.01215 292 40\n",
      "Training Accuracy 0.6969697\n",
      "Loss 139.07982 1 41\n",
      "Training Accuracy 0.755\n",
      "Loss 159.53006 2 41\n",
      "Training Accuracy 0.735\n",
      "Loss 150.00354 3 41\n",
      "Training Accuracy 0.705\n",
      "Loss 183.35904 4 41\n",
      "Training Accuracy 0.685\n",
      "Loss 158.42804 5 41\n",
      "Training Accuracy 0.745\n",
      "Loss 171.6876 6 41\n",
      "Training Accuracy 0.71\n",
      "Loss 182.86913 7 41\n",
      "Training Accuracy 0.67\n",
      "Loss 168.90407 8 41\n",
      "Training Accuracy 0.73\n",
      "Loss 161.94237 9 41\n",
      "Training Accuracy 0.71\n",
      "Loss 180.03578 10 41\n",
      "Training Accuracy 0.69\n",
      "Loss 173.75633 11 41\n",
      "Training Accuracy 0.73\n",
      "Loss 155.5364 12 41\n",
      "Training Accuracy 0.74\n",
      "Loss 154.85413 13 41\n",
      "Training Accuracy 0.725\n",
      "Loss 175.41737 14 41\n",
      "Training Accuracy 0.695\n",
      "Loss 160.73984 15 41\n",
      "Training Accuracy 0.705\n",
      "Loss 198.54463 16 41\n",
      "Training Accuracy 0.69\n",
      "Loss 153.77394 17 41\n",
      "Training Accuracy 0.705\n",
      "Loss 148.64154 18 41\n",
      "Training Accuracy 0.745\n",
      "Loss 155.74644 19 41\n",
      "Training Accuracy 0.715\n",
      "Loss 157.16661 20 41\n",
      "Training Accuracy 0.745\n",
      "Loss 172.76639 21 41\n",
      "Training Accuracy 0.67\n",
      "Loss 152.77454 22 41\n",
      "Training Accuracy 0.76\n",
      "Loss 185.90964 23 41\n",
      "Training Accuracy 0.69\n",
      "Loss 181.28981 24 41\n",
      "Training Accuracy 0.695\n",
      "Loss 142.55328 25 41\n",
      "Training Accuracy 0.755\n",
      "Loss 171.05777 26 41\n",
      "Training Accuracy 0.705\n",
      "Loss 167.5303 27 41\n",
      "Training Accuracy 0.695\n",
      "Loss 151.32132 28 41\n",
      "Training Accuracy 0.73\n",
      "Loss 164.3842 29 41\n",
      "Training Accuracy 0.715\n",
      "Loss 182.28452 30 41\n",
      "Training Accuracy 0.735\n",
      "Loss 169.82779 31 41\n",
      "Training Accuracy 0.725\n",
      "Loss 160.61816 32 41\n",
      "Training Accuracy 0.745\n",
      "Loss 164.0048 33 41\n",
      "Training Accuracy 0.72\n",
      "Loss 152.2475 34 41\n",
      "Training Accuracy 0.715\n",
      "Loss 167.67126 35 41\n",
      "Training Accuracy 0.69\n",
      "Loss 180.60101 36 41\n",
      "Training Accuracy 0.7\n",
      "Loss 154.58095 37 41\n",
      "Training Accuracy 0.725\n",
      "Loss 169.71179 38 41\n",
      "Training Accuracy 0.695\n",
      "Loss 144.09224 39 41\n",
      "Training Accuracy 0.75\n",
      "Loss 170.8391 40 41\n",
      "Training Accuracy 0.715\n",
      "Loss 171.87143 41 41\n",
      "Training Accuracy 0.695\n",
      "Loss 193.21304 42 41\n",
      "Training Accuracy 0.64\n",
      "Loss 165.46936 43 41\n",
      "Training Accuracy 0.68\n",
      "Loss 154.76328 44 41\n",
      "Training Accuracy 0.75\n",
      "Loss 166.77895 45 41\n",
      "Training Accuracy 0.73\n",
      "Loss 189.41852 46 41\n",
      "Training Accuracy 0.685\n",
      "Loss 164.67963 47 41\n",
      "Training Accuracy 0.755\n",
      "Loss 136.96149 48 41\n",
      "Training Accuracy 0.79\n",
      "Loss 170.01503 49 41\n",
      "Training Accuracy 0.705\n",
      "Loss 180.61858 50 41\n",
      "Training Accuracy 0.68\n",
      "Loss 142.04726 51 41\n",
      "Training Accuracy 0.76\n",
      "Loss 151.17863 52 41\n",
      "Training Accuracy 0.745\n",
      "Loss 134.39197 53 41\n",
      "Training Accuracy 0.77\n",
      "Loss 198.25061 54 41\n",
      "Training Accuracy 0.675\n",
      "Loss 166.7915 55 41\n",
      "Training Accuracy 0.705\n",
      "Loss 178.83917 56 41\n",
      "Training Accuracy 0.685\n",
      "Loss 172.54788 57 41\n",
      "Training Accuracy 0.725\n",
      "Loss 156.41258 58 41\n",
      "Training Accuracy 0.72\n",
      "Loss 172.17778 59 41\n",
      "Training Accuracy 0.695\n",
      "Loss 160.35956 60 41\n",
      "Training Accuracy 0.75\n",
      "Loss 171.11867 61 41\n",
      "Training Accuracy 0.7\n",
      "Loss 149.12894 62 41\n",
      "Training Accuracy 0.745\n",
      "Loss 163.55943 63 41\n",
      "Training Accuracy 0.76\n",
      "Loss 172.78137 64 41\n",
      "Training Accuracy 0.725\n",
      "Loss 166.97491 65 41\n",
      "Training Accuracy 0.695\n",
      "Loss 145.75821 66 41\n",
      "Training Accuracy 0.77\n",
      "Loss 172.10353 67 41\n",
      "Training Accuracy 0.7\n",
      "Loss 169.84883 68 41\n",
      "Training Accuracy 0.71\n",
      "Loss 161.23965 69 41\n",
      "Training Accuracy 0.74\n",
      "Loss 165.53105 70 41\n",
      "Training Accuracy 0.745\n",
      "Loss 160.49579 71 41\n",
      "Training Accuracy 0.765\n",
      "Loss 175.70547 72 41\n",
      "Training Accuracy 0.715\n",
      "Loss 179.00197 73 41\n",
      "Training Accuracy 0.68\n",
      "Loss 176.73985 74 41\n",
      "Training Accuracy 0.725\n",
      "Loss 165.95174 75 41\n",
      "Training Accuracy 0.705\n",
      "Loss 144.71492 76 41\n",
      "Training Accuracy 0.735\n",
      "Loss 187.66483 77 41\n",
      "Training Accuracy 0.695\n",
      "Loss 162.30817 78 41\n",
      "Training Accuracy 0.73\n",
      "Loss 167.04745 79 41\n",
      "Training Accuracy 0.69\n",
      "Loss 173.91933 80 41\n",
      "Training Accuracy 0.735\n",
      "Loss 157.45927 81 41\n",
      "Training Accuracy 0.71\n",
      "Loss 156.27371 82 41\n",
      "Training Accuracy 0.73\n",
      "Loss 159.94775 83 41\n",
      "Training Accuracy 0.73\n",
      "Loss 174.04637 84 41\n",
      "Training Accuracy 0.735\n",
      "Loss 167.00243 85 41\n",
      "Training Accuracy 0.68\n",
      "Loss 169.09732 86 41\n",
      "Training Accuracy 0.74\n",
      "Loss 208.18997 87 41\n",
      "Training Accuracy 0.665\n",
      "Loss 194.96875 88 41\n",
      "Training Accuracy 0.65\n",
      "Loss 169.47775 89 41\n",
      "Training Accuracy 0.7\n",
      "Loss 178.25514 90 41\n",
      "Training Accuracy 0.7\n",
      "Loss 164.66818 91 41\n",
      "Training Accuracy 0.72\n",
      "Loss 173.61086 92 41\n",
      "Training Accuracy 0.73\n",
      "Loss 175.65877 93 41\n",
      "Training Accuracy 0.715\n",
      "Loss 173.59451 94 41\n",
      "Training Accuracy 0.695\n",
      "Loss 160.81683 95 41\n",
      "Training Accuracy 0.73\n",
      "Loss 164.09785 96 41\n",
      "Training Accuracy 0.7\n",
      "Loss 178.6656 97 41\n",
      "Training Accuracy 0.69\n",
      "Loss 162.36511 98 41\n",
      "Training Accuracy 0.74\n",
      "Loss 148.00601 99 41\n",
      "Training Accuracy 0.73\n",
      "Loss 159.10776 100 41\n",
      "Training Accuracy 0.765\n",
      "Loss 192.39224 101 41\n",
      "Training Accuracy 0.67\n",
      "Loss 157.45625 102 41\n",
      "Training Accuracy 0.725\n",
      "Loss 163.25525 103 41\n",
      "Training Accuracy 0.73\n",
      "Loss 161.2453 104 41\n",
      "Training Accuracy 0.705\n",
      "Loss 164.05276 105 41\n",
      "Training Accuracy 0.715\n",
      "Loss 147.45415 106 41\n",
      "Training Accuracy 0.78\n",
      "Loss 155.4952 107 41\n",
      "Training Accuracy 0.71\n",
      "Loss 162.85205 108 41\n",
      "Training Accuracy 0.69\n",
      "Loss 160.64766 109 41\n",
      "Training Accuracy 0.705\n",
      "Loss 177.32346 110 41\n",
      "Training Accuracy 0.71\n",
      "Loss 179.87538 111 41\n",
      "Training Accuracy 0.69\n",
      "Loss 183.24982 112 41\n",
      "Training Accuracy 0.69\n",
      "Loss 185.61896 113 41\n",
      "Training Accuracy 0.72\n",
      "Loss 184.54425 114 41\n",
      "Training Accuracy 0.675\n",
      "Loss 187.39816 115 41\n",
      "Training Accuracy 0.665\n",
      "Loss 192.92067 116 41\n",
      "Training Accuracy 0.67\n",
      "Loss 129.50345 117 41\n",
      "Training Accuracy 0.795\n",
      "Loss 154.45448 118 41\n",
      "Training Accuracy 0.73\n",
      "Loss 181.25902 119 41\n",
      "Training Accuracy 0.705\n",
      "Loss 180.3134 120 41\n",
      "Training Accuracy 0.71\n",
      "Loss 174.72636 121 41\n",
      "Training Accuracy 0.685\n",
      "Loss 180.86075 122 41\n",
      "Training Accuracy 0.695\n",
      "Loss 172.04079 123 41\n",
      "Training Accuracy 0.69\n",
      "Loss 170.28226 124 41\n",
      "Training Accuracy 0.74\n",
      "Loss 150.95502 125 41\n",
      "Training Accuracy 0.7\n",
      "Loss 166.06256 126 41\n",
      "Training Accuracy 0.725\n",
      "Loss 183.44528 127 41\n",
      "Training Accuracy 0.645\n",
      "Loss 165.72614 128 41\n",
      "Training Accuracy 0.715\n",
      "Loss 152.56236 129 41\n",
      "Training Accuracy 0.745\n",
      "Loss 145.36711 130 41\n",
      "Training Accuracy 0.725\n",
      "Loss 156.95372 131 41\n",
      "Training Accuracy 0.73\n",
      "Loss 157.59975 132 41\n",
      "Training Accuracy 0.71\n",
      "Loss 155.21704 133 41\n",
      "Training Accuracy 0.745\n",
      "Loss 153.7968 134 41\n",
      "Training Accuracy 0.725\n",
      "Loss 163.74113 135 41\n",
      "Training Accuracy 0.73\n",
      "Loss 173.29428 136 41\n",
      "Training Accuracy 0.71\n",
      "Loss 178.42119 137 41\n",
      "Training Accuracy 0.74\n",
      "Loss 168.7063 138 41\n",
      "Training Accuracy 0.715\n",
      "Loss 170.0459 139 41\n",
      "Training Accuracy 0.715\n",
      "Loss 150.4249 140 41\n",
      "Training Accuracy 0.7\n",
      "Loss 173.10268 141 41\n",
      "Training Accuracy 0.74\n",
      "Loss 165.74579 142 41\n",
      "Training Accuracy 0.685\n",
      "Loss 146.48404 143 41\n",
      "Training Accuracy 0.76\n",
      "Loss 191.53789 144 41\n",
      "Training Accuracy 0.655\n",
      "Loss 160.10486 145 41\n",
      "Training Accuracy 0.72\n",
      "Loss 196.19995 146 41\n",
      "Training Accuracy 0.63\n",
      "Loss 168.9563 147 41\n",
      "Training Accuracy 0.68\n",
      "Loss 176.51872 148 41\n",
      "Training Accuracy 0.665\n",
      "Loss 165.88345 149 41\n",
      "Training Accuracy 0.69\n",
      "Loss 162.5827 150 41\n",
      "Training Accuracy 0.74\n",
      "Loss 174.15283 151 41\n",
      "Training Accuracy 0.695\n",
      "Loss 184.55074 152 41\n",
      "Training Accuracy 0.705\n",
      "Loss 155.74445 153 41\n",
      "Training Accuracy 0.775\n",
      "Loss 160.93938 154 41\n",
      "Training Accuracy 0.72\n",
      "Loss 157.69437 155 41\n",
      "Training Accuracy 0.715\n",
      "Loss 163.21202 156 41\n",
      "Training Accuracy 0.745\n",
      "Loss 151.4186 157 41\n",
      "Training Accuracy 0.725\n",
      "Loss 153.71759 158 41\n",
      "Training Accuracy 0.75\n",
      "Loss 192.3448 159 41\n",
      "Training Accuracy 0.69\n",
      "Loss 164.2037 160 41\n",
      "Training Accuracy 0.715\n",
      "Loss 185.09558 161 41\n",
      "Training Accuracy 0.655\n",
      "Loss 146.60687 162 41\n",
      "Training Accuracy 0.74\n",
      "Loss 180.07578 163 41\n",
      "Training Accuracy 0.685\n",
      "Loss 148.724 164 41\n",
      "Training Accuracy 0.75\n",
      "Loss 166.01826 165 41\n",
      "Training Accuracy 0.705\n",
      "Loss 164.62 166 41\n",
      "Training Accuracy 0.75\n",
      "Loss 158.51546 167 41\n",
      "Training Accuracy 0.76\n",
      "Loss 186.14229 168 41\n",
      "Training Accuracy 0.665\n",
      "Loss 157.99779 169 41\n",
      "Training Accuracy 0.715\n",
      "Loss 191.49896 170 41\n",
      "Training Accuracy 0.665\n",
      "Loss 167.90218 171 41\n",
      "Training Accuracy 0.73\n",
      "Loss 147.846 172 41\n",
      "Training Accuracy 0.76\n",
      "Loss 182.6304 173 41\n",
      "Training Accuracy 0.695\n",
      "Loss 143.36388 174 41\n",
      "Training Accuracy 0.725\n",
      "Loss 148.84174 175 41\n",
      "Training Accuracy 0.725\n",
      "Loss 129.69144 176 41\n",
      "Training Accuracy 0.77\n",
      "Loss 178.38986 177 41\n",
      "Training Accuracy 0.705\n",
      "Loss 156.97824 178 41\n",
      "Training Accuracy 0.745\n",
      "Loss 172.65277 179 41\n",
      "Training Accuracy 0.715\n",
      "Loss 174.88579 180 41\n",
      "Training Accuracy 0.68\n",
      "Loss 150.2631 181 41\n",
      "Training Accuracy 0.745\n",
      "Loss 176.7699 182 41\n",
      "Training Accuracy 0.7\n",
      "Loss 164.92912 183 41\n",
      "Training Accuracy 0.7\n",
      "Loss 137.15001 184 41\n",
      "Training Accuracy 0.795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 159.69427 185 41\n",
      "Training Accuracy 0.705\n",
      "Loss 165.3898 186 41\n",
      "Training Accuracy 0.715\n",
      "Loss 190.00732 187 41\n",
      "Training Accuracy 0.675\n",
      "Loss 176.10669 188 41\n",
      "Training Accuracy 0.71\n",
      "Loss 164.20207 189 41\n",
      "Training Accuracy 0.73\n",
      "Loss 162.30005 190 41\n",
      "Training Accuracy 0.715\n",
      "Loss 160.30415 191 41\n",
      "Training Accuracy 0.74\n",
      "Loss 176.18047 192 41\n",
      "Training Accuracy 0.695\n",
      "Loss 158.00853 193 41\n",
      "Training Accuracy 0.785\n",
      "Loss 156.78978 194 41\n",
      "Training Accuracy 0.785\n",
      "Loss 153.76237 195 41\n",
      "Training Accuracy 0.73\n",
      "Loss 143.92986 196 41\n",
      "Training Accuracy 0.735\n",
      "Loss 178.9239 197 41\n",
      "Training Accuracy 0.68\n",
      "Loss 168.43439 198 41\n",
      "Training Accuracy 0.69\n",
      "Loss 135.68184 199 41\n",
      "Training Accuracy 0.78\n",
      "Loss 160.79965 200 41\n",
      "Training Accuracy 0.72\n",
      "Loss 164.74446 201 41\n",
      "Training Accuracy 0.705\n",
      "Loss 151.89882 202 41\n",
      "Training Accuracy 0.71\n",
      "Loss 173.66463 203 41\n",
      "Training Accuracy 0.69\n",
      "Loss 146.47427 204 41\n",
      "Training Accuracy 0.74\n",
      "Loss 182.19316 205 41\n",
      "Training Accuracy 0.695\n",
      "Loss 170.95467 206 41\n",
      "Training Accuracy 0.725\n",
      "Loss 180.35931 207 41\n",
      "Training Accuracy 0.69\n",
      "Loss 178.85886 208 41\n",
      "Training Accuracy 0.72\n",
      "Loss 177.89471 209 41\n",
      "Training Accuracy 0.66\n",
      "Loss 143.19633 210 41\n",
      "Training Accuracy 0.745\n",
      "Loss 141.18497 211 41\n",
      "Training Accuracy 0.795\n",
      "Loss 155.95787 212 41\n",
      "Training Accuracy 0.71\n",
      "Loss 194.69562 213 41\n",
      "Training Accuracy 0.695\n",
      "Loss 152.45465 214 41\n",
      "Training Accuracy 0.715\n",
      "Loss 175.62968 215 41\n",
      "Training Accuracy 0.69\n",
      "Loss 174.6935 216 41\n",
      "Training Accuracy 0.695\n",
      "Loss 178.885 217 41\n",
      "Training Accuracy 0.67\n",
      "Loss 170.69128 218 41\n",
      "Training Accuracy 0.725\n",
      "Loss 160.36855 219 41\n",
      "Training Accuracy 0.72\n",
      "Loss 171.92317 220 41\n",
      "Training Accuracy 0.7\n",
      "Loss 160.34663 221 41\n",
      "Training Accuracy 0.76\n",
      "Loss 162.58133 222 41\n",
      "Training Accuracy 0.685\n",
      "Loss 186.79477 223 41\n",
      "Training Accuracy 0.685\n",
      "Loss 168.49094 224 41\n",
      "Training Accuracy 0.715\n",
      "Loss 168.85283 225 41\n",
      "Training Accuracy 0.73\n",
      "Loss 145.16429 226 41\n",
      "Training Accuracy 0.75\n",
      "Loss 171.32008 227 41\n",
      "Training Accuracy 0.735\n",
      "Loss 203.67146 228 41\n",
      "Training Accuracy 0.66\n",
      "Loss 160.81691 229 41\n",
      "Training Accuracy 0.705\n",
      "Loss 179.03854 230 41\n",
      "Training Accuracy 0.69\n",
      "Loss 161.38972 231 41\n",
      "Training Accuracy 0.72\n",
      "Loss 185.82925 232 41\n",
      "Training Accuracy 0.665\n",
      "Loss 193.32909 233 41\n",
      "Training Accuracy 0.605\n",
      "Loss 168.28429 234 41\n",
      "Training Accuracy 0.685\n",
      "Loss 164.35706 235 41\n",
      "Training Accuracy 0.755\n",
      "Loss 147.80403 236 41\n",
      "Training Accuracy 0.755\n",
      "Loss 177.7191 237 41\n",
      "Training Accuracy 0.735\n",
      "Loss 163.54091 238 41\n",
      "Training Accuracy 0.69\n",
      "Loss 174.5237 239 41\n",
      "Training Accuracy 0.7\n",
      "Loss 175.15533 240 41\n",
      "Training Accuracy 0.685\n",
      "Loss 199.89334 241 41\n",
      "Training Accuracy 0.68\n",
      "Loss 171.24783 242 41\n",
      "Training Accuracy 0.715\n",
      "Loss 147.6044 243 41\n",
      "Training Accuracy 0.735\n",
      "Loss 150.97507 244 41\n",
      "Training Accuracy 0.72\n",
      "Loss 170.81873 245 41\n",
      "Training Accuracy 0.715\n",
      "Loss 185.49008 246 41\n",
      "Training Accuracy 0.67\n",
      "Loss 149.74474 247 41\n",
      "Training Accuracy 0.705\n",
      "Loss 155.9969 248 41\n",
      "Training Accuracy 0.765\n",
      "Loss 177.35725 249 41\n",
      "Training Accuracy 0.65\n",
      "Loss 175.75926 250 41\n",
      "Training Accuracy 0.69\n",
      "Loss 187.29567 251 41\n",
      "Training Accuracy 0.665\n",
      "Loss 148.34848 252 41\n",
      "Training Accuracy 0.75\n",
      "Loss 132.50328 253 41\n",
      "Training Accuracy 0.805\n",
      "Loss 170.40172 254 41\n",
      "Training Accuracy 0.735\n",
      "Loss 150.7879 255 41\n",
      "Training Accuracy 0.765\n",
      "Loss 181.82878 256 41\n",
      "Training Accuracy 0.685\n",
      "Loss 163.62123 257 41\n",
      "Training Accuracy 0.71\n",
      "Loss 167.69307 258 41\n",
      "Training Accuracy 0.725\n",
      "Loss 158.60185 259 41\n",
      "Training Accuracy 0.725\n",
      "Loss 136.4662 260 41\n",
      "Training Accuracy 0.755\n",
      "Loss 163.50598 261 41\n",
      "Training Accuracy 0.705\n",
      "Loss 176.49814 262 41\n",
      "Training Accuracy 0.715\n",
      "Loss 196.14911 263 41\n",
      "Training Accuracy 0.7\n",
      "Loss 178.00073 264 41\n",
      "Training Accuracy 0.73\n",
      "Loss 148.5613 265 41\n",
      "Training Accuracy 0.76\n",
      "Loss 169.56955 266 41\n",
      "Training Accuracy 0.645\n",
      "Loss 168.06865 267 41\n",
      "Training Accuracy 0.68\n",
      "Loss 184.44551 268 41\n",
      "Training Accuracy 0.665\n",
      "Loss 163.83176 269 41\n",
      "Training Accuracy 0.705\n",
      "Loss 149.18774 270 41\n",
      "Training Accuracy 0.735\n",
      "Loss 172.42798 271 41\n",
      "Training Accuracy 0.7\n",
      "Loss 152.69351 272 41\n",
      "Training Accuracy 0.73\n",
      "Loss 172.74045 273 41\n",
      "Training Accuracy 0.705\n",
      "Loss 167.91663 274 41\n",
      "Training Accuracy 0.73\n",
      "Loss 156.28839 275 41\n",
      "Training Accuracy 0.72\n",
      "Loss 160.40558 276 41\n",
      "Training Accuracy 0.725\n",
      "Loss 164.7196 277 41\n",
      "Training Accuracy 0.71\n",
      "Loss 148.4406 278 41\n",
      "Training Accuracy 0.72\n",
      "Loss 168.3696 279 41\n",
      "Training Accuracy 0.75\n",
      "Loss 169.57507 280 41\n",
      "Training Accuracy 0.705\n",
      "Loss 139.72449 281 41\n",
      "Training Accuracy 0.805\n",
      "Loss 151.26724 282 41\n",
      "Training Accuracy 0.76\n",
      "Loss 153.79344 283 41\n",
      "Training Accuracy 0.78\n",
      "Loss 140.94115 284 41\n",
      "Training Accuracy 0.745\n",
      "Loss 184.80579 285 41\n",
      "Training Accuracy 0.695\n",
      "Loss 168.31883 286 41\n",
      "Training Accuracy 0.74\n",
      "Loss 153.19017 287 41\n",
      "Training Accuracy 0.715\n",
      "Loss 169.38748 288 41\n",
      "Training Accuracy 0.74\n",
      "Loss 159.81152 289 41\n",
      "Training Accuracy 0.72\n",
      "Loss 173.78932 290 41\n",
      "Training Accuracy 0.68\n",
      "Loss 190.22163 291 41\n",
      "Training Accuracy 0.675\n",
      "Loss 115.385574 292 41\n",
      "Training Accuracy 0.70454544\n",
      "Loss 123.88838 1 42\n",
      "Training Accuracy 0.795\n",
      "Loss 158.71614 2 42\n",
      "Training Accuracy 0.745\n",
      "Loss 152.3448 3 42\n",
      "Training Accuracy 0.72\n",
      "Loss 165.02448 4 42\n",
      "Training Accuracy 0.735\n",
      "Loss 134.07579 5 42\n",
      "Training Accuracy 0.785\n",
      "Loss 157.87013 6 42\n",
      "Training Accuracy 0.715\n",
      "Loss 180.87132 7 42\n",
      "Training Accuracy 0.685\n",
      "Loss 166.38306 8 42\n",
      "Training Accuracy 0.74\n",
      "Loss 157.2357 9 42\n",
      "Training Accuracy 0.73\n",
      "Loss 180.37726 10 42\n",
      "Training Accuracy 0.675\n",
      "Loss 181.55037 11 42\n",
      "Training Accuracy 0.72\n",
      "Loss 150.50592 12 42\n",
      "Training Accuracy 0.725\n",
      "Loss 153.03731 13 42\n",
      "Training Accuracy 0.76\n",
      "Loss 175.00706 14 42\n",
      "Training Accuracy 0.71\n",
      "Loss 149.88759 15 42\n",
      "Training Accuracy 0.765\n",
      "Loss 207.15247 16 42\n",
      "Training Accuracy 0.66\n",
      "Loss 141.42728 17 42\n",
      "Training Accuracy 0.765\n",
      "Loss 149.3432 18 42\n",
      "Training Accuracy 0.72\n",
      "Loss 150.23024 19 42\n",
      "Training Accuracy 0.75\n",
      "Loss 161.86815 20 42\n",
      "Training Accuracy 0.695\n",
      "Loss 170.92213 21 42\n",
      "Training Accuracy 0.69\n",
      "Loss 158.17027 22 42\n",
      "Training Accuracy 0.745\n",
      "Loss 166.54892 23 42\n",
      "Training Accuracy 0.725\n",
      "Loss 185.91653 24 42\n",
      "Training Accuracy 0.655\n",
      "Loss 149.5495 25 42\n",
      "Training Accuracy 0.73\n",
      "Loss 156.22281 26 42\n",
      "Training Accuracy 0.74\n",
      "Loss 158.64401 27 42\n",
      "Training Accuracy 0.685\n",
      "Loss 144.13948 28 42\n",
      "Training Accuracy 0.735\n",
      "Loss 165.88626 29 42\n",
      "Training Accuracy 0.7\n",
      "Loss 173.3977 30 42\n",
      "Training Accuracy 0.725\n",
      "Loss 159.31152 31 42\n",
      "Training Accuracy 0.745\n",
      "Loss 157.9351 32 42\n",
      "Training Accuracy 0.715\n",
      "Loss 168.7037 33 42\n",
      "Training Accuracy 0.74\n",
      "Loss 151.97963 34 42\n",
      "Training Accuracy 0.705\n",
      "Loss 165.4572 35 42\n",
      "Training Accuracy 0.665\n",
      "Loss 173.37616 36 42\n",
      "Training Accuracy 0.68\n",
      "Loss 148.11992 37 42\n",
      "Training Accuracy 0.74\n",
      "Loss 163.0136 38 42\n",
      "Training Accuracy 0.71\n",
      "Loss 146.616 39 42\n",
      "Training Accuracy 0.77\n",
      "Loss 163.29956 40 42\n",
      "Training Accuracy 0.74\n",
      "Loss 158.36342 41 42\n",
      "Training Accuracy 0.715\n",
      "Loss 182.74565 42 42\n",
      "Training Accuracy 0.695\n",
      "Loss 169.5317 43 42\n",
      "Training Accuracy 0.69\n",
      "Loss 156.3024 44 42\n",
      "Training Accuracy 0.745\n",
      "Loss 181.1759 45 42\n",
      "Training Accuracy 0.66\n",
      "Loss 174.89923 46 42\n",
      "Training Accuracy 0.72\n",
      "Loss 155.6418 47 42\n",
      "Training Accuracy 0.725\n",
      "Loss 147.63982 48 42\n",
      "Training Accuracy 0.7\n",
      "Loss 162.39484 49 42\n",
      "Training Accuracy 0.71\n",
      "Loss 180.32285 50 42\n",
      "Training Accuracy 0.69\n",
      "Loss 151.73808 51 42\n",
      "Training Accuracy 0.745\n",
      "Loss 153.21712 52 42\n",
      "Training Accuracy 0.755\n",
      "Loss 133.9544 53 42\n",
      "Training Accuracy 0.77\n",
      "Loss 182.55959 54 42\n",
      "Training Accuracy 0.685\n",
      "Loss 169.27052 55 42\n",
      "Training Accuracy 0.725\n",
      "Loss 167.13467 56 42\n",
      "Training Accuracy 0.71\n",
      "Loss 161.78587 57 42\n",
      "Training Accuracy 0.735\n",
      "Loss 149.47333 58 42\n",
      "Training Accuracy 0.73\n",
      "Loss 187.47142 59 42\n",
      "Training Accuracy 0.675\n",
      "Loss 151.84334 60 42\n",
      "Training Accuracy 0.765\n",
      "Loss 172.78578 61 42\n",
      "Training Accuracy 0.68\n",
      "Loss 157.9706 62 42\n",
      "Training Accuracy 0.745\n",
      "Loss 157.44177 63 42\n",
      "Training Accuracy 0.77\n",
      "Loss 169.31197 64 42\n",
      "Training Accuracy 0.72\n",
      "Loss 169.85379 65 42\n",
      "Training Accuracy 0.675\n",
      "Loss 158.12448 66 42\n",
      "Training Accuracy 0.74\n",
      "Loss 158.8658 67 42\n",
      "Training Accuracy 0.79\n",
      "Loss 175.478 68 42\n",
      "Training Accuracy 0.705\n",
      "Loss 163.27513 69 42\n",
      "Training Accuracy 0.725\n",
      "Loss 158.14342 70 42\n",
      "Training Accuracy 0.755\n",
      "Loss 165.89592 71 42\n",
      "Training Accuracy 0.735\n",
      "Loss 159.65402 72 42\n",
      "Training Accuracy 0.73\n",
      "Loss 171.34206 73 42\n",
      "Training Accuracy 0.7\n",
      "Loss 171.2357 74 42\n",
      "Training Accuracy 0.73\n",
      "Loss 165.27863 75 42\n",
      "Training Accuracy 0.705\n",
      "Loss 145.82178 76 42\n",
      "Training Accuracy 0.73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 183.29622 77 42\n",
      "Training Accuracy 0.7\n",
      "Loss 153.15582 78 42\n",
      "Training Accuracy 0.75\n",
      "Loss 163.1411 79 42\n",
      "Training Accuracy 0.675\n",
      "Loss 187.28336 80 42\n",
      "Training Accuracy 0.69\n",
      "Loss 158.35251 81 42\n",
      "Training Accuracy 0.72\n",
      "Loss 160.7974 82 42\n",
      "Training Accuracy 0.725\n",
      "Loss 159.11748 83 42\n",
      "Training Accuracy 0.73\n",
      "Loss 172.72945 84 42\n",
      "Training Accuracy 0.73\n",
      "Loss 169.7562 85 42\n",
      "Training Accuracy 0.715\n",
      "Loss 167.16797 86 42\n",
      "Training Accuracy 0.715\n",
      "Loss 207.79585 87 42\n",
      "Training Accuracy 0.67\n",
      "Loss 190.67058 88 42\n",
      "Training Accuracy 0.685\n",
      "Loss 169.78957 89 42\n",
      "Training Accuracy 0.695\n",
      "Loss 181.53851 90 42\n",
      "Training Accuracy 0.685\n",
      "Loss 165.30101 91 42\n",
      "Training Accuracy 0.71\n",
      "Loss 163.89919 92 42\n",
      "Training Accuracy 0.715\n",
      "Loss 164.7205 93 42\n",
      "Training Accuracy 0.715\n",
      "Loss 159.88457 94 42\n",
      "Training Accuracy 0.695\n",
      "Loss 167.77373 95 42\n",
      "Training Accuracy 0.695\n",
      "Loss 153.18573 96 42\n",
      "Training Accuracy 0.73\n",
      "Loss 163.22037 97 42\n",
      "Training Accuracy 0.74\n",
      "Loss 157.3431 98 42\n",
      "Training Accuracy 0.725\n",
      "Loss 154.94214 99 42\n",
      "Training Accuracy 0.72\n",
      "Loss 159.82553 100 42\n",
      "Training Accuracy 0.76\n",
      "Loss 187.08046 101 42\n",
      "Training Accuracy 0.675\n",
      "Loss 164.70767 102 42\n",
      "Training Accuracy 0.72\n",
      "Loss 160.39005 103 42\n",
      "Training Accuracy 0.735\n",
      "Loss 168.22112 104 42\n",
      "Training Accuracy 0.7\n",
      "Loss 160.54077 105 42\n",
      "Training Accuracy 0.735\n",
      "Loss 150.59708 106 42\n",
      "Training Accuracy 0.74\n",
      "Loss 155.3058 107 42\n",
      "Training Accuracy 0.74\n",
      "Loss 148.96112 108 42\n",
      "Training Accuracy 0.735\n",
      "Loss 151.84186 109 42\n",
      "Training Accuracy 0.745\n",
      "Loss 178.05292 110 42\n",
      "Training Accuracy 0.73\n",
      "Loss 170.52487 111 42\n",
      "Training Accuracy 0.7\n",
      "Loss 180.13641 112 42\n",
      "Training Accuracy 0.72\n",
      "Loss 184.04974 113 42\n",
      "Training Accuracy 0.73\n",
      "Loss 155.59642 114 42\n",
      "Training Accuracy 0.71\n",
      "Loss 175.91296 115 42\n",
      "Training Accuracy 0.705\n",
      "Loss 182.98099 116 42\n",
      "Training Accuracy 0.705\n",
      "Loss 125.176315 117 42\n",
      "Training Accuracy 0.8\n",
      "Loss 177.23505 118 42\n",
      "Training Accuracy 0.695\n",
      "Loss 188.36563 119 42\n",
      "Training Accuracy 0.69\n",
      "Loss 175.01192 120 42\n",
      "Training Accuracy 0.68\n",
      "Loss 182.09146 121 42\n",
      "Training Accuracy 0.685\n",
      "Loss 175.89424 122 42\n",
      "Training Accuracy 0.69\n",
      "Loss 162.08083 123 42\n",
      "Training Accuracy 0.74\n",
      "Loss 162.25763 124 42\n",
      "Training Accuracy 0.72\n",
      "Loss 152.80669 125 42\n",
      "Training Accuracy 0.72\n",
      "Loss 171.84795 126 42\n",
      "Training Accuracy 0.685\n",
      "Loss 182.20341 127 42\n",
      "Training Accuracy 0.665\n",
      "Loss 154.98457 128 42\n",
      "Training Accuracy 0.74\n",
      "Loss 150.5055 129 42\n",
      "Training Accuracy 0.75\n",
      "Loss 143.89473 130 42\n",
      "Training Accuracy 0.74\n",
      "Loss 152.0733 131 42\n",
      "Training Accuracy 0.715\n",
      "Loss 158.11032 132 42\n",
      "Training Accuracy 0.725\n",
      "Loss 165.26973 133 42\n",
      "Training Accuracy 0.715\n",
      "Loss 150.88742 134 42\n",
      "Training Accuracy 0.75\n",
      "Loss 163.09892 135 42\n",
      "Training Accuracy 0.725\n",
      "Loss 170.53648 136 42\n",
      "Training Accuracy 0.725\n",
      "Loss 174.17107 137 42\n",
      "Training Accuracy 0.72\n",
      "Loss 166.98613 138 42\n",
      "Training Accuracy 0.71\n",
      "Loss 173.38008 139 42\n",
      "Training Accuracy 0.715\n",
      "Loss 148.61858 140 42\n",
      "Training Accuracy 0.75\n",
      "Loss 182.72821 141 42\n",
      "Training Accuracy 0.675\n",
      "Loss 169.0277 142 42\n",
      "Training Accuracy 0.69\n",
      "Loss 146.22974 143 42\n",
      "Training Accuracy 0.765\n",
      "Loss 186.33232 144 42\n",
      "Training Accuracy 0.67\n",
      "Loss 155.37163 145 42\n",
      "Training Accuracy 0.735\n",
      "Loss 189.72241 146 42\n",
      "Training Accuracy 0.645\n",
      "Loss 171.53416 147 42\n",
      "Training Accuracy 0.72\n",
      "Loss 176.12154 148 42\n",
      "Training Accuracy 0.7\n",
      "Loss 156.44946 149 42\n",
      "Training Accuracy 0.73\n",
      "Loss 153.00519 150 42\n",
      "Training Accuracy 0.72\n",
      "Loss 170.09216 151 42\n",
      "Training Accuracy 0.705\n",
      "Loss 189.15477 152 42\n",
      "Training Accuracy 0.705\n",
      "Loss 150.44029 153 42\n",
      "Training Accuracy 0.74\n",
      "Loss 164.85349 154 42\n",
      "Training Accuracy 0.715\n",
      "Loss 154.10347 155 42\n",
      "Training Accuracy 0.72\n",
      "Loss 165.91527 156 42\n",
      "Training Accuracy 0.705\n",
      "Loss 161.90372 157 42\n",
      "Training Accuracy 0.68\n",
      "Loss 147.01537 158 42\n",
      "Training Accuracy 0.78\n",
      "Loss 193.66069 159 42\n",
      "Training Accuracy 0.665\n",
      "Loss 158.11621 160 42\n",
      "Training Accuracy 0.725\n",
      "Loss 180.19942 161 42\n",
      "Training Accuracy 0.67\n",
      "Loss 158.24559 162 42\n",
      "Training Accuracy 0.75\n",
      "Loss 186.19366 163 42\n",
      "Training Accuracy 0.695\n",
      "Loss 152.82578 164 42\n",
      "Training Accuracy 0.735\n",
      "Loss 166.49162 165 42\n",
      "Training Accuracy 0.73\n",
      "Loss 161.8019 166 42\n",
      "Training Accuracy 0.745\n",
      "Loss 152.32137 167 42\n",
      "Training Accuracy 0.745\n",
      "Loss 177.41312 168 42\n",
      "Training Accuracy 0.74\n",
      "Loss 165.97673 169 42\n",
      "Training Accuracy 0.68\n",
      "Loss 180.8977 170 42\n",
      "Training Accuracy 0.69\n",
      "Loss 166.04778 171 42\n",
      "Training Accuracy 0.75\n",
      "Loss 156.46657 172 42\n",
      "Training Accuracy 0.725\n",
      "Loss 171.47574 173 42\n",
      "Training Accuracy 0.75\n",
      "Loss 145.35182 174 42\n",
      "Training Accuracy 0.735\n",
      "Loss 140.314 175 42\n",
      "Training Accuracy 0.8\n",
      "Loss 131.7055 176 42\n",
      "Training Accuracy 0.775\n",
      "Loss 182.47168 177 42\n",
      "Training Accuracy 0.68\n",
      "Loss 155.16504 178 42\n",
      "Training Accuracy 0.73\n",
      "Loss 174.85359 179 42\n",
      "Training Accuracy 0.68\n",
      "Loss 177.17816 180 42\n",
      "Training Accuracy 0.69\n",
      "Loss 145.41808 181 42\n",
      "Training Accuracy 0.755\n",
      "Loss 175.30469 182 42\n",
      "Training Accuracy 0.72\n",
      "Loss 173.44116 183 42\n",
      "Training Accuracy 0.685\n",
      "Loss 146.74129 184 42\n",
      "Training Accuracy 0.74\n",
      "Loss 164.3929 185 42\n",
      "Training Accuracy 0.72\n",
      "Loss 159.87134 186 42\n",
      "Training Accuracy 0.725\n",
      "Loss 204.50195 187 42\n",
      "Training Accuracy 0.675\n",
      "Loss 175.79884 188 42\n",
      "Training Accuracy 0.71\n",
      "Loss 162.91872 189 42\n",
      "Training Accuracy 0.735\n",
      "Loss 158.33188 190 42\n",
      "Training Accuracy 0.725\n",
      "Loss 149.34145 191 42\n",
      "Training Accuracy 0.725\n",
      "Loss 175.01788 192 42\n",
      "Training Accuracy 0.69\n",
      "Loss 161.02776 193 42\n",
      "Training Accuracy 0.7\n",
      "Loss 153.61517 194 42\n",
      "Training Accuracy 0.745\n",
      "Loss 136.23428 195 42\n",
      "Training Accuracy 0.785\n",
      "Loss 153.12476 196 42\n",
      "Training Accuracy 0.73\n",
      "Loss 155.76526 197 42\n",
      "Training Accuracy 0.755\n",
      "Loss 156.99619 198 42\n",
      "Training Accuracy 0.72\n",
      "Loss 132.056 199 42\n",
      "Training Accuracy 0.8\n",
      "Loss 136.92766 200 42\n",
      "Training Accuracy 0.78\n",
      "Loss 160.53363 201 42\n",
      "Training Accuracy 0.72\n",
      "Loss 141.42494 202 42\n",
      "Training Accuracy 0.735\n",
      "Loss 173.70753 203 42\n",
      "Training Accuracy 0.695\n",
      "Loss 160.40175 204 42\n",
      "Training Accuracy 0.735\n",
      "Loss 165.97153 205 42\n",
      "Training Accuracy 0.73\n",
      "Loss 170.21857 206 42\n",
      "Training Accuracy 0.71\n",
      "Loss 165.07552 207 42\n",
      "Training Accuracy 0.705\n",
      "Loss 171.18697 208 42\n",
      "Training Accuracy 0.69\n",
      "Loss 164.73428 209 42\n",
      "Training Accuracy 0.69\n",
      "Loss 147.25522 210 42\n",
      "Training Accuracy 0.765\n",
      "Loss 153.79166 211 42\n",
      "Training Accuracy 0.735\n",
      "Loss 156.71391 212 42\n",
      "Training Accuracy 0.74\n",
      "Loss 184.28107 213 42\n",
      "Training Accuracy 0.67\n",
      "Loss 159.3796 214 42\n",
      "Training Accuracy 0.695\n",
      "Loss 176.13379 215 42\n",
      "Training Accuracy 0.67\n",
      "Loss 181.09377 216 42\n",
      "Training Accuracy 0.66\n",
      "Loss 170.75957 217 42\n",
      "Training Accuracy 0.665\n",
      "Loss 168.56837 218 42\n",
      "Training Accuracy 0.69\n",
      "Loss 168.02615 219 42\n",
      "Training Accuracy 0.735\n",
      "Loss 159.84843 220 42\n",
      "Training Accuracy 0.74\n",
      "Loss 158.92073 221 42\n",
      "Training Accuracy 0.715\n",
      "Loss 161.04402 222 42\n",
      "Training Accuracy 0.74\n",
      "Loss 181.07869 223 42\n",
      "Training Accuracy 0.695\n",
      "Loss 176.3148 224 42\n",
      "Training Accuracy 0.72\n",
      "Loss 166.44995 225 42\n",
      "Training Accuracy 0.685\n",
      "Loss 140.38396 226 42\n",
      "Training Accuracy 0.78\n",
      "Loss 174.71463 227 42\n",
      "Training Accuracy 0.67\n",
      "Loss 201.9342 228 42\n",
      "Training Accuracy 0.685\n",
      "Loss 159.29723 229 42\n",
      "Training Accuracy 0.74\n",
      "Loss 183.87471 230 42\n",
      "Training Accuracy 0.675\n",
      "Loss 147.27487 231 42\n",
      "Training Accuracy 0.76\n",
      "Loss 167.04953 232 42\n",
      "Training Accuracy 0.725\n",
      "Loss 191.94206 233 42\n",
      "Training Accuracy 0.61\n",
      "Loss 165.57416 234 42\n",
      "Training Accuracy 0.67\n",
      "Loss 171.57858 235 42\n",
      "Training Accuracy 0.72\n",
      "Loss 145.1066 236 42\n",
      "Training Accuracy 0.76\n",
      "Loss 164.62018 237 42\n",
      "Training Accuracy 0.73\n",
      "Loss 147.50713 238 42\n",
      "Training Accuracy 0.74\n",
      "Loss 161.14638 239 42\n",
      "Training Accuracy 0.765\n",
      "Loss 165.75888 240 42\n",
      "Training Accuracy 0.74\n",
      "Loss 191.33899 241 42\n",
      "Training Accuracy 0.675\n",
      "Loss 169.32903 242 42\n",
      "Training Accuracy 0.71\n",
      "Loss 142.4541 243 42\n",
      "Training Accuracy 0.745\n",
      "Loss 161.38876 244 42\n",
      "Training Accuracy 0.7\n",
      "Loss 163.88914 245 42\n",
      "Training Accuracy 0.745\n",
      "Loss 194.48438 246 42\n",
      "Training Accuracy 0.67\n",
      "Loss 147.767 247 42\n",
      "Training Accuracy 0.715\n",
      "Loss 146.32631 248 42\n",
      "Training Accuracy 0.73\n",
      "Loss 179.38336 249 42\n",
      "Training Accuracy 0.685\n",
      "Loss 166.28354 250 42\n",
      "Training Accuracy 0.695\n",
      "Loss 173.12099 251 42\n",
      "Training Accuracy 0.675\n",
      "Loss 144.15204 252 42\n",
      "Training Accuracy 0.745\n",
      "Loss 124.885155 253 42\n",
      "Training Accuracy 0.79\n",
      "Loss 170.44637 254 42\n",
      "Training Accuracy 0.71\n",
      "Loss 141.11797 255 42\n",
      "Training Accuracy 0.755\n",
      "Loss 181.64587 256 42\n",
      "Training Accuracy 0.71\n",
      "Loss 156.04823 257 42\n",
      "Training Accuracy 0.72\n",
      "Loss 170.03271 258 42\n",
      "Training Accuracy 0.695\n",
      "Loss 160.66629 259 42\n",
      "Training Accuracy 0.725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 129.69075 260 42\n",
      "Training Accuracy 0.755\n",
      "Loss 172.3665 261 42\n",
      "Training Accuracy 0.705\n",
      "Loss 169.8541 262 42\n",
      "Training Accuracy 0.66\n",
      "Loss 198.64116 263 42\n",
      "Training Accuracy 0.68\n",
      "Loss 160.1045 264 42\n",
      "Training Accuracy 0.725\n",
      "Loss 153.74495 265 42\n",
      "Training Accuracy 0.74\n",
      "Loss 156.15392 266 42\n",
      "Training Accuracy 0.75\n",
      "Loss 160.72302 267 42\n",
      "Training Accuracy 0.7\n",
      "Loss 175.48167 268 42\n",
      "Training Accuracy 0.715\n",
      "Loss 159.94203 269 42\n",
      "Training Accuracy 0.69\n",
      "Loss 144.43416 270 42\n",
      "Training Accuracy 0.77\n",
      "Loss 174.32425 271 42\n",
      "Training Accuracy 0.715\n",
      "Loss 158.21797 272 42\n",
      "Training Accuracy 0.72\n",
      "Loss 177.21011 273 42\n",
      "Training Accuracy 0.68\n",
      "Loss 161.23903 274 42\n",
      "Training Accuracy 0.715\n",
      "Loss 155.4367 275 42\n",
      "Training Accuracy 0.735\n",
      "Loss 158.36781 276 42\n",
      "Training Accuracy 0.71\n",
      "Loss 160.5953 277 42\n",
      "Training Accuracy 0.72\n",
      "Loss 157.25587 278 42\n",
      "Training Accuracy 0.715\n",
      "Loss 159.90231 279 42\n",
      "Training Accuracy 0.745\n",
      "Loss 162.00703 280 42\n",
      "Training Accuracy 0.71\n",
      "Loss 145.5178 281 42\n",
      "Training Accuracy 0.735\n",
      "Loss 154.10468 282 42\n",
      "Training Accuracy 0.72\n",
      "Loss 163.8163 283 42\n",
      "Training Accuracy 0.74\n",
      "Loss 127.25796 284 42\n",
      "Training Accuracy 0.77\n",
      "Loss 174.59972 285 42\n",
      "Training Accuracy 0.695\n",
      "Loss 155.38162 286 42\n",
      "Training Accuracy 0.775\n",
      "Loss 156.44656 287 42\n",
      "Training Accuracy 0.745\n",
      "Loss 171.96945 288 42\n",
      "Training Accuracy 0.695\n",
      "Loss 167.27632 289 42\n",
      "Training Accuracy 0.72\n",
      "Loss 168.10544 290 42\n",
      "Training Accuracy 0.725\n",
      "Loss 193.77957 291 42\n",
      "Training Accuracy 0.69\n",
      "Loss 105.792725 292 42\n",
      "Training Accuracy 0.68939394\n",
      "Loss 131.85786 1 43\n",
      "Training Accuracy 0.805\n",
      "Loss 163.17726 2 43\n",
      "Training Accuracy 0.72\n",
      "Loss 144.62656 3 43\n",
      "Training Accuracy 0.77\n",
      "Loss 168.4877 4 43\n",
      "Training Accuracy 0.735\n",
      "Loss 139.22237 5 43\n",
      "Training Accuracy 0.735\n",
      "Loss 171.0487 6 43\n",
      "Training Accuracy 0.69\n",
      "Loss 164.50592 7 43\n",
      "Training Accuracy 0.745\n",
      "Loss 164.14629 8 43\n",
      "Training Accuracy 0.75\n",
      "Loss 146.82506 9 43\n",
      "Training Accuracy 0.735\n",
      "Loss 185.1667 10 43\n",
      "Training Accuracy 0.685\n",
      "Loss 182.55634 11 43\n",
      "Training Accuracy 0.705\n",
      "Loss 144.87395 12 43\n",
      "Training Accuracy 0.765\n",
      "Loss 147.92348 13 43\n",
      "Training Accuracy 0.755\n",
      "Loss 164.08575 14 43\n",
      "Training Accuracy 0.725\n",
      "Loss 149.72537 15 43\n",
      "Training Accuracy 0.735\n",
      "Loss 197.38744 16 43\n",
      "Training Accuracy 0.665\n",
      "Loss 139.4403 17 43\n",
      "Training Accuracy 0.765\n",
      "Loss 140.70845 18 43\n",
      "Training Accuracy 0.765\n",
      "Loss 158.06776 19 43\n",
      "Training Accuracy 0.695\n",
      "Loss 162.07802 20 43\n",
      "Training Accuracy 0.7\n",
      "Loss 179.8444 21 43\n",
      "Training Accuracy 0.69\n",
      "Loss 160.3731 22 43\n",
      "Training Accuracy 0.715\n",
      "Loss 156.67635 23 43\n",
      "Training Accuracy 0.75\n",
      "Loss 170.74367 24 43\n",
      "Training Accuracy 0.68\n",
      "Loss 148.31467 25 43\n",
      "Training Accuracy 0.765\n",
      "Loss 167.67937 26 43\n",
      "Training Accuracy 0.72\n",
      "Loss 155.72823 27 43\n",
      "Training Accuracy 0.715\n",
      "Loss 153.36705 28 43\n",
      "Training Accuracy 0.73\n",
      "Loss 162.8414 29 43\n",
      "Training Accuracy 0.695\n",
      "Loss 172.01709 30 43\n",
      "Training Accuracy 0.715\n",
      "Loss 163.25293 31 43\n",
      "Training Accuracy 0.7\n",
      "Loss 160.64297 32 43\n",
      "Training Accuracy 0.725\n",
      "Loss 169.95181 33 43\n",
      "Training Accuracy 0.695\n",
      "Loss 151.61523 34 43\n",
      "Training Accuracy 0.745\n",
      "Loss 145.57802 35 43\n",
      "Training Accuracy 0.73\n",
      "Loss 171.89565 36 43\n",
      "Training Accuracy 0.71\n",
      "Loss 145.0112 37 43\n",
      "Training Accuracy 0.76\n",
      "Loss 161.72438 38 43\n",
      "Training Accuracy 0.73\n",
      "Loss 135.2754 39 43\n",
      "Training Accuracy 0.765\n",
      "Loss 158.37035 40 43\n",
      "Training Accuracy 0.715\n",
      "Loss 166.5906 41 43\n",
      "Training Accuracy 0.675\n",
      "Loss 174.72287 42 43\n",
      "Training Accuracy 0.7\n",
      "Loss 171.67549 43 43\n",
      "Training Accuracy 0.645\n",
      "Loss 179.54753 44 43\n",
      "Training Accuracy 0.69\n",
      "Loss 165.70984 45 43\n",
      "Training Accuracy 0.725\n",
      "Loss 188.6398 46 43\n",
      "Training Accuracy 0.67\n",
      "Loss 161.17178 47 43\n",
      "Training Accuracy 0.72\n",
      "Loss 135.7505 48 43\n",
      "Training Accuracy 0.76\n",
      "Loss 153.65282 49 43\n",
      "Training Accuracy 0.75\n",
      "Loss 176.23065 50 43\n",
      "Training Accuracy 0.725\n",
      "Loss 124.74477 51 43\n",
      "Training Accuracy 0.8\n",
      "Loss 147.66779 52 43\n",
      "Training Accuracy 0.74\n",
      "Loss 127.85545 53 43\n",
      "Training Accuracy 0.765\n",
      "Loss 192.05334 54 43\n",
      "Training Accuracy 0.685\n",
      "Loss 169.92343 55 43\n",
      "Training Accuracy 0.7\n",
      "Loss 160.16324 56 43\n",
      "Training Accuracy 0.725\n",
      "Loss 157.76646 57 43\n",
      "Training Accuracy 0.74\n",
      "Loss 153.39929 58 43\n",
      "Training Accuracy 0.745\n",
      "Loss 170.94215 59 43\n",
      "Training Accuracy 0.7\n",
      "Loss 153.5658 60 43\n",
      "Training Accuracy 0.76\n",
      "Loss 173.3363 61 43\n",
      "Training Accuracy 0.705\n",
      "Loss 138.2919 62 43\n",
      "Training Accuracy 0.76\n",
      "Loss 159.22131 63 43\n",
      "Training Accuracy 0.715\n",
      "Loss 169.7076 64 43\n",
      "Training Accuracy 0.725\n",
      "Loss 168.08975 65 43\n",
      "Training Accuracy 0.715\n",
      "Loss 139.81789 66 43\n",
      "Training Accuracy 0.75\n",
      "Loss 161.30426 67 43\n",
      "Training Accuracy 0.725\n",
      "Loss 152.07733 68 43\n",
      "Training Accuracy 0.74\n",
      "Loss 168.05951 69 43\n",
      "Training Accuracy 0.685\n",
      "Loss 145.24675 70 43\n",
      "Training Accuracy 0.755\n",
      "Loss 169.48721 71 43\n",
      "Training Accuracy 0.705\n",
      "Loss 167.9997 72 43\n",
      "Training Accuracy 0.715\n",
      "Loss 173.4718 73 43\n",
      "Training Accuracy 0.7\n",
      "Loss 172.00156 74 43\n",
      "Training Accuracy 0.7\n",
      "Loss 171.1963 75 43\n",
      "Training Accuracy 0.7\n",
      "Loss 128.04459 76 43\n",
      "Training Accuracy 0.745\n",
      "Loss 187.953 77 43\n",
      "Training Accuracy 0.66\n",
      "Loss 157.83109 78 43\n",
      "Training Accuracy 0.75\n",
      "Loss 171.17065 79 43\n",
      "Training Accuracy 0.68\n",
      "Loss 181.74796 80 43\n",
      "Training Accuracy 0.72\n",
      "Loss 149.89311 81 43\n",
      "Training Accuracy 0.74\n",
      "Loss 148.06876 82 43\n",
      "Training Accuracy 0.75\n",
      "Loss 158.9827 83 43\n",
      "Training Accuracy 0.74\n",
      "Loss 176.27483 84 43\n",
      "Training Accuracy 0.685\n",
      "Loss 159.00731 85 43\n",
      "Training Accuracy 0.695\n",
      "Loss 157.99886 86 43\n",
      "Training Accuracy 0.755\n",
      "Loss 190.07916 87 43\n",
      "Training Accuracy 0.69\n",
      "Loss 185.20279 88 43\n",
      "Training Accuracy 0.695\n",
      "Loss 167.94879 89 43\n",
      "Training Accuracy 0.705\n",
      "Loss 179.69675 90 43\n",
      "Training Accuracy 0.665\n",
      "Loss 164.84174 91 43\n",
      "Training Accuracy 0.71\n",
      "Loss 168.94226 92 43\n",
      "Training Accuracy 0.725\n",
      "Loss 177.01978 93 43\n",
      "Training Accuracy 0.685\n",
      "Loss 169.75926 94 43\n",
      "Training Accuracy 0.67\n",
      "Loss 161.9192 95 43\n",
      "Training Accuracy 0.69\n",
      "Loss 167.40915 96 43\n",
      "Training Accuracy 0.695\n",
      "Loss 157.34706 97 43\n",
      "Training Accuracy 0.72\n",
      "Loss 164.64786 98 43\n",
      "Training Accuracy 0.715\n",
      "Loss 149.6648 99 43\n",
      "Training Accuracy 0.77\n",
      "Loss 159.10605 100 43\n",
      "Training Accuracy 0.72\n",
      "Loss 177.79968 101 43\n",
      "Training Accuracy 0.68\n",
      "Loss 159.57697 102 43\n",
      "Training Accuracy 0.685\n",
      "Loss 151.2579 103 43\n",
      "Training Accuracy 0.73\n",
      "Loss 162.32002 104 43\n",
      "Training Accuracy 0.72\n",
      "Loss 154.07906 105 43\n",
      "Training Accuracy 0.75\n",
      "Loss 150.14087 106 43\n",
      "Training Accuracy 0.76\n",
      "Loss 152.66815 107 43\n",
      "Training Accuracy 0.71\n",
      "Loss 156.98123 108 43\n",
      "Training Accuracy 0.715\n",
      "Loss 155.653 109 43\n",
      "Training Accuracy 0.75\n",
      "Loss 185.42863 110 43\n",
      "Training Accuracy 0.69\n",
      "Loss 164.62349 111 43\n",
      "Training Accuracy 0.705\n",
      "Loss 174.40628 112 43\n",
      "Training Accuracy 0.69\n",
      "Loss 176.7887 113 43\n",
      "Training Accuracy 0.725\n",
      "Loss 171.7792 114 43\n",
      "Training Accuracy 0.66\n",
      "Loss 182.82751 115 43\n",
      "Training Accuracy 0.7\n",
      "Loss 173.65749 116 43\n",
      "Training Accuracy 0.7\n",
      "Loss 121.876045 117 43\n",
      "Training Accuracy 0.815\n",
      "Loss 156.65215 118 43\n",
      "Training Accuracy 0.69\n",
      "Loss 193.14636 119 43\n",
      "Training Accuracy 0.665\n",
      "Loss 174.05884 120 43\n",
      "Training Accuracy 0.69\n",
      "Loss 172.78615 121 43\n",
      "Training Accuracy 0.725\n",
      "Loss 162.00793 122 43\n",
      "Training Accuracy 0.72\n",
      "Loss 158.58908 123 43\n",
      "Training Accuracy 0.75\n",
      "Loss 160.49619 124 43\n",
      "Training Accuracy 0.705\n",
      "Loss 141.59984 125 43\n",
      "Training Accuracy 0.74\n",
      "Loss 162.4778 126 43\n",
      "Training Accuracy 0.725\n",
      "Loss 174.21414 127 43\n",
      "Training Accuracy 0.7\n",
      "Loss 154.6341 128 43\n",
      "Training Accuracy 0.735\n",
      "Loss 148.90178 129 43\n",
      "Training Accuracy 0.755\n",
      "Loss 151.6362 130 43\n",
      "Training Accuracy 0.695\n",
      "Loss 146.26372 131 43\n",
      "Training Accuracy 0.765\n",
      "Loss 150.40392 132 43\n",
      "Training Accuracy 0.73\n",
      "Loss 149.85031 133 43\n",
      "Training Accuracy 0.74\n",
      "Loss 167.84407 134 43\n",
      "Training Accuracy 0.69\n",
      "Loss 166.87675 135 43\n",
      "Training Accuracy 0.745\n",
      "Loss 167.90521 136 43\n",
      "Training Accuracy 0.685\n",
      "Loss 171.13644 137 43\n",
      "Training Accuracy 0.71\n",
      "Loss 165.36282 138 43\n",
      "Training Accuracy 0.745\n",
      "Loss 162.9976 139 43\n",
      "Training Accuracy 0.725\n",
      "Loss 147.82509 140 43\n",
      "Training Accuracy 0.72\n",
      "Loss 169.8029 141 43\n",
      "Training Accuracy 0.75\n",
      "Loss 171.7936 142 43\n",
      "Training Accuracy 0.68\n",
      "Loss 151.07466 143 43\n",
      "Training Accuracy 0.715\n",
      "Loss 176.09894 144 43\n",
      "Training Accuracy 0.69\n",
      "Loss 172.62877 145 43\n",
      "Training Accuracy 0.675\n",
      "Loss 179.50764 146 43\n",
      "Training Accuracy 0.68\n",
      "Loss 167.7657 147 43\n",
      "Training Accuracy 0.715\n",
      "Loss 167.00526 148 43\n",
      "Training Accuracy 0.685\n",
      "Loss 162.78279 149 43\n",
      "Training Accuracy 0.725\n",
      "Loss 153.40668 150 43\n",
      "Training Accuracy 0.725\n",
      "Loss 160.35428 151 43\n",
      "Training Accuracy 0.73\n",
      "Loss 176.95442 152 43\n",
      "Training Accuracy 0.695\n",
      "Loss 155.67744 153 43\n",
      "Training Accuracy 0.745\n",
      "Loss 159.90489 154 43\n",
      "Training Accuracy 0.71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 148.2133 155 43\n",
      "Training Accuracy 0.75\n",
      "Loss 143.57043 156 43\n",
      "Training Accuracy 0.74\n",
      "Loss 145.99709 157 43\n",
      "Training Accuracy 0.72\n",
      "Loss 157.03842 158 43\n",
      "Training Accuracy 0.745\n",
      "Loss 184.34486 159 43\n",
      "Training Accuracy 0.675\n",
      "Loss 168.24129 160 43\n",
      "Training Accuracy 0.71\n",
      "Loss 182.69627 161 43\n",
      "Training Accuracy 0.66\n",
      "Loss 154.32394 162 43\n",
      "Training Accuracy 0.73\n",
      "Loss 186.00311 163 43\n",
      "Training Accuracy 0.7\n",
      "Loss 156.27188 164 43\n",
      "Training Accuracy 0.685\n",
      "Loss 164.31107 165 43\n",
      "Training Accuracy 0.735\n",
      "Loss 157.2681 166 43\n",
      "Training Accuracy 0.75\n",
      "Loss 147.89757 167 43\n",
      "Training Accuracy 0.74\n",
      "Loss 163.07953 168 43\n",
      "Training Accuracy 0.73\n",
      "Loss 159.20326 169 43\n",
      "Training Accuracy 0.72\n",
      "Loss 184.38158 170 43\n",
      "Training Accuracy 0.67\n",
      "Loss 166.78986 171 43\n",
      "Training Accuracy 0.75\n",
      "Loss 149.24063 172 43\n",
      "Training Accuracy 0.78\n",
      "Loss 167.63571 173 43\n",
      "Training Accuracy 0.745\n",
      "Loss 138.18138 174 43\n",
      "Training Accuracy 0.725\n",
      "Loss 136.52412 175 43\n",
      "Training Accuracy 0.78\n",
      "Loss 121.39502 176 43\n",
      "Training Accuracy 0.795\n",
      "Loss 161.86115 177 43\n",
      "Training Accuracy 0.73\n",
      "Loss 152.89127 178 43\n",
      "Training Accuracy 0.74\n",
      "Loss 161.04163 179 43\n",
      "Training Accuracy 0.695\n",
      "Loss 167.17474 180 43\n",
      "Training Accuracy 0.715\n",
      "Loss 149.60263 181 43\n",
      "Training Accuracy 0.74\n",
      "Loss 170.08595 182 43\n",
      "Training Accuracy 0.7\n",
      "Loss 186.70006 183 43\n",
      "Training Accuracy 0.66\n",
      "Loss 140.60085 184 43\n",
      "Training Accuracy 0.76\n",
      "Loss 163.85954 185 43\n",
      "Training Accuracy 0.715\n",
      "Loss 169.267 186 43\n",
      "Training Accuracy 0.73\n",
      "Loss 193.11813 187 43\n",
      "Training Accuracy 0.655\n",
      "Loss 167.38782 188 43\n",
      "Training Accuracy 0.72\n",
      "Loss 141.472 189 43\n",
      "Training Accuracy 0.75\n",
      "Loss 155.4364 190 43\n",
      "Training Accuracy 0.72\n",
      "Loss 137.99178 191 43\n",
      "Training Accuracy 0.765\n",
      "Loss 168.38058 192 43\n",
      "Training Accuracy 0.69\n",
      "Loss 144.83754 193 43\n",
      "Training Accuracy 0.76\n",
      "Loss 146.97952 194 43\n",
      "Training Accuracy 0.765\n",
      "Loss 138.36618 195 43\n",
      "Training Accuracy 0.79\n",
      "Loss 146.30496 196 43\n",
      "Training Accuracy 0.73\n",
      "Loss 153.10904 197 43\n",
      "Training Accuracy 0.715\n",
      "Loss 164.27371 198 43\n",
      "Training Accuracy 0.69\n",
      "Loss 135.9901 199 43\n",
      "Training Accuracy 0.765\n",
      "Loss 147.8045 200 43\n",
      "Training Accuracy 0.77\n",
      "Loss 148.60541 201 43\n",
      "Training Accuracy 0.735\n",
      "Loss 155.50836 202 43\n",
      "Training Accuracy 0.76\n",
      "Loss 162.29678 203 43\n",
      "Training Accuracy 0.735\n",
      "Loss 146.63847 204 43\n",
      "Training Accuracy 0.74\n",
      "Loss 173.92236 205 43\n",
      "Training Accuracy 0.73\n",
      "Loss 167.23529 206 43\n",
      "Training Accuracy 0.72\n",
      "Loss 170.33574 207 43\n",
      "Training Accuracy 0.73\n",
      "Loss 167.67636 208 43\n",
      "Training Accuracy 0.695\n",
      "Loss 171.72456 209 43\n",
      "Training Accuracy 0.71\n",
      "Loss 151.96317 210 43\n",
      "Training Accuracy 0.765\n",
      "Loss 144.78949 211 43\n",
      "Training Accuracy 0.745\n",
      "Loss 163.5128 212 43\n",
      "Training Accuracy 0.715\n",
      "Loss 198.41624 213 43\n",
      "Training Accuracy 0.69\n",
      "Loss 154.13922 214 43\n",
      "Training Accuracy 0.73\n",
      "Loss 165.2724 215 43\n",
      "Training Accuracy 0.72\n",
      "Loss 155.43837 216 43\n",
      "Training Accuracy 0.755\n",
      "Loss 174.67009 217 43\n",
      "Training Accuracy 0.695\n",
      "Loss 157.33961 218 43\n",
      "Training Accuracy 0.705\n",
      "Loss 153.93414 219 43\n",
      "Training Accuracy 0.75\n",
      "Loss 149.78322 220 43\n",
      "Training Accuracy 0.76\n",
      "Loss 163.55583 221 43\n",
      "Training Accuracy 0.755\n",
      "Loss 156.17795 222 43\n",
      "Training Accuracy 0.725\n",
      "Loss 171.2895 223 43\n",
      "Training Accuracy 0.705\n",
      "Loss 179.10684 224 43\n",
      "Training Accuracy 0.665\n",
      "Loss 172.08095 225 43\n",
      "Training Accuracy 0.69\n",
      "Loss 130.7626 226 43\n",
      "Training Accuracy 0.78\n",
      "Loss 179.20212 227 43\n",
      "Training Accuracy 0.67\n",
      "Loss 198.75456 228 43\n",
      "Training Accuracy 0.65\n",
      "Loss 153.71152 229 43\n",
      "Training Accuracy 0.73\n",
      "Loss 159.61586 230 43\n",
      "Training Accuracy 0.715\n",
      "Loss 156.93488 231 43\n",
      "Training Accuracy 0.73\n",
      "Loss 179.35417 232 43\n",
      "Training Accuracy 0.685\n",
      "Loss 192.19366 233 43\n",
      "Training Accuracy 0.64\n",
      "Loss 158.06319 234 43\n",
      "Training Accuracy 0.705\n",
      "Loss 162.10951 235 43\n",
      "Training Accuracy 0.715\n",
      "Loss 159.15785 236 43\n",
      "Training Accuracy 0.72\n",
      "Loss 169.14261 237 43\n",
      "Training Accuracy 0.715\n",
      "Loss 148.95486 238 43\n",
      "Training Accuracy 0.725\n",
      "Loss 151.46332 239 43\n",
      "Training Accuracy 0.74\n",
      "Loss 167.44441 240 43\n",
      "Training Accuracy 0.7\n",
      "Loss 179.9457 241 43\n",
      "Training Accuracy 0.685\n",
      "Loss 166.09341 242 43\n",
      "Training Accuracy 0.69\n",
      "Loss 139.55107 243 43\n",
      "Training Accuracy 0.775\n",
      "Loss 158.8056 244 43\n",
      "Training Accuracy 0.67\n",
      "Loss 161.56802 245 43\n",
      "Training Accuracy 0.715\n",
      "Loss 179.50278 246 43\n",
      "Training Accuracy 0.675\n",
      "Loss 142.7291 247 43\n",
      "Training Accuracy 0.72\n",
      "Loss 156.13638 248 43\n",
      "Training Accuracy 0.755\n",
      "Loss 169.58307 249 43\n",
      "Training Accuracy 0.7\n",
      "Loss 167.75363 250 43\n",
      "Training Accuracy 0.7\n",
      "Loss 170.3402 251 43\n",
      "Training Accuracy 0.69\n",
      "Loss 136.85135 252 43\n",
      "Training Accuracy 0.755\n",
      "Loss 139.0137 253 43\n",
      "Training Accuracy 0.74\n",
      "Loss 152.5637 254 43\n",
      "Training Accuracy 0.76\n",
      "Loss 140.34804 255 43\n",
      "Training Accuracy 0.765\n",
      "Loss 174.41159 256 43\n",
      "Training Accuracy 0.695\n",
      "Loss 154.73845 257 43\n",
      "Training Accuracy 0.72\n",
      "Loss 166.55493 258 43\n",
      "Training Accuracy 0.72\n",
      "Loss 153.06535 259 43\n",
      "Training Accuracy 0.72\n",
      "Loss 135.09824 260 43\n",
      "Training Accuracy 0.75\n",
      "Loss 159.43358 261 43\n",
      "Training Accuracy 0.705\n",
      "Loss 171.29979 262 43\n",
      "Training Accuracy 0.66\n",
      "Loss 190.68932 263 43\n",
      "Training Accuracy 0.7\n",
      "Loss 161.8507 264 43\n",
      "Training Accuracy 0.725\n",
      "Loss 147.71658 265 43\n",
      "Training Accuracy 0.75\n",
      "Loss 151.54947 266 43\n",
      "Training Accuracy 0.73\n",
      "Loss 171.40741 267 43\n",
      "Training Accuracy 0.67\n",
      "Loss 171.32344 268 43\n",
      "Training Accuracy 0.73\n",
      "Loss 157.82968 269 43\n",
      "Training Accuracy 0.72\n",
      "Loss 133.8788 270 43\n",
      "Training Accuracy 0.765\n",
      "Loss 161.25488 271 43\n",
      "Training Accuracy 0.715\n",
      "Loss 172.11563 272 43\n",
      "Training Accuracy 0.735\n",
      "Loss 162.98193 273 43\n",
      "Training Accuracy 0.67\n",
      "Loss 166.7125 274 43\n",
      "Training Accuracy 0.715\n",
      "Loss 156.5854 275 43\n",
      "Training Accuracy 0.72\n",
      "Loss 143.06262 276 43\n",
      "Training Accuracy 0.78\n",
      "Loss 154.46167 277 43\n",
      "Training Accuracy 0.725\n",
      "Loss 147.81125 278 43\n",
      "Training Accuracy 0.73\n",
      "Loss 158.81477 279 43\n",
      "Training Accuracy 0.72\n",
      "Loss 156.0301 280 43\n",
      "Training Accuracy 0.705\n",
      "Loss 143.87224 281 43\n",
      "Training Accuracy 0.745\n",
      "Loss 143.82343 282 43\n",
      "Training Accuracy 0.725\n",
      "Loss 151.35147 283 43\n",
      "Training Accuracy 0.78\n",
      "Loss 125.29791 284 43\n",
      "Training Accuracy 0.785\n",
      "Loss 187.7464 285 43\n",
      "Training Accuracy 0.67\n",
      "Loss 162.14124 286 43\n",
      "Training Accuracy 0.745\n",
      "Loss 154.73021 287 43\n",
      "Training Accuracy 0.73\n",
      "Loss 168.49731 288 43\n",
      "Training Accuracy 0.725\n",
      "Loss 164.16147 289 43\n",
      "Training Accuracy 0.725\n",
      "Loss 168.72937 290 43\n",
      "Training Accuracy 0.71\n",
      "Loss 183.60547 291 43\n",
      "Training Accuracy 0.685\n",
      "Loss 112.36415 292 43\n",
      "Training Accuracy 0.6818182\n",
      "Loss 129.95712 1 44\n",
      "Training Accuracy 0.775\n",
      "Loss 151.65724 2 44\n",
      "Training Accuracy 0.74\n",
      "Loss 151.62471 3 44\n",
      "Training Accuracy 0.755\n",
      "Loss 164.20163 4 44\n",
      "Training Accuracy 0.71\n",
      "Loss 142.94455 5 44\n",
      "Training Accuracy 0.73\n",
      "Loss 162.56302 6 44\n",
      "Training Accuracy 0.72\n",
      "Loss 155.27011 7 44\n",
      "Training Accuracy 0.75\n",
      "Loss 166.02971 8 44\n",
      "Training Accuracy 0.725\n",
      "Loss 142.52429 9 44\n",
      "Training Accuracy 0.745\n",
      "Loss 179.00638 10 44\n",
      "Training Accuracy 0.685\n",
      "Loss 180.35928 11 44\n",
      "Training Accuracy 0.7\n",
      "Loss 135.6476 12 44\n",
      "Training Accuracy 0.755\n",
      "Loss 147.0587 13 44\n",
      "Training Accuracy 0.75\n",
      "Loss 160.96037 14 44\n",
      "Training Accuracy 0.725\n",
      "Loss 160.81015 15 44\n",
      "Training Accuracy 0.725\n",
      "Loss 196.327 16 44\n",
      "Training Accuracy 0.68\n",
      "Loss 127.336365 17 44\n",
      "Training Accuracy 0.795\n",
      "Loss 144.58241 18 44\n",
      "Training Accuracy 0.74\n",
      "Loss 146.0387 19 44\n",
      "Training Accuracy 0.75\n",
      "Loss 152.78828 20 44\n",
      "Training Accuracy 0.775\n",
      "Loss 166.58153 21 44\n",
      "Training Accuracy 0.7\n",
      "Loss 153.77841 22 44\n",
      "Training Accuracy 0.725\n",
      "Loss 166.02103 23 44\n",
      "Training Accuracy 0.7\n",
      "Loss 170.92012 24 44\n",
      "Training Accuracy 0.7\n",
      "Loss 152.42203 25 44\n",
      "Training Accuracy 0.695\n",
      "Loss 163.26587 26 44\n",
      "Training Accuracy 0.71\n",
      "Loss 160.01147 27 44\n",
      "Training Accuracy 0.73\n",
      "Loss 153.22794 28 44\n",
      "Training Accuracy 0.755\n",
      "Loss 165.13835 29 44\n",
      "Training Accuracy 0.67\n",
      "Loss 173.54846 30 44\n",
      "Training Accuracy 0.71\n",
      "Loss 163.35747 31 44\n",
      "Training Accuracy 0.74\n",
      "Loss 158.63817 32 44\n",
      "Training Accuracy 0.76\n",
      "Loss 179.04538 33 44\n",
      "Training Accuracy 0.705\n",
      "Loss 147.14606 34 44\n",
      "Training Accuracy 0.75\n",
      "Loss 157.14635 35 44\n",
      "Training Accuracy 0.72\n",
      "Loss 157.24858 36 44\n",
      "Training Accuracy 0.74\n",
      "Loss 147.34703 37 44\n",
      "Training Accuracy 0.73\n",
      "Loss 167.4763 38 44\n",
      "Training Accuracy 0.72\n",
      "Loss 136.2685 39 44\n",
      "Training Accuracy 0.8\n",
      "Loss 154.44165 40 44\n",
      "Training Accuracy 0.72\n",
      "Loss 166.46729 41 44\n",
      "Training Accuracy 0.69\n",
      "Loss 182.9378 42 44\n",
      "Training Accuracy 0.65\n",
      "Loss 154.9708 43 44\n",
      "Training Accuracy 0.74\n",
      "Loss 155.46794 44 44\n",
      "Training Accuracy 0.715\n",
      "Loss 158.56389 45 44\n",
      "Training Accuracy 0.725\n",
      "Loss 173.46988 46 44\n",
      "Training Accuracy 0.73\n",
      "Loss 154.26726 47 44\n",
      "Training Accuracy 0.745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 133.9802 48 44\n",
      "Training Accuracy 0.78\n",
      "Loss 149.15793 49 44\n",
      "Training Accuracy 0.725\n",
      "Loss 176.70676 50 44\n",
      "Training Accuracy 0.705\n",
      "Loss 144.0641 51 44\n",
      "Training Accuracy 0.765\n",
      "Loss 147.04395 52 44\n",
      "Training Accuracy 0.75\n",
      "Loss 128.16023 53 44\n",
      "Training Accuracy 0.75\n",
      "Loss 187.58327 54 44\n",
      "Training Accuracy 0.73\n",
      "Loss 161.1601 55 44\n",
      "Training Accuracy 0.73\n",
      "Loss 180.77701 56 44\n",
      "Training Accuracy 0.695\n",
      "Loss 150.31944 57 44\n",
      "Training Accuracy 0.735\n",
      "Loss 147.04938 58 44\n",
      "Training Accuracy 0.745\n",
      "Loss 166.76915 59 44\n",
      "Training Accuracy 0.675\n",
      "Loss 163.85228 60 44\n",
      "Training Accuracy 0.705\n",
      "Loss 163.54396 61 44\n",
      "Training Accuracy 0.72\n",
      "Loss 148.335 62 44\n",
      "Training Accuracy 0.755\n",
      "Loss 158.63823 63 44\n",
      "Training Accuracy 0.72\n",
      "Loss 166.70906 64 44\n",
      "Training Accuracy 0.695\n",
      "Loss 153.40286 65 44\n",
      "Training Accuracy 0.72\n",
      "Loss 150.15862 66 44\n",
      "Training Accuracy 0.725\n",
      "Loss 159.02032 67 44\n",
      "Training Accuracy 0.715\n",
      "Loss 165.38898 68 44\n",
      "Training Accuracy 0.725\n",
      "Loss 165.45163 69 44\n",
      "Training Accuracy 0.685\n",
      "Loss 146.86589 70 44\n",
      "Training Accuracy 0.78\n",
      "Loss 156.12933 71 44\n",
      "Training Accuracy 0.75\n",
      "Loss 161.67484 72 44\n",
      "Training Accuracy 0.76\n",
      "Loss 178.65558 73 44\n",
      "Training Accuracy 0.68\n",
      "Loss 146.2109 74 44\n",
      "Training Accuracy 0.75\n",
      "Loss 164.69351 75 44\n",
      "Training Accuracy 0.72\n",
      "Loss 144.60567 76 44\n",
      "Training Accuracy 0.73\n",
      "Loss 183.75827 77 44\n",
      "Training Accuracy 0.69\n",
      "Loss 161.09358 78 44\n",
      "Training Accuracy 0.745\n",
      "Loss 166.6672 79 44\n",
      "Training Accuracy 0.715\n",
      "Loss 169.38232 80 44\n",
      "Training Accuracy 0.725\n",
      "Loss 142.274 81 44\n",
      "Training Accuracy 0.735\n",
      "Loss 149.7584 82 44\n",
      "Training Accuracy 0.76\n",
      "Loss 156.24637 83 44\n",
      "Training Accuracy 0.72\n",
      "Loss 185.28607 84 44\n",
      "Training Accuracy 0.69\n",
      "Loss 156.29916 85 44\n",
      "Training Accuracy 0.725\n",
      "Loss 153.13643 86 44\n",
      "Training Accuracy 0.715\n",
      "Loss 196.57559 87 44\n",
      "Training Accuracy 0.685\n",
      "Loss 192.77626 88 44\n",
      "Training Accuracy 0.705\n",
      "Loss 159.0176 89 44\n",
      "Training Accuracy 0.715\n",
      "Loss 171.46596 90 44\n",
      "Training Accuracy 0.71\n",
      "Loss 174.24701 91 44\n",
      "Training Accuracy 0.705\n",
      "Loss 161.58763 92 44\n",
      "Training Accuracy 0.73\n",
      "Loss 166.92627 93 44\n",
      "Training Accuracy 0.73\n",
      "Loss 158.26851 94 44\n",
      "Training Accuracy 0.735\n",
      "Loss 158.60818 95 44\n",
      "Training Accuracy 0.69\n",
      "Loss 159.08514 96 44\n",
      "Training Accuracy 0.735\n",
      "Loss 164.53864 97 44\n",
      "Training Accuracy 0.675\n",
      "Loss 152.69058 98 44\n",
      "Training Accuracy 0.75\n",
      "Loss 153.48851 99 44\n",
      "Training Accuracy 0.74\n",
      "Loss 155.64427 100 44\n",
      "Training Accuracy 0.73\n",
      "Loss 183.2882 101 44\n",
      "Training Accuracy 0.69\n",
      "Loss 152.52554 102 44\n",
      "Training Accuracy 0.705\n",
      "Loss 168.10378 103 44\n",
      "Training Accuracy 0.705\n",
      "Loss 156.97697 104 44\n",
      "Training Accuracy 0.73\n",
      "Loss 154.53377 105 44\n",
      "Training Accuracy 0.735\n",
      "Loss 143.83107 106 44\n",
      "Training Accuracy 0.775\n",
      "Loss 149.1307 107 44\n",
      "Training Accuracy 0.74\n",
      "Loss 154.51079 108 44\n",
      "Training Accuracy 0.725\n",
      "Loss 149.83772 109 44\n",
      "Training Accuracy 0.73\n",
      "Loss 160.82751 110 44\n",
      "Training Accuracy 0.745\n",
      "Loss 159.97249 111 44\n",
      "Training Accuracy 0.7\n",
      "Loss 166.13443 112 44\n",
      "Training Accuracy 0.74\n",
      "Loss 178.83989 113 44\n",
      "Training Accuracy 0.685\n",
      "Loss 162.89009 114 44\n",
      "Training Accuracy 0.69\n",
      "Loss 175.27649 115 44\n",
      "Training Accuracy 0.72\n",
      "Loss 183.56424 116 44\n",
      "Training Accuracy 0.7\n",
      "Loss 129.29977 117 44\n",
      "Training Accuracy 0.78\n",
      "Loss 157.06435 118 44\n",
      "Training Accuracy 0.715\n",
      "Loss 175.80199 119 44\n",
      "Training Accuracy 0.685\n",
      "Loss 160.72426 120 44\n",
      "Training Accuracy 0.725\n",
      "Loss 161.37346 121 44\n",
      "Training Accuracy 0.7\n",
      "Loss 165.58131 122 44\n",
      "Training Accuracy 0.72\n",
      "Loss 154.91861 123 44\n",
      "Training Accuracy 0.75\n",
      "Loss 151.71245 124 44\n",
      "Training Accuracy 0.715\n",
      "Loss 144.30855 125 44\n",
      "Training Accuracy 0.75\n",
      "Loss 152.17567 126 44\n",
      "Training Accuracy 0.735\n",
      "Loss 170.20123 127 44\n",
      "Training Accuracy 0.68\n",
      "Loss 151.50139 128 44\n",
      "Training Accuracy 0.745\n",
      "Loss 143.93013 129 44\n",
      "Training Accuracy 0.77\n",
      "Loss 139.86142 130 44\n",
      "Training Accuracy 0.745\n",
      "Loss 147.75957 131 44\n",
      "Training Accuracy 0.74\n",
      "Loss 143.70798 132 44\n",
      "Training Accuracy 0.755\n",
      "Loss 160.08641 133 44\n",
      "Training Accuracy 0.705\n",
      "Loss 154.92747 134 44\n",
      "Training Accuracy 0.71\n",
      "Loss 156.5814 135 44\n",
      "Training Accuracy 0.735\n",
      "Loss 162.77307 136 44\n",
      "Training Accuracy 0.725\n",
      "Loss 166.2359 137 44\n",
      "Training Accuracy 0.705\n",
      "Loss 157.11356 138 44\n",
      "Training Accuracy 0.74\n",
      "Loss 166.97903 139 44\n",
      "Training Accuracy 0.75\n",
      "Loss 146.07515 140 44\n",
      "Training Accuracy 0.765\n",
      "Loss 158.69557 141 44\n",
      "Training Accuracy 0.695\n",
      "Loss 171.7833 142 44\n",
      "Training Accuracy 0.685\n",
      "Loss 140.61914 143 44\n",
      "Training Accuracy 0.745\n",
      "Loss 168.18813 144 44\n",
      "Training Accuracy 0.65\n",
      "Loss 143.82137 145 44\n",
      "Training Accuracy 0.76\n",
      "Loss 180.78505 146 44\n",
      "Training Accuracy 0.65\n",
      "Loss 174.33359 147 44\n",
      "Training Accuracy 0.64\n",
      "Loss 172.3672 148 44\n",
      "Training Accuracy 0.665\n",
      "Loss 162.5224 149 44\n",
      "Training Accuracy 0.675\n",
      "Loss 158.40512 150 44\n",
      "Training Accuracy 0.695\n",
      "Loss 165.98238 151 44\n",
      "Training Accuracy 0.7\n",
      "Loss 176.57239 152 44\n",
      "Training Accuracy 0.715\n",
      "Loss 141.70282 153 44\n",
      "Training Accuracy 0.755\n",
      "Loss 162.02405 154 44\n",
      "Training Accuracy 0.7\n",
      "Loss 147.02939 155 44\n",
      "Training Accuracy 0.745\n",
      "Loss 163.85806 156 44\n",
      "Training Accuracy 0.695\n",
      "Loss 143.60144 157 44\n",
      "Training Accuracy 0.72\n",
      "Loss 144.62605 158 44\n",
      "Training Accuracy 0.76\n",
      "Loss 187.00131 159 44\n",
      "Training Accuracy 0.7\n",
      "Loss 165.71855 160 44\n",
      "Training Accuracy 0.72\n",
      "Loss 187.1693 161 44\n",
      "Training Accuracy 0.645\n",
      "Loss 155.0277 162 44\n",
      "Training Accuracy 0.74\n",
      "Loss 179.45338 163 44\n",
      "Training Accuracy 0.69\n",
      "Loss 146.46915 164 44\n",
      "Training Accuracy 0.75\n",
      "Loss 162.90663 165 44\n",
      "Training Accuracy 0.7\n",
      "Loss 155.23724 166 44\n",
      "Training Accuracy 0.74\n",
      "Loss 145.66508 167 44\n",
      "Training Accuracy 0.76\n",
      "Loss 170.03973 168 44\n",
      "Training Accuracy 0.695\n",
      "Loss 143.26332 169 44\n",
      "Training Accuracy 0.745\n",
      "Loss 160.48425 170 44\n",
      "Training Accuracy 0.725\n",
      "Loss 167.51578 171 44\n",
      "Training Accuracy 0.735\n",
      "Loss 146.47937 172 44\n",
      "Training Accuracy 0.74\n",
      "Loss 170.26251 173 44\n",
      "Training Accuracy 0.69\n",
      "Loss 152.98209 174 44\n",
      "Training Accuracy 0.725\n",
      "Loss 139.76665 175 44\n",
      "Training Accuracy 0.765\n",
      "Loss 133.24196 176 44\n",
      "Training Accuracy 0.75\n",
      "Loss 182.31923 177 44\n",
      "Training Accuracy 0.685\n",
      "Loss 164.64006 178 44\n",
      "Training Accuracy 0.71\n",
      "Loss 176.20627 179 44\n",
      "Training Accuracy 0.69\n",
      "Loss 171.78682 180 44\n",
      "Training Accuracy 0.69\n",
      "Loss 146.5326 181 44\n",
      "Training Accuracy 0.725\n",
      "Loss 163.56218 182 44\n",
      "Training Accuracy 0.72\n",
      "Loss 160.79932 183 44\n",
      "Training Accuracy 0.695\n",
      "Loss 143.46782 184 44\n",
      "Training Accuracy 0.755\n",
      "Loss 159.07182 185 44\n",
      "Training Accuracy 0.745\n",
      "Loss 159.72632 186 44\n",
      "Training Accuracy 0.725\n",
      "Loss 195.99852 187 44\n",
      "Training Accuracy 0.65\n",
      "Loss 158.34772 188 44\n",
      "Training Accuracy 0.72\n",
      "Loss 156.8362 189 44\n",
      "Training Accuracy 0.75\n",
      "Loss 150.42952 190 44\n",
      "Training Accuracy 0.74\n",
      "Loss 142.1827 191 44\n",
      "Training Accuracy 0.735\n",
      "Loss 174.12968 192 44\n",
      "Training Accuracy 0.695\n",
      "Loss 147.71465 193 44\n",
      "Training Accuracy 0.745\n",
      "Loss 159.34856 194 44\n",
      "Training Accuracy 0.75\n",
      "Loss 139.59486 195 44\n",
      "Training Accuracy 0.775\n",
      "Loss 147.95549 196 44\n",
      "Training Accuracy 0.71\n",
      "Loss 161.71346 197 44\n",
      "Training Accuracy 0.725\n",
      "Loss 162.12924 198 44\n",
      "Training Accuracy 0.725\n",
      "Loss 129.58965 199 44\n",
      "Training Accuracy 0.825\n",
      "Loss 136.0169 200 44\n",
      "Training Accuracy 0.775\n",
      "Loss 146.76875 201 44\n",
      "Training Accuracy 0.755\n",
      "Loss 152.7963 202 44\n",
      "Training Accuracy 0.725\n",
      "Loss 160.15884 203 44\n",
      "Training Accuracy 0.725\n",
      "Loss 150.7115 204 44\n",
      "Training Accuracy 0.745\n",
      "Loss 171.26144 205 44\n",
      "Training Accuracy 0.735\n",
      "Loss 165.92111 206 44\n",
      "Training Accuracy 0.695\n",
      "Loss 168.02208 207 44\n",
      "Training Accuracy 0.75\n",
      "Loss 168.81958 208 44\n",
      "Training Accuracy 0.72\n",
      "Loss 154.12091 209 44\n",
      "Training Accuracy 0.73\n",
      "Loss 142.73463 210 44\n",
      "Training Accuracy 0.735\n",
      "Loss 140.44235 211 44\n",
      "Training Accuracy 0.775\n",
      "Loss 166.25064 212 44\n",
      "Training Accuracy 0.72\n",
      "Loss 191.78384 213 44\n",
      "Training Accuracy 0.69\n",
      "Loss 159.00667 214 44\n",
      "Training Accuracy 0.725\n",
      "Loss 165.30504 215 44\n",
      "Training Accuracy 0.705\n",
      "Loss 168.7741 216 44\n",
      "Training Accuracy 0.705\n",
      "Loss 166.23865 217 44\n",
      "Training Accuracy 0.69\n",
      "Loss 165.05164 218 44\n",
      "Training Accuracy 0.725\n",
      "Loss 152.65167 219 44\n",
      "Training Accuracy 0.745\n",
      "Loss 154.83772 220 44\n",
      "Training Accuracy 0.735\n",
      "Loss 152.94061 221 44\n",
      "Training Accuracy 0.73\n",
      "Loss 160.904 222 44\n",
      "Training Accuracy 0.73\n",
      "Loss 164.96732 223 44\n",
      "Training Accuracy 0.73\n",
      "Loss 160.79332 224 44\n",
      "Training Accuracy 0.74\n",
      "Loss 173.11636 225 44\n",
      "Training Accuracy 0.685\n",
      "Loss 130.99492 226 44\n",
      "Training Accuracy 0.785\n",
      "Loss 166.61076 227 44\n",
      "Training Accuracy 0.705\n",
      "Loss 199.67024 228 44\n",
      "Training Accuracy 0.655\n",
      "Loss 152.55077 229 44\n",
      "Training Accuracy 0.73\n",
      "Loss 169.58316 230 44\n",
      "Training Accuracy 0.705\n",
      "Loss 150.38101 231 44\n",
      "Training Accuracy 0.735\n",
      "Loss 174.34143 232 44\n",
      "Training Accuracy 0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 196.39369 233 44\n",
      "Training Accuracy 0.635\n",
      "Loss 163.08688 234 44\n",
      "Training Accuracy 0.685\n",
      "Loss 157.15471 235 44\n",
      "Training Accuracy 0.76\n",
      "Loss 151.14247 236 44\n",
      "Training Accuracy 0.71\n",
      "Loss 162.24384 237 44\n",
      "Training Accuracy 0.725\n",
      "Loss 147.54553 238 44\n",
      "Training Accuracy 0.705\n",
      "Loss 158.40726 239 44\n",
      "Training Accuracy 0.72\n",
      "Loss 166.08853 240 44\n",
      "Training Accuracy 0.665\n",
      "Loss 177.7153 241 44\n",
      "Training Accuracy 0.715\n",
      "Loss 172.17116 242 44\n",
      "Training Accuracy 0.69\n",
      "Loss 133.7993 243 44\n",
      "Training Accuracy 0.77\n",
      "Loss 154.29622 244 44\n",
      "Training Accuracy 0.725\n",
      "Loss 167.4162 245 44\n",
      "Training Accuracy 0.725\n",
      "Loss 173.75372 246 44\n",
      "Training Accuracy 0.705\n",
      "Loss 150.68672 247 44\n",
      "Training Accuracy 0.7\n",
      "Loss 148.85442 248 44\n",
      "Training Accuracy 0.755\n",
      "Loss 163.96045 249 44\n",
      "Training Accuracy 0.715\n",
      "Loss 176.41936 250 44\n",
      "Training Accuracy 0.68\n",
      "Loss 177.44809 251 44\n",
      "Training Accuracy 0.69\n",
      "Loss 136.19254 252 44\n",
      "Training Accuracy 0.74\n",
      "Loss 128.6396 253 44\n",
      "Training Accuracy 0.77\n",
      "Loss 166.03871 254 44\n",
      "Training Accuracy 0.745\n",
      "Loss 140.94493 255 44\n",
      "Training Accuracy 0.775\n",
      "Loss 184.38503 256 44\n",
      "Training Accuracy 0.695\n",
      "Loss 159.63669 257 44\n",
      "Training Accuracy 0.715\n",
      "Loss 166.66034 258 44\n",
      "Training Accuracy 0.715\n",
      "Loss 166.91498 259 44\n",
      "Training Accuracy 0.7\n",
      "Loss 126.96599 260 44\n",
      "Training Accuracy 0.78\n",
      "Loss 158.0764 261 44\n",
      "Training Accuracy 0.71\n",
      "Loss 163.22949 262 44\n",
      "Training Accuracy 0.675\n",
      "Loss 186.59274 263 44\n",
      "Training Accuracy 0.71\n",
      "Loss 158.80495 264 44\n",
      "Training Accuracy 0.73\n",
      "Loss 148.28072 265 44\n",
      "Training Accuracy 0.725\n",
      "Loss 157.5188 266 44\n",
      "Training Accuracy 0.72\n",
      "Loss 161.51312 267 44\n",
      "Training Accuracy 0.67\n",
      "Loss 151.70883 268 44\n",
      "Training Accuracy 0.745\n",
      "Loss 147.26295 269 44\n",
      "Training Accuracy 0.765\n",
      "Loss 133.44594 270 44\n",
      "Training Accuracy 0.75\n",
      "Loss 164.95088 271 44\n",
      "Training Accuracy 0.7\n",
      "Loss 159.65506 272 44\n",
      "Training Accuracy 0.73\n",
      "Loss 159.01004 273 44\n",
      "Training Accuracy 0.72\n",
      "Loss 159.19582 274 44\n",
      "Training Accuracy 0.73\n",
      "Loss 155.73497 275 44\n",
      "Training Accuracy 0.72\n",
      "Loss 158.70174 276 44\n",
      "Training Accuracy 0.695\n",
      "Loss 149.96451 277 44\n",
      "Training Accuracy 0.765\n",
      "Loss 157.69876 278 44\n",
      "Training Accuracy 0.705\n",
      "Loss 157.49362 279 44\n",
      "Training Accuracy 0.75\n",
      "Loss 157.16495 280 44\n",
      "Training Accuracy 0.7\n",
      "Loss 135.369 281 44\n",
      "Training Accuracy 0.785\n",
      "Loss 146.26674 282 44\n",
      "Training Accuracy 0.77\n",
      "Loss 148.68158 283 44\n",
      "Training Accuracy 0.755\n",
      "Loss 121.124626 284 44\n",
      "Training Accuracy 0.815\n",
      "Loss 177.82466 285 44\n",
      "Training Accuracy 0.69\n",
      "Loss 160.63765 286 44\n",
      "Training Accuracy 0.73\n",
      "Loss 143.64467 287 44\n",
      "Training Accuracy 0.765\n",
      "Loss 170.53143 288 44\n",
      "Training Accuracy 0.695\n",
      "Loss 150.13144 289 44\n",
      "Training Accuracy 0.77\n",
      "Loss 162.34833 290 44\n",
      "Training Accuracy 0.72\n",
      "Loss 178.298 291 44\n",
      "Training Accuracy 0.715\n",
      "Loss 99.54602 292 44\n",
      "Training Accuracy 0.72727275\n",
      "Loss 132.55261 1 45\n",
      "Training Accuracy 0.765\n",
      "Loss 153.51839 2 45\n",
      "Training Accuracy 0.755\n",
      "Loss 137.54881 3 45\n",
      "Training Accuracy 0.755\n",
      "Loss 160.03412 4 45\n",
      "Training Accuracy 0.695\n",
      "Loss 135.86902 5 45\n",
      "Training Accuracy 0.75\n",
      "Loss 153.00838 6 45\n",
      "Training Accuracy 0.725\n",
      "Loss 163.85097 7 45\n",
      "Training Accuracy 0.725\n",
      "Loss 160.76683 8 45\n",
      "Training Accuracy 0.74\n",
      "Loss 135.32024 9 45\n",
      "Training Accuracy 0.785\n",
      "Loss 171.5888 10 45\n",
      "Training Accuracy 0.69\n",
      "Loss 180.0655 11 45\n",
      "Training Accuracy 0.725\n",
      "Loss 135.53722 12 45\n",
      "Training Accuracy 0.76\n",
      "Loss 153.01256 13 45\n",
      "Training Accuracy 0.72\n",
      "Loss 168.50188 14 45\n",
      "Training Accuracy 0.735\n",
      "Loss 151.45001 15 45\n",
      "Training Accuracy 0.755\n",
      "Loss 204.13644 16 45\n",
      "Training Accuracy 0.65\n",
      "Loss 143.90326 17 45\n",
      "Training Accuracy 0.745\n",
      "Loss 137.5773 18 45\n",
      "Training Accuracy 0.755\n",
      "Loss 155.70168 19 45\n",
      "Training Accuracy 0.75\n",
      "Loss 149.48349 20 45\n",
      "Training Accuracy 0.735\n",
      "Loss 177.51717 21 45\n",
      "Training Accuracy 0.705\n",
      "Loss 154.40405 22 45\n",
      "Training Accuracy 0.735\n",
      "Loss 183.85414 23 45\n",
      "Training Accuracy 0.715\n",
      "Loss 171.83257 24 45\n",
      "Training Accuracy 0.705\n",
      "Loss 150.37605 25 45\n",
      "Training Accuracy 0.745\n",
      "Loss 163.33124 26 45\n",
      "Training Accuracy 0.725\n",
      "Loss 145.74799 27 45\n",
      "Training Accuracy 0.745\n",
      "Loss 144.68388 28 45\n",
      "Training Accuracy 0.75\n",
      "Loss 154.81917 29 45\n",
      "Training Accuracy 0.71\n",
      "Loss 169.7206 30 45\n",
      "Training Accuracy 0.715\n",
      "Loss 159.88948 31 45\n",
      "Training Accuracy 0.72\n",
      "Loss 159.33449 32 45\n",
      "Training Accuracy 0.695\n",
      "Loss 156.81764 33 45\n",
      "Training Accuracy 0.73\n",
      "Loss 139.39807 34 45\n",
      "Training Accuracy 0.775\n",
      "Loss 159.33286 35 45\n",
      "Training Accuracy 0.71\n",
      "Loss 168.30759 36 45\n",
      "Training Accuracy 0.705\n",
      "Loss 155.35602 37 45\n",
      "Training Accuracy 0.685\n",
      "Loss 172.3103 38 45\n",
      "Training Accuracy 0.69\n",
      "Loss 129.63461 39 45\n",
      "Training Accuracy 0.77\n",
      "Loss 160.67043 40 45\n",
      "Training Accuracy 0.71\n",
      "Loss 156.24883 41 45\n",
      "Training Accuracy 0.725\n",
      "Loss 175.6694 42 45\n",
      "Training Accuracy 0.705\n",
      "Loss 155.58388 43 45\n",
      "Training Accuracy 0.695\n",
      "Loss 161.5294 44 45\n",
      "Training Accuracy 0.755\n",
      "Loss 152.71936 45 45\n",
      "Training Accuracy 0.745\n",
      "Loss 176.97754 46 45\n",
      "Training Accuracy 0.705\n",
      "Loss 152.97095 47 45\n",
      "Training Accuracy 0.72\n",
      "Loss 139.83224 48 45\n",
      "Training Accuracy 0.735\n",
      "Loss 159.56195 49 45\n",
      "Training Accuracy 0.715\n",
      "Loss 169.83159 50 45\n",
      "Training Accuracy 0.715\n",
      "Loss 142.64877 51 45\n",
      "Training Accuracy 0.75\n",
      "Loss 139.44685 52 45\n",
      "Training Accuracy 0.78\n",
      "Loss 120.89058 53 45\n",
      "Training Accuracy 0.785\n",
      "Loss 166.45932 54 45\n",
      "Training Accuracy 0.705\n",
      "Loss 162.35461 55 45\n",
      "Training Accuracy 0.72\n",
      "Loss 164.18393 56 45\n",
      "Training Accuracy 0.735\n",
      "Loss 156.23907 57 45\n",
      "Training Accuracy 0.755\n",
      "Loss 154.42403 58 45\n",
      "Training Accuracy 0.71\n",
      "Loss 154.86908 59 45\n",
      "Training Accuracy 0.735\n",
      "Loss 148.43703 60 45\n",
      "Training Accuracy 0.74\n",
      "Loss 162.52898 61 45\n",
      "Training Accuracy 0.73\n",
      "Loss 146.2263 62 45\n",
      "Training Accuracy 0.77\n",
      "Loss 156.43008 63 45\n",
      "Training Accuracy 0.74\n",
      "Loss 158.06187 64 45\n",
      "Training Accuracy 0.76\n",
      "Loss 160.37923 65 45\n",
      "Training Accuracy 0.715\n",
      "Loss 145.43076 66 45\n",
      "Training Accuracy 0.735\n",
      "Loss 152.32138 67 45\n",
      "Training Accuracy 0.755\n",
      "Loss 172.5203 68 45\n",
      "Training Accuracy 0.7\n",
      "Loss 159.69211 69 45\n",
      "Training Accuracy 0.715\n",
      "Loss 144.70474 70 45\n",
      "Training Accuracy 0.755\n",
      "Loss 164.42722 71 45\n",
      "Training Accuracy 0.75\n",
      "Loss 158.07597 72 45\n",
      "Training Accuracy 0.745\n",
      "Loss 192.02037 73 45\n",
      "Training Accuracy 0.645\n",
      "Loss 164.89836 74 45\n",
      "Training Accuracy 0.725\n",
      "Loss 160.85371 75 45\n",
      "Training Accuracy 0.71\n",
      "Loss 145.24297 76 45\n",
      "Training Accuracy 0.725\n",
      "Loss 176.08719 77 45\n",
      "Training Accuracy 0.685\n",
      "Loss 149.30106 78 45\n",
      "Training Accuracy 0.745\n",
      "Loss 165.11168 79 45\n",
      "Training Accuracy 0.68\n",
      "Loss 163.43808 80 45\n",
      "Training Accuracy 0.735\n",
      "Loss 139.89577 81 45\n",
      "Training Accuracy 0.75\n",
      "Loss 149.43079 82 45\n",
      "Training Accuracy 0.735\n",
      "Loss 156.36426 83 45\n",
      "Training Accuracy 0.735\n",
      "Loss 166.5492 84 45\n",
      "Training Accuracy 0.705\n",
      "Loss 156.37419 85 45\n",
      "Training Accuracy 0.715\n",
      "Loss 159.87636 86 45\n",
      "Training Accuracy 0.73\n",
      "Loss 194.2663 87 45\n",
      "Training Accuracy 0.66\n",
      "Loss 201.70686 88 45\n",
      "Training Accuracy 0.65\n",
      "Loss 160.16377 89 45\n",
      "Training Accuracy 0.73\n",
      "Loss 170.47427 90 45\n",
      "Training Accuracy 0.7\n",
      "Loss 156.5145 91 45\n",
      "Training Accuracy 0.73\n",
      "Loss 156.96257 92 45\n",
      "Training Accuracy 0.725\n",
      "Loss 165.56192 93 45\n",
      "Training Accuracy 0.7\n",
      "Loss 161.95204 94 45\n",
      "Training Accuracy 0.71\n",
      "Loss 157.79393 95 45\n",
      "Training Accuracy 0.715\n",
      "Loss 168.11855 96 45\n",
      "Training Accuracy 0.675\n",
      "Loss 159.94655 97 45\n",
      "Training Accuracy 0.74\n",
      "Loss 150.8587 98 45\n",
      "Training Accuracy 0.765\n",
      "Loss 133.25215 99 45\n",
      "Training Accuracy 0.8\n",
      "Loss 147.54372 100 45\n",
      "Training Accuracy 0.775\n",
      "Loss 172.75862 101 45\n",
      "Training Accuracy 0.69\n",
      "Loss 141.7988 102 45\n",
      "Training Accuracy 0.76\n",
      "Loss 163.25708 103 45\n",
      "Training Accuracy 0.695\n",
      "Loss 158.4764 104 45\n",
      "Training Accuracy 0.725\n",
      "Loss 153.69557 105 45\n",
      "Training Accuracy 0.75\n",
      "Loss 141.48666 106 45\n",
      "Training Accuracy 0.765\n",
      "Loss 131.581 107 45\n",
      "Training Accuracy 0.75\n",
      "Loss 154.4387 108 45\n",
      "Training Accuracy 0.715\n",
      "Loss 159.06627 109 45\n",
      "Training Accuracy 0.725\n",
      "Loss 157.23254 110 45\n",
      "Training Accuracy 0.74\n",
      "Loss 169.9587 111 45\n",
      "Training Accuracy 0.685\n",
      "Loss 172.4823 112 45\n",
      "Training Accuracy 0.745\n",
      "Loss 176.8831 113 45\n",
      "Training Accuracy 0.72\n",
      "Loss 162.01938 114 45\n",
      "Training Accuracy 0.685\n",
      "Loss 168.7159 115 45\n",
      "Training Accuracy 0.685\n",
      "Loss 175.1002 116 45\n",
      "Training Accuracy 0.75\n",
      "Loss 123.98568 117 45\n",
      "Training Accuracy 0.79\n",
      "Loss 153.90668 118 45\n",
      "Training Accuracy 0.72\n",
      "Loss 184.45903 119 45\n",
      "Training Accuracy 0.69\n",
      "Loss 160.09921 120 45\n",
      "Training Accuracy 0.74\n",
      "Loss 165.96526 121 45\n",
      "Training Accuracy 0.715\n",
      "Loss 161.21974 122 45\n",
      "Training Accuracy 0.74\n",
      "Loss 143.65472 123 45\n",
      "Training Accuracy 0.7\n",
      "Loss 157.08772 124 45\n",
      "Training Accuracy 0.725\n",
      "Loss 136.45949 125 45\n",
      "Training Accuracy 0.775\n",
      "Loss 162.23186 126 45\n",
      "Training Accuracy 0.715\n",
      "Loss 161.44293 127 45\n",
      "Training Accuracy 0.67\n",
      "Loss 158.02272 128 45\n",
      "Training Accuracy 0.73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 139.90457 129 45\n",
      "Training Accuracy 0.75\n",
      "Loss 143.72182 130 45\n",
      "Training Accuracy 0.715\n",
      "Loss 135.75534 131 45\n",
      "Training Accuracy 0.75\n",
      "Loss 152.79985 132 45\n",
      "Training Accuracy 0.73\n",
      "Loss 152.0233 133 45\n",
      "Training Accuracy 0.76\n",
      "Loss 160.83452 134 45\n",
      "Training Accuracy 0.72\n",
      "Loss 153.82294 135 45\n",
      "Training Accuracy 0.72\n",
      "Loss 173.2321 136 45\n",
      "Training Accuracy 0.695\n",
      "Loss 168.80763 137 45\n",
      "Training Accuracy 0.735\n",
      "Loss 172.371 138 45\n",
      "Training Accuracy 0.75\n",
      "Loss 162.94476 139 45\n",
      "Training Accuracy 0.72\n",
      "Loss 150.64305 140 45\n",
      "Training Accuracy 0.72\n",
      "Loss 167.1141 141 45\n",
      "Training Accuracy 0.75\n",
      "Loss 170.82994 142 45\n",
      "Training Accuracy 0.67\n",
      "Loss 143.48198 143 45\n",
      "Training Accuracy 0.75\n",
      "Loss 169.18146 144 45\n",
      "Training Accuracy 0.69\n",
      "Loss 153.59383 145 45\n",
      "Training Accuracy 0.72\n",
      "Loss 180.9345 146 45\n",
      "Training Accuracy 0.68\n",
      "Loss 170.79042 147 45\n",
      "Training Accuracy 0.695\n",
      "Loss 164.56596 148 45\n",
      "Training Accuracy 0.7\n",
      "Loss 165.27281 149 45\n",
      "Training Accuracy 0.72\n",
      "Loss 155.49251 150 45\n",
      "Training Accuracy 0.735\n",
      "Loss 159.3862 151 45\n",
      "Training Accuracy 0.715\n",
      "Loss 175.07755 152 45\n",
      "Training Accuracy 0.725\n",
      "Loss 141.39131 153 45\n",
      "Training Accuracy 0.79\n",
      "Loss 167.92923 154 45\n",
      "Training Accuracy 0.69\n",
      "Loss 163.21246 155 45\n",
      "Training Accuracy 0.705\n",
      "Loss 158.6038 156 45\n",
      "Training Accuracy 0.73\n",
      "Loss 150.65083 157 45\n",
      "Training Accuracy 0.72\n",
      "Loss 145.02843 158 45\n",
      "Training Accuracy 0.74\n",
      "Loss 178.37183 159 45\n",
      "Training Accuracy 0.695\n",
      "Loss 166.32077 160 45\n",
      "Training Accuracy 0.705\n",
      "Loss 180.38156 161 45\n",
      "Training Accuracy 0.7\n",
      "Loss 148.52222 162 45\n",
      "Training Accuracy 0.74\n",
      "Loss 170.11389 163 45\n",
      "Training Accuracy 0.725\n",
      "Loss 146.01448 164 45\n",
      "Training Accuracy 0.72\n",
      "Loss 166.28117 165 45\n",
      "Training Accuracy 0.695\n",
      "Loss 155.6438 166 45\n",
      "Training Accuracy 0.735\n",
      "Loss 144.24248 167 45\n",
      "Training Accuracy 0.75\n",
      "Loss 162.9206 168 45\n",
      "Training Accuracy 0.705\n",
      "Loss 164.50233 169 45\n",
      "Training Accuracy 0.7\n",
      "Loss 174.44818 170 45\n",
      "Training Accuracy 0.69\n",
      "Loss 168.25822 171 45\n",
      "Training Accuracy 0.715\n",
      "Loss 142.22818 172 45\n",
      "Training Accuracy 0.74\n",
      "Loss 173.64659 173 45\n",
      "Training Accuracy 0.72\n",
      "Loss 141.54515 174 45\n",
      "Training Accuracy 0.73\n",
      "Loss 123.91081 175 45\n",
      "Training Accuracy 0.81\n",
      "Loss 119.49087 176 45\n",
      "Training Accuracy 0.795\n",
      "Loss 164.36859 177 45\n",
      "Training Accuracy 0.71\n",
      "Loss 150.46068 178 45\n",
      "Training Accuracy 0.74\n",
      "Loss 169.6002 179 45\n",
      "Training Accuracy 0.69\n",
      "Loss 176.44557 180 45\n",
      "Training Accuracy 0.665\n",
      "Loss 150.0352 181 45\n",
      "Training Accuracy 0.745\n",
      "Loss 167.8402 182 45\n",
      "Training Accuracy 0.715\n",
      "Loss 164.93166 183 45\n",
      "Training Accuracy 0.71\n",
      "Loss 126.39756 184 45\n",
      "Training Accuracy 0.805\n",
      "Loss 158.05359 185 45\n",
      "Training Accuracy 0.72\n",
      "Loss 156.22887 186 45\n",
      "Training Accuracy 0.725\n",
      "Loss 181.51152 187 45\n",
      "Training Accuracy 0.695\n",
      "Loss 164.52988 188 45\n",
      "Training Accuracy 0.71\n",
      "Loss 143.16643 189 45\n",
      "Training Accuracy 0.75\n",
      "Loss 148.68881 190 45\n",
      "Training Accuracy 0.745\n",
      "Loss 133.36557 191 45\n",
      "Training Accuracy 0.775\n",
      "Loss 160.98755 192 45\n",
      "Training Accuracy 0.745\n",
      "Loss 141.03049 193 45\n",
      "Training Accuracy 0.78\n",
      "Loss 154.10837 194 45\n",
      "Training Accuracy 0.735\n",
      "Loss 136.237 195 45\n",
      "Training Accuracy 0.785\n",
      "Loss 147.79042 196 45\n",
      "Training Accuracy 0.71\n",
      "Loss 157.8161 197 45\n",
      "Training Accuracy 0.725\n",
      "Loss 151.97577 198 45\n",
      "Training Accuracy 0.705\n",
      "Loss 132.81961 199 45\n",
      "Training Accuracy 0.785\n",
      "Loss 140.59302 200 45\n",
      "Training Accuracy 0.77\n",
      "Loss 156.66063 201 45\n",
      "Training Accuracy 0.74\n",
      "Loss 152.07832 202 45\n",
      "Training Accuracy 0.715\n",
      "Loss 159.55528 203 45\n",
      "Training Accuracy 0.73\n",
      "Loss 141.70325 204 45\n",
      "Training Accuracy 0.755\n",
      "Loss 169.76572 205 45\n",
      "Training Accuracy 0.705\n",
      "Loss 152.9786 206 45\n",
      "Training Accuracy 0.77\n",
      "Loss 156.9219 207 45\n",
      "Training Accuracy 0.74\n",
      "Loss 162.48064 208 45\n",
      "Training Accuracy 0.745\n",
      "Loss 165.2235 209 45\n",
      "Training Accuracy 0.725\n",
      "Loss 156.42303 210 45\n",
      "Training Accuracy 0.69\n",
      "Loss 126.745255 211 45\n",
      "Training Accuracy 0.81\n",
      "Loss 155.25037 212 45\n",
      "Training Accuracy 0.72\n",
      "Loss 179.88727 213 45\n",
      "Training Accuracy 0.705\n",
      "Loss 148.55241 214 45\n",
      "Training Accuracy 0.73\n",
      "Loss 176.1109 215 45\n",
      "Training Accuracy 0.68\n",
      "Loss 162.34311 216 45\n",
      "Training Accuracy 0.72\n",
      "Loss 158.09195 217 45\n",
      "Training Accuracy 0.715\n",
      "Loss 158.11505 218 45\n",
      "Training Accuracy 0.76\n",
      "Loss 156.76068 219 45\n",
      "Training Accuracy 0.76\n",
      "Loss 148.85728 220 45\n",
      "Training Accuracy 0.745\n",
      "Loss 159.10866 221 45\n",
      "Training Accuracy 0.745\n",
      "Loss 147.37335 222 45\n",
      "Training Accuracy 0.745\n",
      "Loss 164.98242 223 45\n",
      "Training Accuracy 0.71\n",
      "Loss 166.97296 224 45\n",
      "Training Accuracy 0.715\n",
      "Loss 169.02197 225 45\n",
      "Training Accuracy 0.705\n",
      "Loss 131.32628 226 45\n",
      "Training Accuracy 0.765\n",
      "Loss 172.82678 227 45\n",
      "Training Accuracy 0.715\n",
      "Loss 202.28654 228 45\n",
      "Training Accuracy 0.655\n",
      "Loss 150.17511 229 45\n",
      "Training Accuracy 0.775\n",
      "Loss 162.07028 230 45\n",
      "Training Accuracy 0.74\n",
      "Loss 150.4605 231 45\n",
      "Training Accuracy 0.745\n",
      "Loss 161.83722 232 45\n",
      "Training Accuracy 0.715\n",
      "Loss 191.18355 233 45\n",
      "Training Accuracy 0.605\n",
      "Loss 167.49814 234 45\n",
      "Training Accuracy 0.695\n",
      "Loss 153.0689 235 45\n",
      "Training Accuracy 0.745\n",
      "Loss 137.82942 236 45\n",
      "Training Accuracy 0.755\n",
      "Loss 159.8159 237 45\n",
      "Training Accuracy 0.755\n",
      "Loss 147.86447 238 45\n",
      "Training Accuracy 0.735\n",
      "Loss 159.06015 239 45\n",
      "Training Accuracy 0.725\n",
      "Loss 160.81517 240 45\n",
      "Training Accuracy 0.71\n",
      "Loss 178.6861 241 45\n",
      "Training Accuracy 0.68\n",
      "Loss 150.01277 242 45\n",
      "Training Accuracy 0.735\n",
      "Loss 137.8529 243 45\n",
      "Training Accuracy 0.775\n",
      "Loss 151.45946 244 45\n",
      "Training Accuracy 0.75\n",
      "Loss 172.33676 245 45\n",
      "Training Accuracy 0.7\n",
      "Loss 176.88419 246 45\n",
      "Training Accuracy 0.705\n",
      "Loss 139.78758 247 45\n",
      "Training Accuracy 0.76\n",
      "Loss 143.03648 248 45\n",
      "Training Accuracy 0.775\n",
      "Loss 167.70703 249 45\n",
      "Training Accuracy 0.68\n",
      "Loss 157.56921 250 45\n",
      "Training Accuracy 0.725\n",
      "Loss 161.01942 251 45\n",
      "Training Accuracy 0.665\n",
      "Loss 135.60536 252 45\n",
      "Training Accuracy 0.775\n",
      "Loss 126.55967 253 45\n",
      "Training Accuracy 0.805\n",
      "Loss 155.9318 254 45\n",
      "Training Accuracy 0.745\n",
      "Loss 129.70226 255 45\n",
      "Training Accuracy 0.805\n",
      "Loss 173.88672 256 45\n",
      "Training Accuracy 0.705\n",
      "Loss 156.1727 257 45\n",
      "Training Accuracy 0.745\n",
      "Loss 168.27245 258 45\n",
      "Training Accuracy 0.755\n",
      "Loss 147.73997 259 45\n",
      "Training Accuracy 0.73\n",
      "Loss 122.17758 260 45\n",
      "Training Accuracy 0.78\n",
      "Loss 149.75117 261 45\n",
      "Training Accuracy 0.745\n",
      "Loss 161.16245 262 45\n",
      "Training Accuracy 0.7\n",
      "Loss 186.76497 263 45\n",
      "Training Accuracy 0.715\n",
      "Loss 161.07181 264 45\n",
      "Training Accuracy 0.705\n",
      "Loss 146.30783 265 45\n",
      "Training Accuracy 0.73\n",
      "Loss 154.71312 266 45\n",
      "Training Accuracy 0.75\n",
      "Loss 161.06148 267 45\n",
      "Training Accuracy 0.715\n",
      "Loss 162.78958 268 45\n",
      "Training Accuracy 0.77\n",
      "Loss 151.854 269 45\n",
      "Training Accuracy 0.745\n",
      "Loss 141.63705 270 45\n",
      "Training Accuracy 0.78\n",
      "Loss 158.5671 271 45\n",
      "Training Accuracy 0.725\n",
      "Loss 143.03598 272 45\n",
      "Training Accuracy 0.74\n",
      "Loss 169.40292 273 45\n",
      "Training Accuracy 0.72\n",
      "Loss 149.68303 274 45\n",
      "Training Accuracy 0.77\n",
      "Loss 146.53351 275 45\n",
      "Training Accuracy 0.77\n",
      "Loss 144.65266 276 45\n",
      "Training Accuracy 0.76\n",
      "Loss 150.52483 277 45\n",
      "Training Accuracy 0.75\n",
      "Loss 139.50298 278 45\n",
      "Training Accuracy 0.73\n",
      "Loss 149.62482 279 45\n",
      "Training Accuracy 0.785\n",
      "Loss 145.16573 280 45\n",
      "Training Accuracy 0.745\n",
      "Loss 134.50336 281 45\n",
      "Training Accuracy 0.77\n",
      "Loss 137.80092 282 45\n",
      "Training Accuracy 0.75\n",
      "Loss 145.94934 283 45\n",
      "Training Accuracy 0.775\n",
      "Loss 125.20015 284 45\n",
      "Training Accuracy 0.79\n",
      "Loss 174.38448 285 45\n",
      "Training Accuracy 0.725\n",
      "Loss 150.16916 286 45\n",
      "Training Accuracy 0.765\n",
      "Loss 148.9546 287 45\n",
      "Training Accuracy 0.77\n",
      "Loss 175.11903 288 45\n",
      "Training Accuracy 0.7\n",
      "Loss 145.45232 289 45\n",
      "Training Accuracy 0.75\n",
      "Loss 150.24876 290 45\n",
      "Training Accuracy 0.705\n",
      "Loss 172.55894 291 45\n",
      "Training Accuracy 0.71\n",
      "Loss 99.06509 292 45\n",
      "Training Accuracy 0.72727275\n",
      "Loss 129.33951 1 46\n",
      "Training Accuracy 0.76\n",
      "Loss 159.27533 2 46\n",
      "Training Accuracy 0.74\n",
      "Loss 154.6313 3 46\n",
      "Training Accuracy 0.74\n",
      "Loss 163.94125 4 46\n",
      "Training Accuracy 0.73\n",
      "Loss 137.68068 5 46\n",
      "Training Accuracy 0.78\n",
      "Loss 157.87741 6 46\n",
      "Training Accuracy 0.72\n",
      "Loss 169.7235 7 46\n",
      "Training Accuracy 0.735\n",
      "Loss 157.95763 8 46\n",
      "Training Accuracy 0.755\n",
      "Loss 148.34566 9 46\n",
      "Training Accuracy 0.75\n",
      "Loss 161.85637 10 46\n",
      "Training Accuracy 0.75\n",
      "Loss 176.41565 11 46\n",
      "Training Accuracy 0.705\n",
      "Loss 145.39418 12 46\n",
      "Training Accuracy 0.74\n",
      "Loss 157.59062 13 46\n",
      "Training Accuracy 0.72\n",
      "Loss 169.45653 14 46\n",
      "Training Accuracy 0.725\n",
      "Loss 149.04947 15 46\n",
      "Training Accuracy 0.76\n",
      "Loss 188.29852 16 46\n",
      "Training Accuracy 0.69\n",
      "Loss 135.26006 17 46\n",
      "Training Accuracy 0.77\n",
      "Loss 139.58205 18 46\n",
      "Training Accuracy 0.755\n",
      "Loss 142.45915 19 46\n",
      "Training Accuracy 0.74\n",
      "Loss 146.12373 20 46\n",
      "Training Accuracy 0.76\n",
      "Loss 169.20053 21 46\n",
      "Training Accuracy 0.685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 146.21866 22 46\n",
      "Training Accuracy 0.755\n",
      "Loss 159.05238 23 46\n",
      "Training Accuracy 0.745\n",
      "Loss 163.39755 24 46\n",
      "Training Accuracy 0.73\n",
      "Loss 135.02402 25 46\n",
      "Training Accuracy 0.8\n",
      "Loss 161.299 26 46\n",
      "Training Accuracy 0.73\n",
      "Loss 146.21301 27 46\n",
      "Training Accuracy 0.75\n",
      "Loss 142.82559 28 46\n",
      "Training Accuracy 0.725\n",
      "Loss 147.77495 29 46\n",
      "Training Accuracy 0.735\n",
      "Loss 174.6243 30 46\n",
      "Training Accuracy 0.7\n",
      "Loss 158.84396 31 46\n",
      "Training Accuracy 0.75\n",
      "Loss 151.41866 32 46\n",
      "Training Accuracy 0.705\n",
      "Loss 146.3098 33 46\n",
      "Training Accuracy 0.755\n",
      "Loss 144.20543 34 46\n",
      "Training Accuracy 0.725\n",
      "Loss 149.37218 35 46\n",
      "Training Accuracy 0.67\n",
      "Loss 157.67183 36 46\n",
      "Training Accuracy 0.72\n",
      "Loss 140.51723 37 46\n",
      "Training Accuracy 0.755\n",
      "Loss 152.13177 38 46\n",
      "Training Accuracy 0.74\n",
      "Loss 131.01208 39 46\n",
      "Training Accuracy 0.755\n",
      "Loss 157.25562 40 46\n",
      "Training Accuracy 0.745\n",
      "Loss 155.2046 41 46\n",
      "Training Accuracy 0.73\n",
      "Loss 176.01636 42 46\n",
      "Training Accuracy 0.685\n",
      "Loss 151.96275 43 46\n",
      "Training Accuracy 0.72\n",
      "Loss 150.95668 44 46\n",
      "Training Accuracy 0.76\n",
      "Loss 164.91037 45 46\n",
      "Training Accuracy 0.7\n",
      "Loss 168.6742 46 46\n",
      "Training Accuracy 0.745\n",
      "Loss 146.5037 47 46\n",
      "Training Accuracy 0.765\n",
      "Loss 130.66934 48 46\n",
      "Training Accuracy 0.765\n",
      "Loss 143.46173 49 46\n",
      "Training Accuracy 0.75\n",
      "Loss 174.46094 50 46\n",
      "Training Accuracy 0.7\n",
      "Loss 136.33548 51 46\n",
      "Training Accuracy 0.765\n",
      "Loss 140.39082 52 46\n",
      "Training Accuracy 0.75\n",
      "Loss 127.43076 53 46\n",
      "Training Accuracy 0.755\n",
      "Loss 168.43996 54 46\n",
      "Training Accuracy 0.725\n",
      "Loss 159.44992 55 46\n",
      "Training Accuracy 0.74\n",
      "Loss 162.16678 56 46\n",
      "Training Accuracy 0.76\n",
      "Loss 145.8609 57 46\n",
      "Training Accuracy 0.76\n",
      "Loss 145.96385 58 46\n",
      "Training Accuracy 0.73\n",
      "Loss 157.54877 59 46\n",
      "Training Accuracy 0.72\n",
      "Loss 158.55676 60 46\n",
      "Training Accuracy 0.725\n",
      "Loss 158.1322 61 46\n",
      "Training Accuracy 0.725\n",
      "Loss 139.4316 62 46\n",
      "Training Accuracy 0.755\n",
      "Loss 145.6197 63 46\n",
      "Training Accuracy 0.765\n",
      "Loss 159.23161 64 46\n",
      "Training Accuracy 0.715\n",
      "Loss 153.39742 65 46\n",
      "Training Accuracy 0.715\n",
      "Loss 147.98999 66 46\n",
      "Training Accuracy 0.72\n",
      "Loss 147.3348 67 46\n",
      "Training Accuracy 0.765\n",
      "Loss 150.5083 68 46\n",
      "Training Accuracy 0.735\n",
      "Loss 146.17766 69 46\n",
      "Training Accuracy 0.765\n",
      "Loss 143.64632 70 46\n",
      "Training Accuracy 0.74\n",
      "Loss 169.32593 71 46\n",
      "Training Accuracy 0.715\n",
      "Loss 158.69823 72 46\n",
      "Training Accuracy 0.74\n",
      "Loss 170.60075 73 46\n",
      "Training Accuracy 0.69\n",
      "Loss 163.7067 74 46\n",
      "Training Accuracy 0.71\n",
      "Loss 162.42085 75 46\n",
      "Training Accuracy 0.735\n",
      "Loss 128.45515 76 46\n",
      "Training Accuracy 0.78\n",
      "Loss 166.25497 77 46\n",
      "Training Accuracy 0.75\n",
      "Loss 145.65617 78 46\n",
      "Training Accuracy 0.76\n",
      "Loss 168.34431 79 46\n",
      "Training Accuracy 0.695\n",
      "Loss 161.61415 80 46\n",
      "Training Accuracy 0.695\n",
      "Loss 136.01202 81 46\n",
      "Training Accuracy 0.76\n",
      "Loss 144.59738 82 46\n",
      "Training Accuracy 0.725\n",
      "Loss 146.94167 83 46\n",
      "Training Accuracy 0.745\n",
      "Loss 162.34761 84 46\n",
      "Training Accuracy 0.7\n",
      "Loss 157.49294 85 46\n",
      "Training Accuracy 0.75\n",
      "Loss 150.85449 86 46\n",
      "Training Accuracy 0.74\n",
      "Loss 194.87794 87 46\n",
      "Training Accuracy 0.685\n",
      "Loss 181.79858 88 46\n",
      "Training Accuracy 0.7\n",
      "Loss 159.16936 89 46\n",
      "Training Accuracy 0.69\n",
      "Loss 172.89906 90 46\n",
      "Training Accuracy 0.68\n",
      "Loss 170.61542 91 46\n",
      "Training Accuracy 0.72\n",
      "Loss 164.36731 92 46\n",
      "Training Accuracy 0.715\n",
      "Loss 156.48569 93 46\n",
      "Training Accuracy 0.735\n",
      "Loss 169.6141 94 46\n",
      "Training Accuracy 0.715\n",
      "Loss 150.24387 95 46\n",
      "Training Accuracy 0.715\n",
      "Loss 167.7659 96 46\n",
      "Training Accuracy 0.74\n",
      "Loss 156.89545 97 46\n",
      "Training Accuracy 0.7\n",
      "Loss 139.93953 98 46\n",
      "Training Accuracy 0.78\n",
      "Loss 147.70386 99 46\n",
      "Training Accuracy 0.73\n",
      "Loss 142.4908 100 46\n",
      "Training Accuracy 0.765\n",
      "Loss 178.97862 101 46\n",
      "Training Accuracy 0.685\n",
      "Loss 146.0338 102 46\n",
      "Training Accuracy 0.73\n",
      "Loss 162.17177 103 46\n",
      "Training Accuracy 0.695\n",
      "Loss 163.08873 104 46\n",
      "Training Accuracy 0.735\n",
      "Loss 145.5407 105 46\n",
      "Training Accuracy 0.75\n",
      "Loss 136.8604 106 46\n",
      "Training Accuracy 0.76\n",
      "Loss 144.0696 107 46\n",
      "Training Accuracy 0.745\n",
      "Loss 151.91246 108 46\n",
      "Training Accuracy 0.71\n",
      "Loss 140.54182 109 46\n",
      "Training Accuracy 0.735\n",
      "Loss 156.16922 110 46\n",
      "Training Accuracy 0.75\n",
      "Loss 165.17375 111 46\n",
      "Training Accuracy 0.7\n",
      "Loss 160.4845 112 46\n",
      "Training Accuracy 0.74\n",
      "Loss 172.73853 113 46\n",
      "Training Accuracy 0.715\n",
      "Loss 154.34415 114 46\n",
      "Training Accuracy 0.71\n",
      "Loss 174.04518 115 46\n",
      "Training Accuracy 0.725\n",
      "Loss 168.37482 116 46\n",
      "Training Accuracy 0.695\n",
      "Loss 127.002235 117 46\n",
      "Training Accuracy 0.8\n",
      "Loss 140.8532 118 46\n",
      "Training Accuracy 0.76\n",
      "Loss 171.79945 119 46\n",
      "Training Accuracy 0.69\n",
      "Loss 160.7973 120 46\n",
      "Training Accuracy 0.705\n",
      "Loss 166.37267 121 46\n",
      "Training Accuracy 0.695\n",
      "Loss 150.27522 122 46\n",
      "Training Accuracy 0.735\n",
      "Loss 132.99731 123 46\n",
      "Training Accuracy 0.785\n",
      "Loss 146.76309 124 46\n",
      "Training Accuracy 0.725\n",
      "Loss 156.99861 125 46\n",
      "Training Accuracy 0.74\n",
      "Loss 161.32108 126 46\n",
      "Training Accuracy 0.725\n",
      "Loss 158.57393 127 46\n",
      "Training Accuracy 0.715\n",
      "Loss 143.0892 128 46\n",
      "Training Accuracy 0.76\n",
      "Loss 140.74796 129 46\n",
      "Training Accuracy 0.8\n",
      "Loss 135.16258 130 46\n",
      "Training Accuracy 0.74\n",
      "Loss 132.1883 131 46\n",
      "Training Accuracy 0.745\n",
      "Loss 151.43706 132 46\n",
      "Training Accuracy 0.76\n",
      "Loss 157.26735 133 46\n",
      "Training Accuracy 0.73\n",
      "Loss 143.62204 134 46\n",
      "Training Accuracy 0.765\n",
      "Loss 139.52516 135 46\n",
      "Training Accuracy 0.775\n",
      "Loss 152.18494 136 46\n",
      "Training Accuracy 0.745\n",
      "Loss 177.33105 137 46\n",
      "Training Accuracy 0.69\n",
      "Loss 150.77725 138 46\n",
      "Training Accuracy 0.77\n",
      "Loss 152.84554 139 46\n",
      "Training Accuracy 0.765\n",
      "Loss 152.58995 140 46\n",
      "Training Accuracy 0.715\n",
      "Loss 165.80072 141 46\n",
      "Training Accuracy 0.725\n",
      "Loss 172.96748 142 46\n",
      "Training Accuracy 0.665\n",
      "Loss 144.1113 143 46\n",
      "Training Accuracy 0.76\n",
      "Loss 160.8337 144 46\n",
      "Training Accuracy 0.72\n",
      "Loss 141.09811 145 46\n",
      "Training Accuracy 0.78\n",
      "Loss 170.3396 146 46\n",
      "Training Accuracy 0.67\n",
      "Loss 164.00533 147 46\n",
      "Training Accuracy 0.705\n",
      "Loss 166.77351 148 46\n",
      "Training Accuracy 0.665\n",
      "Loss 158.68546 149 46\n",
      "Training Accuracy 0.725\n",
      "Loss 137.20416 150 46\n",
      "Training Accuracy 0.75\n",
      "Loss 162.92798 151 46\n",
      "Training Accuracy 0.685\n",
      "Loss 171.52403 152 46\n",
      "Training Accuracy 0.69\n",
      "Loss 141.45015 153 46\n",
      "Training Accuracy 0.77\n",
      "Loss 164.93225 154 46\n",
      "Training Accuracy 0.735\n",
      "Loss 150.09734 155 46\n",
      "Training Accuracy 0.725\n",
      "Loss 161.43925 156 46\n",
      "Training Accuracy 0.695\n",
      "Loss 146.13957 157 46\n",
      "Training Accuracy 0.74\n",
      "Loss 147.22804 158 46\n",
      "Training Accuracy 0.765\n",
      "Loss 180.57959 159 46\n",
      "Training Accuracy 0.67\n",
      "Loss 163.39899 160 46\n",
      "Training Accuracy 0.7\n",
      "Loss 178.17903 161 46\n",
      "Training Accuracy 0.655\n",
      "Loss 153.48117 162 46\n",
      "Training Accuracy 0.745\n",
      "Loss 166.97984 163 46\n",
      "Training Accuracy 0.74\n",
      "Loss 146.40265 164 46\n",
      "Training Accuracy 0.75\n",
      "Loss 157.20557 165 46\n",
      "Training Accuracy 0.73\n",
      "Loss 151.33383 166 46\n",
      "Training Accuracy 0.765\n",
      "Loss 139.394 167 46\n",
      "Training Accuracy 0.755\n",
      "Loss 179.0411 168 46\n",
      "Training Accuracy 0.69\n",
      "Loss 143.56546 169 46\n",
      "Training Accuracy 0.71\n",
      "Loss 169.71675 170 46\n",
      "Training Accuracy 0.695\n",
      "Loss 161.6421 171 46\n",
      "Training Accuracy 0.76\n",
      "Loss 141.39754 172 46\n",
      "Training Accuracy 0.755\n",
      "Loss 168.41458 173 46\n",
      "Training Accuracy 0.73\n",
      "Loss 147.37132 174 46\n",
      "Training Accuracy 0.74\n",
      "Loss 130.41753 175 46\n",
      "Training Accuracy 0.815\n",
      "Loss 124.4727 176 46\n",
      "Training Accuracy 0.775\n",
      "Loss 161.98355 177 46\n",
      "Training Accuracy 0.74\n",
      "Loss 139.05934 178 46\n",
      "Training Accuracy 0.735\n",
      "Loss 153.2309 179 46\n",
      "Training Accuracy 0.74\n",
      "Loss 165.60196 180 46\n",
      "Training Accuracy 0.745\n",
      "Loss 145.44121 181 46\n",
      "Training Accuracy 0.76\n",
      "Loss 161.85115 182 46\n",
      "Training Accuracy 0.72\n",
      "Loss 166.94493 183 46\n",
      "Training Accuracy 0.69\n",
      "Loss 134.51196 184 46\n",
      "Training Accuracy 0.785\n",
      "Loss 159.41858 185 46\n",
      "Training Accuracy 0.735\n",
      "Loss 145.12788 186 46\n",
      "Training Accuracy 0.75\n",
      "Loss 185.78911 187 46\n",
      "Training Accuracy 0.68\n",
      "Loss 157.75203 188 46\n",
      "Training Accuracy 0.73\n",
      "Loss 146.35994 189 46\n",
      "Training Accuracy 0.74\n",
      "Loss 152.87837 190 46\n",
      "Training Accuracy 0.735\n",
      "Loss 144.95923 191 46\n",
      "Training Accuracy 0.73\n",
      "Loss 162.42761 192 46\n",
      "Training Accuracy 0.71\n",
      "Loss 144.38716 193 46\n",
      "Training Accuracy 0.775\n",
      "Loss 151.94617 194 46\n",
      "Training Accuracy 0.76\n",
      "Loss 135.58466 195 46\n",
      "Training Accuracy 0.765\n",
      "Loss 155.06114 196 46\n",
      "Training Accuracy 0.73\n",
      "Loss 152.13472 197 46\n",
      "Training Accuracy 0.685\n",
      "Loss 147.38039 198 46\n",
      "Training Accuracy 0.735\n",
      "Loss 134.88036 199 46\n",
      "Training Accuracy 0.76\n",
      "Loss 131.61002 200 46\n",
      "Training Accuracy 0.775\n",
      "Loss 152.23364 201 46\n",
      "Training Accuracy 0.71\n",
      "Loss 145.21884 202 46\n",
      "Training Accuracy 0.74\n",
      "Loss 166.8832 203 46\n",
      "Training Accuracy 0.725\n",
      "Loss 149.58127 204 46\n",
      "Training Accuracy 0.76\n",
      "Loss 165.632 205 46\n",
      "Training Accuracy 0.71\n",
      "Loss 151.83942 206 46\n",
      "Training Accuracy 0.77\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 170.44374 207 46\n",
      "Training Accuracy 0.72\n",
      "Loss 171.63394 208 46\n",
      "Training Accuracy 0.73\n",
      "Loss 153.48396 209 46\n",
      "Training Accuracy 0.72\n",
      "Loss 140.01537 210 46\n",
      "Training Accuracy 0.78\n",
      "Loss 138.6422 211 46\n",
      "Training Accuracy 0.765\n",
      "Loss 150.50224 212 46\n",
      "Training Accuracy 0.745\n",
      "Loss 171.78047 213 46\n",
      "Training Accuracy 0.71\n",
      "Loss 150.74165 214 46\n",
      "Training Accuracy 0.73\n",
      "Loss 171.27074 215 46\n",
      "Training Accuracy 0.68\n",
      "Loss 160.55328 216 46\n",
      "Training Accuracy 0.735\n",
      "Loss 171.8474 217 46\n",
      "Training Accuracy 0.675\n",
      "Loss 161.91241 218 46\n",
      "Training Accuracy 0.735\n",
      "Loss 155.2354 219 46\n",
      "Training Accuracy 0.75\n",
      "Loss 141.91318 220 46\n",
      "Training Accuracy 0.78\n",
      "Loss 150.57962 221 46\n",
      "Training Accuracy 0.755\n",
      "Loss 153.16228 222 46\n",
      "Training Accuracy 0.72\n",
      "Loss 167.1745 223 46\n",
      "Training Accuracy 0.735\n",
      "Loss 171.08084 224 46\n",
      "Training Accuracy 0.69\n",
      "Loss 168.8633 225 46\n",
      "Training Accuracy 0.68\n",
      "Loss 122.123146 226 46\n",
      "Training Accuracy 0.82\n",
      "Loss 168.41699 227 46\n",
      "Training Accuracy 0.74\n",
      "Loss 180.44664 228 46\n",
      "Training Accuracy 0.71\n",
      "Loss 164.97604 229 46\n",
      "Training Accuracy 0.725\n",
      "Loss 169.13075 230 46\n",
      "Training Accuracy 0.695\n",
      "Loss 145.33804 231 46\n",
      "Training Accuracy 0.745\n",
      "Loss 161.12396 232 46\n",
      "Training Accuracy 0.725\n",
      "Loss 193.19656 233 46\n",
      "Training Accuracy 0.61\n",
      "Loss 161.93643 234 46\n",
      "Training Accuracy 0.67\n",
      "Loss 157.7854 235 46\n",
      "Training Accuracy 0.77\n",
      "Loss 139.28436 236 46\n",
      "Training Accuracy 0.74\n",
      "Loss 164.87785 237 46\n",
      "Training Accuracy 0.705\n",
      "Loss 143.40715 238 46\n",
      "Training Accuracy 0.725\n",
      "Loss 153.35023 239 46\n",
      "Training Accuracy 0.745\n",
      "Loss 154.97249 240 46\n",
      "Training Accuracy 0.72\n",
      "Loss 180.31725 241 46\n",
      "Training Accuracy 0.665\n",
      "Loss 168.05136 242 46\n",
      "Training Accuracy 0.685\n",
      "Loss 128.67372 243 46\n",
      "Training Accuracy 0.81\n",
      "Loss 160.29112 244 46\n",
      "Training Accuracy 0.695\n",
      "Loss 162.8905 245 46\n",
      "Training Accuracy 0.73\n",
      "Loss 170.38033 246 46\n",
      "Training Accuracy 0.68\n",
      "Loss 139.87085 247 46\n",
      "Training Accuracy 0.705\n",
      "Loss 140.60025 248 46\n",
      "Training Accuracy 0.745\n",
      "Loss 169.11833 249 46\n",
      "Training Accuracy 0.68\n",
      "Loss 165.63452 250 46\n",
      "Training Accuracy 0.71\n",
      "Loss 166.33546 251 46\n",
      "Training Accuracy 0.745\n",
      "Loss 132.64713 252 46\n",
      "Training Accuracy 0.755\n",
      "Loss 120.633415 253 46\n",
      "Training Accuracy 0.765\n",
      "Loss 154.06363 254 46\n",
      "Training Accuracy 0.745\n",
      "Loss 145.17088 255 46\n",
      "Training Accuracy 0.735\n",
      "Loss 174.37546 256 46\n",
      "Training Accuracy 0.705\n",
      "Loss 141.8185 257 46\n",
      "Training Accuracy 0.74\n",
      "Loss 167.77097 258 46\n",
      "Training Accuracy 0.73\n",
      "Loss 158.73643 259 46\n",
      "Training Accuracy 0.7\n",
      "Loss 129.03275 260 46\n",
      "Training Accuracy 0.745\n",
      "Loss 159.65837 261 46\n",
      "Training Accuracy 0.72\n",
      "Loss 153.53183 262 46\n",
      "Training Accuracy 0.685\n",
      "Loss 182.885 263 46\n",
      "Training Accuracy 0.72\n",
      "Loss 163.68306 264 46\n",
      "Training Accuracy 0.715\n",
      "Loss 155.37057 265 46\n",
      "Training Accuracy 0.725\n",
      "Loss 158.55203 266 46\n",
      "Training Accuracy 0.695\n",
      "Loss 160.993 267 46\n",
      "Training Accuracy 0.71\n",
      "Loss 168.62685 268 46\n",
      "Training Accuracy 0.725\n",
      "Loss 157.92561 269 46\n",
      "Training Accuracy 0.705\n",
      "Loss 141.38051 270 46\n",
      "Training Accuracy 0.705\n",
      "Loss 162.18466 271 46\n",
      "Training Accuracy 0.73\n",
      "Loss 141.49023 272 46\n",
      "Training Accuracy 0.75\n",
      "Loss 151.6007 273 46\n",
      "Training Accuracy 0.725\n",
      "Loss 140.91359 274 46\n",
      "Training Accuracy 0.785\n",
      "Loss 146.19716 275 46\n",
      "Training Accuracy 0.75\n",
      "Loss 142.70708 276 46\n",
      "Training Accuracy 0.755\n",
      "Loss 156.09062 277 46\n",
      "Training Accuracy 0.73\n",
      "Loss 151.99966 278 46\n",
      "Training Accuracy 0.735\n",
      "Loss 152.20834 279 46\n",
      "Training Accuracy 0.735\n",
      "Loss 144.6007 280 46\n",
      "Training Accuracy 0.735\n",
      "Loss 134.14894 281 46\n",
      "Training Accuracy 0.77\n",
      "Loss 137.91707 282 46\n",
      "Training Accuracy 0.75\n",
      "Loss 151.4232 283 46\n",
      "Training Accuracy 0.77\n",
      "Loss 122.72446 284 46\n",
      "Training Accuracy 0.8\n",
      "Loss 180.09047 285 46\n",
      "Training Accuracy 0.7\n",
      "Loss 163.40804 286 46\n",
      "Training Accuracy 0.72\n",
      "Loss 146.43758 287 46\n",
      "Training Accuracy 0.735\n",
      "Loss 154.02844 288 46\n",
      "Training Accuracy 0.75\n",
      "Loss 152.02827 289 46\n",
      "Training Accuracy 0.745\n",
      "Loss 163.0916 290 46\n",
      "Training Accuracy 0.71\n",
      "Loss 168.92708 291 46\n",
      "Training Accuracy 0.71\n",
      "Loss 106.18026 292 46\n",
      "Training Accuracy 0.65909094\n",
      "Loss 115.873535 1 47\n",
      "Training Accuracy 0.815\n",
      "Loss 143.54631 2 47\n",
      "Training Accuracy 0.77\n",
      "Loss 141.01782 3 47\n",
      "Training Accuracy 0.76\n",
      "Loss 155.62378 4 47\n",
      "Training Accuracy 0.71\n",
      "Loss 134.81535 5 47\n",
      "Training Accuracy 0.765\n",
      "Loss 161.3669 6 47\n",
      "Training Accuracy 0.71\n",
      "Loss 173.34016 7 47\n",
      "Training Accuracy 0.72\n",
      "Loss 156.3021 8 47\n",
      "Training Accuracy 0.74\n",
      "Loss 147.11642 9 47\n",
      "Training Accuracy 0.765\n",
      "Loss 158.1164 10 47\n",
      "Training Accuracy 0.71\n",
      "Loss 170.95215 11 47\n",
      "Training Accuracy 0.745\n",
      "Loss 138.608 12 47\n",
      "Training Accuracy 0.755\n",
      "Loss 145.13759 13 47\n",
      "Training Accuracy 0.725\n",
      "Loss 153.83272 14 47\n",
      "Training Accuracy 0.765\n",
      "Loss 149.81883 15 47\n",
      "Training Accuracy 0.735\n",
      "Loss 181.6607 16 47\n",
      "Training Accuracy 0.7\n",
      "Loss 128.16145 17 47\n",
      "Training Accuracy 0.79\n",
      "Loss 136.27954 18 47\n",
      "Training Accuracy 0.745\n",
      "Loss 151.89822 19 47\n",
      "Training Accuracy 0.745\n",
      "Loss 143.89934 20 47\n",
      "Training Accuracy 0.74\n",
      "Loss 161.78403 21 47\n",
      "Training Accuracy 0.72\n",
      "Loss 144.9103 22 47\n",
      "Training Accuracy 0.77\n",
      "Loss 159.69853 23 47\n",
      "Training Accuracy 0.74\n",
      "Loss 159.26904 24 47\n",
      "Training Accuracy 0.715\n",
      "Loss 136.85704 25 47\n",
      "Training Accuracy 0.74\n",
      "Loss 151.92776 26 47\n",
      "Training Accuracy 0.72\n",
      "Loss 145.2512 27 47\n",
      "Training Accuracy 0.75\n",
      "Loss 146.14061 28 47\n",
      "Training Accuracy 0.715\n",
      "Loss 151.65677 29 47\n",
      "Training Accuracy 0.715\n",
      "Loss 184.1455 30 47\n",
      "Training Accuracy 0.69\n",
      "Loss 152.18549 31 47\n",
      "Training Accuracy 0.76\n",
      "Loss 145.99916 32 47\n",
      "Training Accuracy 0.745\n",
      "Loss 159.33614 33 47\n",
      "Training Accuracy 0.72\n",
      "Loss 143.85306 34 47\n",
      "Training Accuracy 0.715\n",
      "Loss 138.04607 35 47\n",
      "Training Accuracy 0.72\n",
      "Loss 166.77806 36 47\n",
      "Training Accuracy 0.66\n",
      "Loss 141.73381 37 47\n",
      "Training Accuracy 0.75\n",
      "Loss 159.31326 38 47\n",
      "Training Accuracy 0.725\n",
      "Loss 117.633896 39 47\n",
      "Training Accuracy 0.8\n",
      "Loss 153.50127 40 47\n",
      "Training Accuracy 0.69\n",
      "Loss 161.46513 41 47\n",
      "Training Accuracy 0.695\n",
      "Loss 169.9621 42 47\n",
      "Training Accuracy 0.685\n",
      "Loss 156.57109 43 47\n",
      "Training Accuracy 0.685\n",
      "Loss 152.67365 44 47\n",
      "Training Accuracy 0.73\n",
      "Loss 155.30025 45 47\n",
      "Training Accuracy 0.715\n",
      "Loss 166.91347 46 47\n",
      "Training Accuracy 0.735\n",
      "Loss 152.14803 47 47\n",
      "Training Accuracy 0.745\n",
      "Loss 127.44465 48 47\n",
      "Training Accuracy 0.765\n",
      "Loss 149.6325 49 47\n",
      "Training Accuracy 0.72\n",
      "Loss 184.75784 50 47\n",
      "Training Accuracy 0.695\n",
      "Loss 141.36021 51 47\n",
      "Training Accuracy 0.745\n",
      "Loss 145.7864 52 47\n",
      "Training Accuracy 0.765\n",
      "Loss 117.72867 53 47\n",
      "Training Accuracy 0.785\n",
      "Loss 178.13788 54 47\n",
      "Training Accuracy 0.675\n",
      "Loss 149.58731 55 47\n",
      "Training Accuracy 0.73\n",
      "Loss 165.98528 56 47\n",
      "Training Accuracy 0.74\n",
      "Loss 144.55742 57 47\n",
      "Training Accuracy 0.775\n",
      "Loss 156.62917 58 47\n",
      "Training Accuracy 0.735\n",
      "Loss 141.91441 59 47\n",
      "Training Accuracy 0.785\n",
      "Loss 144.6924 60 47\n",
      "Training Accuracy 0.75\n",
      "Loss 159.13309 61 47\n",
      "Training Accuracy 0.715\n",
      "Loss 130.26385 62 47\n",
      "Training Accuracy 0.765\n",
      "Loss 153.54645 63 47\n",
      "Training Accuracy 0.765\n",
      "Loss 158.69197 64 47\n",
      "Training Accuracy 0.705\n",
      "Loss 154.88895 65 47\n",
      "Training Accuracy 0.71\n",
      "Loss 143.0353 66 47\n",
      "Training Accuracy 0.75\n",
      "Loss 142.93304 67 47\n",
      "Training Accuracy 0.75\n",
      "Loss 154.421 68 47\n",
      "Training Accuracy 0.73\n",
      "Loss 163.55641 69 47\n",
      "Training Accuracy 0.7\n",
      "Loss 135.75198 70 47\n",
      "Training Accuracy 0.77\n",
      "Loss 155.34044 71 47\n",
      "Training Accuracy 0.76\n",
      "Loss 160.42708 72 47\n",
      "Training Accuracy 0.73\n",
      "Loss 176.2448 73 47\n",
      "Training Accuracy 0.655\n",
      "Loss 156.26175 74 47\n",
      "Training Accuracy 0.72\n",
      "Loss 153.27568 75 47\n",
      "Training Accuracy 0.775\n",
      "Loss 132.14531 76 47\n",
      "Training Accuracy 0.765\n",
      "Loss 165.73291 77 47\n",
      "Training Accuracy 0.735\n",
      "Loss 156.97838 78 47\n",
      "Training Accuracy 0.715\n",
      "Loss 154.82498 79 47\n",
      "Training Accuracy 0.705\n",
      "Loss 161.28474 80 47\n",
      "Training Accuracy 0.72\n",
      "Loss 153.14114 81 47\n",
      "Training Accuracy 0.725\n",
      "Loss 147.36356 82 47\n",
      "Training Accuracy 0.755\n",
      "Loss 151.52269 83 47\n",
      "Training Accuracy 0.725\n",
      "Loss 161.98892 84 47\n",
      "Training Accuracy 0.735\n",
      "Loss 145.9845 85 47\n",
      "Training Accuracy 0.765\n",
      "Loss 155.28638 86 47\n",
      "Training Accuracy 0.725\n",
      "Loss 189.55963 87 47\n",
      "Training Accuracy 0.72\n",
      "Loss 176.79897 88 47\n",
      "Training Accuracy 0.715\n",
      "Loss 156.96788 89 47\n",
      "Training Accuracy 0.705\n",
      "Loss 163.21497 90 47\n",
      "Training Accuracy 0.725\n",
      "Loss 152.08553 91 47\n",
      "Training Accuracy 0.76\n",
      "Loss 166.21 92 47\n",
      "Training Accuracy 0.705\n",
      "Loss 156.50757 93 47\n",
      "Training Accuracy 0.7\n",
      "Loss 147.21527 94 47\n",
      "Training Accuracy 0.75\n",
      "Loss 156.12036 95 47\n",
      "Training Accuracy 0.685\n",
      "Loss 153.60991 96 47\n",
      "Training Accuracy 0.745\n",
      "Loss 151.27032 97 47\n",
      "Training Accuracy 0.74\n",
      "Loss 144.41435 98 47\n",
      "Training Accuracy 0.78\n",
      "Loss 143.84695 99 47\n",
      "Training Accuracy 0.77\n",
      "Loss 140.46846 100 47\n",
      "Training Accuracy 0.77\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 177.06366 101 47\n",
      "Training Accuracy 0.69\n",
      "Loss 156.12498 102 47\n",
      "Training Accuracy 0.7\n",
      "Loss 151.36914 103 47\n",
      "Training Accuracy 0.73\n",
      "Loss 165.94925 104 47\n",
      "Training Accuracy 0.715\n",
      "Loss 149.66818 105 47\n",
      "Training Accuracy 0.725\n",
      "Loss 141.25797 106 47\n",
      "Training Accuracy 0.755\n",
      "Loss 139.9572 107 47\n",
      "Training Accuracy 0.755\n",
      "Loss 152.37532 108 47\n",
      "Training Accuracy 0.74\n",
      "Loss 138.39915 109 47\n",
      "Training Accuracy 0.765\n",
      "Loss 149.5284 110 47\n",
      "Training Accuracy 0.785\n",
      "Loss 164.40755 111 47\n",
      "Training Accuracy 0.7\n",
      "Loss 156.10136 112 47\n",
      "Training Accuracy 0.73\n",
      "Loss 172.60193 113 47\n",
      "Training Accuracy 0.72\n",
      "Loss 164.98912 114 47\n",
      "Training Accuracy 0.675\n",
      "Loss 168.38893 115 47\n",
      "Training Accuracy 0.7\n",
      "Loss 169.84174 116 47\n",
      "Training Accuracy 0.715\n",
      "Loss 123.057945 117 47\n",
      "Training Accuracy 0.815\n",
      "Loss 144.80898 118 47\n",
      "Training Accuracy 0.74\n",
      "Loss 177.44586 119 47\n",
      "Training Accuracy 0.68\n",
      "Loss 151.8152 120 47\n",
      "Training Accuracy 0.755\n",
      "Loss 169.44977 121 47\n",
      "Training Accuracy 0.7\n",
      "Loss 156.40103 122 47\n",
      "Training Accuracy 0.725\n",
      "Loss 152.57416 123 47\n",
      "Training Accuracy 0.705\n",
      "Loss 145.29002 124 47\n",
      "Training Accuracy 0.735\n",
      "Loss 139.1005 125 47\n",
      "Training Accuracy 0.75\n",
      "Loss 163.2758 126 47\n",
      "Training Accuracy 0.71\n",
      "Loss 165.14168 127 47\n",
      "Training Accuracy 0.69\n",
      "Loss 147.81387 128 47\n",
      "Training Accuracy 0.715\n",
      "Loss 138.93555 129 47\n",
      "Training Accuracy 0.76\n",
      "Loss 129.88147 130 47\n",
      "Training Accuracy 0.76\n",
      "Loss 144.71123 131 47\n",
      "Training Accuracy 0.77\n",
      "Loss 139.16675 132 47\n",
      "Training Accuracy 0.755\n",
      "Loss 156.20045 133 47\n",
      "Training Accuracy 0.72\n",
      "Loss 148.27657 134 47\n",
      "Training Accuracy 0.72\n",
      "Loss 156.3396 135 47\n",
      "Training Accuracy 0.725\n",
      "Loss 150.8891 136 47\n",
      "Training Accuracy 0.745\n",
      "Loss 164.79047 137 47\n",
      "Training Accuracy 0.74\n",
      "Loss 164.20729 138 47\n",
      "Training Accuracy 0.73\n",
      "Loss 159.2239 139 47\n",
      "Training Accuracy 0.735\n",
      "Loss 140.02776 140 47\n",
      "Training Accuracy 0.77\n",
      "Loss 173.81787 141 47\n",
      "Training Accuracy 0.65\n",
      "Loss 169.73872 142 47\n",
      "Training Accuracy 0.645\n",
      "Loss 134.25122 143 47\n",
      "Training Accuracy 0.73\n",
      "Loss 175.1319 144 47\n",
      "Training Accuracy 0.69\n",
      "Loss 141.077 145 47\n",
      "Training Accuracy 0.76\n",
      "Loss 179.2489 146 47\n",
      "Training Accuracy 0.68\n",
      "Loss 167.64273 147 47\n",
      "Training Accuracy 0.7\n",
      "Loss 161.70631 148 47\n",
      "Training Accuracy 0.705\n",
      "Loss 150.66234 149 47\n",
      "Training Accuracy 0.73\n",
      "Loss 151.04227 150 47\n",
      "Training Accuracy 0.75\n",
      "Loss 163.48735 151 47\n",
      "Training Accuracy 0.75\n",
      "Loss 169.37189 152 47\n",
      "Training Accuracy 0.73\n",
      "Loss 143.32327 153 47\n",
      "Training Accuracy 0.765\n",
      "Loss 158.3104 154 47\n",
      "Training Accuracy 0.69\n",
      "Loss 144.86092 155 47\n",
      "Training Accuracy 0.75\n",
      "Loss 148.84749 156 47\n",
      "Training Accuracy 0.725\n",
      "Loss 134.16335 157 47\n",
      "Training Accuracy 0.745\n",
      "Loss 144.43231 158 47\n",
      "Training Accuracy 0.76\n",
      "Loss 170.20366 159 47\n",
      "Training Accuracy 0.7\n",
      "Loss 159.70125 160 47\n",
      "Training Accuracy 0.715\n",
      "Loss 164.69666 161 47\n",
      "Training Accuracy 0.705\n",
      "Loss 139.24142 162 47\n",
      "Training Accuracy 0.74\n",
      "Loss 168.20691 163 47\n",
      "Training Accuracy 0.735\n",
      "Loss 152.3713 164 47\n",
      "Training Accuracy 0.735\n",
      "Loss 166.16328 165 47\n",
      "Training Accuracy 0.715\n",
      "Loss 141.40263 166 47\n",
      "Training Accuracy 0.795\n",
      "Loss 148.16817 167 47\n",
      "Training Accuracy 0.715\n",
      "Loss 173.48033 168 47\n",
      "Training Accuracy 0.675\n",
      "Loss 137.04483 169 47\n",
      "Training Accuracy 0.75\n",
      "Loss 175.3668 170 47\n",
      "Training Accuracy 0.7\n",
      "Loss 143.4653 171 47\n",
      "Training Accuracy 0.795\n",
      "Loss 139.80905 172 47\n",
      "Training Accuracy 0.775\n",
      "Loss 165.84152 173 47\n",
      "Training Accuracy 0.755\n",
      "Loss 139.81247 174 47\n",
      "Training Accuracy 0.75\n",
      "Loss 135.54967 175 47\n",
      "Training Accuracy 0.795\n",
      "Loss 127.84844 176 47\n",
      "Training Accuracy 0.75\n",
      "Loss 155.75919 177 47\n",
      "Training Accuracy 0.72\n",
      "Loss 146.4738 178 47\n",
      "Training Accuracy 0.745\n",
      "Loss 164.38753 179 47\n",
      "Training Accuracy 0.725\n",
      "Loss 161.77367 180 47\n",
      "Training Accuracy 0.745\n",
      "Loss 135.8404 181 47\n",
      "Training Accuracy 0.78\n",
      "Loss 160.52104 182 47\n",
      "Training Accuracy 0.71\n",
      "Loss 157.68889 183 47\n",
      "Training Accuracy 0.73\n",
      "Loss 129.05351 184 47\n",
      "Training Accuracy 0.805\n",
      "Loss 147.80688 185 47\n",
      "Training Accuracy 0.73\n",
      "Loss 167.02383 186 47\n",
      "Training Accuracy 0.705\n",
      "Loss 167.78389 187 47\n",
      "Training Accuracy 0.72\n",
      "Loss 152.42023 188 47\n",
      "Training Accuracy 0.755\n",
      "Loss 137.92918 189 47\n",
      "Training Accuracy 0.79\n",
      "Loss 152.48741 190 47\n",
      "Training Accuracy 0.73\n",
      "Loss 136.72787 191 47\n",
      "Training Accuracy 0.78\n",
      "Loss 162.40816 192 47\n",
      "Training Accuracy 0.69\n",
      "Loss 136.68636 193 47\n",
      "Training Accuracy 0.775\n",
      "Loss 138.31096 194 47\n",
      "Training Accuracy 0.805\n",
      "Loss 123.89966 195 47\n",
      "Training Accuracy 0.81\n",
      "Loss 134.62994 196 47\n",
      "Training Accuracy 0.755\n",
      "Loss 141.30972 197 47\n",
      "Training Accuracy 0.74\n",
      "Loss 155.10649 198 47\n",
      "Training Accuracy 0.725\n",
      "Loss 126.51538 199 47\n",
      "Training Accuracy 0.78\n",
      "Loss 151.40645 200 47\n",
      "Training Accuracy 0.715\n",
      "Loss 149.03865 201 47\n",
      "Training Accuracy 0.71\n",
      "Loss 129.23114 202 47\n",
      "Training Accuracy 0.755\n",
      "Loss 159.92737 203 47\n",
      "Training Accuracy 0.75\n",
      "Loss 145.56387 204 47\n",
      "Training Accuracy 0.735\n",
      "Loss 167.67215 205 47\n",
      "Training Accuracy 0.72\n",
      "Loss 155.9212 206 47\n",
      "Training Accuracy 0.77\n",
      "Loss 164.91293 207 47\n",
      "Training Accuracy 0.71\n",
      "Loss 171.05324 208 47\n",
      "Training Accuracy 0.705\n",
      "Loss 161.7789 209 47\n",
      "Training Accuracy 0.725\n",
      "Loss 139.1893 210 47\n",
      "Training Accuracy 0.77\n",
      "Loss 121.91995 211 47\n",
      "Training Accuracy 0.785\n",
      "Loss 155.84955 212 47\n",
      "Training Accuracy 0.7\n",
      "Loss 180.31064 213 47\n",
      "Training Accuracy 0.675\n",
      "Loss 158.26454 214 47\n",
      "Training Accuracy 0.755\n",
      "Loss 174.63515 215 47\n",
      "Training Accuracy 0.705\n",
      "Loss 150.94864 216 47\n",
      "Training Accuracy 0.74\n",
      "Loss 166.24207 217 47\n",
      "Training Accuracy 0.675\n",
      "Loss 160.81815 218 47\n",
      "Training Accuracy 0.695\n",
      "Loss 134.66449 219 47\n",
      "Training Accuracy 0.78\n",
      "Loss 144.52167 220 47\n",
      "Training Accuracy 0.765\n",
      "Loss 159.7698 221 47\n",
      "Training Accuracy 0.75\n",
      "Loss 144.80624 222 47\n",
      "Training Accuracy 0.73\n",
      "Loss 172.39038 223 47\n",
      "Training Accuracy 0.72\n",
      "Loss 168.96414 224 47\n",
      "Training Accuracy 0.735\n",
      "Loss 158.91649 225 47\n",
      "Training Accuracy 0.74\n",
      "Loss 122.35032 226 47\n",
      "Training Accuracy 0.765\n",
      "Loss 168.34235 227 47\n",
      "Training Accuracy 0.755\n",
      "Loss 186.29944 228 47\n",
      "Training Accuracy 0.68\n",
      "Loss 144.94781 229 47\n",
      "Training Accuracy 0.745\n",
      "Loss 180.80948 230 47\n",
      "Training Accuracy 0.69\n",
      "Loss 140.41364 231 47\n",
      "Training Accuracy 0.755\n",
      "Loss 164.44312 232 47\n",
      "Training Accuracy 0.73\n",
      "Loss 182.70975 233 47\n",
      "Training Accuracy 0.64\n",
      "Loss 158.99976 234 47\n",
      "Training Accuracy 0.695\n",
      "Loss 157.95715 235 47\n",
      "Training Accuracy 0.735\n",
      "Loss 142.4323 236 47\n",
      "Training Accuracy 0.77\n",
      "Loss 156.41687 237 47\n",
      "Training Accuracy 0.71\n",
      "Loss 155.12952 238 47\n",
      "Training Accuracy 0.71\n",
      "Loss 149.45128 239 47\n",
      "Training Accuracy 0.73\n",
      "Loss 155.99695 240 47\n",
      "Training Accuracy 0.695\n",
      "Loss 175.36176 241 47\n",
      "Training Accuracy 0.7\n",
      "Loss 167.1288 242 47\n",
      "Training Accuracy 0.69\n",
      "Loss 124.39733 243 47\n",
      "Training Accuracy 0.785\n",
      "Loss 147.8213 244 47\n",
      "Training Accuracy 0.74\n",
      "Loss 153.0497 245 47\n",
      "Training Accuracy 0.765\n",
      "Loss 177.93274 246 47\n",
      "Training Accuracy 0.705\n",
      "Loss 138.41527 247 47\n",
      "Training Accuracy 0.73\n",
      "Loss 144.14287 248 47\n",
      "Training Accuracy 0.735\n",
      "Loss 173.20059 249 47\n",
      "Training Accuracy 0.675\n",
      "Loss 159.28001 250 47\n",
      "Training Accuracy 0.735\n",
      "Loss 165.17409 251 47\n",
      "Training Accuracy 0.685\n",
      "Loss 127.4864 252 47\n",
      "Training Accuracy 0.75\n",
      "Loss 118.5646 253 47\n",
      "Training Accuracy 0.78\n",
      "Loss 158.34715 254 47\n",
      "Training Accuracy 0.72\n",
      "Loss 128.02454 255 47\n",
      "Training Accuracy 0.76\n",
      "Loss 160.42055 256 47\n",
      "Training Accuracy 0.72\n",
      "Loss 144.22667 257 47\n",
      "Training Accuracy 0.775\n",
      "Loss 159.8178 258 47\n",
      "Training Accuracy 0.76\n",
      "Loss 145.40047 259 47\n",
      "Training Accuracy 0.735\n",
      "Loss 133.63507 260 47\n",
      "Training Accuracy 0.77\n",
      "Loss 155.29614 261 47\n",
      "Training Accuracy 0.705\n",
      "Loss 162.18698 262 47\n",
      "Training Accuracy 0.71\n",
      "Loss 176.06046 263 47\n",
      "Training Accuracy 0.735\n",
      "Loss 162.45111 264 47\n",
      "Training Accuracy 0.74\n",
      "Loss 145.20862 265 47\n",
      "Training Accuracy 0.715\n",
      "Loss 145.31824 266 47\n",
      "Training Accuracy 0.775\n",
      "Loss 149.66028 267 47\n",
      "Training Accuracy 0.71\n",
      "Loss 163.57715 268 47\n",
      "Training Accuracy 0.76\n",
      "Loss 150.12285 269 47\n",
      "Training Accuracy 0.73\n",
      "Loss 136.41216 270 47\n",
      "Training Accuracy 0.75\n",
      "Loss 159.0215 271 47\n",
      "Training Accuracy 0.72\n",
      "Loss 145.24988 272 47\n",
      "Training Accuracy 0.745\n",
      "Loss 162.11769 273 47\n",
      "Training Accuracy 0.695\n",
      "Loss 151.0318 274 47\n",
      "Training Accuracy 0.74\n",
      "Loss 146.38605 275 47\n",
      "Training Accuracy 0.73\n",
      "Loss 144.24509 276 47\n",
      "Training Accuracy 0.765\n",
      "Loss 150.60231 277 47\n",
      "Training Accuracy 0.77\n",
      "Loss 139.12364 278 47\n",
      "Training Accuracy 0.765\n",
      "Loss 152.15105 279 47\n",
      "Training Accuracy 0.725\n",
      "Loss 149.76106 280 47\n",
      "Training Accuracy 0.7\n",
      "Loss 127.60823 281 47\n",
      "Training Accuracy 0.785\n",
      "Loss 144.63972 282 47\n",
      "Training Accuracy 0.725\n",
      "Loss 147.0407 283 47\n",
      "Training Accuracy 0.79\n",
      "Loss 119.12595 284 47\n",
      "Training Accuracy 0.815\n",
      "Loss 170.87796 285 47\n",
      "Training Accuracy 0.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 149.31374 286 47\n",
      "Training Accuracy 0.77\n",
      "Loss 144.21098 287 47\n",
      "Training Accuracy 0.77\n",
      "Loss 162.73375 288 47\n",
      "Training Accuracy 0.76\n",
      "Loss 154.48763 289 47\n",
      "Training Accuracy 0.73\n",
      "Loss 164.21426 290 47\n",
      "Training Accuracy 0.69\n",
      "Loss 174.33601 291 47\n",
      "Training Accuracy 0.72\n",
      "Loss 112.75618 292 47\n",
      "Training Accuracy 0.67424244\n",
      "Loss 116.8736 1 48\n",
      "Training Accuracy 0.8\n",
      "Loss 139.19844 2 48\n",
      "Training Accuracy 0.755\n",
      "Loss 140.59804 3 48\n",
      "Training Accuracy 0.765\n",
      "Loss 155.08325 4 48\n",
      "Training Accuracy 0.75\n",
      "Loss 141.93619 5 48\n",
      "Training Accuracy 0.74\n",
      "Loss 157.9974 6 48\n",
      "Training Accuracy 0.705\n",
      "Loss 162.61807 7 48\n",
      "Training Accuracy 0.735\n",
      "Loss 149.48619 8 48\n",
      "Training Accuracy 0.78\n",
      "Loss 140.78726 9 48\n",
      "Training Accuracy 0.75\n",
      "Loss 158.90536 10 48\n",
      "Training Accuracy 0.725\n",
      "Loss 166.15166 11 48\n",
      "Training Accuracy 0.725\n",
      "Loss 131.46349 12 48\n",
      "Training Accuracy 0.76\n",
      "Loss 133.11188 13 48\n",
      "Training Accuracy 0.765\n",
      "Loss 160.7366 14 48\n",
      "Training Accuracy 0.755\n",
      "Loss 149.80815 15 48\n",
      "Training Accuracy 0.735\n",
      "Loss 183.3982 16 48\n",
      "Training Accuracy 0.69\n",
      "Loss 134.95592 17 48\n",
      "Training Accuracy 0.76\n",
      "Loss 136.56255 18 48\n",
      "Training Accuracy 0.735\n",
      "Loss 154.09099 19 48\n",
      "Training Accuracy 0.735\n",
      "Loss 145.41257 20 48\n",
      "Training Accuracy 0.73\n",
      "Loss 148.84326 21 48\n",
      "Training Accuracy 0.72\n",
      "Loss 148.75984 22 48\n",
      "Training Accuracy 0.745\n",
      "Loss 153.82195 23 48\n",
      "Training Accuracy 0.74\n",
      "Loss 156.75546 24 48\n",
      "Training Accuracy 0.745\n",
      "Loss 149.33931 25 48\n",
      "Training Accuracy 0.78\n",
      "Loss 165.9153 26 48\n",
      "Training Accuracy 0.69\n",
      "Loss 140.35275 27 48\n",
      "Training Accuracy 0.74\n",
      "Loss 133.68831 28 48\n",
      "Training Accuracy 0.74\n",
      "Loss 151.68127 29 48\n",
      "Training Accuracy 0.72\n",
      "Loss 173.37556 30 48\n",
      "Training Accuracy 0.685\n",
      "Loss 154.32889 31 48\n",
      "Training Accuracy 0.74\n",
      "Loss 156.41698 32 48\n",
      "Training Accuracy 0.695\n",
      "Loss 160.66748 33 48\n",
      "Training Accuracy 0.74\n",
      "Loss 137.1404 34 48\n",
      "Training Accuracy 0.755\n",
      "Loss 140.33308 35 48\n",
      "Training Accuracy 0.745\n",
      "Loss 156.6413 36 48\n",
      "Training Accuracy 0.675\n",
      "Loss 128.5494 37 48\n",
      "Training Accuracy 0.775\n",
      "Loss 154.5031 38 48\n",
      "Training Accuracy 0.7\n",
      "Loss 135.36385 39 48\n",
      "Training Accuracy 0.81\n",
      "Loss 150.8939 40 48\n",
      "Training Accuracy 0.715\n",
      "Loss 152.50116 41 48\n",
      "Training Accuracy 0.715\n",
      "Loss 172.16699 42 48\n",
      "Training Accuracy 0.725\n",
      "Loss 150.81349 43 48\n",
      "Training Accuracy 0.69\n",
      "Loss 156.03145 44 48\n",
      "Training Accuracy 0.715\n",
      "Loss 163.7251 45 48\n",
      "Training Accuracy 0.705\n",
      "Loss 161.99437 46 48\n",
      "Training Accuracy 0.745\n",
      "Loss 154.59996 47 48\n",
      "Training Accuracy 0.73\n",
      "Loss 125.150185 48 48\n",
      "Training Accuracy 0.785\n",
      "Loss 151.77097 49 48\n",
      "Training Accuracy 0.7\n",
      "Loss 174.5671 50 48\n",
      "Training Accuracy 0.68\n",
      "Loss 130.0005 51 48\n",
      "Training Accuracy 0.79\n",
      "Loss 148.13028 52 48\n",
      "Training Accuracy 0.735\n",
      "Loss 128.18796 53 48\n",
      "Training Accuracy 0.76\n",
      "Loss 169.83429 54 48\n",
      "Training Accuracy 0.74\n",
      "Loss 159.01445 55 48\n",
      "Training Accuracy 0.735\n",
      "Loss 173.13882 56 48\n",
      "Training Accuracy 0.705\n",
      "Loss 147.58788 57 48\n",
      "Training Accuracy 0.755\n",
      "Loss 133.90791 58 48\n",
      "Training Accuracy 0.775\n",
      "Loss 152.69133 59 48\n",
      "Training Accuracy 0.76\n",
      "Loss 146.504 60 48\n",
      "Training Accuracy 0.755\n",
      "Loss 158.05426 61 48\n",
      "Training Accuracy 0.74\n",
      "Loss 144.68121 62 48\n",
      "Training Accuracy 0.705\n",
      "Loss 145.86478 63 48\n",
      "Training Accuracy 0.76\n",
      "Loss 148.60007 64 48\n",
      "Training Accuracy 0.755\n",
      "Loss 158.37958 65 48\n",
      "Training Accuracy 0.68\n",
      "Loss 140.53899 66 48\n",
      "Training Accuracy 0.77\n",
      "Loss 140.5193 67 48\n",
      "Training Accuracy 0.755\n",
      "Loss 147.23575 68 48\n",
      "Training Accuracy 0.72\n",
      "Loss 144.30171 69 48\n",
      "Training Accuracy 0.735\n",
      "Loss 143.20802 70 48\n",
      "Training Accuracy 0.755\n",
      "Loss 152.08542 71 48\n",
      "Training Accuracy 0.765\n",
      "Loss 157.25586 72 48\n",
      "Training Accuracy 0.72\n",
      "Loss 169.18669 73 48\n",
      "Training Accuracy 0.695\n",
      "Loss 158.12405 74 48\n",
      "Training Accuracy 0.755\n",
      "Loss 159.02611 75 48\n",
      "Training Accuracy 0.725\n",
      "Loss 133.9318 76 48\n",
      "Training Accuracy 0.745\n",
      "Loss 170.9102 77 48\n",
      "Training Accuracy 0.7\n",
      "Loss 151.15297 78 48\n",
      "Training Accuracy 0.735\n",
      "Loss 150.0832 79 48\n",
      "Training Accuracy 0.7\n",
      "Loss 166.32175 80 48\n",
      "Training Accuracy 0.75\n",
      "Loss 129.70088 81 48\n",
      "Training Accuracy 0.82\n",
      "Loss 144.7424 82 48\n",
      "Training Accuracy 0.76\n",
      "Loss 144.5657 83 48\n",
      "Training Accuracy 0.755\n",
      "Loss 158.62103 84 48\n",
      "Training Accuracy 0.715\n",
      "Loss 155.06432 85 48\n",
      "Training Accuracy 0.73\n",
      "Loss 141.80504 86 48\n",
      "Training Accuracy 0.77\n",
      "Loss 188.87137 87 48\n",
      "Training Accuracy 0.68\n",
      "Loss 168.99504 88 48\n",
      "Training Accuracy 0.72\n",
      "Loss 158.58742 89 48\n",
      "Training Accuracy 0.72\n",
      "Loss 171.20642 90 48\n",
      "Training Accuracy 0.71\n",
      "Loss 158.28845 91 48\n",
      "Training Accuracy 0.745\n",
      "Loss 155.26947 92 48\n",
      "Training Accuracy 0.76\n",
      "Loss 162.69199 93 48\n",
      "Training Accuracy 0.71\n",
      "Loss 157.36504 94 48\n",
      "Training Accuracy 0.7\n",
      "Loss 150.3814 95 48\n",
      "Training Accuracy 0.72\n",
      "Loss 149.01917 96 48\n",
      "Training Accuracy 0.73\n",
      "Loss 154.32275 97 48\n",
      "Training Accuracy 0.73\n",
      "Loss 141.79889 98 48\n",
      "Training Accuracy 0.75\n",
      "Loss 141.86548 99 48\n",
      "Training Accuracy 0.71\n",
      "Loss 142.09933 100 48\n",
      "Training Accuracy 0.76\n",
      "Loss 161.24878 101 48\n",
      "Training Accuracy 0.735\n",
      "Loss 149.55186 102 48\n",
      "Training Accuracy 0.735\n",
      "Loss 153.89973 103 48\n",
      "Training Accuracy 0.725\n",
      "Loss 154.84172 104 48\n",
      "Training Accuracy 0.735\n",
      "Loss 154.56934 105 48\n",
      "Training Accuracy 0.72\n",
      "Loss 138.37044 106 48\n",
      "Training Accuracy 0.765\n",
      "Loss 147.2175 107 48\n",
      "Training Accuracy 0.73\n",
      "Loss 148.92381 108 48\n",
      "Training Accuracy 0.72\n",
      "Loss 144.35345 109 48\n",
      "Training Accuracy 0.755\n",
      "Loss 161.93547 110 48\n",
      "Training Accuracy 0.73\n",
      "Loss 149.02286 111 48\n",
      "Training Accuracy 0.745\n",
      "Loss 166.99402 112 48\n",
      "Training Accuracy 0.74\n",
      "Loss 168.02554 113 48\n",
      "Training Accuracy 0.695\n",
      "Loss 144.23866 114 48\n",
      "Training Accuracy 0.73\n",
      "Loss 169.817 115 48\n",
      "Training Accuracy 0.695\n",
      "Loss 152.53226 116 48\n",
      "Training Accuracy 0.735\n",
      "Loss 113.98327 117 48\n",
      "Training Accuracy 0.82\n",
      "Loss 138.0996 118 48\n",
      "Training Accuracy 0.755\n",
      "Loss 169.3433 119 48\n",
      "Training Accuracy 0.715\n",
      "Loss 142.77412 120 48\n",
      "Training Accuracy 0.76\n",
      "Loss 159.14168 121 48\n",
      "Training Accuracy 0.755\n",
      "Loss 155.17174 122 48\n",
      "Training Accuracy 0.725\n",
      "Loss 145.27545 123 48\n",
      "Training Accuracy 0.755\n",
      "Loss 145.85315 124 48\n",
      "Training Accuracy 0.72\n",
      "Loss 141.6472 125 48\n",
      "Training Accuracy 0.755\n",
      "Loss 149.34473 126 48\n",
      "Training Accuracy 0.76\n",
      "Loss 161.2376 127 48\n",
      "Training Accuracy 0.705\n",
      "Loss 146.42967 128 48\n",
      "Training Accuracy 0.765\n",
      "Loss 134.79846 129 48\n",
      "Training Accuracy 0.8\n",
      "Loss 131.81474 130 48\n",
      "Training Accuracy 0.74\n",
      "Loss 126.90737 131 48\n",
      "Training Accuracy 0.775\n",
      "Loss 135.16898 132 48\n",
      "Training Accuracy 0.735\n",
      "Loss 149.28957 133 48\n",
      "Training Accuracy 0.76\n",
      "Loss 134.55386 134 48\n",
      "Training Accuracy 0.765\n",
      "Loss 145.44926 135 48\n",
      "Training Accuracy 0.755\n",
      "Loss 146.72682 136 48\n",
      "Training Accuracy 0.74\n",
      "Loss 152.0604 137 48\n",
      "Training Accuracy 0.78\n",
      "Loss 155.27612 138 48\n",
      "Training Accuracy 0.745\n",
      "Loss 161.62245 139 48\n",
      "Training Accuracy 0.705\n",
      "Loss 135.35349 140 48\n",
      "Training Accuracy 0.77\n",
      "Loss 146.26387 141 48\n",
      "Training Accuracy 0.77\n",
      "Loss 158.70316 142 48\n",
      "Training Accuracy 0.725\n",
      "Loss 145.44398 143 48\n",
      "Training Accuracy 0.74\n",
      "Loss 158.80823 144 48\n",
      "Training Accuracy 0.72\n",
      "Loss 148.8668 145 48\n",
      "Training Accuracy 0.73\n",
      "Loss 165.27054 146 48\n",
      "Training Accuracy 0.705\n",
      "Loss 158.81693 147 48\n",
      "Training Accuracy 0.705\n",
      "Loss 152.47672 148 48\n",
      "Training Accuracy 0.755\n",
      "Loss 147.30986 149 48\n",
      "Training Accuracy 0.74\n",
      "Loss 142.7299 150 48\n",
      "Training Accuracy 0.765\n",
      "Loss 167.88118 151 48\n",
      "Training Accuracy 0.715\n",
      "Loss 162.9823 152 48\n",
      "Training Accuracy 0.715\n",
      "Loss 144.27426 153 48\n",
      "Training Accuracy 0.725\n",
      "Loss 159.96568 154 48\n",
      "Training Accuracy 0.74\n",
      "Loss 151.34734 155 48\n",
      "Training Accuracy 0.735\n",
      "Loss 157.13501 156 48\n",
      "Training Accuracy 0.72\n",
      "Loss 133.02406 157 48\n",
      "Training Accuracy 0.75\n",
      "Loss 144.28435 158 48\n",
      "Training Accuracy 0.745\n",
      "Loss 177.01617 159 48\n",
      "Training Accuracy 0.715\n",
      "Loss 154.3672 160 48\n",
      "Training Accuracy 0.72\n",
      "Loss 165.82533 161 48\n",
      "Training Accuracy 0.705\n",
      "Loss 147.7299 162 48\n",
      "Training Accuracy 0.75\n",
      "Loss 173.73035 163 48\n",
      "Training Accuracy 0.69\n",
      "Loss 138.99217 164 48\n",
      "Training Accuracy 0.765\n",
      "Loss 156.80936 165 48\n",
      "Training Accuracy 0.725\n",
      "Loss 149.06943 166 48\n",
      "Training Accuracy 0.74\n",
      "Loss 142.7551 167 48\n",
      "Training Accuracy 0.75\n",
      "Loss 169.20554 168 48\n",
      "Training Accuracy 0.695\n",
      "Loss 141.85895 169 48\n",
      "Training Accuracy 0.73\n",
      "Loss 171.70369 170 48\n",
      "Training Accuracy 0.7\n",
      "Loss 154.27788 171 48\n",
      "Training Accuracy 0.77\n",
      "Loss 139.94453 172 48\n",
      "Training Accuracy 0.755\n",
      "Loss 144.61588 173 48\n",
      "Training Accuracy 0.755\n",
      "Loss 132.4668 174 48\n",
      "Training Accuracy 0.745\n",
      "Loss 132.94092 175 48\n",
      "Training Accuracy 0.765\n",
      "Loss 117.06537 176 48\n",
      "Training Accuracy 0.805\n",
      "Loss 149.56813 177 48\n",
      "Training Accuracy 0.745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 137.22069 178 48\n",
      "Training Accuracy 0.755\n",
      "Loss 167.56439 179 48\n",
      "Training Accuracy 0.685\n",
      "Loss 162.4782 180 48\n",
      "Training Accuracy 0.725\n",
      "Loss 143.21826 181 48\n",
      "Training Accuracy 0.785\n",
      "Loss 174.7753 182 48\n",
      "Training Accuracy 0.69\n",
      "Loss 164.97716 183 48\n",
      "Training Accuracy 0.71\n",
      "Loss 135.98337 184 48\n",
      "Training Accuracy 0.765\n",
      "Loss 140.9929 185 48\n",
      "Training Accuracy 0.765\n",
      "Loss 157.82448 186 48\n",
      "Training Accuracy 0.74\n",
      "Loss 177.62822 187 48\n",
      "Training Accuracy 0.685\n",
      "Loss 158.64447 188 48\n",
      "Training Accuracy 0.75\n",
      "Loss 139.62302 189 48\n",
      "Training Accuracy 0.765\n",
      "Loss 148.20953 190 48\n",
      "Training Accuracy 0.74\n",
      "Loss 125.10545 191 48\n",
      "Training Accuracy 0.8\n",
      "Loss 160.32722 192 48\n",
      "Training Accuracy 0.715\n",
      "Loss 140.99825 193 48\n",
      "Training Accuracy 0.755\n",
      "Loss 146.3066 194 48\n",
      "Training Accuracy 0.745\n",
      "Loss 141.2265 195 48\n",
      "Training Accuracy 0.765\n",
      "Loss 146.32117 196 48\n",
      "Training Accuracy 0.705\n",
      "Loss 153.68074 197 48\n",
      "Training Accuracy 0.73\n",
      "Loss 148.23526 198 48\n",
      "Training Accuracy 0.73\n",
      "Loss 116.38656 199 48\n",
      "Training Accuracy 0.82\n",
      "Loss 135.75479 200 48\n",
      "Training Accuracy 0.76\n",
      "Loss 136.99463 201 48\n",
      "Training Accuracy 0.75\n",
      "Loss 134.83868 202 48\n",
      "Training Accuracy 0.775\n",
      "Loss 156.21744 203 48\n",
      "Training Accuracy 0.685\n",
      "Loss 142.93658 204 48\n",
      "Training Accuracy 0.755\n",
      "Loss 165.98373 205 48\n",
      "Training Accuracy 0.715\n",
      "Loss 152.43216 206 48\n",
      "Training Accuracy 0.78\n",
      "Loss 159.75418 207 48\n",
      "Training Accuracy 0.735\n",
      "Loss 157.8913 208 48\n",
      "Training Accuracy 0.745\n",
      "Loss 149.03307 209 48\n",
      "Training Accuracy 0.75\n",
      "Loss 135.63492 210 48\n",
      "Training Accuracy 0.76\n",
      "Loss 142.13928 211 48\n",
      "Training Accuracy 0.77\n",
      "Loss 146.68097 212 48\n",
      "Training Accuracy 0.725\n",
      "Loss 177.03378 213 48\n",
      "Training Accuracy 0.735\n",
      "Loss 144.42271 214 48\n",
      "Training Accuracy 0.72\n",
      "Loss 172.74576 215 48\n",
      "Training Accuracy 0.685\n",
      "Loss 145.30289 216 48\n",
      "Training Accuracy 0.74\n",
      "Loss 152.93372 217 48\n",
      "Training Accuracy 0.745\n",
      "Loss 153.32999 218 48\n",
      "Training Accuracy 0.715\n",
      "Loss 144.60382 219 48\n",
      "Training Accuracy 0.745\n",
      "Loss 139.79796 220 48\n",
      "Training Accuracy 0.765\n",
      "Loss 155.502 221 48\n",
      "Training Accuracy 0.75\n",
      "Loss 134.71893 222 48\n",
      "Training Accuracy 0.77\n",
      "Loss 166.64287 223 48\n",
      "Training Accuracy 0.74\n",
      "Loss 163.06683 224 48\n",
      "Training Accuracy 0.71\n",
      "Loss 166.94382 225 48\n",
      "Training Accuracy 0.695\n",
      "Loss 116.4761 226 48\n",
      "Training Accuracy 0.8\n",
      "Loss 164.20647 227 48\n",
      "Training Accuracy 0.75\n",
      "Loss 174.54718 228 48\n",
      "Training Accuracy 0.7\n",
      "Loss 143.81291 229 48\n",
      "Training Accuracy 0.74\n",
      "Loss 163.42813 230 48\n",
      "Training Accuracy 0.725\n",
      "Loss 130.62462 231 48\n",
      "Training Accuracy 0.8\n",
      "Loss 167.89044 232 48\n",
      "Training Accuracy 0.74\n",
      "Loss 179.2678 233 48\n",
      "Training Accuracy 0.65\n",
      "Loss 159.70476 234 48\n",
      "Training Accuracy 0.71\n",
      "Loss 157.7215 235 48\n",
      "Training Accuracy 0.77\n",
      "Loss 127.07785 236 48\n",
      "Training Accuracy 0.815\n",
      "Loss 171.00647 237 48\n",
      "Training Accuracy 0.705\n",
      "Loss 139.8117 238 48\n",
      "Training Accuracy 0.77\n",
      "Loss 133.35614 239 48\n",
      "Training Accuracy 0.78\n",
      "Loss 149.49472 240 48\n",
      "Training Accuracy 0.72\n",
      "Loss 165.85773 241 48\n",
      "Training Accuracy 0.72\n",
      "Loss 159.56859 242 48\n",
      "Training Accuracy 0.725\n",
      "Loss 140.0996 243 48\n",
      "Training Accuracy 0.755\n",
      "Loss 147.25363 244 48\n",
      "Training Accuracy 0.75\n",
      "Loss 148.56514 245 48\n",
      "Training Accuracy 0.75\n",
      "Loss 158.52461 246 48\n",
      "Training Accuracy 0.745\n",
      "Loss 129.63077 247 48\n",
      "Training Accuracy 0.785\n",
      "Loss 131.90439 248 48\n",
      "Training Accuracy 0.8\n",
      "Loss 162.15518 249 48\n",
      "Training Accuracy 0.715\n",
      "Loss 146.58548 250 48\n",
      "Training Accuracy 0.735\n",
      "Loss 165.50511 251 48\n",
      "Training Accuracy 0.71\n",
      "Loss 141.80273 252 48\n",
      "Training Accuracy 0.73\n",
      "Loss 117.65694 253 48\n",
      "Training Accuracy 0.825\n",
      "Loss 169.89723 254 48\n",
      "Training Accuracy 0.71\n",
      "Loss 143.11063 255 48\n",
      "Training Accuracy 0.725\n",
      "Loss 168.0551 256 48\n",
      "Training Accuracy 0.735\n",
      "Loss 148.40927 257 48\n",
      "Training Accuracy 0.74\n",
      "Loss 159.46544 258 48\n",
      "Training Accuracy 0.72\n",
      "Loss 149.38864 259 48\n",
      "Training Accuracy 0.735\n",
      "Loss 126.150406 260 48\n",
      "Training Accuracy 0.81\n",
      "Loss 160.27621 261 48\n",
      "Training Accuracy 0.7\n",
      "Loss 152.15953 262 48\n",
      "Training Accuracy 0.72\n",
      "Loss 171.88693 263 48\n",
      "Training Accuracy 0.7\n",
      "Loss 162.92612 264 48\n",
      "Training Accuracy 0.745\n",
      "Loss 139.37769 265 48\n",
      "Training Accuracy 0.765\n",
      "Loss 150.52396 266 48\n",
      "Training Accuracy 0.735\n",
      "Loss 149.23637 267 48\n",
      "Training Accuracy 0.74\n",
      "Loss 155.76181 268 48\n",
      "Training Accuracy 0.73\n",
      "Loss 145.39613 269 48\n",
      "Training Accuracy 0.73\n",
      "Loss 135.79822 270 48\n",
      "Training Accuracy 0.745\n",
      "Loss 155.05028 271 48\n",
      "Training Accuracy 0.74\n",
      "Loss 146.1894 272 48\n",
      "Training Accuracy 0.745\n",
      "Loss 152.21658 273 48\n",
      "Training Accuracy 0.77\n",
      "Loss 148.29391 274 48\n",
      "Training Accuracy 0.74\n",
      "Loss 143.97018 275 48\n",
      "Training Accuracy 0.76\n",
      "Loss 150.78102 276 48\n",
      "Training Accuracy 0.745\n",
      "Loss 147.98482 277 48\n",
      "Training Accuracy 0.765\n",
      "Loss 148.24919 278 48\n",
      "Training Accuracy 0.705\n",
      "Loss 156.90005 279 48\n",
      "Training Accuracy 0.74\n",
      "Loss 147.98523 280 48\n",
      "Training Accuracy 0.715\n",
      "Loss 134.31555 281 48\n",
      "Training Accuracy 0.795\n",
      "Loss 140.81613 282 48\n",
      "Training Accuracy 0.755\n",
      "Loss 153.69702 283 48\n",
      "Training Accuracy 0.72\n",
      "Loss 125.190674 284 48\n",
      "Training Accuracy 0.79\n",
      "Loss 178.20915 285 48\n",
      "Training Accuracy 0.69\n",
      "Loss 153.18346 286 48\n",
      "Training Accuracy 0.72\n",
      "Loss 140.57208 287 48\n",
      "Training Accuracy 0.77\n",
      "Loss 165.67305 288 48\n",
      "Training Accuracy 0.74\n",
      "Loss 143.52711 289 48\n",
      "Training Accuracy 0.765\n",
      "Loss 144.14595 290 48\n",
      "Training Accuracy 0.76\n",
      "Loss 165.24017 291 48\n",
      "Training Accuracy 0.74\n",
      "Loss 99.77211 292 48\n",
      "Training Accuracy 0.72727275\n",
      "Loss 115.31194 1 49\n",
      "Training Accuracy 0.795\n",
      "Loss 154.26187 2 49\n",
      "Training Accuracy 0.72\n",
      "Loss 143.24889 3 49\n",
      "Training Accuracy 0.74\n",
      "Loss 159.74495 4 49\n",
      "Training Accuracy 0.705\n",
      "Loss 134.71863 5 49\n",
      "Training Accuracy 0.765\n",
      "Loss 156.25682 6 49\n",
      "Training Accuracy 0.705\n",
      "Loss 158.83574 7 49\n",
      "Training Accuracy 0.72\n",
      "Loss 149.24536 8 49\n",
      "Training Accuracy 0.76\n",
      "Loss 134.74742 9 49\n",
      "Training Accuracy 0.75\n",
      "Loss 169.89792 10 49\n",
      "Training Accuracy 0.7\n",
      "Loss 167.44164 11 49\n",
      "Training Accuracy 0.765\n",
      "Loss 128.38478 12 49\n",
      "Training Accuracy 0.785\n",
      "Loss 143.78764 13 49\n",
      "Training Accuracy 0.715\n",
      "Loss 161.09694 14 49\n",
      "Training Accuracy 0.705\n",
      "Loss 146.67842 15 49\n",
      "Training Accuracy 0.77\n",
      "Loss 183.86018 16 49\n",
      "Training Accuracy 0.715\n",
      "Loss 123.55539 17 49\n",
      "Training Accuracy 0.805\n",
      "Loss 131.29587 18 49\n",
      "Training Accuracy 0.785\n",
      "Loss 142.67188 19 49\n",
      "Training Accuracy 0.725\n",
      "Loss 137.53418 20 49\n",
      "Training Accuracy 0.75\n",
      "Loss 158.04721 21 49\n",
      "Training Accuracy 0.735\n",
      "Loss 143.71974 22 49\n",
      "Training Accuracy 0.75\n",
      "Loss 156.81795 23 49\n",
      "Training Accuracy 0.72\n",
      "Loss 151.68597 24 49\n",
      "Training Accuracy 0.725\n",
      "Loss 137.2239 25 49\n",
      "Training Accuracy 0.775\n",
      "Loss 144.90585 26 49\n",
      "Training Accuracy 0.725\n",
      "Loss 139.17564 27 49\n",
      "Training Accuracy 0.75\n",
      "Loss 139.0442 28 49\n",
      "Training Accuracy 0.73\n",
      "Loss 156.27267 29 49\n",
      "Training Accuracy 0.7\n",
      "Loss 164.47406 30 49\n",
      "Training Accuracy 0.725\n",
      "Loss 145.25581 31 49\n",
      "Training Accuracy 0.765\n",
      "Loss 148.42331 32 49\n",
      "Training Accuracy 0.74\n",
      "Loss 144.87447 33 49\n",
      "Training Accuracy 0.775\n",
      "Loss 133.7236 34 49\n",
      "Training Accuracy 0.795\n",
      "Loss 140.00186 35 49\n",
      "Training Accuracy 0.725\n",
      "Loss 157.94518 36 49\n",
      "Training Accuracy 0.74\n",
      "Loss 150.2208 37 49\n",
      "Training Accuracy 0.735\n",
      "Loss 156.96936 38 49\n",
      "Training Accuracy 0.735\n",
      "Loss 127.854996 39 49\n",
      "Training Accuracy 0.785\n",
      "Loss 147.58762 40 49\n",
      "Training Accuracy 0.73\n",
      "Loss 153.328 41 49\n",
      "Training Accuracy 0.715\n",
      "Loss 158.23137 42 49\n",
      "Training Accuracy 0.695\n",
      "Loss 154.23811 43 49\n",
      "Training Accuracy 0.725\n",
      "Loss 152.34883 44 49\n",
      "Training Accuracy 0.735\n",
      "Loss 139.10057 45 49\n",
      "Training Accuracy 0.75\n",
      "Loss 167.75241 46 49\n",
      "Training Accuracy 0.72\n",
      "Loss 148.10315 47 49\n",
      "Training Accuracy 0.775\n",
      "Loss 128.24284 48 49\n",
      "Training Accuracy 0.77\n",
      "Loss 149.96005 49 49\n",
      "Training Accuracy 0.745\n",
      "Loss 164.22937 50 49\n",
      "Training Accuracy 0.74\n",
      "Loss 126.82003 51 49\n",
      "Training Accuracy 0.77\n",
      "Loss 132.48119 52 49\n",
      "Training Accuracy 0.775\n",
      "Loss 121.41344 53 49\n",
      "Training Accuracy 0.775\n",
      "Loss 163.78099 54 49\n",
      "Training Accuracy 0.7\n",
      "Loss 137.47093 55 49\n",
      "Training Accuracy 0.785\n",
      "Loss 163.22607 56 49\n",
      "Training Accuracy 0.725\n",
      "Loss 140.84833 57 49\n",
      "Training Accuracy 0.745\n",
      "Loss 151.09077 58 49\n",
      "Training Accuracy 0.745\n",
      "Loss 150.95178 59 49\n",
      "Training Accuracy 0.745\n",
      "Loss 144.79337 60 49\n",
      "Training Accuracy 0.755\n",
      "Loss 157.56407 61 49\n",
      "Training Accuracy 0.74\n",
      "Loss 134.09209 62 49\n",
      "Training Accuracy 0.755\n",
      "Loss 126.42079 63 49\n",
      "Training Accuracy 0.81\n",
      "Loss 153.61389 64 49\n",
      "Training Accuracy 0.775\n",
      "Loss 140.98978 65 49\n",
      "Training Accuracy 0.735\n",
      "Loss 135.22897 66 49\n",
      "Training Accuracy 0.8\n",
      "Loss 141.51184 67 49\n",
      "Training Accuracy 0.765\n",
      "Loss 143.604 68 49\n",
      "Training Accuracy 0.745\n",
      "Loss 148.68765 69 49\n",
      "Training Accuracy 0.735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 143.20409 70 49\n",
      "Training Accuracy 0.79\n",
      "Loss 150.24524 71 49\n",
      "Training Accuracy 0.735\n",
      "Loss 142.89854 72 49\n",
      "Training Accuracy 0.73\n",
      "Loss 164.2442 73 49\n",
      "Training Accuracy 0.7\n",
      "Loss 152.21214 74 49\n",
      "Training Accuracy 0.74\n",
      "Loss 147.96785 75 49\n",
      "Training Accuracy 0.75\n",
      "Loss 145.15997 76 49\n",
      "Training Accuracy 0.725\n",
      "Loss 165.33101 77 49\n",
      "Training Accuracy 0.715\n",
      "Loss 147.38297 78 49\n",
      "Training Accuracy 0.78\n",
      "Loss 156.59694 79 49\n",
      "Training Accuracy 0.685\n",
      "Loss 162.54433 80 49\n",
      "Training Accuracy 0.72\n",
      "Loss 135.29434 81 49\n",
      "Training Accuracy 0.775\n",
      "Loss 140.42409 82 49\n",
      "Training Accuracy 0.745\n",
      "Loss 152.58493 83 49\n",
      "Training Accuracy 0.75\n",
      "Loss 150.64294 84 49\n",
      "Training Accuracy 0.765\n",
      "Loss 148.59373 85 49\n",
      "Training Accuracy 0.73\n",
      "Loss 153.44673 86 49\n",
      "Training Accuracy 0.725\n",
      "Loss 186.2502 87 49\n",
      "Training Accuracy 0.67\n",
      "Loss 174.89133 88 49\n",
      "Training Accuracy 0.71\n",
      "Loss 158.12517 89 49\n",
      "Training Accuracy 0.72\n",
      "Loss 156.57336 90 49\n",
      "Training Accuracy 0.72\n",
      "Loss 150.3516 91 49\n",
      "Training Accuracy 0.77\n",
      "Loss 159.68483 92 49\n",
      "Training Accuracy 0.745\n",
      "Loss 166.51123 93 49\n",
      "Training Accuracy 0.705\n",
      "Loss 147.3825 94 49\n",
      "Training Accuracy 0.74\n",
      "Loss 151.52325 95 49\n",
      "Training Accuracy 0.715\n",
      "Loss 148.26515 96 49\n",
      "Training Accuracy 0.775\n",
      "Loss 150.71223 97 49\n",
      "Training Accuracy 0.77\n",
      "Loss 145.58717 98 49\n",
      "Training Accuracy 0.75\n",
      "Loss 153.44934 99 49\n",
      "Training Accuracy 0.715\n",
      "Loss 146.48563 100 49\n",
      "Training Accuracy 0.76\n",
      "Loss 164.41496 101 49\n",
      "Training Accuracy 0.7\n",
      "Loss 142.57993 102 49\n",
      "Training Accuracy 0.735\n",
      "Loss 146.55545 103 49\n",
      "Training Accuracy 0.725\n",
      "Loss 155.31895 104 49\n",
      "Training Accuracy 0.745\n",
      "Loss 149.75003 105 49\n",
      "Training Accuracy 0.76\n",
      "Loss 128.96352 106 49\n",
      "Training Accuracy 0.79\n",
      "Loss 128.37593 107 49\n",
      "Training Accuracy 0.79\n",
      "Loss 142.89987 108 49\n",
      "Training Accuracy 0.715\n",
      "Loss 155.49252 109 49\n",
      "Training Accuracy 0.725\n",
      "Loss 149.8688 110 49\n",
      "Training Accuracy 0.74\n",
      "Loss 148.94739 111 49\n",
      "Training Accuracy 0.72\n",
      "Loss 164.64331 112 49\n",
      "Training Accuracy 0.725\n",
      "Loss 157.84814 113 49\n",
      "Training Accuracy 0.735\n",
      "Loss 158.3548 114 49\n",
      "Training Accuracy 0.685\n",
      "Loss 155.3995 115 49\n",
      "Training Accuracy 0.73\n",
      "Loss 150.22543 116 49\n",
      "Training Accuracy 0.78\n",
      "Loss 124.53351 117 49\n",
      "Training Accuracy 0.82\n",
      "Loss 136.86678 118 49\n",
      "Training Accuracy 0.755\n",
      "Loss 166.23286 119 49\n",
      "Training Accuracy 0.72\n",
      "Loss 157.59698 120 49\n",
      "Training Accuracy 0.735\n",
      "Loss 160.39737 121 49\n",
      "Training Accuracy 0.735\n",
      "Loss 155.09277 122 49\n",
      "Training Accuracy 0.725\n",
      "Loss 144.72147 123 49\n",
      "Training Accuracy 0.745\n",
      "Loss 138.7404 124 49\n",
      "Training Accuracy 0.745\n",
      "Loss 139.31572 125 49\n",
      "Training Accuracy 0.74\n",
      "Loss 146.24791 126 49\n",
      "Training Accuracy 0.74\n",
      "Loss 158.85605 127 49\n",
      "Training Accuracy 0.72\n",
      "Loss 132.12904 128 49\n",
      "Training Accuracy 0.77\n",
      "Loss 129.50253 129 49\n",
      "Training Accuracy 0.81\n",
      "Loss 138.61569 130 49\n",
      "Training Accuracy 0.735\n",
      "Loss 136.199 131 49\n",
      "Training Accuracy 0.76\n",
      "Loss 134.66043 132 49\n",
      "Training Accuracy 0.765\n",
      "Loss 133.01352 133 49\n",
      "Training Accuracy 0.76\n",
      "Loss 148.93718 134 49\n",
      "Training Accuracy 0.735\n",
      "Loss 149.40633 135 49\n",
      "Training Accuracy 0.745\n",
      "Loss 150.73973 136 49\n",
      "Training Accuracy 0.745\n",
      "Loss 160.34209 137 49\n",
      "Training Accuracy 0.735\n",
      "Loss 148.98749 138 49\n",
      "Training Accuracy 0.75\n",
      "Loss 154.48497 139 49\n",
      "Training Accuracy 0.745\n",
      "Loss 132.40353 140 49\n",
      "Training Accuracy 0.745\n",
      "Loss 151.39943 141 49\n",
      "Training Accuracy 0.735\n",
      "Loss 157.71973 142 49\n",
      "Training Accuracy 0.695\n",
      "Loss 125.42034 143 49\n",
      "Training Accuracy 0.8\n",
      "Loss 158.61479 144 49\n",
      "Training Accuracy 0.74\n",
      "Loss 146.9165 145 49\n",
      "Training Accuracy 0.755\n",
      "Loss 162.91754 146 49\n",
      "Training Accuracy 0.7\n",
      "Loss 159.88683 147 49\n",
      "Training Accuracy 0.7\n",
      "Loss 153.48615 148 49\n",
      "Training Accuracy 0.735\n",
      "Loss 136.86757 149 49\n",
      "Training Accuracy 0.755\n",
      "Loss 144.36494 150 49\n",
      "Training Accuracy 0.74\n",
      "Loss 151.24095 151 49\n",
      "Training Accuracy 0.765\n",
      "Loss 157.38292 152 49\n",
      "Training Accuracy 0.735\n",
      "Loss 139.00774 153 49\n",
      "Training Accuracy 0.775\n",
      "Loss 155.42284 154 49\n",
      "Training Accuracy 0.74\n",
      "Loss 132.47322 155 49\n",
      "Training Accuracy 0.76\n",
      "Loss 136.20934 156 49\n",
      "Training Accuracy 0.77\n",
      "Loss 135.43837 157 49\n",
      "Training Accuracy 0.76\n",
      "Loss 136.39487 158 49\n",
      "Training Accuracy 0.775\n",
      "Loss 175.21185 159 49\n",
      "Training Accuracy 0.715\n",
      "Loss 147.27965 160 49\n",
      "Training Accuracy 0.745\n",
      "Loss 163.54063 161 49\n",
      "Training Accuracy 0.72\n",
      "Loss 134.86528 162 49\n",
      "Training Accuracy 0.735\n",
      "Loss 164.58447 163 49\n",
      "Training Accuracy 0.725\n",
      "Loss 145.12106 164 49\n",
      "Training Accuracy 0.735\n",
      "Loss 152.95563 165 49\n",
      "Training Accuracy 0.735\n",
      "Loss 147.53198 166 49\n",
      "Training Accuracy 0.76\n",
      "Loss 146.56248 167 49\n",
      "Training Accuracy 0.755\n",
      "Loss 154.14482 168 49\n",
      "Training Accuracy 0.72\n",
      "Loss 137.42383 169 49\n",
      "Training Accuracy 0.745\n",
      "Loss 175.05486 170 49\n",
      "Training Accuracy 0.69\n",
      "Loss 164.89291 171 49\n",
      "Training Accuracy 0.72\n",
      "Loss 135.96574 172 49\n",
      "Training Accuracy 0.79\n",
      "Loss 151.00304 173 49\n",
      "Training Accuracy 0.77\n",
      "Loss 137.84254 174 49\n",
      "Training Accuracy 0.75\n",
      "Loss 132.89688 175 49\n",
      "Training Accuracy 0.77\n",
      "Loss 115.97749 176 49\n",
      "Training Accuracy 0.8\n",
      "Loss 161.89099 177 49\n",
      "Training Accuracy 0.725\n",
      "Loss 143.86357 178 49\n",
      "Training Accuracy 0.755\n",
      "Loss 159.04482 179 49\n",
      "Training Accuracy 0.705\n",
      "Loss 159.94072 180 49\n",
      "Training Accuracy 0.695\n",
      "Loss 138.89157 181 49\n",
      "Training Accuracy 0.77\n",
      "Loss 154.08119 182 49\n",
      "Training Accuracy 0.74\n",
      "Loss 156.03806 183 49\n",
      "Training Accuracy 0.725\n",
      "Loss 128.9845 184 49\n",
      "Training Accuracy 0.79\n",
      "Loss 157.93468 185 49\n",
      "Training Accuracy 0.71\n",
      "Loss 131.88156 186 49\n",
      "Training Accuracy 0.745\n",
      "Loss 160.0623 187 49\n",
      "Training Accuracy 0.7\n",
      "Loss 140.81137 188 49\n",
      "Training Accuracy 0.75\n",
      "Loss 133.54494 189 49\n",
      "Training Accuracy 0.795\n",
      "Loss 135.61606 190 49\n",
      "Training Accuracy 0.77\n",
      "Loss 127.454025 191 49\n",
      "Training Accuracy 0.79\n",
      "Loss 155.27203 192 49\n",
      "Training Accuracy 0.74\n",
      "Loss 132.85233 193 49\n",
      "Training Accuracy 0.79\n",
      "Loss 144.60046 194 49\n",
      "Training Accuracy 0.76\n",
      "Loss 121.1577 195 49\n",
      "Training Accuracy 0.8\n",
      "Loss 144.33252 196 49\n",
      "Training Accuracy 0.7\n",
      "Loss 147.81116 197 49\n",
      "Training Accuracy 0.73\n",
      "Loss 147.98886 198 49\n",
      "Training Accuracy 0.725\n",
      "Loss 130.76012 199 49\n",
      "Training Accuracy 0.81\n",
      "Loss 131.3414 200 49\n",
      "Training Accuracy 0.755\n",
      "Loss 144.70462 201 49\n",
      "Training Accuracy 0.735\n",
      "Loss 131.16878 202 49\n",
      "Training Accuracy 0.77\n",
      "Loss 157.51321 203 49\n",
      "Training Accuracy 0.73\n",
      "Loss 143.23065 204 49\n",
      "Training Accuracy 0.765\n",
      "Loss 162.3405 205 49\n",
      "Training Accuracy 0.705\n",
      "Loss 153.0473 206 49\n",
      "Training Accuracy 0.735\n",
      "Loss 152.33315 207 49\n",
      "Training Accuracy 0.73\n",
      "Loss 157.06801 208 49\n",
      "Training Accuracy 0.73\n",
      "Loss 142.93283 209 49\n",
      "Training Accuracy 0.75\n",
      "Loss 134.18088 210 49\n",
      "Training Accuracy 0.75\n",
      "Loss 116.27691 211 49\n",
      "Training Accuracy 0.815\n",
      "Loss 145.02388 212 49\n",
      "Training Accuracy 0.74\n",
      "Loss 172.2332 213 49\n",
      "Training Accuracy 0.72\n",
      "Loss 143.47035 214 49\n",
      "Training Accuracy 0.725\n",
      "Loss 168.24399 215 49\n",
      "Training Accuracy 0.69\n",
      "Loss 153.14917 216 49\n",
      "Training Accuracy 0.74\n",
      "Loss 156.23976 217 49\n",
      "Training Accuracy 0.665\n",
      "Loss 148.88438 218 49\n",
      "Training Accuracy 0.75\n",
      "Loss 122.93948 219 49\n",
      "Training Accuracy 0.8\n",
      "Loss 141.81212 220 49\n",
      "Training Accuracy 0.77\n",
      "Loss 158.32928 221 49\n",
      "Training Accuracy 0.725\n",
      "Loss 141.1505 222 49\n",
      "Training Accuracy 0.76\n",
      "Loss 156.94533 223 49\n",
      "Training Accuracy 0.705\n",
      "Loss 157.06837 224 49\n",
      "Training Accuracy 0.725\n",
      "Loss 154.04984 225 49\n",
      "Training Accuracy 0.745\n",
      "Loss 122.9648 226 49\n",
      "Training Accuracy 0.77\n",
      "Loss 158.68822 227 49\n",
      "Training Accuracy 0.74\n",
      "Loss 184.27135 228 49\n",
      "Training Accuracy 0.685\n",
      "Loss 142.70122 229 49\n",
      "Training Accuracy 0.76\n",
      "Loss 161.64333 230 49\n",
      "Training Accuracy 0.74\n",
      "Loss 142.7952 231 49\n",
      "Training Accuracy 0.72\n",
      "Loss 166.2055 232 49\n",
      "Training Accuracy 0.715\n",
      "Loss 188.70168 233 49\n",
      "Training Accuracy 0.635\n",
      "Loss 156.03226 234 49\n",
      "Training Accuracy 0.67\n",
      "Loss 144.83752 235 49\n",
      "Training Accuracy 0.75\n",
      "Loss 138.75137 236 49\n",
      "Training Accuracy 0.795\n",
      "Loss 161.95674 237 49\n",
      "Training Accuracy 0.715\n",
      "Loss 143.78448 238 49\n",
      "Training Accuracy 0.715\n",
      "Loss 132.06369 239 49\n",
      "Training Accuracy 0.77\n",
      "Loss 151.24463 240 49\n",
      "Training Accuracy 0.745\n",
      "Loss 165.83109 241 49\n",
      "Training Accuracy 0.695\n",
      "Loss 151.00998 242 49\n",
      "Training Accuracy 0.71\n",
      "Loss 128.87296 243 49\n",
      "Training Accuracy 0.795\n",
      "Loss 144.53207 244 49\n",
      "Training Accuracy 0.745\n",
      "Loss 163.54521 245 49\n",
      "Training Accuracy 0.73\n",
      "Loss 160.11081 246 49\n",
      "Training Accuracy 0.72\n",
      "Loss 138.3032 247 49\n",
      "Training Accuracy 0.74\n",
      "Loss 135.31421 248 49\n",
      "Training Accuracy 0.765\n",
      "Loss 156.7566 249 49\n",
      "Training Accuracy 0.675\n",
      "Loss 150.03653 250 49\n",
      "Training Accuracy 0.73\n",
      "Loss 157.00017 251 49\n",
      "Training Accuracy 0.695\n",
      "Loss 129.52362 252 49\n",
      "Training Accuracy 0.74\n",
      "Loss 110.59221 253 49\n",
      "Training Accuracy 0.815\n",
      "Loss 152.45018 254 49\n",
      "Training Accuracy 0.73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 129.88007 255 49\n",
      "Training Accuracy 0.75\n",
      "Loss 164.31204 256 49\n",
      "Training Accuracy 0.72\n",
      "Loss 141.30783 257 49\n",
      "Training Accuracy 0.755\n",
      "Loss 142.68092 258 49\n",
      "Training Accuracy 0.755\n",
      "Loss 141.75987 259 49\n",
      "Training Accuracy 0.735\n",
      "Loss 121.59691 260 49\n",
      "Training Accuracy 0.775\n",
      "Loss 138.58258 261 49\n",
      "Training Accuracy 0.74\n",
      "Loss 149.35551 262 49\n",
      "Training Accuracy 0.735\n",
      "Loss 178.6309 263 49\n",
      "Training Accuracy 0.715\n",
      "Loss 158.57182 264 49\n",
      "Training Accuracy 0.755\n",
      "Loss 133.00566 265 49\n",
      "Training Accuracy 0.755\n",
      "Loss 145.98398 266 49\n",
      "Training Accuracy 0.745\n",
      "Loss 148.98259 267 49\n",
      "Training Accuracy 0.715\n",
      "Loss 159.78311 268 49\n",
      "Training Accuracy 0.72\n",
      "Loss 135.16711 269 49\n",
      "Training Accuracy 0.765\n",
      "Loss 137.81827 270 49\n",
      "Training Accuracy 0.75\n",
      "Loss 156.97081 271 49\n",
      "Training Accuracy 0.725\n",
      "Loss 147.55565 272 49\n",
      "Training Accuracy 0.73\n",
      "Loss 153.17938 273 49\n",
      "Training Accuracy 0.72\n",
      "Loss 151.43372 274 49\n",
      "Training Accuracy 0.75\n",
      "Loss 149.09781 275 49\n",
      "Training Accuracy 0.72\n",
      "Loss 137.07254 276 49\n",
      "Training Accuracy 0.755\n",
      "Loss 137.97194 277 49\n",
      "Training Accuracy 0.795\n",
      "Loss 132.6571 278 49\n",
      "Training Accuracy 0.775\n",
      "Loss 145.28062 279 49\n",
      "Training Accuracy 0.77\n",
      "Loss 148.58804 280 49\n",
      "Training Accuracy 0.765\n",
      "Loss 126.71675 281 49\n",
      "Training Accuracy 0.77\n",
      "Loss 131.88005 282 49\n",
      "Training Accuracy 0.765\n",
      "Loss 143.1645 283 49\n",
      "Training Accuracy 0.75\n",
      "Loss 120.05465 284 49\n",
      "Training Accuracy 0.79\n",
      "Loss 168.85013 285 49\n",
      "Training Accuracy 0.685\n",
      "Loss 152.966 286 49\n",
      "Training Accuracy 0.745\n",
      "Loss 129.09535 287 49\n",
      "Training Accuracy 0.79\n",
      "Loss 154.0619 288 49\n",
      "Training Accuracy 0.725\n",
      "Loss 142.04196 289 49\n",
      "Training Accuracy 0.765\n",
      "Loss 156.13168 290 49\n",
      "Training Accuracy 0.74\n",
      "Loss 170.60994 291 49\n",
      "Training Accuracy 0.685\n",
      "Loss 90.91547 292 49\n",
      "Training Accuracy 0.75757575\n"
     ]
    }
   ],
   "source": [
    "run train.py --learning_rate 0.0002 --epoch 50 --lstm_direc uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
